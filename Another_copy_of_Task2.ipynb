{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "ROJJPJZq3dbN"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import tensorflow as tf\n",
        "from sklearn.model_selection import train_test_split\n",
        "from datetime import datetime\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras.callbacks import Callback"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "z0aD220T4_Q7",
        "outputId": "8c2c4543-442e-44b0-fe8e-f89166840609"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Load the data\n",
        "df = pd.read_csv('/content/drive/MyDrive/Task2/Steel_industry_data.csv')"
      ],
      "metadata": {
        "id": "jX3VNBMM4K1c"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.head(2)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 167
        },
        "id": "sAax1_Mp5l9O",
        "outputId": "eb92039c-f8a7-4e07-af39-4e66ca30cca4"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "               date  Usage_kWh  Lagging_Current_Reactive.Power_kVarh  \\\n",
              "0  01/01/2018 00:15       3.17                                  2.95   \n",
              "1  01/01/2018 00:30       4.00                                  4.46   \n",
              "\n",
              "   Leading_Current_Reactive_Power_kVarh  CO2(tCO2)  \\\n",
              "0                                   0.0        0.0   \n",
              "1                                   0.0        0.0   \n",
              "\n",
              "   Lagging_Current_Power_Factor  Leading_Current_Power_Factor   NSM  \\\n",
              "0                         73.21                         100.0   900   \n",
              "1                         66.77                         100.0  1800   \n",
              "\n",
              "  WeekStatus Day_of_week   Load_Type  \n",
              "0    Weekday      Monday  Light_Load  \n",
              "1    Weekday      Monday  Light_Load  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-e2fda31b-b0fc-4324-a5d2-aed2dd918fd1\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>date</th>\n",
              "      <th>Usage_kWh</th>\n",
              "      <th>Lagging_Current_Reactive.Power_kVarh</th>\n",
              "      <th>Leading_Current_Reactive_Power_kVarh</th>\n",
              "      <th>CO2(tCO2)</th>\n",
              "      <th>Lagging_Current_Power_Factor</th>\n",
              "      <th>Leading_Current_Power_Factor</th>\n",
              "      <th>NSM</th>\n",
              "      <th>WeekStatus</th>\n",
              "      <th>Day_of_week</th>\n",
              "      <th>Load_Type</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>01/01/2018 00:15</td>\n",
              "      <td>3.17</td>\n",
              "      <td>2.95</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>73.21</td>\n",
              "      <td>100.0</td>\n",
              "      <td>900</td>\n",
              "      <td>Weekday</td>\n",
              "      <td>Monday</td>\n",
              "      <td>Light_Load</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>01/01/2018 00:30</td>\n",
              "      <td>4.00</td>\n",
              "      <td>4.46</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>66.77</td>\n",
              "      <td>100.0</td>\n",
              "      <td>1800</td>\n",
              "      <td>Weekday</td>\n",
              "      <td>Monday</td>\n",
              "      <td>Light_Load</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-e2fda31b-b0fc-4324-a5d2-aed2dd918fd1')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-e2fda31b-b0fc-4324-a5d2-aed2dd918fd1 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-e2fda31b-b0fc-4324-a5d2-aed2dd918fd1');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-75a21c82-0b08-4228-9a16-dded2d4cdb88\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-75a21c82-0b08-4228-9a16-dded2d4cdb88')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-75a21c82-0b08-4228-9a16-dded2d4cdb88 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "df",
              "summary": "{\n  \"name\": \"df\",\n  \"rows\": 35040,\n  \"fields\": [\n    {\n      \"column\": \"date\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 35040,\n        \"samples\": [\n          \"29/04/2018 07:15\",\n          \"04/10/2018 12:00\",\n          \"26/01/2018 11:30\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Usage_kWh\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 33.44437970801513,\n        \"min\": 0.0,\n        \"max\": 157.18,\n        \"num_unique_values\": 3343,\n        \"samples\": [\n          12.02,\n          28.51,\n          77.18\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Lagging_Current_Reactive.Power_kVarh\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 16.305999973081924,\n        \"min\": 0.0,\n        \"max\": 96.91,\n        \"num_unique_values\": 1954,\n        \"samples\": [\n          20.88,\n          69.84,\n          7.02\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Leading_Current_Reactive_Power_kVarh\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 7.424462753103645,\n        \"min\": 0.0,\n        \"max\": 27.76,\n        \"num_unique_values\": 768,\n        \"samples\": [\n          21.06,\n          23.04,\n          13.61\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"CO2(tCO2)\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.016150821534429337,\n        \"min\": 0.0,\n        \"max\": 0.07,\n        \"num_unique_values\": 8,\n        \"samples\": [\n          0.02,\n          0.04,\n          0.0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Lagging_Current_Power_Factor\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 18.92132226781741,\n        \"min\": 0.0,\n        \"max\": 100.0,\n        \"num_unique_values\": 5079,\n        \"samples\": [\n          77.48,\n          46.28,\n          100.0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Leading_Current_Power_Factor\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 30.45653515758771,\n        \"min\": 0.0,\n        \"max\": 100.0,\n        \"num_unique_values\": 3366,\n        \"samples\": [\n          97.26,\n          54.38,\n          19.51\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"NSM\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 24940,\n        \"min\": 0,\n        \"max\": 85500,\n        \"num_unique_values\": 96,\n        \"samples\": [\n          72900,\n          70200,\n          66600\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"WeekStatus\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 2,\n        \"samples\": [\n          \"Weekend\",\n          \"Weekday\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Day_of_week\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 7,\n        \"samples\": [\n          \"Monday\",\n          \"Tuesday\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Load_Type\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 3,\n        \"samples\": [\n          \"Light_Load\",\n          \"Medium_Load\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Info for Dtypes and non-null values\n",
        "df.info()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hwXSB43554SM",
        "outputId": "c32def72-d056-4488-c9f2-ce24843becb9"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 35040 entries, 0 to 35039\n",
            "Data columns (total 11 columns):\n",
            " #   Column                                Non-Null Count  Dtype  \n",
            "---  ------                                --------------  -----  \n",
            " 0   date                                  35040 non-null  object \n",
            " 1   Usage_kWh                             35040 non-null  float64\n",
            " 2   Lagging_Current_Reactive.Power_kVarh  35040 non-null  float64\n",
            " 3   Leading_Current_Reactive_Power_kVarh  35040 non-null  float64\n",
            " 4   CO2(tCO2)                             35040 non-null  float64\n",
            " 5   Lagging_Current_Power_Factor          35040 non-null  float64\n",
            " 6   Leading_Current_Power_Factor          35040 non-null  float64\n",
            " 7   NSM                                   35040 non-null  int64  \n",
            " 8   WeekStatus                            35040 non-null  object \n",
            " 9   Day_of_week                           35040 non-null  object \n",
            " 10  Load_Type                             35040 non-null  object \n",
            "dtypes: float64(6), int64(1), object(4)\n",
            "memory usage: 2.9+ MB\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Rename the columns for simplicity\n",
        "df = df.rename(columns={'CO2(tCO2)': 'tco2',\n",
        "                        'Lagging_Current_Reactive.Power_kVarh': 'lagging_kvarh',\n",
        "                        'Leading_Current_Reactive_Power_kVarh': 'leading_kvarh',\n",
        "                       'Lagging_Current_Power_Factor': 'lagging_pf',\n",
        "                       'Leading_Current_Power_Factor': 'leading_pf'})"
      ],
      "metadata": {
        "id": "2LCGapyr6GYx"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Change all column names into lowercase\n",
        "df.columns = df.columns.str.lower()"
      ],
      "metadata": {
        "id": "60YrI_kl6Jsh"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Check for null values\n",
        "print(\"NA values: \" , df.isna().sum().sum())\n",
        "print(\"Null values: \", df.isnull().sum().sum())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cTaqEk1g6TNS",
        "outputId": "10604f93-1fc4-42b6-97ea-f18209599341"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "NA values:  0\n",
            "Null values:  0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Create new column and drop the old one\n",
        "df[\"kgco2\"] = df.tco2 * 1000\n",
        "df.drop('tco2', inplace=True, axis=1)"
      ],
      "metadata": {
        "id": "rgkdUPSV6aCo"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.head(2)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 112
        },
        "id": "QGaGtXb_DRQE",
        "outputId": "b9f591b6-90c5-41ab-d054-1536a092e483"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "               date  usage_kwh  lagging_kvarh  leading_kvarh  lagging_pf  \\\n",
              "0  01/01/2018 00:15       3.17           2.95            0.0       73.21   \n",
              "1  01/01/2018 00:30       4.00           4.46            0.0       66.77   \n",
              "\n",
              "   leading_pf   nsm weekstatus day_of_week   load_type  kgco2  \n",
              "0       100.0   900    Weekday      Monday  Light_Load    0.0  \n",
              "1       100.0  1800    Weekday      Monday  Light_Load    0.0  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-37e6e81e-fa10-4315-b5f3-a4851dae4dc2\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>date</th>\n",
              "      <th>usage_kwh</th>\n",
              "      <th>lagging_kvarh</th>\n",
              "      <th>leading_kvarh</th>\n",
              "      <th>lagging_pf</th>\n",
              "      <th>leading_pf</th>\n",
              "      <th>nsm</th>\n",
              "      <th>weekstatus</th>\n",
              "      <th>day_of_week</th>\n",
              "      <th>load_type</th>\n",
              "      <th>kgco2</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>01/01/2018 00:15</td>\n",
              "      <td>3.17</td>\n",
              "      <td>2.95</td>\n",
              "      <td>0.0</td>\n",
              "      <td>73.21</td>\n",
              "      <td>100.0</td>\n",
              "      <td>900</td>\n",
              "      <td>Weekday</td>\n",
              "      <td>Monday</td>\n",
              "      <td>Light_Load</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>01/01/2018 00:30</td>\n",
              "      <td>4.00</td>\n",
              "      <td>4.46</td>\n",
              "      <td>0.0</td>\n",
              "      <td>66.77</td>\n",
              "      <td>100.0</td>\n",
              "      <td>1800</td>\n",
              "      <td>Weekday</td>\n",
              "      <td>Monday</td>\n",
              "      <td>Light_Load</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-37e6e81e-fa10-4315-b5f3-a4851dae4dc2')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-37e6e81e-fa10-4315-b5f3-a4851dae4dc2 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-37e6e81e-fa10-4315-b5f3-a4851dae4dc2');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-fdd0fbec-6645-45ac-a253-a660e418bccc\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-fdd0fbec-6645-45ac-a253-a660e418bccc')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-fdd0fbec-6645-45ac-a253-a660e418bccc button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "df",
              "summary": "{\n  \"name\": \"df\",\n  \"rows\": 35040,\n  \"fields\": [\n    {\n      \"column\": \"date\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 35040,\n        \"samples\": [\n          \"29/04/2018 07:15\",\n          \"04/10/2018 12:00\",\n          \"26/01/2018 11:30\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"usage_kwh\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 33.44437970801513,\n        \"min\": 0.0,\n        \"max\": 157.18,\n        \"num_unique_values\": 3343,\n        \"samples\": [\n          12.02,\n          28.51,\n          77.18\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"lagging_kvarh\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 16.305999973081924,\n        \"min\": 0.0,\n        \"max\": 96.91,\n        \"num_unique_values\": 1954,\n        \"samples\": [\n          20.88,\n          69.84,\n          7.02\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"leading_kvarh\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 7.424462753103645,\n        \"min\": 0.0,\n        \"max\": 27.76,\n        \"num_unique_values\": 768,\n        \"samples\": [\n          21.06,\n          23.04,\n          13.61\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"lagging_pf\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 18.92132226781741,\n        \"min\": 0.0,\n        \"max\": 100.0,\n        \"num_unique_values\": 5079,\n        \"samples\": [\n          77.48,\n          46.28,\n          100.0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"leading_pf\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 30.45653515758771,\n        \"min\": 0.0,\n        \"max\": 100.0,\n        \"num_unique_values\": 3366,\n        \"samples\": [\n          97.26,\n          54.38,\n          19.51\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"nsm\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 24940,\n        \"min\": 0,\n        \"max\": 85500,\n        \"num_unique_values\": 96,\n        \"samples\": [\n          72900,\n          70200,\n          66600\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"weekstatus\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 2,\n        \"samples\": [\n          \"Weekend\",\n          \"Weekday\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"day_of_week\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 7,\n        \"samples\": [\n          \"Monday\",\n          \"Tuesday\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"load_type\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 3,\n        \"samples\": [\n          \"Light_Load\",\n          \"Medium_Load\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"kgco2\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 16.150821534429333,\n        \"min\": 0.0,\n        \"max\": 70.0,\n        \"num_unique_values\": 8,\n        \"samples\": [\n          20.0,\n          40.0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "unique_values = df['weekstatus'].unique()\n",
        "unique_values"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e8zRqv6uDIgb",
        "outputId": "63b41a8b-b1d5-4027-b007-76f58ad5f11d"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array(['Weekday', 'Weekend'], dtype=object)"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def preprocessing_column(dataframe, old_name, new_name, function):\n",
        "    dataframe[new_name] = df[old_name].apply(function)\n",
        "    dataframe.drop(old_name, axis = 1, inplace=True)\n",
        "\n",
        "def encoding_day_of_week(value):\n",
        "    mapping = {\n",
        "          'Monday': 2,\n",
        "          'Tuesday': 3,\n",
        "          'Wednesday': 4,\n",
        "          'Thursday': 5,\n",
        "          'Friday': 6,\n",
        "          'Saturday': 7,\n",
        "          'Sunday': 1\n",
        "      }\n",
        "    return mapping.get(value)\n",
        "def encoding_load_type(value):\n",
        "    mapping = {\n",
        "          'Light_Load': 0,\n",
        "          'Medium_Load': 1,\n",
        "          'Maximum_Load': 2,\n",
        "      }\n",
        "    return mapping.get(value)\n",
        "def encoding_weekstatus(value):\n",
        "    mapping = {\n",
        "          'Weekday': 0,\n",
        "          'Weekend': 1,\n",
        "      }\n",
        "    return mapping.get(value)\n",
        "def encoding_date(value):\n",
        "    date_obj = datetime.strptime(value, '%d/%m/%Y %H:%M')\n",
        "    hour = date_obj.hour\n",
        "    minute = date_obj.minute\n",
        "\n",
        "    encoded_value = (hour * 60 + minute) // 15\n",
        "    return encoded_value"
      ],
      "metadata": {
        "id": "pG4RA9fxAoef"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "preprocessing_column(df,'day_of_week', 'new_day_of_week', encoding_day_of_week)\n",
        "preprocessing_column(df,'load_type', 'new_load_type', encoding_load_type)\n",
        "preprocessing_column(df,'date', 'new_date', encoding_date)\n",
        "preprocessing_column(df,'weekstatus', 'new_weekstatus', encoding_weekstatus)"
      ],
      "metadata": {
        "id": "U8iNr_cqLa6o"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.head(2)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 112
        },
        "id": "D1vgx9FkAold",
        "outputId": "eabbba52-7343-41d4-9a60-55c9d0fc7c7e"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "   usage_kwh  lagging_kvarh  leading_kvarh  lagging_pf  leading_pf   nsm  \\\n",
              "0       3.17           2.95            0.0       73.21       100.0   900   \n",
              "1       4.00           4.46            0.0       66.77       100.0  1800   \n",
              "\n",
              "   kgco2  new_day_of_week  new_load_type  new_date  new_weekstatus  \n",
              "0    0.0                2              0         1               0  \n",
              "1    0.0                2              0         2               0  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-dc420bb8-c892-4727-a613-c97289977465\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>usage_kwh</th>\n",
              "      <th>lagging_kvarh</th>\n",
              "      <th>leading_kvarh</th>\n",
              "      <th>lagging_pf</th>\n",
              "      <th>leading_pf</th>\n",
              "      <th>nsm</th>\n",
              "      <th>kgco2</th>\n",
              "      <th>new_day_of_week</th>\n",
              "      <th>new_load_type</th>\n",
              "      <th>new_date</th>\n",
              "      <th>new_weekstatus</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>3.17</td>\n",
              "      <td>2.95</td>\n",
              "      <td>0.0</td>\n",
              "      <td>73.21</td>\n",
              "      <td>100.0</td>\n",
              "      <td>900</td>\n",
              "      <td>0.0</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>4.00</td>\n",
              "      <td>4.46</td>\n",
              "      <td>0.0</td>\n",
              "      <td>66.77</td>\n",
              "      <td>100.0</td>\n",
              "      <td>1800</td>\n",
              "      <td>0.0</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-dc420bb8-c892-4727-a613-c97289977465')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-dc420bb8-c892-4727-a613-c97289977465 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-dc420bb8-c892-4727-a613-c97289977465');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-c3304f79-a7e7-4248-a064-df184bbffacd\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-c3304f79-a7e7-4248-a064-df184bbffacd')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-c3304f79-a7e7-4248-a064-df184bbffacd button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "df",
              "summary": "{\n  \"name\": \"df\",\n  \"rows\": 35040,\n  \"fields\": [\n    {\n      \"column\": \"usage_kwh\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 33.44437970801513,\n        \"min\": 0.0,\n        \"max\": 157.18,\n        \"num_unique_values\": 3343,\n        \"samples\": [\n          12.02,\n          28.51,\n          77.18\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"lagging_kvarh\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 16.305999973081924,\n        \"min\": 0.0,\n        \"max\": 96.91,\n        \"num_unique_values\": 1954,\n        \"samples\": [\n          20.88,\n          69.84,\n          7.02\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"leading_kvarh\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 7.424462753103645,\n        \"min\": 0.0,\n        \"max\": 27.76,\n        \"num_unique_values\": 768,\n        \"samples\": [\n          21.06,\n          23.04,\n          13.61\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"lagging_pf\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 18.92132226781741,\n        \"min\": 0.0,\n        \"max\": 100.0,\n        \"num_unique_values\": 5079,\n        \"samples\": [\n          77.48,\n          46.28,\n          100.0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"leading_pf\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 30.45653515758771,\n        \"min\": 0.0,\n        \"max\": 100.0,\n        \"num_unique_values\": 3366,\n        \"samples\": [\n          97.26,\n          54.38,\n          19.51\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"nsm\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 24940,\n        \"min\": 0,\n        \"max\": 85500,\n        \"num_unique_values\": 96,\n        \"samples\": [\n          72900,\n          70200,\n          66600\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"kgco2\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 16.150821534429333,\n        \"min\": 0.0,\n        \"max\": 70.0,\n        \"num_unique_values\": 8,\n        \"samples\": [\n          20.0,\n          40.0,\n          0.0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"new_day_of_week\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 2,\n        \"min\": 1,\n        \"max\": 7,\n        \"num_unique_values\": 7,\n        \"samples\": [\n          2,\n          3,\n          7\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"new_load_type\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 0,\n        \"max\": 2,\n        \"num_unique_values\": 3,\n        \"samples\": [\n          0,\n          1,\n          2\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"new_date\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 27,\n        \"min\": 0,\n        \"max\": 95,\n        \"num_unique_values\": 96,\n        \"samples\": [\n          81,\n          78,\n          74\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"new_weekstatus\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 0,\n        \"max\": 1,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          1,\n          0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "Y = df['usage_kwh'].to_numpy()\n",
        "X = df.drop('usage_kwh', axis =1). to_numpy()"
      ],
      "metadata": {
        "id": "1UE-ukaHAopA"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_3D = X.reshape((X.shape[0], X.shape[1], 1))\n",
        "Y_3D = Y.reshape((Y.shape[0], 1))"
      ],
      "metadata": {
        "id": "JYeieNDIAosg"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_3D.shape, Y_3D.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-HiwhJ9VOJFl",
        "outputId": "76d88b3b-6fe8-4a6f-f5d8-b87f386c8b21"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((35040, 10, 1), (35040, 1))"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X_train, X_test, Y_train, Y_test = train_test_split(X_3D, Y_3D, test_size=0.2, random_state= 128)"
      ],
      "metadata": {
        "id": "hPcsjZp2OPma"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class MetricsHistory(Callback):\n",
        "    def __init__(self, x_train, y_train, tittle_graph, path_tosaveImg):\n",
        "        super(MetricsHistory, self).__init__()\n",
        "        self.metrics_values = {\n",
        "            'mse': [],\n",
        "            'rmse': [],\n",
        "            'r_squared': [],\n",
        "            'loss': []\n",
        "        }\n",
        "        self.epoch_values = []\n",
        "        self.x_train = x_train\n",
        "        self.y_train = y_train\n",
        "        self.tittle_graph = tittle_graph\n",
        "        self.path_tosaveImg = path_tosaveImg\n",
        "\n",
        "    def on_epoch_end(self, epoch, logs=None):\n",
        "        y_true = self.y_train\n",
        "        y_pred = self.model.predict(self.x_train)\n",
        "\n",
        "        mse, rmse, r_squared = calculate_metrics(y_true, y_pred)\n",
        "        loss = logs['loss']\n",
        "\n",
        "        self.metrics_values['mse'].append(mse)\n",
        "        self.metrics_values['rmse'].append(rmse)\n",
        "        self.metrics_values['r_squared'].append(r_squared)\n",
        "        self.metrics_values['loss'].append(loss)\n",
        "        self.epoch_values.append(epoch + 1)\n",
        "\n",
        "    def on_train_end(self, logs=None):\n",
        "        plt.figure(1)\n",
        "        plt.plot(self.epoch_values, self.metrics_values['mse'], 'b-', label='MSE')\n",
        "        plt.plot(self.epoch_values, self.metrics_values['rmse'], 'r-', label='RMSE')\n",
        "        plt.plot(self.epoch_values, self.metrics_values['r_squared'], 'g-', label='R^2')\n",
        "        plt.xlabel('Epochs')\n",
        "        plt.ylabel('Metrics')\n",
        "        plt.title(self.tittle_graph[0])\n",
        "        plt.legend()\n",
        "        plt.savefig( self.path_tosaveImg[0] )\n",
        "\n",
        "        plt.figure(2)\n",
        "        plt.plot(self.epoch_values, self.metrics_values['loss'], 'y-', label='Loss')\n",
        "        plt.xlabel('Epochs')\n",
        "        plt.ylabel('Loss')\n",
        "        plt.title(self.tittle_graph[1])\n",
        "        plt.legend()\n",
        "        plt.savefig( self.path_tosaveImg[1])\n",
        "\n",
        "        plt.show()\n",
        "\n",
        "def calculate_metrics(y_true, y_pred):\n",
        "    n = len(y_true)\n",
        "    mse = np.mean((y_true - y_pred)**2)\n",
        "    rmse = np.sqrt(mse)\n",
        "    ss_total = np.sum((y_true - np.mean(y_true))**2)\n",
        "    ss_residual = np.sum((y_true - y_pred)**2)\n",
        "    r_squared = 1 - (ss_residual / ss_total)\n",
        "    return mse, rmse, r_squared"
      ],
      "metadata": {
        "id": "cwjWdhMvPrSB"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_RNN = keras.Sequential()\n",
        "model_RNN.add(keras.layers.SimpleRNN(units = 64, input_shape=(X_train.shape[1], X_train.shape[2])))\n",
        "model_RNN.add(keras.layers.Dense(units=1))\n",
        "model_RNN.compile(optimizer='adam', loss='mse')\n",
        "metrics_history_callback = MetricsHistory(X_train, Y_train,['Metrics over Epochs on RNN','Loss over Epochs on RNN'],['/content/drive/MyDrive/Task2/metricsRNN.png', '/content/drive/MyDrive/Task2/lossRNN.png'] )\n",
        "model_RNN.fit(X_train, Y_train,validation_data =(X_test, Y_test), epochs= 1200, batch_size= 256, callbacks=[metrics_history_callback])\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "cgxrXN7ZO3zJ",
        "outputId": "58381e03-69bb-4130-e075-3e93958b73dc"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/1200\n",
            "876/876 [==============================] - 3s 3ms/step\n",
            "110/110 [==============================] - 7s 58ms/step - loss: 1365.3337 - val_loss: 1167.6522\n",
            "Epoch 2/1200\n",
            "876/876 [==============================] - 2s 2ms/step\n",
            "110/110 [==============================] - 3s 27ms/step - loss: 1013.4993 - val_loss: 891.5206\n",
            "Epoch 3/1200\n",
            "876/876 [==============================] - 2s 2ms/step\n",
            "110/110 [==============================] - 3s 29ms/step - loss: 789.8973 - val_loss: 705.6199\n",
            "Epoch 4/1200\n",
            "876/876 [==============================] - 2s 2ms/step\n",
            "110/110 [==============================] - 3s 24ms/step - loss: 629.0119 - val_loss: 566.0012\n",
            "Epoch 5/1200\n",
            "876/876 [==============================] - 2s 3ms/step\n",
            "110/110 [==============================] - 4s 34ms/step - loss: 508.1308 - val_loss: 461.5269\n",
            "Epoch 6/1200\n",
            "876/876 [==============================] - 2s 2ms/step\n",
            "110/110 [==============================] - 3s 27ms/step - loss: 418.6964 - val_loss: 384.5690\n",
            "Epoch 7/1200\n",
            "876/876 [==============================] - 2s 2ms/step\n",
            "110/110 [==============================] - 3s 29ms/step - loss: 352.8290 - val_loss: 324.6999\n",
            "Epoch 8/1200\n",
            "876/876 [==============================] - 2s 2ms/step\n",
            "110/110 [==============================] - 2s 23ms/step - loss: 296.5005 - val_loss: 273.4092\n",
            "Epoch 9/1200\n",
            "876/876 [==============================] - 2s 2ms/step\n",
            "110/110 [==============================] - 3s 24ms/step - loss: 250.8156 - val_loss: 233.0899\n",
            "Epoch 10/1200\n",
            "876/876 [==============================] - 2s 2ms/step\n",
            "110/110 [==============================] - 4s 33ms/step - loss: 215.0567 - val_loss: 201.6674\n",
            "Epoch 11/1200\n",
            "876/876 [==============================] - 2s 2ms/step\n",
            "110/110 [==============================] - 4s 32ms/step - loss: 187.8124 - val_loss: 177.4844\n",
            "Epoch 12/1200\n",
            "876/876 [==============================] - 2s 2ms/step\n",
            "110/110 [==============================] - 3s 29ms/step - loss: 166.7556 - val_loss: 159.2397\n",
            "Epoch 13/1200\n",
            "876/876 [==============================] - 2s 2ms/step\n",
            "110/110 [==============================] - 3s 29ms/step - loss: 150.9854 - val_loss: 142.9631\n",
            "Epoch 14/1200\n",
            "876/876 [==============================] - 2s 2ms/step\n",
            "110/110 [==============================] - 3s 30ms/step - loss: 132.8301 - val_loss: 126.0254\n",
            "Epoch 15/1200\n",
            "876/876 [==============================] - 2s 3ms/step\n",
            "110/110 [==============================] - 4s 34ms/step - loss: 117.0339 - val_loss: 112.5481\n",
            "Epoch 16/1200\n",
            "876/876 [==============================] - 2s 2ms/step\n",
            "110/110 [==============================] - 3s 30ms/step - loss: 103.5715 - val_loss: 98.0443\n",
            "Epoch 17/1200\n",
            "876/876 [==============================] - 2s 2ms/step\n",
            "110/110 [==============================] - 4s 33ms/step - loss: 92.0233 - val_loss: 87.6539\n",
            "Epoch 18/1200\n",
            "876/876 [==============================] - 2s 2ms/step\n",
            "110/110 [==============================] - 3s 23ms/step - loss: 81.9762 - val_loss: 78.7837\n",
            "Epoch 19/1200\n",
            "876/876 [==============================] - 2s 2ms/step\n",
            "110/110 [==============================] - 3s 32ms/step - loss: 73.8304 - val_loss: 71.3460\n",
            "Epoch 20/1200\n",
            "876/876 [==============================] - 2s 2ms/step\n",
            "110/110 [==============================] - 4s 33ms/step - loss: 67.2554 - val_loss: 65.1713\n",
            "Epoch 21/1200\n",
            "876/876 [==============================] - 2s 2ms/step\n",
            "110/110 [==============================] - 3s 29ms/step - loss: 62.2684 - val_loss: 60.3833\n",
            "Epoch 22/1200\n",
            "876/876 [==============================] - 2s 2ms/step\n",
            "110/110 [==============================] - 3s 30ms/step - loss: 57.8952 - val_loss: 56.1969\n",
            "Epoch 23/1200\n",
            "876/876 [==============================] - 2s 2ms/step\n",
            "110/110 [==============================] - 3s 30ms/step - loss: 54.3409 - val_loss: 52.8508\n",
            "Epoch 24/1200\n",
            "876/876 [==============================] - 2s 3ms/step\n",
            "110/110 [==============================] - 4s 34ms/step - loss: 51.3994 - val_loss: 48.9613\n",
            "Epoch 25/1200\n",
            "876/876 [==============================] - 2s 2ms/step\n",
            "110/110 [==============================] - 3s 23ms/step - loss: 47.4184 - val_loss: 45.9614\n",
            "Epoch 26/1200\n",
            "876/876 [==============================] - 2s 2ms/step\n",
            "110/110 [==============================] - 3s 29ms/step - loss: 44.0195 - val_loss: 42.5891\n",
            "Epoch 27/1200\n",
            "876/876 [==============================] - 2s 2ms/step\n",
            "110/110 [==============================] - 3s 30ms/step - loss: 41.4829 - val_loss: 39.7892\n",
            "Epoch 28/1200\n",
            "876/876 [==============================] - 2s 2ms/step\n",
            "110/110 [==============================] - 6s 54ms/step - loss: 38.7525 - val_loss: 37.2995\n",
            "Epoch 29/1200\n",
            "876/876 [==============================] - 2s 2ms/step\n",
            "110/110 [==============================] - 3s 30ms/step - loss: 36.9550 - val_loss: 35.3878\n",
            "Epoch 30/1200\n",
            "876/876 [==============================] - 2s 3ms/step\n",
            "110/110 [==============================] - 4s 34ms/step - loss: 35.0423 - val_loss: 34.6842\n",
            "Epoch 31/1200\n",
            "876/876 [==============================] - 2s 2ms/step\n",
            "110/110 [==============================] - 3s 26ms/step - loss: 33.8320 - val_loss: 33.4115\n",
            "Epoch 32/1200\n",
            "876/876 [==============================] - 2s 3ms/step\n",
            "110/110 [==============================] - 6s 56ms/step - loss: 32.6133 - val_loss: 30.7908\n",
            "Epoch 33/1200\n",
            "876/876 [==============================] - 2s 2ms/step\n",
            "110/110 [==============================] - 3s 23ms/step - loss: 31.3839 - val_loss: 30.6022\n",
            "Epoch 34/1200\n",
            "876/876 [==============================] - 2s 2ms/step\n",
            "110/110 [==============================] - 3s 30ms/step - loss: 30.5963 - val_loss: 29.2298\n",
            "Epoch 35/1200\n",
            "876/876 [==============================] - 2s 2ms/step\n",
            "110/110 [==============================] - 3s 29ms/step - loss: 29.9024 - val_loss: 28.7351\n",
            "Epoch 36/1200\n",
            "876/876 [==============================] - 2s 2ms/step\n",
            "110/110 [==============================] - 4s 33ms/step - loss: 29.2258 - val_loss: 28.0280\n",
            "Epoch 37/1200\n",
            "876/876 [==============================] - 2s 2ms/step\n",
            "110/110 [==============================] - 3s 23ms/step - loss: 28.7910 - val_loss: 27.5436\n",
            "Epoch 38/1200\n",
            "876/876 [==============================] - 2s 2ms/step\n",
            "110/110 [==============================] - 3s 30ms/step - loss: 28.6351 - val_loss: 28.2448\n",
            "Epoch 39/1200\n",
            "876/876 [==============================] - 2s 2ms/step\n",
            "110/110 [==============================] - 3s 29ms/step - loss: 28.2349 - val_loss: 27.5632\n",
            "Epoch 40/1200\n",
            "876/876 [==============================] - 2s 3ms/step\n",
            "110/110 [==============================] - 6s 55ms/step - loss: 27.7592 - val_loss: 26.6767\n",
            "Epoch 41/1200\n",
            "876/876 [==============================] - 2s 2ms/step\n",
            "110/110 [==============================] - 3s 30ms/step - loss: 27.8129 - val_loss: 26.3464\n",
            "Epoch 42/1200\n",
            "876/876 [==============================] - 2s 2ms/step\n",
            "110/110 [==============================] - 3s 29ms/step - loss: 27.1662 - val_loss: 25.5922\n",
            "Epoch 43/1200\n",
            "876/876 [==============================] - 2s 2ms/step\n",
            "110/110 [==============================] - 3s 25ms/step - loss: 26.9930 - val_loss: 25.5931\n",
            "Epoch 44/1200\n",
            "876/876 [==============================] - 2s 3ms/step\n",
            "110/110 [==============================] - 4s 34ms/step - loss: 26.4287 - val_loss: 25.5355\n",
            "Epoch 45/1200\n",
            "876/876 [==============================] - 2s 2ms/step\n",
            "110/110 [==============================] - 3s 23ms/step - loss: 26.0195 - val_loss: 24.7493\n",
            "Epoch 46/1200\n",
            "876/876 [==============================] - 2s 2ms/step\n",
            "110/110 [==============================] - 2s 23ms/step - loss: 25.7207 - val_loss: 25.4111\n",
            "Epoch 47/1200\n",
            "876/876 [==============================] - 2s 2ms/step\n",
            "110/110 [==============================] - 3s 23ms/step - loss: 25.4659 - val_loss: 23.5191\n",
            "Epoch 48/1200\n",
            "876/876 [==============================] - 2s 2ms/step\n",
            "110/110 [==============================] - 3s 24ms/step - loss: 25.0696 - val_loss: 23.3712\n",
            "Epoch 49/1200\n",
            "876/876 [==============================] - 2s 3ms/step\n",
            "110/110 [==============================] - 4s 35ms/step - loss: 24.9307 - val_loss: 23.2509\n",
            "Epoch 50/1200\n",
            "876/876 [==============================] - 2s 2ms/step\n",
            "110/110 [==============================] - 4s 32ms/step - loss: 24.6862 - val_loss: 23.2349\n",
            "Epoch 51/1200\n",
            "876/876 [==============================] - 2s 2ms/step\n",
            "110/110 [==============================] - 3s 30ms/step - loss: 24.2204 - val_loss: 23.4532\n",
            "Epoch 52/1200\n",
            "876/876 [==============================] - 2s 2ms/step\n",
            "110/110 [==============================] - 3s 30ms/step - loss: 24.3240 - val_loss: 23.7356\n",
            "Epoch 53/1200\n",
            "876/876 [==============================] - 2s 2ms/step\n",
            "110/110 [==============================] - 3s 28ms/step - loss: 23.8896 - val_loss: 22.6102\n",
            "Epoch 54/1200\n",
            "876/876 [==============================] - 2s 3ms/step\n",
            "110/110 [==============================] - 6s 57ms/step - loss: 23.7655 - val_loss: 22.0787\n",
            "Epoch 55/1200\n",
            "876/876 [==============================] - 2s 2ms/step\n",
            "110/110 [==============================] - 3s 30ms/step - loss: 23.4751 - val_loss: 21.5908\n",
            "Epoch 56/1200\n",
            "876/876 [==============================] - 2s 2ms/step\n",
            "110/110 [==============================] - 3s 24ms/step - loss: 23.4688 - val_loss: 21.8809\n",
            "Epoch 57/1200\n",
            "876/876 [==============================] - 2s 2ms/step\n",
            "110/110 [==============================] - 3s 30ms/step - loss: 23.2404 - val_loss: 22.1275\n",
            "Epoch 58/1200\n",
            "876/876 [==============================] - 2s 3ms/step\n",
            "110/110 [==============================] - 4s 37ms/step - loss: 23.3694 - val_loss: 22.1174\n",
            "Epoch 59/1200\n",
            "876/876 [==============================] - 2s 3ms/step\n",
            "110/110 [==============================] - 6s 56ms/step - loss: 23.2678 - val_loss: 22.3446\n",
            "Epoch 60/1200\n",
            "876/876 [==============================] - 2s 2ms/step\n",
            "110/110 [==============================] - 3s 29ms/step - loss: 22.8134 - val_loss: 21.4953\n",
            "Epoch 61/1200\n",
            "876/876 [==============================] - 2s 3ms/step\n",
            "110/110 [==============================] - 6s 54ms/step - loss: 22.6912 - val_loss: 21.8352\n",
            "Epoch 62/1200\n",
            "876/876 [==============================] - 2s 2ms/step\n",
            "110/110 [==============================] - 3s 30ms/step - loss: 22.9032 - val_loss: 21.0347\n",
            "Epoch 63/1200\n",
            "876/876 [==============================] - 2s 2ms/step\n",
            "110/110 [==============================] - 3s 30ms/step - loss: 22.5957 - val_loss: 21.0775\n",
            "Epoch 64/1200\n",
            "876/876 [==============================] - 2s 2ms/step\n",
            "110/110 [==============================] - 3s 26ms/step - loss: 22.6761 - val_loss: 21.4984\n",
            "Epoch 65/1200\n",
            "876/876 [==============================] - 2s 3ms/step\n",
            "110/110 [==============================] - 6s 56ms/step - loss: 22.6730 - val_loss: 22.4872\n",
            "Epoch 66/1200\n",
            "876/876 [==============================] - 2s 2ms/step\n",
            "110/110 [==============================] - 3s 23ms/step - loss: 22.5215 - val_loss: 21.7018\n",
            "Epoch 67/1200\n",
            "876/876 [==============================] - 2s 2ms/step\n",
            "110/110 [==============================] - 3s 30ms/step - loss: 22.4302 - val_loss: 21.0517\n",
            "Epoch 68/1200\n",
            "876/876 [==============================] - 2s 2ms/step\n",
            "110/110 [==============================] - 3s 30ms/step - loss: 22.2344 - val_loss: 20.9148\n",
            "Epoch 69/1200\n",
            "876/876 [==============================] - 2s 3ms/step\n",
            "110/110 [==============================] - 4s 33ms/step - loss: 22.2508 - val_loss: 20.5221\n",
            "Epoch 70/1200\n",
            "876/876 [==============================] - 2s 2ms/step\n",
            "110/110 [==============================] - 3s 23ms/step - loss: 22.1314 - val_loss: 21.2545\n",
            "Epoch 71/1200\n",
            "876/876 [==============================] - 2s 2ms/step\n",
            "110/110 [==============================] - 3s 30ms/step - loss: 22.2676 - val_loss: 20.7835\n",
            "Epoch 72/1200\n",
            "876/876 [==============================] - 2s 2ms/step\n",
            "110/110 [==============================] - 3s 24ms/step - loss: 22.1804 - val_loss: 20.7633\n",
            "Epoch 73/1200\n",
            "876/876 [==============================] - 2s 2ms/step\n",
            "110/110 [==============================] - 3s 30ms/step - loss: 22.1705 - val_loss: 20.2704\n",
            "Epoch 74/1200\n",
            "876/876 [==============================] - 2s 2ms/step\n",
            "110/110 [==============================] - 3s 31ms/step - loss: 22.0021 - val_loss: 20.6125\n",
            "Epoch 75/1200\n",
            "876/876 [==============================] - 2s 2ms/step\n",
            "110/110 [==============================] - 3s 30ms/step - loss: 21.9931 - val_loss: 20.5470\n",
            "Epoch 76/1200\n",
            "876/876 [==============================] - 2s 2ms/step\n",
            "110/110 [==============================] - 3s 24ms/step - loss: 21.9876 - val_loss: 21.0934\n",
            "Epoch 77/1200\n",
            "876/876 [==============================] - 2s 2ms/step\n",
            "110/110 [==============================] - 3s 24ms/step - loss: 21.9175 - val_loss: 20.9288\n",
            "Epoch 78/1200\n",
            "876/876 [==============================] - 2s 2ms/step\n",
            "110/110 [==============================] - 3s 30ms/step - loss: 22.1633 - val_loss: 20.1561\n",
            "Epoch 79/1200\n",
            "876/876 [==============================] - 2s 3ms/step\n",
            "110/110 [==============================] - 4s 34ms/step - loss: 22.0449 - val_loss: 20.3994\n",
            "Epoch 80/1200\n",
            "876/876 [==============================] - 2s 2ms/step\n",
            "110/110 [==============================] - 3s 30ms/step - loss: 21.9150 - val_loss: 20.7426\n",
            "Epoch 81/1200\n",
            "876/876 [==============================] - 2s 2ms/step\n",
            "110/110 [==============================] - 3s 24ms/step - loss: 21.5723 - val_loss: 21.1220\n",
            "Epoch 82/1200\n",
            "876/876 [==============================] - 2s 2ms/step\n",
            "110/110 [==============================] - 3s 30ms/step - loss: 21.8665 - val_loss: 20.3395\n",
            "Epoch 83/1200\n",
            "876/876 [==============================] - 2s 3ms/step\n",
            "110/110 [==============================] - 4s 35ms/step - loss: 21.4524 - val_loss: 20.1866\n",
            "Epoch 84/1200\n",
            "876/876 [==============================] - 2s 2ms/step\n",
            "110/110 [==============================] - 4s 33ms/step - loss: 21.5864 - val_loss: 20.5658\n",
            "Epoch 85/1200\n",
            "876/876 [==============================] - 2s 2ms/step\n",
            "110/110 [==============================] - 3s 23ms/step - loss: 21.6654 - val_loss: 20.3564\n",
            "Epoch 86/1200\n",
            "876/876 [==============================] - 2s 2ms/step\n",
            "110/110 [==============================] - 3s 24ms/step - loss: 21.4177 - val_loss: 20.6391\n",
            "Epoch 87/1200\n",
            "876/876 [==============================] - 2s 2ms/step\n",
            "110/110 [==============================] - 3s 24ms/step - loss: 21.3242 - val_loss: 20.2453\n",
            "Epoch 88/1200\n",
            "876/876 [==============================] - 2s 3ms/step\n",
            "110/110 [==============================] - 4s 34ms/step - loss: 21.9223 - val_loss: 21.1590\n",
            "Epoch 89/1200\n",
            "876/876 [==============================] - 2s 2ms/step\n",
            "110/110 [==============================] - 4s 33ms/step - loss: 21.4814 - val_loss: 20.1193\n",
            "Epoch 90/1200\n",
            "876/876 [==============================] - 2s 2ms/step\n",
            "110/110 [==============================] - 3s 23ms/step - loss: 21.2669 - val_loss: 19.9755\n",
            "Epoch 91/1200\n",
            "876/876 [==============================] - 2s 2ms/step\n",
            "110/110 [==============================] - 3s 30ms/step - loss: 21.1392 - val_loss: 20.5174\n",
            "Epoch 92/1200\n",
            "876/876 [==============================] - 2s 2ms/step\n",
            "110/110 [==============================] - 3s 25ms/step - loss: 21.1130 - val_loss: 20.4138\n",
            "Epoch 93/1200\n",
            "876/876 [==============================] - 2s 3ms/step\n",
            "110/110 [==============================] - 4s 34ms/step - loss: 21.2653 - val_loss: 19.9094\n",
            "Epoch 94/1200\n",
            "876/876 [==============================] - 2s 2ms/step\n",
            "110/110 [==============================] - 3s 26ms/step - loss: 21.0282 - val_loss: 20.2594\n",
            "Epoch 95/1200\n",
            "876/876 [==============================] - 2s 2ms/step\n",
            "110/110 [==============================] - 3s 30ms/step - loss: 21.0708 - val_loss: 20.2721\n",
            "Epoch 96/1200\n",
            "876/876 [==============================] - 2s 2ms/step\n",
            "110/110 [==============================] - 3s 24ms/step - loss: 21.0931 - val_loss: 20.5278\n",
            "Epoch 97/1200\n",
            "876/876 [==============================] - 2s 2ms/step\n",
            "110/110 [==============================] - 3s 25ms/step - loss: 20.7831 - val_loss: 20.9546\n",
            "Epoch 98/1200\n",
            "876/876 [==============================] - 2s 3ms/step\n",
            "110/110 [==============================] - 6s 57ms/step - loss: 20.9022 - val_loss: 20.6263\n",
            "Epoch 99/1200\n",
            "876/876 [==============================] - 2s 2ms/step\n",
            "110/110 [==============================] - 3s 30ms/step - loss: 21.1925 - val_loss: 19.7877\n",
            "Epoch 100/1200\n",
            "876/876 [==============================] - 2s 2ms/step\n",
            "110/110 [==============================] - 3s 23ms/step - loss: 20.9232 - val_loss: 19.5616\n",
            "Epoch 101/1200\n",
            "876/876 [==============================] - 2s 2ms/step\n",
            "110/110 [==============================] - 3s 26ms/step - loss: 20.9340 - val_loss: 19.6269\n",
            "Epoch 102/1200\n",
            "876/876 [==============================] - 2s 3ms/step\n",
            "110/110 [==============================] - 4s 35ms/step - loss: 20.4478 - val_loss: 19.7126\n",
            "Epoch 103/1200\n",
            "876/876 [==============================] - 2s 2ms/step\n",
            "110/110 [==============================] - 4s 32ms/step - loss: 21.0813 - val_loss: 20.0236\n",
            "Epoch 104/1200\n",
            "876/876 [==============================] - 2s 2ms/step\n",
            "110/110 [==============================] - 3s 24ms/step - loss: 20.4715 - val_loss: 19.7091\n",
            "Epoch 105/1200\n",
            "876/876 [==============================] - 2s 2ms/step\n",
            "110/110 [==============================] - 3s 24ms/step - loss: 20.6246 - val_loss: 19.8089\n",
            "Epoch 106/1200\n",
            "876/876 [==============================] - 2s 2ms/step\n",
            "110/110 [==============================] - 3s 27ms/step - loss: 20.5738 - val_loss: 19.2207\n",
            "Epoch 107/1200\n",
            "876/876 [==============================] - 2s 3ms/step\n",
            "110/110 [==============================] - 6s 56ms/step - loss: 20.4542 - val_loss: 19.6336\n",
            "Epoch 108/1200\n",
            "876/876 [==============================] - 2s 2ms/step\n",
            "110/110 [==============================] - 3s 24ms/step - loss: 20.5622 - val_loss: 19.8447\n",
            "Epoch 109/1200\n",
            "876/876 [==============================] - 2s 2ms/step\n",
            "110/110 [==============================] - 3s 25ms/step - loss: 20.3549 - val_loss: 21.2704\n",
            "Epoch 110/1200\n",
            "876/876 [==============================] - 2s 2ms/step\n",
            "110/110 [==============================] - 3s 30ms/step - loss: 20.2466 - val_loss: 19.5613\n",
            "Epoch 111/1200\n",
            "876/876 [==============================] - 2s 3ms/step\n",
            "110/110 [==============================] - 6s 57ms/step - loss: 20.4490 - val_loss: 20.0283\n",
            "Epoch 112/1200\n",
            "876/876 [==============================] - 2s 2ms/step\n",
            "110/110 [==============================] - 3s 24ms/step - loss: 20.3553 - val_loss: 20.2176\n",
            "Epoch 113/1200\n",
            "876/876 [==============================] - 2s 2ms/step\n",
            "110/110 [==============================] - 3s 30ms/step - loss: 20.0611 - val_loss: 19.4223\n",
            "Epoch 114/1200\n",
            "876/876 [==============================] - 2s 2ms/step\n",
            "110/110 [==============================] - 3s 30ms/step - loss: 20.6478 - val_loss: 20.1248\n",
            "Epoch 115/1200\n",
            "876/876 [==============================] - 2s 3ms/step\n",
            "110/110 [==============================] - 6s 57ms/step - loss: 20.1338 - val_loss: 19.6164\n",
            "Epoch 116/1200\n",
            "876/876 [==============================] - 2s 2ms/step\n",
            "110/110 [==============================] - 3s 24ms/step - loss: 19.7482 - val_loss: 19.5810\n",
            "Epoch 117/1200\n",
            "876/876 [==============================] - 2s 2ms/step\n",
            "110/110 [==============================] - 3s 30ms/step - loss: 20.0935 - val_loss: 20.2371\n",
            "Epoch 118/1200\n",
            "876/876 [==============================] - 2s 2ms/step\n",
            "110/110 [==============================] - 3s 30ms/step - loss: 20.3311 - val_loss: 20.0934\n",
            "Epoch 119/1200\n",
            "876/876 [==============================] - 2s 3ms/step\n",
            "110/110 [==============================] - 4s 34ms/step - loss: 19.9158 - val_loss: 19.6088\n",
            "Epoch 120/1200\n",
            "876/876 [==============================] - 2s 2ms/step\n",
            "110/110 [==============================] - 3s 24ms/step - loss: 19.8898 - val_loss: 20.0331\n",
            "Epoch 121/1200\n",
            "876/876 [==============================] - 2s 2ms/step\n",
            "110/110 [==============================] - 3s 30ms/step - loss: 19.8907 - val_loss: 19.6389\n",
            "Epoch 122/1200\n",
            "876/876 [==============================] - 2s 2ms/step\n",
            "110/110 [==============================] - 3s 24ms/step - loss: 19.5594 - val_loss: 19.4394\n",
            "Epoch 123/1200\n",
            "876/876 [==============================] - 2s 2ms/step\n",
            "110/110 [==============================] - 3s 30ms/step - loss: 19.6992 - val_loss: 19.2376\n",
            "Epoch 124/1200\n",
            "876/876 [==============================] - 2s 3ms/step\n",
            "110/110 [==============================] - 4s 33ms/step - loss: 19.7735 - val_loss: 19.6954\n",
            "Epoch 125/1200\n",
            "876/876 [==============================] - 2s 2ms/step\n",
            "110/110 [==============================] - 3s 23ms/step - loss: 19.6518 - val_loss: 19.7773\n",
            "Epoch 126/1200\n",
            "876/876 [==============================] - 2s 2ms/step\n",
            "110/110 [==============================] - 3s 24ms/step - loss: 19.3085 - val_loss: 19.3181\n",
            "Epoch 127/1200\n",
            "876/876 [==============================] - 2s 2ms/step\n",
            "110/110 [==============================] - 3s 30ms/step - loss: 19.4564 - val_loss: 19.3717\n",
            "Epoch 128/1200\n",
            "876/876 [==============================] - 3s 3ms/step\n",
            "110/110 [==============================] - 6s 57ms/step - loss: 20.3296 - val_loss: 22.4610\n",
            "Epoch 129/1200\n",
            "876/876 [==============================] - 2s 2ms/step\n",
            "110/110 [==============================] - 3s 24ms/step - loss: 20.5612 - val_loss: 19.9486\n",
            "Epoch 130/1200\n",
            "876/876 [==============================] - 2s 2ms/step\n",
            "110/110 [==============================] - 3s 30ms/step - loss: 19.4992 - val_loss: 19.1800\n",
            "Epoch 131/1200\n",
            "876/876 [==============================] - 2s 2ms/step\n",
            "110/110 [==============================] - 3s 24ms/step - loss: 19.3489 - val_loss: 19.9767\n",
            "Epoch 132/1200\n",
            "876/876 [==============================] - 2s 2ms/step\n",
            "110/110 [==============================] - 3s 27ms/step - loss: 19.3371 - val_loss: 20.1449\n",
            "Epoch 133/1200\n",
            "876/876 [==============================] - 2s 3ms/step\n",
            "110/110 [==============================] - 4s 35ms/step - loss: 19.2787 - val_loss: 19.1658\n",
            "Epoch 134/1200\n",
            "876/876 [==============================] - 2s 2ms/step\n",
            "110/110 [==============================] - 3s 30ms/step - loss: 19.2647 - val_loss: 19.8476\n",
            "Epoch 135/1200\n",
            "876/876 [==============================] - 2s 2ms/step\n",
            "110/110 [==============================] - 3s 24ms/step - loss: 19.2487 - val_loss: 18.9538\n",
            "Epoch 136/1200\n",
            "876/876 [==============================] - 2s 2ms/step\n",
            "110/110 [==============================] - 3s 24ms/step - loss: 19.2733 - val_loss: 19.1711\n",
            "Epoch 137/1200\n",
            "876/876 [==============================] - 2s 2ms/step\n",
            "110/110 [==============================] - 3s 29ms/step - loss: 19.0241 - val_loss: 18.5754\n",
            "Epoch 138/1200\n",
            "876/876 [==============================] - 2s 2ms/step\n",
            "110/110 [==============================] - 4s 32ms/step - loss: 19.1497 - val_loss: 19.1435\n",
            "Epoch 139/1200\n",
            "876/876 [==============================] - 2s 2ms/step\n",
            "110/110 [==============================] - 3s 24ms/step - loss: 18.9743 - val_loss: 20.0806\n",
            "Epoch 140/1200\n",
            "876/876 [==============================] - 2s 2ms/step\n",
            "110/110 [==============================] - 3s 30ms/step - loss: 19.1165 - val_loss: 18.8934\n",
            "Epoch 141/1200\n",
            "876/876 [==============================] - 2s 2ms/step\n",
            "110/110 [==============================] - 3s 24ms/step - loss: 19.1109 - val_loss: 19.1693\n",
            "Epoch 142/1200\n",
            "876/876 [==============================] - 2s 2ms/step\n",
            "110/110 [==============================] - 3s 29ms/step - loss: 18.9921 - val_loss: 18.7104\n",
            "Epoch 143/1200\n",
            "876/876 [==============================] - 2s 3ms/step\n",
            "110/110 [==============================] - 3s 32ms/step - loss: 19.0057 - val_loss: 20.0357\n",
            "Epoch 144/1200\n",
            "876/876 [==============================] - 2s 2ms/step\n",
            "110/110 [==============================] - 3s 23ms/step - loss: 19.8247 - val_loss: 20.8349\n",
            "Epoch 145/1200\n",
            "876/876 [==============================] - 2s 2ms/step\n",
            "110/110 [==============================] - 3s 23ms/step - loss: 18.9494 - val_loss: 19.2095\n",
            "Epoch 146/1200\n",
            "876/876 [==============================] - 2s 2ms/step\n",
            "110/110 [==============================] - 3s 30ms/step - loss: 18.6637 - val_loss: 19.6302\n",
            "Epoch 147/1200\n",
            "876/876 [==============================] - 2s 2ms/step\n",
            "110/110 [==============================] - 3s 29ms/step - loss: 18.6728 - val_loss: 18.5805\n",
            "Epoch 148/1200\n",
            "876/876 [==============================] - 2s 3ms/step\n",
            "110/110 [==============================] - 4s 33ms/step - loss: 18.7001 - val_loss: 19.0524\n",
            "Epoch 149/1200\n",
            "876/876 [==============================] - 2s 2ms/step\n",
            "110/110 [==============================] - 3s 24ms/step - loss: 18.4939 - val_loss: 20.4336\n",
            "Epoch 150/1200\n",
            "876/876 [==============================] - 2s 2ms/step\n",
            "110/110 [==============================] - 3s 30ms/step - loss: 18.8605 - val_loss: 18.7192\n",
            "Epoch 151/1200\n",
            "876/876 [==============================] - 2s 2ms/step\n",
            "110/110 [==============================] - 3s 23ms/step - loss: 18.3952 - val_loss: 18.0758\n",
            "Epoch 152/1200\n",
            "876/876 [==============================] - 2s 2ms/step\n",
            "110/110 [==============================] - 3s 30ms/step - loss: 18.3581 - val_loss: 18.5443\n",
            "Epoch 153/1200\n",
            "876/876 [==============================] - 2s 2ms/step\n",
            "110/110 [==============================] - 4s 32ms/step - loss: 19.4881 - val_loss: 19.6131\n",
            "Epoch 154/1200\n",
            "876/876 [==============================] - 2s 2ms/step\n",
            "110/110 [==============================] - 3s 29ms/step - loss: 18.6760 - val_loss: 18.9221\n",
            "Epoch 155/1200\n",
            "876/876 [==============================] - 2s 2ms/step\n",
            "110/110 [==============================] - 3s 31ms/step - loss: 18.3935 - val_loss: 18.6332\n",
            "Epoch 156/1200\n",
            "876/876 [==============================] - 2s 2ms/step\n",
            "110/110 [==============================] - 3s 24ms/step - loss: 18.2901 - val_loss: 19.8311\n",
            "Epoch 157/1200\n",
            "876/876 [==============================] - 2s 2ms/step\n",
            "110/110 [==============================] - 6s 56ms/step - loss: 18.4175 - val_loss: 18.8688\n",
            "Epoch 158/1200\n",
            "876/876 [==============================] - 2s 2ms/step\n",
            "110/110 [==============================] - 3s 24ms/step - loss: 18.2855 - val_loss: 18.9786\n",
            "Epoch 159/1200\n",
            "876/876 [==============================] - 2s 2ms/step\n",
            "110/110 [==============================] - 3s 24ms/step - loss: 18.4115 - val_loss: 18.5915\n",
            "Epoch 160/1200\n",
            "876/876 [==============================] - 2s 2ms/step\n",
            "110/110 [==============================] - 3s 24ms/step - loss: 18.1377 - val_loss: 18.8757\n",
            "Epoch 161/1200\n",
            "876/876 [==============================] - 2s 3ms/step\n",
            "110/110 [==============================] - 6s 56ms/step - loss: 18.0127 - val_loss: 18.5718\n",
            "Epoch 162/1200\n",
            "876/876 [==============================] - 2s 2ms/step\n",
            "110/110 [==============================] - 3s 30ms/step - loss: 18.1440 - val_loss: 19.1320\n",
            "Epoch 163/1200\n",
            "876/876 [==============================] - 2s 2ms/step\n",
            "110/110 [==============================] - 3s 24ms/step - loss: 18.4774 - val_loss: 18.0628\n",
            "Epoch 164/1200\n",
            "876/876 [==============================] - 2s 2ms/step\n",
            "110/110 [==============================] - 3s 30ms/step - loss: 17.9636 - val_loss: 18.7437\n",
            "Epoch 165/1200\n",
            "876/876 [==============================] - 2s 3ms/step\n",
            "110/110 [==============================] - 4s 35ms/step - loss: 18.0639 - val_loss: 18.3092\n",
            "Epoch 166/1200\n",
            "876/876 [==============================] - 2s 2ms/step\n",
            "110/110 [==============================] - 3s 23ms/step - loss: 17.8415 - val_loss: 18.0307\n",
            "Epoch 167/1200\n",
            "876/876 [==============================] - 2s 2ms/step\n",
            "110/110 [==============================] - 3s 31ms/step - loss: 17.6859 - val_loss: 18.4632\n",
            "Epoch 168/1200\n",
            "876/876 [==============================] - 2s 2ms/step\n",
            "110/110 [==============================] - 3s 24ms/step - loss: 17.8018 - val_loss: 18.4734\n",
            "Epoch 169/1200\n",
            "876/876 [==============================] - 2s 2ms/step\n",
            "110/110 [==============================] - 3s 29ms/step - loss: 18.2275 - val_loss: 19.0602\n",
            "Epoch 170/1200\n",
            "876/876 [==============================] - 2s 3ms/step\n",
            "110/110 [==============================] - 4s 34ms/step - loss: 17.7454 - val_loss: 19.4356\n",
            "Epoch 171/1200\n",
            "876/876 [==============================] - 2s 2ms/step\n",
            "110/110 [==============================] - 3s 23ms/step - loss: 17.5430 - val_loss: 17.5597\n",
            "Epoch 172/1200\n",
            "876/876 [==============================] - 2s 2ms/step\n",
            "110/110 [==============================] - 3s 30ms/step - loss: 17.8448 - val_loss: 19.1180\n",
            "Epoch 173/1200\n",
            "876/876 [==============================] - 2s 2ms/step\n",
            "110/110 [==============================] - 3s 30ms/step - loss: 17.8493 - val_loss: 18.5643\n",
            "Epoch 174/1200\n",
            "876/876 [==============================] - 2s 3ms/step\n",
            "110/110 [==============================] - 3s 30ms/step - loss: 17.6072 - val_loss: 18.5160\n",
            "Epoch 175/1200\n",
            "876/876 [==============================] - 2s 3ms/step\n",
            "110/110 [==============================] - 4s 32ms/step - loss: 17.4007 - val_loss: 18.6771\n",
            "Epoch 176/1200\n",
            "876/876 [==============================] - 2s 2ms/step\n",
            "110/110 [==============================] - 3s 24ms/step - loss: 17.9875 - val_loss: 17.8471\n",
            "Epoch 177/1200\n",
            "876/876 [==============================] - 2s 2ms/step\n",
            "110/110 [==============================] - 3s 24ms/step - loss: 18.0919 - val_loss: 18.2840\n",
            "Epoch 178/1200\n",
            "876/876 [==============================] - 2s 2ms/step\n",
            "110/110 [==============================] - 3s 23ms/step - loss: 17.5727 - val_loss: 18.1737\n",
            "Epoch 179/1200\n",
            "876/876 [==============================] - 2s 2ms/step\n",
            "110/110 [==============================] - 3s 26ms/step - loss: 17.4577 - val_loss: 17.9742\n",
            "Epoch 180/1200\n",
            "876/876 [==============================] - 2s 3ms/step\n",
            "110/110 [==============================] - 4s 35ms/step - loss: 17.6012 - val_loss: 20.7592\n",
            "Epoch 181/1200\n",
            "876/876 [==============================] - 2s 2ms/step\n",
            "110/110 [==============================] - 3s 25ms/step - loss: 17.9327 - val_loss: 17.8634\n",
            "Epoch 182/1200\n",
            "876/876 [==============================] - 2s 2ms/step\n",
            "110/110 [==============================] - 3s 23ms/step - loss: 18.0000 - val_loss: 18.5970\n",
            "Epoch 183/1200\n",
            "876/876 [==============================] - 2s 2ms/step\n",
            "110/110 [==============================] - 3s 30ms/step - loss: 17.7657 - val_loss: 18.6757\n",
            "Epoch 184/1200\n",
            "876/876 [==============================] - 2s 2ms/step\n",
            "110/110 [==============================] - 3s 30ms/step - loss: 17.7393 - val_loss: 19.8183\n",
            "Epoch 185/1200\n",
            "876/876 [==============================] - 2s 3ms/step\n",
            "110/110 [==============================] - 4s 33ms/step - loss: 17.7293 - val_loss: 18.0003\n",
            "Epoch 186/1200\n",
            "876/876 [==============================] - 2s 2ms/step\n",
            "110/110 [==============================] - 3s 24ms/step - loss: 17.2300 - val_loss: 18.4405\n",
            "Epoch 187/1200\n",
            "876/876 [==============================] - 2s 2ms/step\n",
            "110/110 [==============================] - 3s 25ms/step - loss: 17.4226 - val_loss: 18.4599\n",
            "Epoch 188/1200\n",
            "876/876 [==============================] - 2s 2ms/step\n",
            "110/110 [==============================] - 3s 24ms/step - loss: 17.1202 - val_loss: 18.1833\n",
            "Epoch 189/1200\n",
            "876/876 [==============================] - 2s 2ms/step\n",
            "110/110 [==============================] - 3s 25ms/step - loss: 17.3963 - val_loss: 17.8296\n",
            "Epoch 190/1200\n",
            "876/876 [==============================] - 2s 3ms/step\n",
            "110/110 [==============================] - 4s 34ms/step - loss: 17.5157 - val_loss: 18.0433\n",
            "Epoch 191/1200\n",
            "876/876 [==============================] - 2s 2ms/step\n",
            "110/110 [==============================] - 4s 33ms/step - loss: 17.2370 - val_loss: 17.8962\n",
            "Epoch 192/1200\n",
            "876/876 [==============================] - 2s 2ms/step\n",
            "110/110 [==============================] - 3s 30ms/step - loss: 17.6383 - val_loss: 21.0931\n",
            "Epoch 193/1200\n",
            "876/876 [==============================] - 2s 2ms/step\n",
            "110/110 [==============================] - 3s 30ms/step - loss: 22.4939 - val_loss: 23.2851\n",
            "Epoch 194/1200\n",
            "876/876 [==============================] - 2s 3ms/step\n",
            "110/110 [==============================] - 6s 54ms/step - loss: 21.7431 - val_loss: 19.0616\n",
            "Epoch 195/1200\n",
            "876/876 [==============================] - 2s 2ms/step\n",
            "110/110 [==============================] - 3s 30ms/step - loss: 17.6953 - val_loss: 19.1985\n",
            "Epoch 196/1200\n",
            "876/876 [==============================] - 2s 2ms/step\n",
            "110/110 [==============================] - 6s 54ms/step - loss: 17.1453 - val_loss: 17.8802\n",
            "Epoch 197/1200\n",
            "876/876 [==============================] - 2s 3ms/step\n",
            "110/110 [==============================] - 4s 35ms/step - loss: 17.6330 - val_loss: 18.1483\n",
            "Epoch 198/1200\n",
            "876/876 [==============================] - 2s 2ms/step\n",
            "110/110 [==============================] - 3s 24ms/step - loss: 17.0602 - val_loss: 18.0133\n",
            "Epoch 199/1200\n",
            "876/876 [==============================] - 2s 2ms/step\n",
            "110/110 [==============================] - 3s 24ms/step - loss: 17.2133 - val_loss: 18.9737\n",
            "Epoch 200/1200\n",
            "876/876 [==============================] - 2s 2ms/step\n",
            "110/110 [==============================] - 3s 30ms/step - loss: 16.9113 - val_loss: 17.1364\n",
            "Epoch 201/1200\n",
            "876/876 [==============================] - 2s 3ms/step\n",
            "110/110 [==============================] - 6s 57ms/step - loss: 16.8553 - val_loss: 17.4901\n",
            "Epoch 202/1200\n",
            "876/876 [==============================] - 2s 2ms/step\n",
            "110/110 [==============================] - 3s 25ms/step - loss: 17.1933 - val_loss: 17.9395\n",
            "Epoch 203/1200\n",
            "876/876 [==============================] - 2s 2ms/step\n",
            "110/110 [==============================] - 3s 25ms/step - loss: 17.6846 - val_loss: 18.8446\n",
            "Epoch 204/1200\n",
            "876/876 [==============================] - 2s 2ms/step\n",
            "110/110 [==============================] - 3s 24ms/step - loss: 21.2445 - val_loss: 19.0022\n",
            "Epoch 205/1200\n",
            "876/876 [==============================] - 2s 2ms/step\n",
            "110/110 [==============================] - 3s 27ms/step - loss: 17.3076 - val_loss: 19.7500\n",
            "Epoch 206/1200\n",
            "876/876 [==============================] - 2s 3ms/step\n",
            "110/110 [==============================] - 6s 57ms/step - loss: 17.4224 - val_loss: 17.9721\n",
            "Epoch 207/1200\n",
            "876/876 [==============================] - 2s 2ms/step\n",
            "110/110 [==============================] - 3s 30ms/step - loss: 17.2287 - val_loss: 17.7225\n",
            "Epoch 208/1200\n",
            "876/876 [==============================] - 2s 2ms/step\n",
            "110/110 [==============================] - 3s 25ms/step - loss: 16.8615 - val_loss: 18.8913\n",
            "Epoch 209/1200\n",
            "876/876 [==============================] - 2s 2ms/step\n",
            "110/110 [==============================] - 3s 26ms/step - loss: 17.5554 - val_loss: 18.2010\n",
            "Epoch 210/1200\n",
            "876/876 [==============================] - 2s 3ms/step\n",
            "110/110 [==============================] - 4s 35ms/step - loss: 17.0896 - val_loss: 18.3648\n",
            "Epoch 211/1200\n",
            "876/876 [==============================] - 2s 2ms/step\n",
            "110/110 [==============================] - 3s 31ms/step - loss: 16.7536 - val_loss: 18.3334\n",
            "Epoch 212/1200\n",
            "876/876 [==============================] - 2s 2ms/step\n",
            "110/110 [==============================] - 3s 30ms/step - loss: 17.1168 - val_loss: 18.5610\n",
            "Epoch 213/1200\n",
            "876/876 [==============================] - 2s 2ms/step\n",
            "110/110 [==============================] - 3s 30ms/step - loss: 17.4074 - val_loss: 18.1856\n",
            "Epoch 214/1200\n",
            "876/876 [==============================] - 2s 3ms/step\n",
            "110/110 [==============================] - 6s 56ms/step - loss: 16.8526 - val_loss: 17.7761\n",
            "Epoch 215/1200\n",
            "876/876 [==============================] - 2s 2ms/step\n",
            "110/110 [==============================] - 3s 24ms/step - loss: 16.9863 - val_loss: 17.6685\n",
            "Epoch 216/1200\n",
            "876/876 [==============================] - 2s 2ms/step\n",
            "110/110 [==============================] - 3s 25ms/step - loss: 17.1490 - val_loss: 18.9829\n",
            "Epoch 217/1200\n",
            "876/876 [==============================] - 2s 2ms/step\n",
            "110/110 [==============================] - 3s 30ms/step - loss: 16.7421 - val_loss: 18.5371\n",
            "Epoch 218/1200\n",
            "876/876 [==============================] - 2s 3ms/step\n",
            "110/110 [==============================] - 4s 34ms/step - loss: 16.9565 - val_loss: 19.5358\n",
            "Epoch 219/1200\n",
            "876/876 [==============================] - 2s 2ms/step\n",
            "110/110 [==============================] - 3s 28ms/step - loss: 16.6828 - val_loss: 18.9175\n",
            "Epoch 220/1200\n",
            "876/876 [==============================] - 2s 2ms/step\n",
            "110/110 [==============================] - 3s 24ms/step - loss: 16.8462 - val_loss: 17.2598\n",
            "Epoch 221/1200\n",
            "876/876 [==============================] - 2s 2ms/step\n",
            "110/110 [==============================] - 3s 24ms/step - loss: 17.2148 - val_loss: 18.3008\n",
            "Epoch 222/1200\n",
            "876/876 [==============================] - 2s 2ms/step\n",
            "110/110 [==============================] - 3s 30ms/step - loss: 16.5292 - val_loss: 19.1103\n",
            "Epoch 223/1200\n",
            "876/876 [==============================] - 2s 3ms/step\n",
            "110/110 [==============================] - 4s 34ms/step - loss: 16.8995 - val_loss: 18.2478\n",
            "Epoch 224/1200\n",
            "876/876 [==============================] - 2s 2ms/step\n",
            "110/110 [==============================] - 4s 33ms/step - loss: 16.7959 - val_loss: 17.8963\n",
            "Epoch 225/1200\n",
            "876/876 [==============================] - 2s 2ms/step\n",
            "110/110 [==============================] - 3s 24ms/step - loss: 16.9992 - val_loss: 19.5162\n",
            "Epoch 226/1200\n",
            "876/876 [==============================] - 2s 2ms/step\n",
            "110/110 [==============================] - 3s 24ms/step - loss: 17.0171 - val_loss: 17.9709\n",
            "Epoch 227/1200\n",
            "876/876 [==============================] - 2s 2ms/step\n",
            "110/110 [==============================] - 3s 30ms/step - loss: 16.5438 - val_loss: 18.5896\n",
            "Epoch 228/1200\n",
            "876/876 [==============================] - 2s 3ms/step\n",
            "110/110 [==============================] - 4s 35ms/step - loss: 16.7456 - val_loss: 18.5186\n",
            "Epoch 229/1200\n",
            "876/876 [==============================] - 2s 2ms/step\n",
            "110/110 [==============================] - 3s 30ms/step - loss: 16.7098 - val_loss: 18.4553\n",
            "Epoch 230/1200\n",
            "876/876 [==============================] - 2s 2ms/step\n",
            "110/110 [==============================] - 3s 25ms/step - loss: 16.7756 - val_loss: 17.1956\n",
            "Epoch 231/1200\n",
            "876/876 [==============================] - 2s 2ms/step\n",
            "110/110 [==============================] - 3s 24ms/step - loss: 16.5478 - val_loss: 18.6302\n",
            "Epoch 232/1200\n",
            "876/876 [==============================] - 2s 2ms/step\n",
            "110/110 [==============================] - 3s 30ms/step - loss: 17.0991 - val_loss: 18.7375\n",
            "Epoch 233/1200\n",
            "876/876 [==============================] - 2s 3ms/step\n",
            "110/110 [==============================] - 6s 57ms/step - loss: 16.8151 - val_loss: 17.9488\n",
            "Epoch 234/1200\n",
            "876/876 [==============================] - 2s 2ms/step\n",
            "110/110 [==============================] - 3s 24ms/step - loss: 16.6368 - val_loss: 17.5935\n",
            "Epoch 235/1200\n",
            "876/876 [==============================] - 2s 2ms/step\n",
            "110/110 [==============================] - 3s 30ms/step - loss: 17.1123 - val_loss: 20.7362\n",
            "Epoch 236/1200\n",
            "876/876 [==============================] - 2s 2ms/step\n",
            "110/110 [==============================] - 3s 30ms/step - loss: 18.3794 - val_loss: 18.3777\n",
            "Epoch 237/1200\n",
            "876/876 [==============================] - 2s 3ms/step\n",
            "110/110 [==============================] - 4s 34ms/step - loss: 16.6450 - val_loss: 18.2537\n",
            "Epoch 238/1200\n",
            "876/876 [==============================] - 2s 2ms/step\n",
            "110/110 [==============================] - 3s 25ms/step - loss: 16.5235 - val_loss: 17.7573\n",
            "Epoch 239/1200\n",
            "876/876 [==============================] - 2s 2ms/step\n",
            "110/110 [==============================] - 3s 30ms/step - loss: 16.5814 - val_loss: 18.7038\n",
            "Epoch 240/1200\n",
            "876/876 [==============================] - 2s 2ms/step\n",
            "110/110 [==============================] - 3s 30ms/step - loss: 16.6576 - val_loss: 19.3636\n",
            "Epoch 241/1200\n",
            "876/876 [==============================] - 2s 3ms/step\n",
            "110/110 [==============================] - 6s 54ms/step - loss: 16.4910 - val_loss: 17.7881\n",
            "Epoch 242/1200\n",
            "876/876 [==============================] - 2s 2ms/step\n",
            "110/110 [==============================] - 3s 30ms/step - loss: 16.3295 - val_loss: 17.5074\n",
            "Epoch 243/1200\n",
            "876/876 [==============================] - 2s 2ms/step\n",
            "110/110 [==============================] - 3s 30ms/step - loss: 16.3363 - val_loss: 17.4985\n",
            "Epoch 244/1200\n",
            "876/876 [==============================] - 2s 2ms/step\n",
            "110/110 [==============================] - 3s 27ms/step - loss: 16.4819 - val_loss: 19.3856\n",
            "Epoch 245/1200\n",
            "876/876 [==============================] - 2s 3ms/step\n",
            "110/110 [==============================] - 6s 57ms/step - loss: 16.2778 - val_loss: 17.6520\n",
            "Epoch 246/1200\n",
            "876/876 [==============================] - 2s 2ms/step\n",
            "110/110 [==============================] - 3s 30ms/step - loss: 16.4897 - val_loss: 17.5943\n",
            "Epoch 247/1200\n",
            "876/876 [==============================] - 2s 2ms/step\n",
            "110/110 [==============================] - 3s 24ms/step - loss: 16.6493 - val_loss: 18.3809\n",
            "Epoch 248/1200\n",
            "876/876 [==============================] - 2s 2ms/step\n",
            "110/110 [==============================] - 3s 26ms/step - loss: 16.4325 - val_loss: 17.8658\n",
            "Epoch 249/1200\n",
            "876/876 [==============================] - 2s 3ms/step\n",
            "110/110 [==============================] - 4s 35ms/step - loss: 16.4938 - val_loss: 18.3655\n",
            "Epoch 250/1200\n",
            "876/876 [==============================] - 2s 2ms/step\n",
            "110/110 [==============================] - 3s 28ms/step - loss: 16.4465 - val_loss: 17.3915\n",
            "Epoch 251/1200\n",
            "876/876 [==============================] - 2s 2ms/step\n",
            "110/110 [==============================] - 3s 30ms/step - loss: 16.6916 - val_loss: 17.9192\n",
            "Epoch 252/1200\n",
            "876/876 [==============================] - 2s 2ms/step\n",
            "110/110 [==============================] - 3s 24ms/step - loss: 16.8508 - val_loss: 17.6294\n",
            "Epoch 253/1200\n",
            "876/876 [==============================] - 2s 2ms/step\n",
            "110/110 [==============================] - 3s 28ms/step - loss: 16.5176 - val_loss: 17.8886\n",
            "Epoch 254/1200\n",
            "876/876 [==============================] - 2s 3ms/step\n",
            "110/110 [==============================] - 4s 35ms/step - loss: 16.2645 - val_loss: 17.9094\n",
            "Epoch 255/1200\n",
            "876/876 [==============================] - 2s 2ms/step\n",
            "110/110 [==============================] - 3s 25ms/step - loss: 16.4808 - val_loss: 19.0802\n",
            "Epoch 256/1200\n",
            "876/876 [==============================] - 2s 2ms/step\n",
            "110/110 [==============================] - 3s 30ms/step - loss: 16.7491 - val_loss: 18.7300\n",
            "Epoch 257/1200\n",
            "876/876 [==============================] - 2s 2ms/step\n",
            "110/110 [==============================] - 3s 30ms/step - loss: 16.3070 - val_loss: 19.1288\n",
            "Epoch 258/1200\n",
            "876/876 [==============================] - 2s 2ms/step\n",
            "110/110 [==============================] - 3s 30ms/step - loss: 16.3995 - val_loss: 17.6639\n",
            "Epoch 259/1200\n",
            "876/876 [==============================] - 2s 3ms/step\n",
            "110/110 [==============================] - 4s 34ms/step - loss: 16.4578 - val_loss: 17.3192\n",
            "Epoch 260/1200\n",
            "876/876 [==============================] - 2s 2ms/step\n",
            "110/110 [==============================] - 3s 25ms/step - loss: 16.0689 - val_loss: 17.7385\n",
            "Epoch 261/1200\n",
            "876/876 [==============================] - 2s 2ms/step\n",
            "110/110 [==============================] - 3s 25ms/step - loss: 16.3808 - val_loss: 20.1716\n",
            "Epoch 262/1200\n",
            "876/876 [==============================] - 2s 2ms/step\n",
            "110/110 [==============================] - 3s 25ms/step - loss: 16.3702 - val_loss: 17.5611\n",
            "Epoch 263/1200\n",
            "876/876 [==============================] - 2s 2ms/step\n",
            "110/110 [==============================] - 3s 30ms/step - loss: 16.3069 - val_loss: 19.6245\n",
            "Epoch 264/1200\n",
            "876/876 [==============================] - 2s 3ms/step\n",
            "110/110 [==============================] - 4s 35ms/step - loss: 16.6355 - val_loss: 17.0810\n",
            "Epoch 265/1200\n",
            "876/876 [==============================] - 2s 2ms/step\n",
            "110/110 [==============================] - 3s 30ms/step - loss: 16.3255 - val_loss: 16.8232\n",
            "Epoch 266/1200\n",
            "876/876 [==============================] - 2s 2ms/step\n",
            "110/110 [==============================] - 3s 30ms/step - loss: 16.3923 - val_loss: 18.6725\n",
            "Epoch 267/1200\n",
            "876/876 [==============================] - 2s 2ms/step\n",
            "110/110 [==============================] - 3s 30ms/step - loss: 17.5404 - val_loss: 19.5692\n",
            "Epoch 268/1200\n",
            "876/876 [==============================] - 2s 3ms/step\n",
            "110/110 [==============================] - 4s 36ms/step - loss: 16.2406 - val_loss: 17.7605\n",
            "Epoch 269/1200\n",
            "876/876 [==============================] - 2s 2ms/step\n",
            "110/110 [==============================] - 3s 29ms/step - loss: 17.3958 - val_loss: 17.9046\n",
            "Epoch 270/1200\n",
            "876/876 [==============================] - 2s 2ms/step\n",
            "110/110 [==============================] - 3s 24ms/step - loss: 16.2582 - val_loss: 19.2370\n",
            "Epoch 271/1200\n",
            "876/876 [==============================] - 2s 2ms/step\n",
            "110/110 [==============================] - 3s 30ms/step - loss: 16.4512 - val_loss: 18.0144\n",
            "Epoch 272/1200\n",
            "876/876 [==============================] - 2s 2ms/step\n",
            "110/110 [==============================] - 6s 54ms/step - loss: 16.2575 - val_loss: 18.2591\n",
            "Epoch 273/1200\n",
            "876/876 [==============================] - 2s 2ms/step\n",
            "110/110 [==============================] - 4s 33ms/step - loss: 16.1068 - val_loss: 17.8329\n",
            "Epoch 274/1200\n",
            "876/876 [==============================] - 2s 2ms/step\n",
            "110/110 [==============================] - 3s 30ms/step - loss: 16.1430 - val_loss: 18.2540\n",
            "Epoch 275/1200\n",
            "876/876 [==============================] - 2s 2ms/step\n",
            "110/110 [==============================] - 3s 24ms/step - loss: 16.4681 - val_loss: 17.2044\n",
            "Epoch 276/1200\n",
            "876/876 [==============================] - 2s 2ms/step\n",
            "110/110 [==============================] - 3s 30ms/step - loss: 16.2199 - val_loss: 18.1451\n",
            "Epoch 277/1200\n",
            "876/876 [==============================] - 2s 3ms/step\n",
            "110/110 [==============================] - 4s 36ms/step - loss: 16.1545 - val_loss: 18.1504\n",
            "Epoch 278/1200\n",
            "876/876 [==============================] - 2s 2ms/step\n",
            "110/110 [==============================] - 4s 33ms/step - loss: 16.9135 - val_loss: 20.0623\n",
            "Epoch 279/1200\n",
            "876/876 [==============================] - 2s 3ms/step\n",
            "110/110 [==============================] - 6s 57ms/step - loss: 17.1013 - val_loss: 18.3240\n",
            "Epoch 280/1200\n",
            "876/876 [==============================] - 2s 2ms/step\n",
            "110/110 [==============================] - 3s 30ms/step - loss: 16.0753 - val_loss: 17.5012\n",
            "Epoch 281/1200\n",
            "876/876 [==============================] - 2s 3ms/step\n",
            "110/110 [==============================] - 4s 35ms/step - loss: 16.7355 - val_loss: 19.7769\n",
            "Epoch 282/1200\n",
            "876/876 [==============================] - 2s 2ms/step\n",
            "110/110 [==============================] - 3s 24ms/step - loss: 16.6947 - val_loss: 18.5103\n",
            "Epoch 283/1200\n",
            "876/876 [==============================] - 2s 2ms/step\n",
            "110/110 [==============================] - 3s 25ms/step - loss: 16.2443 - val_loss: 18.1777\n",
            "Epoch 284/1200\n",
            "876/876 [==============================] - 2s 2ms/step\n",
            "110/110 [==============================] - 3s 30ms/step - loss: 15.9484 - val_loss: 18.1492\n",
            "Epoch 285/1200\n",
            "876/876 [==============================] - 2s 2ms/step\n",
            "110/110 [==============================] - 3s 30ms/step - loss: 16.2081 - val_loss: 17.4953\n",
            "Epoch 286/1200\n",
            "876/876 [==============================] - 2s 3ms/step\n",
            "110/110 [==============================] - 6s 57ms/step - loss: 16.0617 - val_loss: 18.2062\n",
            "Epoch 287/1200\n",
            "876/876 [==============================] - 2s 2ms/step\n",
            "110/110 [==============================] - 3s 30ms/step - loss: 16.1032 - val_loss: 18.9161\n",
            "Epoch 288/1200\n",
            "876/876 [==============================] - 2s 2ms/step\n",
            "110/110 [==============================] - 3s 30ms/step - loss: 16.1544 - val_loss: 17.5489\n",
            "Epoch 289/1200\n",
            "876/876 [==============================] - 2s 3ms/step\n",
            "110/110 [==============================] - 3s 31ms/step - loss: 16.0004 - val_loss: 19.8002\n",
            "Epoch 290/1200\n",
            "876/876 [==============================] - 2s 3ms/step\n",
            "110/110 [==============================] - 4s 34ms/step - loss: 16.5400 - val_loss: 18.0044\n",
            "Epoch 291/1200\n",
            "876/876 [==============================] - 2s 2ms/step\n",
            "110/110 [==============================] - 3s 25ms/step - loss: 16.2898 - val_loss: 18.0665\n",
            "Epoch 292/1200\n",
            "876/876 [==============================] - 2s 2ms/step\n",
            "110/110 [==============================] - 3s 25ms/step - loss: 15.9942 - val_loss: 21.2566\n",
            "Epoch 293/1200\n",
            "876/876 [==============================] - 2s 2ms/step\n",
            "110/110 [==============================] - 3s 25ms/step - loss: 16.8969 - val_loss: 17.1760\n",
            "Epoch 294/1200\n",
            "876/876 [==============================] - 2s 3ms/step\n",
            "110/110 [==============================] - 6s 55ms/step - loss: 16.3335 - val_loss: 17.4495\n",
            "Epoch 295/1200\n",
            "876/876 [==============================] - 2s 2ms/step\n",
            "110/110 [==============================] - 3s 30ms/step - loss: 16.0470 - val_loss: 18.3980\n",
            "Epoch 296/1200\n",
            "876/876 [==============================] - 2s 2ms/step\n",
            "110/110 [==============================] - 3s 30ms/step - loss: 15.9448 - val_loss: 17.7005\n",
            "Epoch 297/1200\n",
            "876/876 [==============================] - 2s 2ms/step\n",
            "110/110 [==============================] - 3s 30ms/step - loss: 16.0852 - val_loss: 17.3869\n",
            "Epoch 298/1200\n",
            "876/876 [==============================] - 2s 3ms/step\n",
            "110/110 [==============================] - 6s 57ms/step - loss: 16.7807 - val_loss: 18.4778\n",
            "Epoch 299/1200\n",
            "876/876 [==============================] - 2s 2ms/step\n",
            "110/110 [==============================] - 3s 24ms/step - loss: 16.2820 - val_loss: 17.8509\n",
            "Epoch 300/1200\n",
            "876/876 [==============================] - 2s 2ms/step\n",
            "110/110 [==============================] - 3s 25ms/step - loss: 15.8526 - val_loss: 17.8829\n",
            "Epoch 301/1200\n",
            "876/876 [==============================] - 2s 2ms/step\n",
            "110/110 [==============================] - 3s 25ms/step - loss: 15.8595 - val_loss: 16.7300\n",
            "Epoch 302/1200\n",
            "876/876 [==============================] - 2s 3ms/step\n",
            "110/110 [==============================] - 6s 57ms/step - loss: 16.5499 - val_loss: 17.4380\n",
            "Epoch 303/1200\n",
            "876/876 [==============================] - 3s 3ms/step\n",
            "110/110 [==============================] - 4s 39ms/step - loss: 16.3950 - val_loss: 18.3523\n",
            "Epoch 304/1200\n",
            "876/876 [==============================] - 2s 2ms/step\n",
            "110/110 [==============================] - 3s 29ms/step - loss: 15.9644 - val_loss: 18.1109\n",
            "Epoch 305/1200\n",
            "876/876 [==============================] - 2s 3ms/step\n",
            "110/110 [==============================] - 3s 31ms/step - loss: 15.7967 - val_loss: 18.3323\n",
            "Epoch 306/1200\n",
            "876/876 [==============================] - 2s 3ms/step\n",
            "110/110 [==============================] - 6s 57ms/step - loss: 15.8844 - val_loss: 17.9199\n",
            "Epoch 307/1200\n",
            "876/876 [==============================] - 2s 2ms/step\n",
            "110/110 [==============================] - 3s 25ms/step - loss: 18.0373 - val_loss: 18.7858\n",
            "Epoch 308/1200\n",
            "876/876 [==============================] - 2s 2ms/step\n",
            "110/110 [==============================] - 3s 31ms/step - loss: 16.7442 - val_loss: 19.7679\n",
            "Epoch 309/1200\n",
            "876/876 [==============================] - 2s 3ms/step\n",
            "110/110 [==============================] - 6s 54ms/step - loss: 16.0480 - val_loss: 17.5405\n",
            "Epoch 310/1200\n",
            "876/876 [==============================] - 2s 2ms/step\n",
            "110/110 [==============================] - 3s 25ms/step - loss: 16.0142 - val_loss: 18.3018\n",
            "Epoch 311/1200\n",
            "876/876 [==============================] - 2s 2ms/step\n",
            "110/110 [==============================] - 3s 30ms/step - loss: 15.9303 - val_loss: 18.2536\n",
            "Epoch 312/1200\n",
            "876/876 [==============================] - 2s 2ms/step\n",
            "110/110 [==============================] - 3s 30ms/step - loss: 15.7109 - val_loss: 18.4634\n",
            "Epoch 313/1200\n",
            "876/876 [==============================] - 2s 3ms/step\n",
            "110/110 [==============================] - 4s 35ms/step - loss: 16.2717 - val_loss: 17.3656\n",
            "Epoch 314/1200\n",
            "876/876 [==============================] - 2s 2ms/step\n",
            "110/110 [==============================] - 4s 33ms/step - loss: 16.0874 - val_loss: 17.8779\n",
            "Epoch 315/1200\n",
            "876/876 [==============================] - 2s 2ms/step\n",
            "110/110 [==============================] - 3s 30ms/step - loss: 16.0820 - val_loss: 16.9262\n",
            "Epoch 316/1200\n",
            "876/876 [==============================] - 2s 2ms/step\n",
            "110/110 [==============================] - 3s 25ms/step - loss: 15.8179 - val_loss: 17.6373\n",
            "Epoch 317/1200\n",
            "876/876 [==============================] - 2s 2ms/step\n",
            "110/110 [==============================] - 3s 30ms/step - loss: 15.7959 - val_loss: 18.8328\n",
            "Epoch 318/1200\n",
            "876/876 [==============================] - 2s 3ms/step\n",
            "110/110 [==============================] - 4s 35ms/step - loss: 15.8058 - val_loss: 19.3735\n",
            "Epoch 319/1200\n",
            "876/876 [==============================] - 2s 2ms/step\n",
            "110/110 [==============================] - 3s 25ms/step - loss: 15.8918 - val_loss: 18.9043\n",
            "Epoch 320/1200\n",
            "876/876 [==============================] - 2s 2ms/step\n",
            "110/110 [==============================] - 3s 25ms/step - loss: 16.1364 - val_loss: 16.7431\n",
            "Epoch 321/1200\n",
            "876/876 [==============================] - 2s 2ms/step\n",
            "110/110 [==============================] - 3s 25ms/step - loss: 17.3570 - val_loss: 18.3370\n",
            "Epoch 322/1200\n",
            "876/876 [==============================] - 2s 2ms/step\n",
            "110/110 [==============================] - 3s 30ms/step - loss: 15.8097 - val_loss: 18.0105\n",
            "Epoch 323/1200\n",
            "876/876 [==============================] - 2s 3ms/step\n",
            "110/110 [==============================] - 6s 56ms/step - loss: 15.9130 - val_loss: 18.7930\n",
            "Epoch 324/1200\n",
            "876/876 [==============================] - 2s 2ms/step\n",
            "110/110 [==============================] - 4s 33ms/step - loss: 15.7288 - val_loss: 17.8727\n",
            "Epoch 325/1200\n",
            "876/876 [==============================] - 2s 2ms/step\n",
            "110/110 [==============================] - 3s 30ms/step - loss: 15.6812 - val_loss: 18.3113\n",
            "Epoch 326/1200\n",
            "876/876 [==============================] - 2s 3ms/step\n",
            "110/110 [==============================] - 6s 54ms/step - loss: 16.1812 - val_loss: 17.3544\n",
            "Epoch 327/1200\n",
            "876/876 [==============================] - 2s 2ms/step\n",
            "110/110 [==============================] - 3s 30ms/step - loss: 16.0953 - val_loss: 17.8251\n",
            "Epoch 328/1200\n",
            "876/876 [==============================] - 2s 2ms/step\n",
            "110/110 [==============================] - 3s 30ms/step - loss: 15.7081 - val_loss: 19.4397\n",
            "Epoch 329/1200\n",
            "876/876 [==============================] - 2s 2ms/step\n",
            "110/110 [==============================] - 3s 30ms/step - loss: 15.6431 - val_loss: 17.9714\n",
            "Epoch 330/1200\n",
            "876/876 [==============================] - 2s 3ms/step\n",
            "110/110 [==============================] - 6s 57ms/step - loss: 15.9595 - val_loss: 17.6138\n",
            "Epoch 331/1200\n",
            "876/876 [==============================] - 2s 2ms/step\n",
            "110/110 [==============================] - 3s 24ms/step - loss: 16.0498 - val_loss: 18.4944\n",
            "Epoch 332/1200\n",
            "876/876 [==============================] - 2s 2ms/step\n",
            "110/110 [==============================] - 3s 25ms/step - loss: 15.8352 - val_loss: 16.5777\n",
            "Epoch 333/1200\n",
            "876/876 [==============================] - 2s 2ms/step\n",
            "110/110 [==============================] - 3s 25ms/step - loss: 15.9733 - val_loss: 16.7714\n",
            "Epoch 334/1200\n",
            "876/876 [==============================] - 2s 3ms/step\n",
            "110/110 [==============================] - 6s 57ms/step - loss: 15.7172 - val_loss: 17.7752\n",
            "Epoch 335/1200\n",
            "876/876 [==============================] - 2s 3ms/step\n",
            "110/110 [==============================] - 4s 33ms/step - loss: 16.0682 - val_loss: 17.5766\n",
            "Epoch 336/1200\n",
            "876/876 [==============================] - 2s 2ms/step\n",
            "110/110 [==============================] - 3s 32ms/step - loss: 16.3875 - val_loss: 17.7802\n",
            "Epoch 337/1200\n",
            "876/876 [==============================] - 2s 2ms/step\n",
            "110/110 [==============================] - 3s 30ms/step - loss: 15.8108 - val_loss: 17.1014\n",
            "Epoch 338/1200\n",
            "876/876 [==============================] - 2s 3ms/step\n",
            "110/110 [==============================] - 4s 36ms/step - loss: 16.0525 - val_loss: 17.6895\n",
            "Epoch 339/1200\n",
            "876/876 [==============================] - 2s 2ms/step\n",
            "110/110 [==============================] - 3s 25ms/step - loss: 15.5120 - val_loss: 17.3503\n",
            "Epoch 340/1200\n",
            "876/876 [==============================] - 2s 2ms/step\n",
            "110/110 [==============================] - 3s 25ms/step - loss: 15.8084 - val_loss: 19.0483\n",
            "Epoch 341/1200\n",
            "876/876 [==============================] - 2s 2ms/step\n",
            "110/110 [==============================] - 3s 26ms/step - loss: 15.7191 - val_loss: 17.4018\n",
            "Epoch 342/1200\n",
            "876/876 [==============================] - 2s 2ms/step\n",
            "110/110 [==============================] - 3s 29ms/step - loss: 16.0300 - val_loss: 17.3496\n",
            "Epoch 343/1200\n",
            "876/876 [==============================] - 2s 3ms/step\n",
            "110/110 [==============================] - 6s 56ms/step - loss: 15.7323 - val_loss: 17.2831\n",
            "Epoch 344/1200\n",
            "876/876 [==============================] - 2s 2ms/step\n",
            "110/110 [==============================] - 3s 26ms/step - loss: 15.5912 - val_loss: 16.8191\n",
            "Epoch 345/1200\n",
            "876/876 [==============================] - 2s 2ms/step\n",
            "110/110 [==============================] - 3s 30ms/step - loss: 15.6929 - val_loss: 18.3347\n",
            "Epoch 346/1200\n",
            "876/876 [==============================] - 2s 2ms/step\n",
            "110/110 [==============================] - 3s 30ms/step - loss: 15.6800 - val_loss: 18.1573\n",
            "Epoch 347/1200\n",
            "876/876 [==============================] - 2s 3ms/step\n",
            "110/110 [==============================] - 6s 58ms/step - loss: 15.8313 - val_loss: 18.1428\n",
            "Epoch 348/1200\n",
            "876/876 [==============================] - 2s 2ms/step\n",
            "110/110 [==============================] - 3s 25ms/step - loss: 15.6046 - val_loss: 17.8936\n",
            "Epoch 349/1200\n",
            "876/876 [==============================] - 2s 2ms/step\n",
            "110/110 [==============================] - 3s 25ms/step - loss: 15.8209 - val_loss: 18.3681\n",
            "Epoch 350/1200\n",
            "876/876 [==============================] - 2s 2ms/step\n",
            "110/110 [==============================] - 3s 30ms/step - loss: 15.9087 - val_loss: 17.9924\n",
            "Epoch 351/1200\n",
            "876/876 [==============================] - 2s 3ms/step\n",
            "110/110 [==============================] - 4s 36ms/step - loss: 15.8593 - val_loss: 17.4819\n",
            "Epoch 352/1200\n",
            "876/876 [==============================] - 2s 2ms/step\n",
            "110/110 [==============================] - 3s 26ms/step - loss: 15.7183 - val_loss: 18.8649\n",
            "Epoch 353/1200\n",
            "876/876 [==============================] - 2s 2ms/step\n",
            "110/110 [==============================] - 3s 25ms/step - loss: 16.2973 - val_loss: 17.1460\n",
            "Epoch 354/1200\n",
            "876/876 [==============================] - 3s 3ms/step\n",
            "110/110 [==============================] - 6s 57ms/step - loss: 19.6192 - val_loss: 20.1613\n",
            "Epoch 355/1200\n",
            "876/876 [==============================] - 2s 3ms/step\n",
            "110/110 [==============================] - 4s 33ms/step - loss: 16.6095 - val_loss: 19.8986\n",
            "Epoch 356/1200\n",
            "876/876 [==============================] - 2s 2ms/step\n",
            "110/110 [==============================] - 3s 30ms/step - loss: 16.0048 - val_loss: 18.0686\n",
            "Epoch 357/1200\n",
            "876/876 [==============================] - 2s 2ms/step\n",
            "110/110 [==============================] - 3s 25ms/step - loss: 15.8856 - val_loss: 17.8040\n",
            "Epoch 358/1200\n",
            "876/876 [==============================] - 2s 2ms/step\n",
            "110/110 [==============================] - 3s 30ms/step - loss: 15.7270 - val_loss: 18.2960\n",
            "Epoch 359/1200\n",
            "876/876 [==============================] - 2s 3ms/step\n",
            "110/110 [==============================] - 4s 34ms/step - loss: 16.1944 - val_loss: 18.4244\n",
            "Epoch 360/1200\n",
            "876/876 [==============================] - 2s 2ms/step\n",
            "110/110 [==============================] - 3s 29ms/step - loss: 15.6603 - val_loss: 18.0333\n",
            "Epoch 361/1200\n",
            "876/876 [==============================] - 2s 2ms/step\n",
            "110/110 [==============================] - 3s 25ms/step - loss: 15.7977 - val_loss: 18.2159\n",
            "Epoch 362/1200\n",
            "876/876 [==============================] - 2s 2ms/step\n",
            "110/110 [==============================] - 3s 30ms/step - loss: 15.8760 - val_loss: 18.3812\n",
            "Epoch 363/1200\n",
            "876/876 [==============================] - 2s 2ms/step\n",
            "110/110 [==============================] - 3s 31ms/step - loss: 15.5865 - val_loss: 17.5721\n",
            "Epoch 364/1200\n",
            "876/876 [==============================] - 2s 3ms/step\n",
            "110/110 [==============================] - 4s 36ms/step - loss: 15.6990 - val_loss: 19.0038\n",
            "Epoch 365/1200\n",
            "876/876 [==============================] - 2s 2ms/step\n",
            "110/110 [==============================] - 4s 32ms/step - loss: 15.7051 - val_loss: 18.1972\n",
            "Epoch 366/1200\n",
            "876/876 [==============================] - 2s 2ms/step\n",
            "110/110 [==============================] - 3s 31ms/step - loss: 15.6808 - val_loss: 17.0854\n",
            "Epoch 367/1200\n",
            "876/876 [==============================] - 2s 2ms/step\n",
            "110/110 [==============================] - 3s 25ms/step - loss: 15.9414 - val_loss: 16.9777\n",
            "Epoch 368/1200\n",
            "876/876 [==============================] - 2s 3ms/step\n",
            "110/110 [==============================] - 6s 55ms/step - loss: 15.9427 - val_loss: 18.3948\n",
            "Epoch 369/1200\n",
            "876/876 [==============================] - 2s 2ms/step\n",
            "110/110 [==============================] - 3s 30ms/step - loss: 15.8647 - val_loss: 17.3861\n",
            "Epoch 370/1200\n",
            "876/876 [==============================] - 2s 2ms/step\n",
            "110/110 [==============================] - 3s 25ms/step - loss: 15.7293 - val_loss: 17.6021\n",
            "Epoch 371/1200\n",
            "876/876 [==============================] - 2s 2ms/step\n",
            "110/110 [==============================] - 3s 26ms/step - loss: 15.9564 - val_loss: 17.2836\n",
            "Epoch 372/1200\n",
            "876/876 [==============================] - 2s 3ms/step\n",
            "110/110 [==============================] - 6s 57ms/step - loss: 16.1668 - val_loss: 18.9986\n",
            "Epoch 373/1200\n",
            "876/876 [==============================] - 2s 2ms/step\n",
            "110/110 [==============================] - 3s 30ms/step - loss: 15.7701 - val_loss: 17.1195\n",
            "Epoch 374/1200\n",
            "876/876 [==============================] - 2s 2ms/step\n",
            "110/110 [==============================] - 3s 25ms/step - loss: 15.6594 - val_loss: 17.8202\n",
            "Epoch 375/1200\n",
            "876/876 [==============================] - 2s 2ms/step\n",
            "110/110 [==============================] - 3s 30ms/step - loss: 15.8037 - val_loss: 17.6394\n",
            "Epoch 376/1200\n",
            "876/876 [==============================] - 2s 3ms/step\n",
            "110/110 [==============================] - 6s 57ms/step - loss: 15.5259 - val_loss: 17.2875\n",
            "Epoch 377/1200\n",
            "876/876 [==============================] - 2s 2ms/step\n",
            "110/110 [==============================] - 3s 27ms/step - loss: 15.8344 - val_loss: 17.2884\n",
            "Epoch 378/1200\n",
            "876/876 [==============================] - 2s 2ms/step\n",
            "110/110 [==============================] - 3s 26ms/step - loss: 15.9624 - val_loss: 17.2945\n",
            "Epoch 379/1200\n",
            "876/876 [==============================] - 2s 2ms/step\n",
            "110/110 [==============================] - 3s 27ms/step - loss: 15.6218 - val_loss: 17.8318\n",
            "Epoch 380/1200\n",
            "876/876 [==============================] - 2s 3ms/step\n",
            "110/110 [==============================] - 6s 57ms/step - loss: 15.7555 - val_loss: 18.4323\n",
            "Epoch 381/1200\n",
            "876/876 [==============================] - 2s 2ms/step\n",
            "110/110 [==============================] - 3s 26ms/step - loss: 19.7302 - val_loss: 24.8034\n",
            "Epoch 382/1200\n",
            "876/876 [==============================] - 2s 2ms/step\n",
            "110/110 [==============================] - 3s 30ms/step - loss: 23.4567 - val_loss: 23.6300\n",
            "Epoch 383/1200\n",
            "876/876 [==============================] - 2s 2ms/step\n",
            "110/110 [==============================] - 3s 28ms/step - loss: 21.2539 - val_loss: 19.6855\n",
            "Epoch 384/1200\n",
            "876/876 [==============================] - 2s 3ms/step\n",
            "110/110 [==============================] - 6s 57ms/step - loss: 15.9718 - val_loss: 18.5974\n",
            "Epoch 385/1200\n",
            "876/876 [==============================] - 2s 2ms/step\n",
            "110/110 [==============================] - 3s 25ms/step - loss: 15.7993 - val_loss: 18.1970\n",
            "Epoch 386/1200\n",
            "876/876 [==============================] - 2s 2ms/step\n",
            "110/110 [==============================] - 3s 25ms/step - loss: 15.5110 - val_loss: 17.8687\n",
            "Epoch 387/1200\n",
            "876/876 [==============================] - 2s 2ms/step\n",
            "110/110 [==============================] - 3s 26ms/step - loss: 16.3380 - val_loss: 17.7110\n",
            "Epoch 388/1200\n",
            "876/876 [==============================] - 2s 3ms/step\n",
            "110/110 [==============================] - 6s 57ms/step - loss: 15.6906 - val_loss: 17.8172\n",
            "Epoch 389/1200\n",
            "876/876 [==============================] - 2s 2ms/step\n",
            "110/110 [==============================] - 3s 30ms/step - loss: 16.6450 - val_loss: 18.3321\n",
            "Epoch 390/1200\n",
            "876/876 [==============================] - 2s 2ms/step\n",
            "110/110 [==============================] - 3s 30ms/step - loss: 17.0322 - val_loss: 21.7488\n",
            "Epoch 391/1200\n",
            "876/876 [==============================] - 2s 2ms/step\n",
            "110/110 [==============================] - 3s 30ms/step - loss: 15.4432 - val_loss: 18.5549\n",
            "Epoch 392/1200\n",
            "876/876 [==============================] - 2s 3ms/step\n",
            "110/110 [==============================] - 4s 35ms/step - loss: 15.5654 - val_loss: 18.3417\n",
            "Epoch 393/1200\n",
            "876/876 [==============================] - 2s 2ms/step\n",
            "110/110 [==============================] - 3s 31ms/step - loss: 15.8750 - val_loss: 19.2064\n",
            "Epoch 394/1200\n",
            "876/876 [==============================] - 2s 2ms/step\n",
            "110/110 [==============================] - 3s 25ms/step - loss: 15.4444 - val_loss: 17.5291\n",
            "Epoch 395/1200\n",
            "876/876 [==============================] - 2s 2ms/step\n",
            "110/110 [==============================] - 3s 30ms/step - loss: 15.7206 - val_loss: 17.7814\n",
            "Epoch 396/1200\n",
            "876/876 [==============================] - 2s 3ms/step\n",
            "110/110 [==============================] - 4s 33ms/step - loss: 15.8243 - val_loss: 17.6213\n",
            "Epoch 397/1200\n",
            "876/876 [==============================] - 2s 3ms/step\n",
            "110/110 [==============================] - 4s 35ms/step - loss: 15.5745 - val_loss: 19.1031\n",
            "Epoch 398/1200\n",
            "876/876 [==============================] - 2s 2ms/step\n",
            "110/110 [==============================] - 3s 31ms/step - loss: 15.5101 - val_loss: 17.6665\n",
            "Epoch 399/1200\n",
            "876/876 [==============================] - 2s 2ms/step\n",
            "110/110 [==============================] - 3s 26ms/step - loss: 15.6278 - val_loss: 17.6199\n",
            "Epoch 400/1200\n",
            "876/876 [==============================] - 2s 3ms/step\n",
            "110/110 [==============================] - 6s 54ms/step - loss: 15.4022 - val_loss: 18.7457\n",
            "Epoch 401/1200\n",
            "876/876 [==============================] - 2s 3ms/step\n",
            "110/110 [==============================] - 6s 57ms/step - loss: 15.6738 - val_loss: 18.2441\n",
            "Epoch 402/1200\n",
            "876/876 [==============================] - 2s 2ms/step\n",
            "110/110 [==============================] - 3s 26ms/step - loss: 15.8887 - val_loss: 18.2423\n",
            "Epoch 403/1200\n",
            "876/876 [==============================] - 2s 2ms/step\n",
            "110/110 [==============================] - 3s 25ms/step - loss: 15.8319 - val_loss: 17.8398\n",
            "Epoch 404/1200\n",
            "876/876 [==============================] - 2s 2ms/step\n",
            "110/110 [==============================] - 3s 29ms/step - loss: 15.7103 - val_loss: 18.3496\n",
            "Epoch 405/1200\n",
            "876/876 [==============================] - 2s 3ms/step\n",
            "110/110 [==============================] - 4s 36ms/step - loss: 16.1941 - val_loss: 19.8003\n",
            "Epoch 406/1200\n",
            "876/876 [==============================] - 2s 2ms/step\n",
            "110/110 [==============================] - 3s 32ms/step - loss: 15.5861 - val_loss: 18.3176\n",
            "Epoch 407/1200\n",
            "876/876 [==============================] - 2s 2ms/step\n",
            "110/110 [==============================] - 3s 25ms/step - loss: 15.8511 - val_loss: 17.3587\n",
            "Epoch 408/1200\n",
            "876/876 [==============================] - 2s 2ms/step\n",
            "110/110 [==============================] - 3s 25ms/step - loss: 15.5177 - val_loss: 17.7099\n",
            "Epoch 409/1200\n",
            "876/876 [==============================] - 2s 2ms/step\n",
            "110/110 [==============================] - 3s 31ms/step - loss: 15.4797 - val_loss: 18.1579\n",
            "Epoch 410/1200\n",
            "876/876 [==============================] - 2s 3ms/step\n",
            "110/110 [==============================] - 6s 56ms/step - loss: 15.6042 - val_loss: 18.2595\n",
            "Epoch 411/1200\n",
            "876/876 [==============================] - 2s 2ms/step\n",
            "110/110 [==============================] - 3s 26ms/step - loss: 15.7208 - val_loss: 18.2210\n",
            "Epoch 412/1200\n",
            "876/876 [==============================] - 2s 2ms/step\n",
            "110/110 [==============================] - 3s 26ms/step - loss: 15.9576 - val_loss: 18.1278\n",
            "Epoch 413/1200\n",
            "876/876 [==============================] - 2s 2ms/step\n",
            "110/110 [==============================] - 3s 30ms/step - loss: 15.4924 - val_loss: 17.1871\n",
            "Epoch 414/1200\n",
            "876/876 [==============================] - 2s 3ms/step\n",
            "110/110 [==============================] - 6s 57ms/step - loss: 15.8913 - val_loss: 17.7070\n",
            "Epoch 415/1200\n",
            "876/876 [==============================] - 2s 2ms/step\n",
            "110/110 [==============================] - 3s 30ms/step - loss: 15.4443 - val_loss: 17.6285\n",
            "Epoch 416/1200\n",
            "876/876 [==============================] - 2s 2ms/step\n",
            "110/110 [==============================] - 3s 25ms/step - loss: 15.5696 - val_loss: 17.4859\n",
            "Epoch 417/1200\n",
            "876/876 [==============================] - 2s 2ms/step\n",
            "110/110 [==============================] - 3s 30ms/step - loss: 15.4827 - val_loss: 17.2401\n",
            "Epoch 418/1200\n",
            "876/876 [==============================] - 2s 3ms/step\n",
            "110/110 [==============================] - 4s 35ms/step - loss: 15.9157 - val_loss: 16.9620\n",
            "Epoch 419/1200\n",
            "876/876 [==============================] - 2s 2ms/step\n",
            "110/110 [==============================] - 3s 31ms/step - loss: 15.3541 - val_loss: 17.7025\n",
            "Epoch 420/1200\n",
            "876/876 [==============================] - 2s 2ms/step\n",
            "110/110 [==============================] - 3s 30ms/step - loss: 15.4244 - val_loss: 17.6505\n",
            "Epoch 421/1200\n",
            "876/876 [==============================] - 2s 2ms/step\n",
            "110/110 [==============================] - 3s 25ms/step - loss: 15.4442 - val_loss: 16.9275\n",
            "Epoch 422/1200\n",
            "876/876 [==============================] - 2s 3ms/step\n",
            "110/110 [==============================] - 4s 32ms/step - loss: 15.5598 - val_loss: 17.6685\n",
            "Epoch 423/1200\n",
            "876/876 [==============================] - 2s 3ms/step\n",
            "110/110 [==============================] - 6s 57ms/step - loss: 15.2690 - val_loss: 17.9141\n",
            "Epoch 424/1200\n",
            "876/876 [==============================] - 2s 2ms/step\n",
            "110/110 [==============================] - 3s 25ms/step - loss: 15.4496 - val_loss: 18.6040\n",
            "Epoch 425/1200\n",
            "876/876 [==============================] - 2s 2ms/step\n",
            "110/110 [==============================] - 3s 26ms/step - loss: 15.4362 - val_loss: 17.8757\n",
            "Epoch 426/1200\n",
            "876/876 [==============================] - 2s 2ms/step\n",
            "110/110 [==============================] - 3s 30ms/step - loss: 15.9262 - val_loss: 17.7825\n",
            "Epoch 427/1200\n",
            "876/876 [==============================] - 2s 3ms/step\n",
            "110/110 [==============================] - 4s 35ms/step - loss: 15.4740 - val_loss: 18.1689\n",
            "Epoch 428/1200\n",
            "876/876 [==============================] - 2s 2ms/step\n",
            "110/110 [==============================] - 3s 27ms/step - loss: 15.2075 - val_loss: 17.7255\n",
            "Epoch 429/1200\n",
            "876/876 [==============================] - 2s 3ms/step\n",
            "110/110 [==============================] - 6s 54ms/step - loss: 15.8066 - val_loss: 18.1064\n",
            "Epoch 430/1200\n",
            "876/876 [==============================] - 2s 2ms/step\n",
            "110/110 [==============================] - 3s 31ms/step - loss: 15.7750 - val_loss: 18.1910\n",
            "Epoch 431/1200\n",
            "876/876 [==============================] - 2s 3ms/step\n",
            "110/110 [==============================] - 6s 56ms/step - loss: 16.1960 - val_loss: 17.4517\n",
            "Epoch 432/1200\n",
            "876/876 [==============================] - 2s 2ms/step\n",
            "110/110 [==============================] - 3s 30ms/step - loss: 15.2820 - val_loss: 18.1436\n",
            "Epoch 433/1200\n",
            "876/876 [==============================] - 2s 2ms/step\n",
            "110/110 [==============================] - 3s 30ms/step - loss: 15.9392 - val_loss: 19.1435\n",
            "Epoch 434/1200\n",
            "876/876 [==============================] - 2s 3ms/step\n",
            "110/110 [==============================] - 6s 54ms/step - loss: 16.4124 - val_loss: 17.8988\n",
            "Epoch 435/1200\n",
            "876/876 [==============================] - 2s 2ms/step\n",
            "110/110 [==============================] - 3s 30ms/step - loss: 15.5407 - val_loss: 17.5261\n",
            "Epoch 436/1200\n",
            "876/876 [==============================] - 2s 2ms/step\n",
            "110/110 [==============================] - 3s 26ms/step - loss: 15.4943 - val_loss: 18.2174\n",
            "Epoch 437/1200\n",
            "876/876 [==============================] - 2s 2ms/step\n",
            "110/110 [==============================] - 3s 31ms/step - loss: 15.1164 - val_loss: 17.6563\n",
            "Epoch 438/1200\n",
            "876/876 [==============================] - 2s 3ms/step\n",
            "110/110 [==============================] - 6s 57ms/step - loss: 15.3068 - val_loss: 18.6780\n",
            "Epoch 439/1200\n",
            "876/876 [==============================] - 2s 2ms/step\n",
            "110/110 [==============================] - 3s 30ms/step - loss: 17.0048 - val_loss: 24.1031\n",
            "Epoch 440/1200\n",
            "876/876 [==============================] - 2s 2ms/step\n",
            "110/110 [==============================] - 3s 26ms/step - loss: 23.2159 - val_loss: 23.7332\n",
            "Epoch 441/1200\n",
            "876/876 [==============================] - 2s 2ms/step\n",
            "110/110 [==============================] - 3s 30ms/step - loss: 20.2716 - val_loss: 18.1511\n",
            "Epoch 442/1200\n",
            "876/876 [==============================] - 2s 3ms/step\n",
            "110/110 [==============================] - 4s 35ms/step - loss: 15.7780 - val_loss: 17.6793\n",
            "Epoch 443/1200\n",
            "876/876 [==============================] - 2s 2ms/step\n",
            "110/110 [==============================] - 3s 28ms/step - loss: 15.1311 - val_loss: 16.8869\n",
            "Epoch 444/1200\n",
            "876/876 [==============================] - 2s 2ms/step\n",
            "110/110 [==============================] - 3s 30ms/step - loss: 15.5218 - val_loss: 19.8183\n",
            "Epoch 445/1200\n",
            "876/876 [==============================] - 2s 2ms/step\n",
            "110/110 [==============================] - 3s 30ms/step - loss: 15.8089 - val_loss: 18.5980\n",
            "Epoch 446/1200\n",
            "876/876 [==============================] - 2s 2ms/step\n",
            "110/110 [==============================] - 3s 30ms/step - loss: 15.4856 - val_loss: 17.6807\n",
            "Epoch 447/1200\n",
            "876/876 [==============================] - 2s 3ms/step\n",
            "110/110 [==============================] - 6s 57ms/step - loss: 15.2632 - val_loss: 17.3333\n",
            "Epoch 448/1200\n",
            "876/876 [==============================] - 2s 2ms/step\n",
            "110/110 [==============================] - 3s 30ms/step - loss: 15.4511 - val_loss: 16.8306\n",
            "Epoch 449/1200\n",
            "876/876 [==============================] - 2s 2ms/step\n",
            "110/110 [==============================] - 3s 30ms/step - loss: 15.3886 - val_loss: 17.7648\n",
            "Epoch 450/1200\n",
            "876/876 [==============================] - 2s 2ms/step\n",
            "110/110 [==============================] - 6s 54ms/step - loss: 15.1631 - val_loss: 17.0626\n",
            "Epoch 451/1200\n",
            "876/876 [==============================] - 2s 2ms/step\n",
            "110/110 [==============================] - 3s 31ms/step - loss: 15.6064 - val_loss: 18.3368\n",
            "Epoch 452/1200\n",
            "876/876 [==============================] - 2s 2ms/step\n",
            "110/110 [==============================] - 3s 26ms/step - loss: 15.3757 - val_loss: 17.9498\n",
            "Epoch 453/1200\n",
            "876/876 [==============================] - 2s 2ms/step\n",
            "110/110 [==============================] - 3s 26ms/step - loss: 15.7584 - val_loss: 17.5016\n",
            "Epoch 454/1200\n",
            "876/876 [==============================] - 2s 3ms/step\n",
            "110/110 [==============================] - 6s 57ms/step - loss: 15.6782 - val_loss: 17.3496\n",
            "Epoch 455/1200\n",
            "876/876 [==============================] - 2s 2ms/step\n",
            "110/110 [==============================] - 3s 26ms/step - loss: 15.4828 - val_loss: 17.3990\n",
            "Epoch 456/1200\n",
            "876/876 [==============================] - 2s 2ms/step\n",
            "110/110 [==============================] - 3s 25ms/step - loss: 15.7054 - val_loss: 18.1243\n",
            "Epoch 457/1200\n",
            "876/876 [==============================] - 2s 2ms/step\n",
            "110/110 [==============================] - 3s 30ms/step - loss: 16.8785 - val_loss: 17.7453\n",
            "Epoch 458/1200\n",
            "876/876 [==============================] - 2s 3ms/step\n",
            "110/110 [==============================] - 6s 57ms/step - loss: 15.5058 - val_loss: 17.7910\n",
            "Epoch 459/1200\n",
            "876/876 [==============================] - 2s 2ms/step\n",
            "110/110 [==============================] - 3s 30ms/step - loss: 15.3908 - val_loss: 17.8644\n",
            "Epoch 460/1200\n",
            "876/876 [==============================] - 2s 2ms/step\n",
            "110/110 [==============================] - 3s 27ms/step - loss: 15.1316 - val_loss: 17.2594\n",
            "Epoch 461/1200\n",
            "876/876 [==============================] - 2s 2ms/step\n",
            "110/110 [==============================] - 6s 54ms/step - loss: 16.4542 - val_loss: 17.3734\n",
            "Epoch 462/1200\n",
            "876/876 [==============================] - 2s 3ms/step\n",
            "110/110 [==============================] - 4s 37ms/step - loss: 15.4698 - val_loss: 17.3662\n",
            "Epoch 463/1200\n",
            "876/876 [==============================] - 2s 2ms/step\n",
            "110/110 [==============================] - 3s 26ms/step - loss: 15.2995 - val_loss: 18.0715\n",
            "Epoch 464/1200\n",
            "876/876 [==============================] - 2s 2ms/step\n",
            "110/110 [==============================] - 3s 30ms/step - loss: 15.3868 - val_loss: 18.3236\n",
            "Epoch 465/1200\n",
            "876/876 [==============================] - 2s 2ms/step\n",
            "110/110 [==============================] - 3s 27ms/step - loss: 15.3771 - val_loss: 17.8871\n",
            "Epoch 466/1200\n",
            "876/876 [==============================] - 2s 3ms/step\n",
            "110/110 [==============================] - 6s 58ms/step - loss: 15.1624 - val_loss: 18.1092\n",
            "Epoch 467/1200\n",
            "876/876 [==============================] - 2s 2ms/step\n",
            "110/110 [==============================] - 3s 25ms/step - loss: 15.5333 - val_loss: 19.6042\n",
            "Epoch 468/1200\n",
            "876/876 [==============================] - 2s 2ms/step\n",
            "110/110 [==============================] - 3s 30ms/step - loss: 15.6911 - val_loss: 17.8660\n",
            "Epoch 469/1200\n",
            "876/876 [==============================] - 2s 2ms/step\n",
            "110/110 [==============================] - 3s 30ms/step - loss: 15.0678 - val_loss: 18.1345\n",
            "Epoch 470/1200\n",
            "876/876 [==============================] - 3s 3ms/step\n",
            "110/110 [==============================] - 4s 36ms/step - loss: 15.1195 - val_loss: 17.9788\n",
            "Epoch 471/1200\n",
            "876/876 [==============================] - 2s 2ms/step\n",
            "110/110 [==============================] - 4s 33ms/step - loss: 15.1095 - val_loss: 17.9947\n",
            "Epoch 472/1200\n",
            "876/876 [==============================] - 2s 2ms/step\n",
            "110/110 [==============================] - 3s 25ms/step - loss: 15.4938 - val_loss: 17.9445\n",
            "Epoch 473/1200\n",
            "876/876 [==============================] - 2s 2ms/step\n",
            "110/110 [==============================] - 3s 26ms/step - loss: 15.6041 - val_loss: 18.0528\n",
            "Epoch 474/1200\n",
            "876/876 [==============================] - 2s 2ms/step\n",
            "110/110 [==============================] - 3s 29ms/step - loss: 15.2028 - val_loss: 18.6393\n",
            "Epoch 475/1200\n",
            "876/876 [==============================] - 2s 3ms/step\n",
            "110/110 [==============================] - 4s 36ms/step - loss: 15.8361 - val_loss: 20.2214\n",
            "Epoch 476/1200\n",
            "876/876 [==============================] - 2s 2ms/step\n",
            "110/110 [==============================] - 3s 27ms/step - loss: 20.2562 - val_loss: 23.4862\n",
            "Epoch 477/1200\n",
            "876/876 [==============================] - 2s 2ms/step\n",
            "110/110 [==============================] - 3s 26ms/step - loss: 21.4591 - val_loss: 19.9785\n",
            "Epoch 478/1200\n",
            "876/876 [==============================] - 2s 2ms/step\n",
            "110/110 [==============================] - 3s 30ms/step - loss: 16.0223 - val_loss: 18.3586\n",
            "Epoch 479/1200\n",
            "876/876 [==============================] - 2s 3ms/step\n",
            "110/110 [==============================] - 6s 54ms/step - loss: 15.7923 - val_loss: 17.3047\n",
            "Epoch 480/1200\n",
            "876/876 [==============================] - 2s 2ms/step\n",
            "110/110 [==============================] - 3s 26ms/step - loss: 15.2223 - val_loss: 18.1904\n",
            "Epoch 481/1200\n",
            "876/876 [==============================] - 2s 2ms/step\n",
            "110/110 [==============================] - 3s 26ms/step - loss: 14.9818 - val_loss: 17.9503\n",
            "Epoch 482/1200\n",
            "876/876 [==============================] - 2s 2ms/step\n",
            "110/110 [==============================] - 3s 30ms/step - loss: 15.3512 - val_loss: 18.1512\n",
            "Epoch 483/1200\n",
            "876/876 [==============================] - 2s 3ms/step\n",
            "110/110 [==============================] - 4s 36ms/step - loss: 15.1625 - val_loss: 18.2678\n",
            "Epoch 484/1200\n",
            "876/876 [==============================] - 2s 2ms/step\n",
            "110/110 [==============================] - 4s 33ms/step - loss: 15.3248 - val_loss: 18.4007\n",
            "Epoch 485/1200\n",
            "876/876 [==============================] - 2s 2ms/step\n",
            "110/110 [==============================] - 3s 30ms/step - loss: 15.3111 - val_loss: 18.4607\n",
            "Epoch 486/1200\n",
            "876/876 [==============================] - 2s 2ms/step\n",
            "110/110 [==============================] - 3s 31ms/step - loss: 15.1517 - val_loss: 18.2260\n",
            "Epoch 487/1200\n",
            "876/876 [==============================] - 2s 2ms/step\n",
            "110/110 [==============================] - 3s 31ms/step - loss: 15.4610 - val_loss: 19.9918\n",
            "Epoch 488/1200\n",
            "876/876 [==============================] - 2s 3ms/step\n",
            "110/110 [==============================] - 6s 56ms/step - loss: 15.6148 - val_loss: 19.1213\n",
            "Epoch 489/1200\n",
            "876/876 [==============================] - 2s 2ms/step\n",
            "110/110 [==============================] - 3s 26ms/step - loss: 15.6908 - val_loss: 19.0269\n",
            "Epoch 490/1200\n",
            "876/876 [==============================] - 2s 2ms/step\n",
            "110/110 [==============================] - 3s 27ms/step - loss: 15.7610 - val_loss: 21.0109\n",
            "Epoch 491/1200\n",
            "876/876 [==============================] - 2s 2ms/step\n",
            "110/110 [==============================] - 3s 30ms/step - loss: 15.8037 - val_loss: 18.5951\n",
            "Epoch 492/1200\n",
            "876/876 [==============================] - 2s 3ms/step\n",
            "110/110 [==============================] - 4s 35ms/step - loss: 15.1618 - val_loss: 19.5550\n",
            "Epoch 493/1200\n",
            "876/876 [==============================] - 2s 2ms/step\n",
            "110/110 [==============================] - 3s 29ms/step - loss: 15.5766 - val_loss: 18.1452\n",
            "Epoch 494/1200\n",
            "876/876 [==============================] - 2s 2ms/step\n",
            "110/110 [==============================] - 3s 26ms/step - loss: 15.3096 - val_loss: 18.4877\n",
            "Epoch 495/1200\n",
            "876/876 [==============================] - 2s 2ms/step\n",
            "110/110 [==============================] - 3s 26ms/step - loss: 15.0343 - val_loss: 18.1901\n",
            "Epoch 496/1200\n",
            "876/876 [==============================] - 2s 2ms/step\n",
            "110/110 [==============================] - 3s 27ms/step - loss: 15.1077 - val_loss: 19.0129\n",
            "Epoch 497/1200\n",
            "876/876 [==============================] - 2s 3ms/step\n",
            "110/110 [==============================] - 6s 56ms/step - loss: 15.2970 - val_loss: 18.2493\n",
            "Epoch 498/1200\n",
            "876/876 [==============================] - 2s 2ms/step\n",
            "110/110 [==============================] - 3s 30ms/step - loss: 14.9704 - val_loss: 17.9984\n",
            "Epoch 499/1200\n",
            "876/876 [==============================] - 2s 2ms/step\n",
            "110/110 [==============================] - 3s 30ms/step - loss: 14.9471 - val_loss: 17.9691\n",
            "Epoch 500/1200\n",
            "876/876 [==============================] - 2s 2ms/step\n",
            "110/110 [==============================] - 3s 30ms/step - loss: 15.5049 - val_loss: 20.3919\n",
            "Epoch 501/1200\n",
            "876/876 [==============================] - 2s 3ms/step\n",
            "110/110 [==============================] - 6s 56ms/step - loss: 15.8560 - val_loss: 20.4378\n",
            "Epoch 502/1200\n",
            "876/876 [==============================] - 2s 3ms/step\n",
            "110/110 [==============================] - 6s 57ms/step - loss: 15.4049 - val_loss: 18.9002\n",
            "Epoch 503/1200\n",
            "876/876 [==============================] - 2s 2ms/step\n",
            "110/110 [==============================] - 3s 30ms/step - loss: 15.3825 - val_loss: 18.4254\n",
            "Epoch 504/1200\n",
            "876/876 [==============================] - 2s 3ms/step\n",
            "110/110 [==============================] - 6s 56ms/step - loss: 15.5013 - val_loss: 17.7690\n",
            "Epoch 505/1200\n",
            "876/876 [==============================] - 2s 2ms/step\n",
            "110/110 [==============================] - 3s 30ms/step - loss: 15.0366 - val_loss: 17.9187\n",
            "Epoch 506/1200\n",
            "876/876 [==============================] - 2s 2ms/step\n",
            "110/110 [==============================] - 3s 30ms/step - loss: 15.0253 - val_loss: 18.2767\n",
            "Epoch 507/1200\n",
            "876/876 [==============================] - 2s 2ms/step\n",
            "110/110 [==============================] - 3s 30ms/step - loss: 15.1063 - val_loss: 18.5259\n",
            "Epoch 508/1200\n",
            "876/876 [==============================] - 2s 3ms/step\n",
            "110/110 [==============================] - 4s 35ms/step - loss: 15.6913 - val_loss: 18.3396\n",
            "Epoch 509/1200\n",
            "876/876 [==============================] - 2s 2ms/step\n",
            "110/110 [==============================] - 3s 29ms/step - loss: 15.1116 - val_loss: 18.2580\n",
            "Epoch 510/1200\n",
            "876/876 [==============================] - 2s 2ms/step\n",
            "110/110 [==============================] - 3s 30ms/step - loss: 15.1968 - val_loss: 18.7452\n",
            "Epoch 511/1200\n",
            "876/876 [==============================] - 2s 2ms/step\n",
            "110/110 [==============================] - 3s 30ms/step - loss: 15.4314 - val_loss: 17.8467\n",
            "Epoch 512/1200\n",
            "876/876 [==============================] - 2s 2ms/step\n",
            "110/110 [==============================] - 3s 30ms/step - loss: 15.6433 - val_loss: 18.4800\n",
            "Epoch 513/1200\n",
            "876/876 [==============================] - 2s 3ms/step\n",
            "110/110 [==============================] - 6s 57ms/step - loss: 15.4564 - val_loss: 18.3335\n",
            "Epoch 514/1200\n",
            "876/876 [==============================] - 2s 2ms/step\n",
            "110/110 [==============================] - 3s 30ms/step - loss: 15.1339 - val_loss: 18.9487\n",
            "Epoch 515/1200\n",
            "876/876 [==============================] - 2s 2ms/step\n",
            "110/110 [==============================] - 3s 26ms/step - loss: 15.7813 - val_loss: 19.0441\n",
            "Epoch 516/1200\n",
            "876/876 [==============================] - 2s 2ms/step\n",
            "110/110 [==============================] - 3s 31ms/step - loss: 15.2005 - val_loss: 18.1490\n",
            "Epoch 517/1200\n",
            "876/876 [==============================] - 2s 3ms/step\n",
            "110/110 [==============================] - 4s 37ms/step - loss: 15.6040 - val_loss: 19.3854\n",
            "Epoch 518/1200\n",
            "876/876 [==============================] - 2s 2ms/step\n",
            "110/110 [==============================] - 3s 29ms/step - loss: 16.1744 - val_loss: 20.1498\n",
            "Epoch 519/1200\n",
            "876/876 [==============================] - 2s 2ms/step\n",
            "110/110 [==============================] - 3s 30ms/step - loss: 15.3810 - val_loss: 18.9906\n",
            "Epoch 520/1200\n",
            "876/876 [==============================] - 2s 2ms/step\n",
            "110/110 [==============================] - 3s 26ms/step - loss: 15.1650 - val_loss: 18.5509\n",
            "Epoch 521/1200\n",
            "876/876 [==============================] - 2s 2ms/step\n",
            "110/110 [==============================] - 3s 30ms/step - loss: 15.4426 - val_loss: 18.5436\n",
            "Epoch 522/1200\n",
            "876/876 [==============================] - 2s 3ms/step\n",
            "110/110 [==============================] - 4s 37ms/step - loss: 15.6197 - val_loss: 19.0976\n",
            "Epoch 523/1200\n",
            "876/876 [==============================] - 2s 2ms/step\n",
            "110/110 [==============================] - 3s 31ms/step - loss: 15.3601 - val_loss: 17.8952\n",
            "Epoch 524/1200\n",
            "876/876 [==============================] - 2s 3ms/step\n",
            "110/110 [==============================] - 6s 55ms/step - loss: 15.1857 - val_loss: 18.1325\n",
            "Epoch 525/1200\n",
            "876/876 [==============================] - 2s 3ms/step\n",
            "110/110 [==============================] - 4s 34ms/step - loss: 15.8002 - val_loss: 17.2999\n",
            "Epoch 526/1200\n",
            "876/876 [==============================] - 3s 3ms/step\n",
            "110/110 [==============================] - 4s 37ms/step - loss: 15.0548 - val_loss: 18.1240\n",
            "Epoch 527/1200\n",
            "876/876 [==============================] - 2s 2ms/step\n",
            "110/110 [==============================] - 3s 26ms/step - loss: 15.0283 - val_loss: 17.7859\n",
            "Epoch 528/1200\n",
            "876/876 [==============================] - 2s 2ms/step\n",
            "110/110 [==============================] - 3s 26ms/step - loss: 15.4296 - val_loss: 18.6232\n",
            "Epoch 529/1200\n",
            "876/876 [==============================] - 2s 2ms/step\n",
            "110/110 [==============================] - 3s 30ms/step - loss: 14.9227 - val_loss: 18.6022\n",
            "Epoch 530/1200\n",
            "876/876 [==============================] - 2s 3ms/step\n",
            "110/110 [==============================] - 6s 54ms/step - loss: 15.2859 - val_loss: 17.9665\n",
            "Epoch 531/1200\n",
            "876/876 [==============================] - 2s 2ms/step\n",
            "110/110 [==============================] - 3s 31ms/step - loss: 15.4498 - val_loss: 19.0468\n",
            "Epoch 532/1200\n",
            "876/876 [==============================] - 2s 2ms/step\n",
            "110/110 [==============================] - 3s 25ms/step - loss: 15.1099 - val_loss: 18.3819\n",
            "Epoch 533/1200\n",
            "876/876 [==============================] - 2s 2ms/step\n",
            "110/110 [==============================] - 3s 31ms/step - loss: 15.6320 - val_loss: 19.7111\n",
            "Epoch 534/1200\n",
            "876/876 [==============================] - 2s 3ms/step\n",
            "110/110 [==============================] - 6s 57ms/step - loss: 15.3823 - val_loss: 18.0938\n",
            "Epoch 535/1200\n",
            "876/876 [==============================] - 2s 2ms/step\n",
            "110/110 [==============================] - 3s 30ms/step - loss: 15.0127 - val_loss: 18.3254\n",
            "Epoch 536/1200\n",
            "876/876 [==============================] - 2s 2ms/step\n",
            "110/110 [==============================] - 3s 26ms/step - loss: 15.1875 - val_loss: 18.3661\n",
            "Epoch 537/1200\n",
            "876/876 [==============================] - 2s 2ms/step\n",
            "110/110 [==============================] - 3s 30ms/step - loss: 15.0780 - val_loss: 18.1940\n",
            "Epoch 538/1200\n",
            "876/876 [==============================] - 2s 3ms/step\n",
            "110/110 [==============================] - 4s 36ms/step - loss: 15.2899 - val_loss: 18.4384\n",
            "Epoch 539/1200\n",
            "876/876 [==============================] - 2s 2ms/step\n",
            "110/110 [==============================] - 4s 34ms/step - loss: 15.6410 - val_loss: 19.4235\n",
            "Epoch 540/1200\n",
            "876/876 [==============================] - 2s 2ms/step\n",
            "110/110 [==============================] - 3s 25ms/step - loss: 15.8596 - val_loss: 19.0606\n",
            "Epoch 541/1200\n",
            "876/876 [==============================] - 2s 2ms/step\n",
            "110/110 [==============================] - 3s 30ms/step - loss: 15.2042 - val_loss: 19.1220\n",
            "Epoch 542/1200\n",
            "876/876 [==============================] - 2s 2ms/step\n",
            "110/110 [==============================] - 3s 30ms/step - loss: 14.9647 - val_loss: 18.8700\n",
            "Epoch 543/1200\n",
            "876/876 [==============================] - 2s 3ms/step\n",
            "110/110 [==============================] - 4s 35ms/step - loss: 15.1672 - val_loss: 19.2061\n",
            "Epoch 544/1200\n",
            "876/876 [==============================] - 2s 2ms/step\n",
            "110/110 [==============================] - 4s 34ms/step - loss: 15.5390 - val_loss: 19.1429\n",
            "Epoch 545/1200\n",
            "876/876 [==============================] - 2s 2ms/step\n",
            "110/110 [==============================] - 3s 26ms/step - loss: 15.3759 - val_loss: 18.3040\n",
            "Epoch 546/1200\n",
            "876/876 [==============================] - 2s 2ms/step\n",
            "110/110 [==============================] - 3s 30ms/step - loss: 15.2138 - val_loss: 19.1237\n",
            "Epoch 547/1200\n",
            "876/876 [==============================] - 2s 3ms/step\n",
            "110/110 [==============================] - 3s 31ms/step - loss: 15.0882 - val_loss: 18.6365\n",
            "Epoch 548/1200\n",
            "876/876 [==============================] - 2s 3ms/step\n",
            "110/110 [==============================] - 6s 57ms/step - loss: 15.0639 - val_loss: 19.0210\n",
            "Epoch 549/1200\n",
            "876/876 [==============================] - 2s 2ms/step\n",
            "110/110 [==============================] - 3s 26ms/step - loss: 15.0935 - val_loss: 18.7616\n",
            "Epoch 550/1200\n",
            "876/876 [==============================] - 2s 2ms/step\n",
            "110/110 [==============================] - 3s 30ms/step - loss: 14.9755 - val_loss: 18.0863\n",
            "Epoch 551/1200\n",
            "876/876 [==============================] - 2s 2ms/step\n",
            "110/110 [==============================] - 3s 30ms/step - loss: 15.0384 - val_loss: 18.7607\n",
            "Epoch 552/1200\n",
            "876/876 [==============================] - 2s 3ms/step\n",
            "110/110 [==============================] - 6s 56ms/step - loss: 14.9290 - val_loss: 18.6848\n",
            "Epoch 553/1200\n",
            "876/876 [==============================] - 2s 2ms/step\n",
            "110/110 [==============================] - 3s 26ms/step - loss: 15.3335 - val_loss: 18.5328\n",
            "Epoch 554/1200\n",
            "876/876 [==============================] - 2s 2ms/step\n",
            "110/110 [==============================] - 3s 27ms/step - loss: 15.2922 - val_loss: 18.4610\n",
            "Epoch 555/1200\n",
            "876/876 [==============================] - 2s 2ms/step\n",
            "110/110 [==============================] - 3s 28ms/step - loss: 20.3616 - val_loss: 17.2038\n",
            "Epoch 556/1200\n",
            "876/876 [==============================] - 2s 3ms/step\n",
            "110/110 [==============================] - 6s 57ms/step - loss: 15.3183 - val_loss: 18.3782\n",
            "Epoch 557/1200\n",
            "876/876 [==============================] - 2s 2ms/step\n",
            "110/110 [==============================] - 3s 30ms/step - loss: 15.4661 - val_loss: 17.5634\n",
            "Epoch 558/1200\n",
            "876/876 [==============================] - 2s 2ms/step\n",
            "110/110 [==============================] - 3s 31ms/step - loss: 15.0548 - val_loss: 17.7327\n",
            "Epoch 559/1200\n",
            "876/876 [==============================] - 2s 2ms/step\n",
            "110/110 [==============================] - 3s 31ms/step - loss: 14.8667 - val_loss: 18.3560\n",
            "Epoch 560/1200\n",
            "876/876 [==============================] - 2s 3ms/step\n",
            "110/110 [==============================] - 4s 35ms/step - loss: 15.1661 - val_loss: 18.1555\n",
            "Epoch 561/1200\n",
            "876/876 [==============================] - 2s 2ms/step\n",
            "110/110 [==============================] - 4s 33ms/step - loss: 15.2146 - val_loss: 18.4374\n",
            "Epoch 562/1200\n",
            "876/876 [==============================] - 2s 2ms/step\n",
            "110/110 [==============================] - 3s 26ms/step - loss: 15.2532 - val_loss: 18.3928\n",
            "Epoch 563/1200\n",
            "876/876 [==============================] - 2s 2ms/step\n",
            "110/110 [==============================] - 3s 26ms/step - loss: 15.4410 - val_loss: 18.1985\n",
            "Epoch 564/1200\n",
            "876/876 [==============================] - 2s 2ms/step\n",
            "110/110 [==============================] - 3s 28ms/step - loss: 15.1672 - val_loss: 18.6085\n",
            "Epoch 565/1200\n",
            "876/876 [==============================] - 2s 3ms/step\n",
            "110/110 [==============================] - 6s 57ms/step - loss: 15.1998 - val_loss: 17.4197\n",
            "Epoch 566/1200\n",
            "876/876 [==============================] - 2s 2ms/step\n",
            "110/110 [==============================] - 3s 30ms/step - loss: 14.9967 - val_loss: 17.8125\n",
            "Epoch 567/1200\n",
            "876/876 [==============================] - 2s 2ms/step\n",
            "110/110 [==============================] - 3s 26ms/step - loss: 15.0628 - val_loss: 17.9617\n",
            "Epoch 568/1200\n",
            "876/876 [==============================] - 2s 2ms/step\n",
            "110/110 [==============================] - 3s 31ms/step - loss: 14.8500 - val_loss: 18.7529\n",
            "Epoch 569/1200\n",
            "876/876 [==============================] - 2s 3ms/step\n",
            "110/110 [==============================] - 6s 57ms/step - loss: 15.2714 - val_loss: 18.6004\n",
            "Epoch 570/1200\n",
            "876/876 [==============================] - 2s 2ms/step\n",
            "110/110 [==============================] - 3s 30ms/step - loss: 14.9851 - val_loss: 17.7591\n",
            "Epoch 571/1200\n",
            "876/876 [==============================] - 2s 2ms/step\n",
            "110/110 [==============================] - 3s 31ms/step - loss: 15.7627 - val_loss: 20.6504\n",
            "Epoch 572/1200\n",
            "876/876 [==============================] - 2s 2ms/step\n",
            "110/110 [==============================] - 3s 31ms/step - loss: 16.4744 - val_loss: 17.7129\n",
            "Epoch 573/1200\n",
            "876/876 [==============================] - 2s 3ms/step\n",
            "110/110 [==============================] - 4s 34ms/step - loss: 15.3130 - val_loss: 22.7363\n",
            "Epoch 574/1200\n",
            "876/876 [==============================] - 2s 2ms/step\n",
            "110/110 [==============================] - 4s 34ms/step - loss: 17.4199 - val_loss: 18.1817\n",
            "Epoch 575/1200\n",
            "876/876 [==============================] - 2s 2ms/step\n",
            "110/110 [==============================] - 3s 31ms/step - loss: 14.9763 - val_loss: 17.9438\n",
            "Epoch 576/1200\n",
            "876/876 [==============================] - 2s 2ms/step\n",
            "110/110 [==============================] - 3s 31ms/step - loss: 15.1466 - val_loss: 17.7166\n",
            "Epoch 577/1200\n",
            "876/876 [==============================] - 2s 3ms/step\n",
            "110/110 [==============================] - 4s 32ms/step - loss: 15.3108 - val_loss: 17.8135\n",
            "Epoch 578/1200\n",
            "876/876 [==============================] - 2s 3ms/step\n",
            "110/110 [==============================] - 6s 58ms/step - loss: 15.1613 - val_loss: 18.1533\n",
            "Epoch 579/1200\n",
            "876/876 [==============================] - 2s 2ms/step\n",
            "110/110 [==============================] - 3s 30ms/step - loss: 15.2570 - val_loss: 18.4242\n",
            "Epoch 580/1200\n",
            "876/876 [==============================] - 2s 2ms/step\n",
            "110/110 [==============================] - 3s 30ms/step - loss: 15.2690 - val_loss: 18.0552\n",
            "Epoch 581/1200\n",
            "876/876 [==============================] - 2s 3ms/step\n",
            "110/110 [==============================] - 3s 32ms/step - loss: 14.8706 - val_loss: 18.2665\n",
            "Epoch 582/1200\n",
            "876/876 [==============================] - 2s 3ms/step\n",
            "110/110 [==============================] - 6s 57ms/step - loss: 15.1187 - val_loss: 17.7512\n",
            "Epoch 583/1200\n",
            "876/876 [==============================] - 2s 2ms/step\n",
            "110/110 [==============================] - 3s 31ms/step - loss: 15.0219 - val_loss: 17.8565\n",
            "Epoch 584/1200\n",
            "876/876 [==============================] - 2s 2ms/step\n",
            "110/110 [==============================] - 3s 31ms/step - loss: 14.8741 - val_loss: 17.8430\n",
            "Epoch 585/1200\n",
            "876/876 [==============================] - 2s 3ms/step\n",
            "110/110 [==============================] - 4s 32ms/step - loss: 15.0752 - val_loss: 18.0145\n",
            "Epoch 586/1200\n",
            "876/876 [==============================] - 2s 3ms/step\n",
            "110/110 [==============================] - 4s 38ms/step - loss: 15.1554 - val_loss: 17.8203\n",
            "Epoch 587/1200\n",
            "876/876 [==============================] - 3s 3ms/step\n",
            "110/110 [==============================] - 4s 40ms/step - loss: 15.2918 - val_loss: 18.5868\n",
            "Epoch 588/1200\n",
            "876/876 [==============================] - 3s 3ms/step\n",
            "110/110 [==============================] - 6s 58ms/step - loss: 14.9971 - val_loss: 18.3586\n",
            "Epoch 589/1200\n",
            "876/876 [==============================] - 2s 2ms/step\n",
            "110/110 [==============================] - 3s 31ms/step - loss: 15.2116 - val_loss: 18.3623\n",
            "Epoch 590/1200\n",
            "876/876 [==============================] - 2s 3ms/step\n",
            "110/110 [==============================] - 4s 33ms/step - loss: 15.0710 - val_loss: 17.3305\n",
            "Epoch 591/1200\n",
            "876/876 [==============================] - 2s 3ms/step\n",
            "110/110 [==============================] - 6s 57ms/step - loss: 14.8654 - val_loss: 18.3016\n",
            "Epoch 592/1200\n",
            "876/876 [==============================] - 2s 2ms/step\n",
            "110/110 [==============================] - 3s 30ms/step - loss: 15.0995 - val_loss: 17.9175\n",
            "Epoch 593/1200\n",
            "876/876 [==============================] - 2s 2ms/step\n",
            "110/110 [==============================] - 3s 26ms/step - loss: 15.1984 - val_loss: 18.2726\n",
            "Epoch 594/1200\n",
            "876/876 [==============================] - 2s 2ms/step\n",
            "110/110 [==============================] - 3s 31ms/step - loss: 15.5772 - val_loss: 18.0358\n",
            "Epoch 595/1200\n",
            "876/876 [==============================] - 2s 3ms/step\n",
            "110/110 [==============================] - 4s 36ms/step - loss: 15.1464 - val_loss: 20.8466\n",
            "Epoch 596/1200\n",
            "876/876 [==============================] - 2s 2ms/step\n",
            "110/110 [==============================] - 4s 34ms/step - loss: 15.3100 - val_loss: 17.6721\n",
            "Epoch 597/1200\n",
            "876/876 [==============================] - 2s 2ms/step\n",
            "110/110 [==============================] - 3s 26ms/step - loss: 14.8460 - val_loss: 17.7628\n",
            "Epoch 598/1200\n",
            "876/876 [==============================] - 2s 2ms/step\n",
            "110/110 [==============================] - 3s 26ms/step - loss: 14.9957 - val_loss: 18.1303\n",
            "Epoch 599/1200\n",
            "876/876 [==============================] - 2s 2ms/step\n",
            "110/110 [==============================] - 3s 30ms/step - loss: 15.4486 - val_loss: 18.3141\n",
            "Epoch 600/1200\n",
            "876/876 [==============================] - 3s 3ms/step\n",
            "110/110 [==============================] - 6s 57ms/step - loss: 15.2095 - val_loss: 18.3831\n",
            "Epoch 601/1200\n",
            "876/876 [==============================] - 2s 2ms/step\n",
            "110/110 [==============================] - 3s 30ms/step - loss: 14.8384 - val_loss: 17.4768\n",
            "Epoch 602/1200\n",
            "876/876 [==============================] - 2s 2ms/step\n",
            "110/110 [==============================] - 3s 30ms/step - loss: 14.8632 - val_loss: 17.9639\n",
            "Epoch 603/1200\n",
            "876/876 [==============================] - 2s 2ms/step\n",
            "110/110 [==============================] - 3s 30ms/step - loss: 16.0285 - val_loss: 17.8686\n",
            "Epoch 604/1200\n",
            "876/876 [==============================] - 2s 3ms/step\n",
            "110/110 [==============================] - 4s 37ms/step - loss: 15.1426 - val_loss: 17.9340\n",
            "Epoch 605/1200\n",
            "876/876 [==============================] - 2s 2ms/step\n",
            "110/110 [==============================] - 3s 29ms/step - loss: 14.7801 - val_loss: 18.2764\n",
            "Epoch 606/1200\n",
            "876/876 [==============================] - 2s 2ms/step\n",
            "110/110 [==============================] - 3s 26ms/step - loss: 15.0210 - val_loss: 17.3717\n",
            "Epoch 607/1200\n",
            "876/876 [==============================] - 2s 2ms/step\n",
            "110/110 [==============================] - 3s 26ms/step - loss: 14.8027 - val_loss: 18.1431\n",
            "Epoch 608/1200\n",
            "876/876 [==============================] - 2s 2ms/step\n",
            "110/110 [==============================] - 3s 30ms/step - loss: 14.9236 - val_loss: 18.1885\n",
            "Epoch 609/1200\n",
            "876/876 [==============================] - 2s 3ms/step\n",
            "110/110 [==============================] - 4s 36ms/step - loss: 15.1587 - val_loss: 18.0534\n",
            "Epoch 610/1200\n",
            "876/876 [==============================] - 2s 2ms/step\n",
            "110/110 [==============================] - 3s 28ms/step - loss: 15.1510 - val_loss: 18.4839\n",
            "Epoch 611/1200\n",
            "876/876 [==============================] - 2s 2ms/step\n",
            "110/110 [==============================] - 3s 26ms/step - loss: 16.0415 - val_loss: 19.8801\n",
            "Epoch 612/1200\n",
            "876/876 [==============================] - 2s 2ms/step\n",
            "110/110 [==============================] - 3s 25ms/step - loss: 15.3961 - val_loss: 18.0515\n",
            "Epoch 613/1200\n",
            "876/876 [==============================] - 2s 2ms/step\n",
            "110/110 [==============================] - 3s 31ms/step - loss: 14.8687 - val_loss: 17.9785\n",
            "Epoch 614/1200\n",
            "876/876 [==============================] - 2s 3ms/step\n",
            "110/110 [==============================] - 4s 37ms/step - loss: 14.9986 - val_loss: 17.4624\n",
            "Epoch 615/1200\n",
            "876/876 [==============================] - 2s 2ms/step\n",
            "110/110 [==============================] - 3s 28ms/step - loss: 15.2159 - val_loss: 18.6275\n",
            "Epoch 616/1200\n",
            "876/876 [==============================] - 2s 2ms/step\n",
            "110/110 [==============================] - 3s 30ms/step - loss: 15.1414 - val_loss: 18.7222\n",
            "Epoch 617/1200\n",
            "876/876 [==============================] - 2s 2ms/step\n",
            "110/110 [==============================] - 3s 31ms/step - loss: 14.9928 - val_loss: 18.0582\n",
            "Epoch 618/1200\n",
            "876/876 [==============================] - 2s 3ms/step\n",
            "110/110 [==============================] - 6s 54ms/step - loss: 15.7681 - val_loss: 19.4501\n",
            "Epoch 619/1200\n",
            "876/876 [==============================] - 2s 2ms/step\n",
            "110/110 [==============================] - 3s 26ms/step - loss: 15.2449 - val_loss: 18.1272\n",
            "Epoch 620/1200\n",
            "876/876 [==============================] - 2s 2ms/step\n",
            "110/110 [==============================] - 3s 31ms/step - loss: 14.9877 - val_loss: 19.4171\n",
            "Epoch 621/1200\n",
            "876/876 [==============================] - 2s 2ms/step\n",
            "110/110 [==============================] - 3s 26ms/step - loss: 14.8374 - val_loss: 18.1830\n",
            "Epoch 622/1200\n",
            "876/876 [==============================] - 2s 3ms/step\n",
            "110/110 [==============================] - 6s 57ms/step - loss: 14.8425 - val_loss: 18.4003\n",
            "Epoch 623/1200\n",
            "876/876 [==============================] - 2s 2ms/step\n",
            "110/110 [==============================] - 3s 27ms/step - loss: 15.4958 - val_loss: 18.4029\n",
            "Epoch 624/1200\n",
            "876/876 [==============================] - 2s 2ms/step\n",
            "110/110 [==============================] - 3s 26ms/step - loss: 14.7667 - val_loss: 17.9212\n",
            "Epoch 625/1200\n",
            "876/876 [==============================] - 2s 2ms/step\n",
            "110/110 [==============================] - 3s 26ms/step - loss: 15.0603 - val_loss: 19.0173\n",
            "Epoch 626/1200\n",
            "876/876 [==============================] - 2s 3ms/step\n",
            "110/110 [==============================] - 4s 35ms/step - loss: 14.9514 - val_loss: 17.8708\n",
            "Epoch 627/1200\n",
            "876/876 [==============================] - 2s 3ms/step\n",
            "110/110 [==============================] - 4s 34ms/step - loss: 14.8919 - val_loss: 17.6863\n",
            "Epoch 628/1200\n",
            "876/876 [==============================] - 2s 2ms/step\n",
            "110/110 [==============================] - 3s 26ms/step - loss: 14.8364 - val_loss: 18.0347\n",
            "Epoch 629/1200\n",
            "876/876 [==============================] - 2s 2ms/step\n",
            "110/110 [==============================] - 3s 30ms/step - loss: 14.7968 - val_loss: 18.2210\n",
            "Epoch 630/1200\n",
            "876/876 [==============================] - 2s 2ms/step\n",
            "110/110 [==============================] - 3s 31ms/step - loss: 15.0670 - val_loss: 17.8421\n",
            "Epoch 631/1200\n",
            "876/876 [==============================] - 2s 3ms/step\n",
            "110/110 [==============================] - 4s 35ms/step - loss: 14.9662 - val_loss: 19.1315\n",
            "Epoch 632/1200\n",
            "876/876 [==============================] - 2s 3ms/step\n",
            "110/110 [==============================] - 4s 37ms/step - loss: 15.3617 - val_loss: 18.5240\n",
            "Epoch 633/1200\n",
            "876/876 [==============================] - 2s 2ms/step\n",
            "110/110 [==============================] - 3s 31ms/step - loss: 14.8758 - val_loss: 18.0220\n",
            "Epoch 634/1200\n",
            "876/876 [==============================] - 2s 2ms/step\n",
            "110/110 [==============================] - 3s 26ms/step - loss: 14.8062 - val_loss: 18.4160\n",
            "Epoch 635/1200\n",
            "876/876 [==============================] - 2s 2ms/step\n",
            "110/110 [==============================] - 3s 26ms/step - loss: 14.9782 - val_loss: 18.2329\n",
            "Epoch 636/1200\n",
            "876/876 [==============================] - 2s 3ms/step\n",
            "110/110 [==============================] - 4s 36ms/step - loss: 15.1921 - val_loss: 16.8887\n",
            "Epoch 637/1200\n",
            "876/876 [==============================] - 2s 3ms/step\n",
            "110/110 [==============================] - 4s 34ms/step - loss: 14.8550 - val_loss: 18.5482\n",
            "Epoch 638/1200\n",
            "876/876 [==============================] - 2s 2ms/step\n",
            "110/110 [==============================] - 3s 26ms/step - loss: 14.9268 - val_loss: 17.9187\n",
            "Epoch 639/1200\n",
            "876/876 [==============================] - 2s 2ms/step\n",
            "110/110 [==============================] - 3s 30ms/step - loss: 14.8415 - val_loss: 18.6334\n",
            "Epoch 640/1200\n",
            "876/876 [==============================] - 2s 2ms/step\n",
            "110/110 [==============================] - 3s 28ms/step - loss: 15.5959 - val_loss: 18.1153\n",
            "Epoch 641/1200\n",
            "876/876 [==============================] - 2s 3ms/step\n",
            "110/110 [==============================] - 4s 34ms/step - loss: 15.2027 - val_loss: 18.3258\n",
            "Epoch 642/1200\n",
            "876/876 [==============================] - 2s 3ms/step\n",
            "110/110 [==============================] - 6s 56ms/step - loss: 14.8966 - val_loss: 17.8929\n",
            "Epoch 643/1200\n",
            "876/876 [==============================] - 2s 2ms/step\n",
            "110/110 [==============================] - 3s 26ms/step - loss: 14.8584 - val_loss: 18.1703\n",
            "Epoch 644/1200\n",
            "876/876 [==============================] - 2s 2ms/step\n",
            "110/110 [==============================] - 3s 30ms/step - loss: 15.4186 - val_loss: 19.0001\n",
            "Epoch 645/1200\n",
            "876/876 [==============================] - 2s 2ms/step\n",
            "110/110 [==============================] - 3s 30ms/step - loss: 15.3499 - val_loss: 17.3016\n",
            "Epoch 646/1200\n",
            "876/876 [==============================] - 2s 3ms/step\n",
            "110/110 [==============================] - 4s 36ms/step - loss: 14.7630 - val_loss: 18.1790\n",
            "Epoch 647/1200\n",
            "876/876 [==============================] - 2s 2ms/step\n",
            "110/110 [==============================] - 3s 29ms/step - loss: 17.2768 - val_loss: 20.3570\n",
            "Epoch 648/1200\n",
            "876/876 [==============================] - 2s 2ms/step\n",
            "110/110 [==============================] - 3s 30ms/step - loss: 16.9184 - val_loss: 17.6631\n",
            "Epoch 649/1200\n",
            "876/876 [==============================] - 2s 2ms/step\n",
            "110/110 [==============================] - 3s 27ms/step - loss: 15.0433 - val_loss: 17.6752\n",
            "Epoch 650/1200\n",
            "876/876 [==============================] - 2s 3ms/step\n",
            "110/110 [==============================] - 6s 55ms/step - loss: 15.6806 - val_loss: 18.0379\n",
            "Epoch 651/1200\n",
            "876/876 [==============================] - 2s 3ms/step\n",
            "110/110 [==============================] - 4s 35ms/step - loss: 15.2296 - val_loss: 17.5027\n",
            "Epoch 652/1200\n",
            "876/876 [==============================] - 2s 2ms/step\n",
            "110/110 [==============================] - 3s 26ms/step - loss: 15.5577 - val_loss: 17.9192\n",
            "Epoch 653/1200\n",
            "876/876 [==============================] - 2s 2ms/step\n",
            "110/110 [==============================] - 3s 30ms/step - loss: 15.1288 - val_loss: 18.2507\n",
            "Epoch 654/1200\n",
            "876/876 [==============================] - 2s 2ms/step\n",
            "110/110 [==============================] - 3s 26ms/step - loss: 14.8637 - val_loss: 18.2591\n",
            "Epoch 655/1200\n",
            "876/876 [==============================] - 2s 3ms/step\n",
            "110/110 [==============================] - 4s 34ms/step - loss: 15.3705 - val_loss: 18.1868\n",
            "Epoch 656/1200\n",
            "876/876 [==============================] - 2s 3ms/step\n",
            "110/110 [==============================] - 4s 35ms/step - loss: 14.9939 - val_loss: 18.0498\n",
            "Epoch 657/1200\n",
            "876/876 [==============================] - 2s 2ms/step\n",
            "110/110 [==============================] - 3s 30ms/step - loss: 14.7703 - val_loss: 17.8256\n",
            "Epoch 658/1200\n",
            "876/876 [==============================] - 2s 2ms/step\n",
            "110/110 [==============================] - 3s 26ms/step - loss: 14.7967 - val_loss: 17.8396\n",
            "Epoch 659/1200\n",
            "876/876 [==============================] - 2s 2ms/step\n",
            "110/110 [==============================] - 3s 26ms/step - loss: 14.7662 - val_loss: 17.6573\n",
            "Epoch 660/1200\n",
            "876/876 [==============================] - 2s 3ms/step\n",
            "110/110 [==============================] - 4s 32ms/step - loss: 14.7684 - val_loss: 17.3527\n",
            "Epoch 661/1200\n",
            "876/876 [==============================] - 2s 3ms/step\n",
            "110/110 [==============================] - 6s 56ms/step - loss: 14.8454 - val_loss: 17.1187\n",
            "Epoch 662/1200\n",
            "876/876 [==============================] - 2s 2ms/step\n",
            "110/110 [==============================] - 3s 27ms/step - loss: 14.9473 - val_loss: 17.5873\n",
            "Epoch 663/1200\n",
            "876/876 [==============================] - 2s 2ms/step\n",
            "110/110 [==============================] - 3s 26ms/step - loss: 14.9716 - val_loss: 17.7981\n",
            "Epoch 664/1200\n",
            "876/876 [==============================] - 2s 3ms/step\n",
            "110/110 [==============================] - 4s 36ms/step - loss: 14.8083 - val_loss: 18.0787\n",
            "Epoch 665/1200\n",
            "876/876 [==============================] - 3s 3ms/step\n",
            "110/110 [==============================] - 6s 58ms/step - loss: 15.4834 - val_loss: 19.0281\n",
            "Epoch 666/1200\n",
            "876/876 [==============================] - 2s 2ms/step\n",
            "110/110 [==============================] - 3s 31ms/step - loss: 15.2072 - val_loss: 18.4181\n",
            "Epoch 667/1200\n",
            "876/876 [==============================] - 2s 2ms/step\n",
            "110/110 [==============================] - 3s 30ms/step - loss: 14.7942 - val_loss: 17.7820\n",
            "Epoch 668/1200\n",
            "876/876 [==============================] - 2s 2ms/step\n",
            "110/110 [==============================] - 3s 26ms/step - loss: 14.8662 - val_loss: 18.2118\n",
            "Epoch 669/1200\n",
            "876/876 [==============================] - 2s 3ms/step\n",
            "110/110 [==============================] - 6s 57ms/step - loss: 14.9762 - val_loss: 16.7221\n",
            "Epoch 670/1200\n",
            "876/876 [==============================] - 2s 2ms/step\n",
            "110/110 [==============================] - 3s 25ms/step - loss: 14.8079 - val_loss: 17.9107\n",
            "Epoch 671/1200\n",
            "876/876 [==============================] - 2s 2ms/step\n",
            "110/110 [==============================] - 3s 26ms/step - loss: 15.4553 - val_loss: 17.8125\n",
            "Epoch 672/1200\n",
            "876/876 [==============================] - 2s 2ms/step\n",
            "110/110 [==============================] - 3s 26ms/step - loss: 14.8338 - val_loss: 17.6534\n",
            "Epoch 673/1200\n",
            "876/876 [==============================] - 2s 3ms/step\n",
            "110/110 [==============================] - 6s 56ms/step - loss: 15.0227 - val_loss: 18.2947\n",
            "Epoch 674/1200\n",
            "876/876 [==============================] - 2s 2ms/step\n",
            "110/110 [==============================] - 3s 32ms/step - loss: 14.6747 - val_loss: 18.1308\n",
            "Epoch 675/1200\n",
            "876/876 [==============================] - 2s 2ms/step\n",
            "110/110 [==============================] - 3s 31ms/step - loss: 14.7267 - val_loss: 17.9028\n",
            "Epoch 676/1200\n",
            "876/876 [==============================] - 2s 2ms/step\n",
            "110/110 [==============================] - 3s 30ms/step - loss: 14.8644 - val_loss: 16.6783\n",
            "Epoch 677/1200\n",
            "876/876 [==============================] - 2s 3ms/step\n",
            "110/110 [==============================] - 6s 57ms/step - loss: 14.7458 - val_loss: 17.1305\n",
            "Epoch 678/1200\n",
            "876/876 [==============================] - 2s 2ms/step\n",
            "110/110 [==============================] - 3s 31ms/step - loss: 14.6716 - val_loss: 17.4795\n",
            "Epoch 679/1200\n",
            "876/876 [==============================] - 2s 2ms/step\n",
            "110/110 [==============================] - 3s 26ms/step - loss: 14.9263 - val_loss: 17.5444\n",
            "Epoch 680/1200\n",
            "876/876 [==============================] - 2s 2ms/step\n",
            "110/110 [==============================] - 3s 31ms/step - loss: 14.9910 - val_loss: 18.6522\n",
            "Epoch 681/1200\n",
            "876/876 [==============================] - 2s 3ms/step\n",
            "110/110 [==============================] - 4s 36ms/step - loss: 15.0200 - val_loss: 17.4147\n",
            "Epoch 682/1200\n",
            "876/876 [==============================] - 2s 2ms/step\n",
            "110/110 [==============================] - 3s 30ms/step - loss: 14.9127 - val_loss: 19.2816\n",
            "Epoch 683/1200\n",
            "876/876 [==============================] - 2s 2ms/step\n",
            "110/110 [==============================] - 3s 30ms/step - loss: 15.4162 - val_loss: 19.8078\n",
            "Epoch 684/1200\n",
            "876/876 [==============================] - 2s 2ms/step\n",
            "110/110 [==============================] - 3s 26ms/step - loss: 15.1067 - val_loss: 17.9304\n",
            "Epoch 685/1200\n",
            "876/876 [==============================] - 2s 2ms/step\n",
            "110/110 [==============================] - 3s 30ms/step - loss: 15.2203 - val_loss: 18.6613\n",
            "Epoch 686/1200\n",
            "876/876 [==============================] - 2s 3ms/step\n",
            "110/110 [==============================] - 6s 57ms/step - loss: 14.9083 - val_loss: 18.6746\n",
            "Epoch 687/1200\n",
            "876/876 [==============================] - 2s 2ms/step\n",
            "110/110 [==============================] - 3s 31ms/step - loss: 14.8187 - val_loss: 17.5277\n",
            "Epoch 688/1200\n",
            "876/876 [==============================] - 2s 2ms/step\n",
            "110/110 [==============================] - 3s 26ms/step - loss: 14.7642 - val_loss: 17.9153\n",
            "Epoch 689/1200\n",
            "876/876 [==============================] - 2s 2ms/step\n",
            "110/110 [==============================] - 3s 31ms/step - loss: 14.9635 - val_loss: 18.3290\n",
            "Epoch 690/1200\n",
            "876/876 [==============================] - 2s 3ms/step\n",
            "110/110 [==============================] - 6s 58ms/step - loss: 14.8431 - val_loss: 17.5006\n",
            "Epoch 691/1200\n",
            "876/876 [==============================] - 2s 2ms/step\n",
            "110/110 [==============================] - 3s 31ms/step - loss: 14.9960 - val_loss: 17.6656\n",
            "Epoch 692/1200\n",
            "876/876 [==============================] - 2s 2ms/step\n",
            "110/110 [==============================] - 3s 27ms/step - loss: 15.7395 - val_loss: 17.8106\n",
            "Epoch 693/1200\n",
            "876/876 [==============================] - 2s 2ms/step\n",
            "110/110 [==============================] - 3s 31ms/step - loss: 15.3239 - val_loss: 17.3522\n",
            "Epoch 694/1200\n",
            "876/876 [==============================] - 2s 3ms/step\n",
            "110/110 [==============================] - 4s 35ms/step - loss: 14.7954 - val_loss: 18.2237\n",
            "Epoch 695/1200\n",
            "876/876 [==============================] - 2s 2ms/step\n",
            "110/110 [==============================] - 3s 30ms/step - loss: 15.3880 - val_loss: 16.6806\n",
            "Epoch 696/1200\n",
            "876/876 [==============================] - 2s 2ms/step\n",
            "110/110 [==============================] - 3s 27ms/step - loss: 14.6771 - val_loss: 17.4023\n",
            "Epoch 697/1200\n",
            "876/876 [==============================] - 2s 2ms/step\n",
            "110/110 [==============================] - 3s 27ms/step - loss: 15.2417 - val_loss: 18.0030\n",
            "Epoch 698/1200\n",
            "876/876 [==============================] - 2s 2ms/step\n",
            "110/110 [==============================] - 3s 30ms/step - loss: 14.6621 - val_loss: 17.9022\n",
            "Epoch 699/1200\n",
            "876/876 [==============================] - 2s 3ms/step\n",
            "110/110 [==============================] - 4s 35ms/step - loss: 14.7058 - val_loss: 17.3445\n",
            "Epoch 700/1200\n",
            "876/876 [==============================] - 2s 2ms/step\n",
            "110/110 [==============================] - 3s 31ms/step - loss: 14.9595 - val_loss: 18.3736\n",
            "Epoch 701/1200\n",
            "876/876 [==============================] - 2s 2ms/step\n",
            "110/110 [==============================] - 3s 26ms/step - loss: 16.1485 - val_loss: 19.4730\n",
            "Epoch 702/1200\n",
            "876/876 [==============================] - 2s 2ms/step\n",
            "110/110 [==============================] - 3s 31ms/step - loss: 17.2989 - val_loss: 18.4901\n",
            "Epoch 703/1200\n",
            "876/876 [==============================] - 2s 2ms/step\n",
            "110/110 [==============================] - 3s 30ms/step - loss: 14.8197 - val_loss: 19.0811\n",
            "Epoch 704/1200\n",
            "876/876 [==============================] - 2s 3ms/step\n",
            "110/110 [==============================] - 4s 36ms/step - loss: 14.8604 - val_loss: 17.7478\n",
            "Epoch 705/1200\n",
            "876/876 [==============================] - 2s 2ms/step\n",
            "110/110 [==============================] - 4s 33ms/step - loss: 16.5739 - val_loss: 18.1592\n",
            "Epoch 706/1200\n",
            "876/876 [==============================] - 2s 2ms/step\n",
            "110/110 [==============================] - 3s 26ms/step - loss: 16.0445 - val_loss: 18.0940\n",
            "Epoch 707/1200\n",
            "876/876 [==============================] - 2s 2ms/step\n",
            "110/110 [==============================] - 3s 27ms/step - loss: 14.8571 - val_loss: 17.8763\n",
            "Epoch 708/1200\n",
            "876/876 [==============================] - 2s 2ms/step\n",
            "110/110 [==============================] - 3s 31ms/step - loss: 14.8928 - val_loss: 17.9350\n",
            "Epoch 709/1200\n",
            "876/876 [==============================] - 3s 3ms/step\n",
            "110/110 [==============================] - 6s 58ms/step - loss: 16.0072 - val_loss: 18.5208\n",
            "Epoch 710/1200\n",
            "876/876 [==============================] - 2s 2ms/step\n",
            "110/110 [==============================] - 3s 27ms/step - loss: 15.0272 - val_loss: 17.6152\n",
            "Epoch 711/1200\n",
            "876/876 [==============================] - 2s 2ms/step\n",
            "110/110 [==============================] - 3s 31ms/step - loss: 14.6523 - val_loss: 17.2191\n",
            "Epoch 712/1200\n",
            "876/876 [==============================] - 2s 3ms/step\n",
            "110/110 [==============================] - 4s 37ms/step - loss: 14.9214 - val_loss: 17.3625\n",
            "Epoch 713/1200\n",
            "876/876 [==============================] - 2s 3ms/step\n",
            "110/110 [==============================] - 7s 60ms/step - loss: 14.6231 - val_loss: 18.0135\n",
            "Epoch 714/1200\n",
            "876/876 [==============================] - 2s 2ms/step\n",
            "110/110 [==============================] - 3s 27ms/step - loss: 15.1531 - val_loss: 18.1296\n",
            "Epoch 715/1200\n",
            "876/876 [==============================] - 2s 2ms/step\n",
            "110/110 [==============================] - 3s 31ms/step - loss: 14.6304 - val_loss: 17.3800\n",
            "Epoch 716/1200\n",
            "876/876 [==============================] - 2s 2ms/step\n",
            "110/110 [==============================] - 3s 28ms/step - loss: 14.6276 - val_loss: 17.6135\n",
            "Epoch 717/1200\n",
            "876/876 [==============================] - 2s 3ms/step\n",
            "110/110 [==============================] - 6s 57ms/step - loss: 14.6690 - val_loss: 18.3180\n",
            "Epoch 718/1200\n",
            "876/876 [==============================] - 2s 2ms/step\n",
            "110/110 [==============================] - 3s 31ms/step - loss: 14.9166 - val_loss: 17.7449\n",
            "Epoch 719/1200\n",
            "876/876 [==============================] - 2s 2ms/step\n",
            "110/110 [==============================] - 3s 27ms/step - loss: 14.6706 - val_loss: 18.2171\n",
            "Epoch 720/1200\n",
            "876/876 [==============================] - 2s 2ms/step\n",
            "110/110 [==============================] - 3s 30ms/step - loss: 14.6694 - val_loss: 17.6858\n",
            "Epoch 721/1200\n",
            "876/876 [==============================] - 2s 3ms/step\n",
            "110/110 [==============================] - 6s 57ms/step - loss: 14.8808 - val_loss: 18.0804\n",
            "Epoch 722/1200\n",
            "876/876 [==============================] - 2s 2ms/step\n",
            "110/110 [==============================] - 3s 31ms/step - loss: 14.7178 - val_loss: 17.8743\n",
            "Epoch 723/1200\n",
            "876/876 [==============================] - 2s 2ms/step\n",
            "110/110 [==============================] - 3s 30ms/step - loss: 14.8596 - val_loss: 17.5691\n",
            "Epoch 724/1200\n",
            "876/876 [==============================] - 2s 3ms/step\n",
            "110/110 [==============================] - 3s 31ms/step - loss: 14.8887 - val_loss: 17.9411\n",
            "Epoch 725/1200\n",
            "876/876 [==============================] - 2s 3ms/step\n",
            "110/110 [==============================] - 6s 57ms/step - loss: 14.7003 - val_loss: 18.1083\n",
            "Epoch 726/1200\n",
            "876/876 [==============================] - 2s 2ms/step\n",
            "110/110 [==============================] - 3s 31ms/step - loss: 14.8700 - val_loss: 18.3917\n",
            "Epoch 727/1200\n",
            "876/876 [==============================] - 2s 2ms/step\n",
            "110/110 [==============================] - 3s 27ms/step - loss: 14.6013 - val_loss: 18.1783\n",
            "Epoch 728/1200\n",
            "876/876 [==============================] - 2s 2ms/step\n",
            "110/110 [==============================] - 6s 54ms/step - loss: 14.9485 - val_loss: 18.2110\n",
            "Epoch 729/1200\n",
            "876/876 [==============================] - 2s 2ms/step\n",
            "110/110 [==============================] - 3s 31ms/step - loss: 14.8823 - val_loss: 17.7180\n",
            "Epoch 730/1200\n",
            "876/876 [==============================] - 2s 2ms/step\n",
            "110/110 [==============================] - 3s 27ms/step - loss: 14.9534 - val_loss: 17.9232\n",
            "Epoch 731/1200\n",
            "876/876 [==============================] - 2s 2ms/step\n",
            "110/110 [==============================] - 3s 31ms/step - loss: 14.5713 - val_loss: 17.8045\n",
            "Epoch 732/1200\n",
            "876/876 [==============================] - 2s 3ms/step\n",
            "110/110 [==============================] - 6s 58ms/step - loss: 14.6353 - val_loss: 18.0379\n",
            "Epoch 733/1200\n",
            "876/876 [==============================] - 2s 2ms/step\n",
            "110/110 [==============================] - 3s 31ms/step - loss: 14.9809 - val_loss: 18.0129\n",
            "Epoch 734/1200\n",
            "876/876 [==============================] - 2s 3ms/step\n",
            "110/110 [==============================] - 4s 33ms/step - loss: 14.9940 - val_loss: 17.5875\n",
            "Epoch 735/1200\n",
            "876/876 [==============================] - 3s 3ms/step\n",
            "110/110 [==============================] - 6s 58ms/step - loss: 14.9386 - val_loss: 18.3357\n",
            "Epoch 736/1200\n",
            "876/876 [==============================] - 2s 2ms/step\n",
            "110/110 [==============================] - 3s 27ms/step - loss: 15.5614 - val_loss: 19.0031\n",
            "Epoch 737/1200\n",
            "876/876 [==============================] - 2s 2ms/step\n",
            "110/110 [==============================] - 3s 27ms/step - loss: 14.6772 - val_loss: 17.8156\n",
            "Epoch 738/1200\n",
            "876/876 [==============================] - 2s 2ms/step\n",
            "110/110 [==============================] - 3s 27ms/step - loss: 14.7196 - val_loss: 17.6029\n",
            "Epoch 739/1200\n",
            "876/876 [==============================] - 2s 3ms/step\n",
            "110/110 [==============================] - 4s 32ms/step - loss: 14.7628 - val_loss: 18.1727\n",
            "Epoch 740/1200\n",
            "876/876 [==============================] - 2s 3ms/step\n",
            "110/110 [==============================] - 6s 58ms/step - loss: 14.6698 - val_loss: 18.0931\n",
            "Epoch 741/1200\n",
            "876/876 [==============================] - 2s 2ms/step\n",
            "110/110 [==============================] - 3s 31ms/step - loss: 14.8628 - val_loss: 18.9718\n",
            "Epoch 742/1200\n",
            "876/876 [==============================] - 2s 2ms/step\n",
            "110/110 [==============================] - 3s 31ms/step - loss: 14.7373 - val_loss: 17.8317\n",
            "Epoch 743/1200\n",
            "876/876 [==============================] - 2s 3ms/step\n",
            "110/110 [==============================] - 3s 31ms/step - loss: 14.6735 - val_loss: 17.5159\n",
            "Epoch 744/1200\n",
            "876/876 [==============================] - 2s 3ms/step\n",
            "110/110 [==============================] - 6s 57ms/step - loss: 14.6648 - val_loss: 18.1365\n",
            "Epoch 745/1200\n",
            "876/876 [==============================] - 2s 2ms/step\n",
            "110/110 [==============================] - 3s 31ms/step - loss: 14.7076 - val_loss: 18.4986\n",
            "Epoch 746/1200\n",
            "876/876 [==============================] - 2s 2ms/step\n",
            "110/110 [==============================] - 3s 31ms/step - loss: 14.9629 - val_loss: 17.6842\n",
            "Epoch 747/1200\n",
            "876/876 [==============================] - 2s 3ms/step\n",
            "110/110 [==============================] - 6s 54ms/step - loss: 14.7778 - val_loss: 18.3878\n",
            "Epoch 748/1200\n",
            "876/876 [==============================] - 2s 2ms/step\n",
            "110/110 [==============================] - 3s 31ms/step - loss: 14.6739 - val_loss: 18.0630\n",
            "Epoch 749/1200\n",
            "876/876 [==============================] - 2s 2ms/step\n",
            "110/110 [==============================] - 3s 28ms/step - loss: 14.6493 - val_loss: 17.2352\n",
            "Epoch 750/1200\n",
            "876/876 [==============================] - 2s 2ms/step\n",
            "110/110 [==============================] - 3s 31ms/step - loss: 16.2215 - val_loss: 17.6743\n",
            "Epoch 751/1200\n",
            "876/876 [==============================] - 2s 3ms/step\n",
            "110/110 [==============================] - 6s 58ms/step - loss: 14.9456 - val_loss: 17.6666\n",
            "Epoch 752/1200\n",
            "876/876 [==============================] - 2s 2ms/step\n",
            "110/110 [==============================] - 3s 28ms/step - loss: 15.8716 - val_loss: 19.0074\n",
            "Epoch 753/1200\n",
            "876/876 [==============================] - 2s 2ms/step\n",
            "110/110 [==============================] - 3s 27ms/step - loss: 15.2195 - val_loss: 18.7246\n",
            "Epoch 754/1200\n",
            "876/876 [==============================] - 2s 2ms/step\n",
            "110/110 [==============================] - 3s 31ms/step - loss: 14.7650 - val_loss: 17.7152\n",
            "Epoch 755/1200\n",
            "876/876 [==============================] - 2s 3ms/step\n",
            "110/110 [==============================] - 4s 36ms/step - loss: 15.0860 - val_loss: 18.0604\n",
            "Epoch 756/1200\n",
            "876/876 [==============================] - 2s 2ms/step\n",
            "110/110 [==============================] - 4s 33ms/step - loss: 14.5952 - val_loss: 17.4688\n",
            "Epoch 757/1200\n",
            "876/876 [==============================] - 2s 2ms/step\n",
            "110/110 [==============================] - 3s 31ms/step - loss: 14.6437 - val_loss: 17.5404\n",
            "Epoch 758/1200\n",
            "876/876 [==============================] - 2s 2ms/step\n",
            "110/110 [==============================] - 3s 27ms/step - loss: 15.2700 - val_loss: 17.9253\n",
            "Epoch 759/1200\n",
            "876/876 [==============================] - 2s 3ms/step\n",
            "110/110 [==============================] - 6s 54ms/step - loss: 15.0195 - val_loss: 18.0591\n",
            "Epoch 760/1200\n",
            "876/876 [==============================] - 2s 2ms/step\n",
            "110/110 [==============================] - 3s 31ms/step - loss: 14.5481 - val_loss: 17.6179\n",
            "Epoch 761/1200\n",
            "876/876 [==============================] - 2s 2ms/step\n",
            "110/110 [==============================] - 3s 28ms/step - loss: 14.9769 - val_loss: 17.8652\n",
            "Epoch 762/1200\n",
            "876/876 [==============================] - 2s 2ms/step\n",
            "110/110 [==============================] - 3s 28ms/step - loss: 14.8626 - val_loss: 17.1754\n",
            "Epoch 763/1200\n",
            "876/876 [==============================] - 2s 3ms/step\n",
            "110/110 [==============================] - 6s 57ms/step - loss: 15.1246 - val_loss: 18.2901\n",
            "Epoch 764/1200\n",
            "876/876 [==============================] - 2s 2ms/step\n",
            "110/110 [==============================] - 3s 31ms/step - loss: 15.2426 - val_loss: 17.3954\n",
            "Epoch 765/1200\n",
            "876/876 [==============================] - 2s 2ms/step\n",
            "110/110 [==============================] - 3s 31ms/step - loss: 14.6229 - val_loss: 18.1023\n",
            "Epoch 766/1200\n",
            "876/876 [==============================] - 2s 3ms/step\n",
            "110/110 [==============================] - 3s 31ms/step - loss: 15.2280 - val_loss: 18.4616\n",
            "Epoch 767/1200\n",
            "876/876 [==============================] - 2s 3ms/step\n",
            "110/110 [==============================] - 4s 36ms/step - loss: 14.6008 - val_loss: 16.8071\n",
            "Epoch 768/1200\n",
            "876/876 [==============================] - 3s 3ms/step\n",
            "110/110 [==============================] - 6s 58ms/step - loss: 14.6526 - val_loss: 17.6543\n",
            "Epoch 769/1200\n",
            "876/876 [==============================] - 2s 2ms/step\n",
            "110/110 [==============================] - 3s 31ms/step - loss: 14.7247 - val_loss: 18.4747\n",
            "Epoch 770/1200\n",
            "876/876 [==============================] - 2s 2ms/step\n",
            "110/110 [==============================] - 3s 27ms/step - loss: 14.6568 - val_loss: 18.7036\n",
            "Epoch 771/1200\n",
            "876/876 [==============================] - 2s 2ms/step\n",
            "110/110 [==============================] - 3s 31ms/step - loss: 14.7612 - val_loss: 17.4098\n",
            "Epoch 772/1200\n",
            "876/876 [==============================] - 2s 3ms/step\n",
            "110/110 [==============================] - 6s 57ms/step - loss: 15.3355 - val_loss: 17.8028\n",
            "Epoch 773/1200\n",
            "876/876 [==============================] - 2s 2ms/step\n",
            "110/110 [==============================] - 3s 27ms/step - loss: 14.6970 - val_loss: 17.2204\n",
            "Epoch 774/1200\n",
            "876/876 [==============================] - 2s 2ms/step\n",
            "110/110 [==============================] - 3s 27ms/step - loss: 15.3908 - val_loss: 18.3103\n",
            "Epoch 775/1200\n",
            "876/876 [==============================] - 2s 2ms/step\n",
            "110/110 [==============================] - 3s 29ms/step - loss: 15.4404 - val_loss: 18.9246\n",
            "Epoch 776/1200\n",
            "876/876 [==============================] - 2s 3ms/step\n",
            "110/110 [==============================] - 6s 57ms/step - loss: 14.8204 - val_loss: 18.1295\n",
            "Epoch 777/1200\n",
            "876/876 [==============================] - 2s 2ms/step\n",
            "110/110 [==============================] - 3s 31ms/step - loss: 14.6019 - val_loss: 18.1054\n",
            "Epoch 778/1200\n",
            "876/876 [==============================] - 2s 2ms/step\n",
            "110/110 [==============================] - 3s 27ms/step - loss: 14.6854 - val_loss: 17.7170\n",
            "Epoch 779/1200\n",
            "876/876 [==============================] - 2s 2ms/step\n",
            "110/110 [==============================] - 3s 30ms/step - loss: 14.5244 - val_loss: 16.8908\n",
            "Epoch 780/1200\n",
            "876/876 [==============================] - 2s 3ms/step\n",
            "110/110 [==============================] - 6s 57ms/step - loss: 14.5928 - val_loss: 18.1247\n",
            "Epoch 781/1200\n",
            "876/876 [==============================] - 2s 2ms/step\n",
            "110/110 [==============================] - 3s 28ms/step - loss: 14.5998 - val_loss: 18.0967\n",
            "Epoch 782/1200\n",
            "876/876 [==============================] - 2s 2ms/step\n",
            "110/110 [==============================] - 3s 27ms/step - loss: 15.3481 - val_loss: 18.2259\n",
            "Epoch 783/1200\n",
            "876/876 [==============================] - 2s 2ms/step\n",
            "110/110 [==============================] - 3s 31ms/step - loss: 15.1234 - val_loss: 17.0912\n",
            "Epoch 784/1200\n",
            "876/876 [==============================] - 2s 3ms/step\n",
            "110/110 [==============================] - 6s 57ms/step - loss: 14.7146 - val_loss: 18.4982\n",
            "Epoch 785/1200\n",
            "876/876 [==============================] - 2s 2ms/step\n",
            "110/110 [==============================] - 3s 31ms/step - loss: 14.5893 - val_loss: 18.1206\n",
            "Epoch 786/1200\n",
            "876/876 [==============================] - 2s 2ms/step\n",
            "110/110 [==============================] - 3s 31ms/step - loss: 14.7785 - val_loss: 17.9094\n",
            "Epoch 787/1200\n",
            "876/876 [==============================] - 2s 2ms/step\n",
            "110/110 [==============================] - 6s 55ms/step - loss: 15.0955 - val_loss: 17.1198\n",
            "Epoch 788/1200\n",
            "876/876 [==============================] - 2s 2ms/step\n",
            "110/110 [==============================] - 3s 28ms/step - loss: 14.7705 - val_loss: 17.9229\n",
            "Epoch 789/1200\n",
            "876/876 [==============================] - 2s 2ms/step\n",
            "110/110 [==============================] - 3s 28ms/step - loss: 14.8299 - val_loss: 18.7047\n",
            "Epoch 790/1200\n",
            "876/876 [==============================] - 2s 2ms/step\n",
            "110/110 [==============================] - 3s 28ms/step - loss: 14.8548 - val_loss: 17.8934\n",
            "Epoch 791/1200\n",
            "876/876 [==============================] - 2s 3ms/step\n",
            "110/110 [==============================] - 6s 57ms/step - loss: 15.4596 - val_loss: 17.8084\n",
            "Epoch 792/1200\n",
            "876/876 [==============================] - 2s 2ms/step\n",
            "110/110 [==============================] - 3s 28ms/step - loss: 14.8618 - val_loss: 18.5596\n",
            "Epoch 793/1200\n",
            "876/876 [==============================] - 2s 2ms/step\n",
            "110/110 [==============================] - 3s 32ms/step - loss: 14.5946 - val_loss: 17.4969\n",
            "Epoch 794/1200\n",
            "876/876 [==============================] - 2s 2ms/step\n",
            "110/110 [==============================] - 3s 31ms/step - loss: 14.5212 - val_loss: 17.3787\n",
            "Epoch 795/1200\n",
            "876/876 [==============================] - 2s 3ms/step\n",
            "110/110 [==============================] - 6s 59ms/step - loss: 14.6740 - val_loss: 18.5415\n",
            "Epoch 796/1200\n",
            "876/876 [==============================] - 2s 2ms/step\n",
            "110/110 [==============================] - 3s 31ms/step - loss: 14.9276 - val_loss: 17.0736\n",
            "Epoch 797/1200\n",
            "876/876 [==============================] - 2s 2ms/step\n",
            "110/110 [==============================] - 3s 31ms/step - loss: 21.7651 - val_loss: 23.4000\n",
            "Epoch 798/1200\n",
            "876/876 [==============================] - 2s 3ms/step\n",
            "110/110 [==============================] - 6s 55ms/step - loss: 21.2802 - val_loss: 22.6175\n",
            "Epoch 799/1200\n",
            "876/876 [==============================] - 2s 2ms/step\n",
            "110/110 [==============================] - 3s 31ms/step - loss: 20.8937 - val_loss: 23.5168\n",
            "Epoch 800/1200\n",
            "876/876 [==============================] - 2s 2ms/step\n",
            "110/110 [==============================] - 3s 31ms/step - loss: 20.3011 - val_loss: 22.5846\n",
            "Epoch 801/1200\n",
            "876/876 [==============================] - 2s 3ms/step\n",
            "110/110 [==============================] - 6s 57ms/step - loss: 19.0903 - val_loss: 22.1380\n",
            "Epoch 802/1200\n",
            "876/876 [==============================] - 2s 2ms/step\n",
            "110/110 [==============================] - 4s 33ms/step - loss: 18.7047 - val_loss: 22.0528\n",
            "Epoch 803/1200\n",
            "876/876 [==============================] - 2s 2ms/step\n",
            "110/110 [==============================] - 3s 31ms/step - loss: 18.7063 - val_loss: 22.0031\n",
            "Epoch 804/1200\n",
            "876/876 [==============================] - 2s 2ms/step\n",
            "110/110 [==============================] - 3s 26ms/step - loss: 18.3528 - val_loss: 21.9958\n",
            "Epoch 805/1200\n",
            "876/876 [==============================] - 2s 2ms/step\n",
            "110/110 [==============================] - 3s 31ms/step - loss: 18.1617 - val_loss: 21.8506\n",
            "Epoch 806/1200\n",
            "876/876 [==============================] - 2s 3ms/step\n",
            "110/110 [==============================] - 6s 58ms/step - loss: 18.0300 - val_loss: 21.8938\n",
            "Epoch 807/1200\n",
            "876/876 [==============================] - 2s 2ms/step\n",
            "110/110 [==============================] - 3s 27ms/step - loss: 18.0701 - val_loss: 21.7555\n",
            "Epoch 808/1200\n",
            "876/876 [==============================] - 2s 2ms/step\n",
            "110/110 [==============================] - 3s 27ms/step - loss: 17.8455 - val_loss: 21.5977\n",
            "Epoch 809/1200\n",
            "876/876 [==============================] - 2s 2ms/step\n",
            "110/110 [==============================] - 3s 31ms/step - loss: 17.7587 - val_loss: 21.5422\n",
            "Epoch 810/1200\n",
            "876/876 [==============================] - 2s 3ms/step\n",
            "110/110 [==============================] - 6s 56ms/step - loss: 17.9527 - val_loss: 21.9908\n",
            "Epoch 811/1200\n",
            "876/876 [==============================] - 2s 2ms/step\n",
            "110/110 [==============================] - 3s 27ms/step - loss: 17.3636 - val_loss: 21.4279\n",
            "Epoch 812/1200\n",
            "876/876 [==============================] - 2s 2ms/step\n",
            "110/110 [==============================] - 3s 31ms/step - loss: 17.2708 - val_loss: 22.2497\n",
            "Epoch 813/1200\n",
            "876/876 [==============================] - 2s 2ms/step\n",
            "110/110 [==============================] - 3s 31ms/step - loss: 17.5065 - val_loss: 21.9163\n",
            "Epoch 814/1200\n",
            "876/876 [==============================] - 2s 3ms/step\n",
            "110/110 [==============================] - 4s 38ms/step - loss: 16.9667 - val_loss: 22.5011\n",
            "Epoch 815/1200\n",
            "876/876 [==============================] - 2s 2ms/step\n",
            "110/110 [==============================] - 4s 34ms/step - loss: 17.4737 - val_loss: 21.7079\n",
            "Epoch 816/1200\n",
            "876/876 [==============================] - 2s 2ms/step\n",
            "110/110 [==============================] - 3s 27ms/step - loss: 17.6316 - val_loss: 21.2182\n",
            "Epoch 817/1200\n",
            "876/876 [==============================] - 2s 2ms/step\n",
            "110/110 [==============================] - 3s 27ms/step - loss: 18.3372 - val_loss: 21.2914\n",
            "Epoch 818/1200\n",
            "876/876 [==============================] - 2s 2ms/step\n",
            "110/110 [==============================] - 6s 54ms/step - loss: 16.8717 - val_loss: 21.1449\n",
            "Epoch 819/1200\n",
            "876/876 [==============================] - 2s 2ms/step\n",
            "110/110 [==============================] - 3s 27ms/step - loss: 16.6859 - val_loss: 21.0747\n",
            "Epoch 820/1200\n",
            "876/876 [==============================] - 2s 2ms/step\n",
            "110/110 [==============================] - 3s 31ms/step - loss: 16.8526 - val_loss: 21.4475\n",
            "Epoch 821/1200\n",
            "876/876 [==============================] - 2s 2ms/step\n",
            "110/110 [==============================] - 3s 31ms/step - loss: 16.6981 - val_loss: 21.1308\n",
            "Epoch 822/1200\n",
            "876/876 [==============================] - 2s 3ms/step\n",
            "110/110 [==============================] - 6s 57ms/step - loss: 16.2368 - val_loss: 21.2162\n",
            "Epoch 823/1200\n",
            "876/876 [==============================] - 2s 3ms/step\n",
            "110/110 [==============================] - 4s 33ms/step - loss: 16.8773 - val_loss: 21.0421\n",
            "Epoch 824/1200\n",
            "876/876 [==============================] - 3s 3ms/step\n",
            "110/110 [==============================] - 4s 36ms/step - loss: 16.1363 - val_loss: 20.8967\n",
            "Epoch 825/1200\n",
            "876/876 [==============================] - 2s 3ms/step\n",
            "110/110 [==============================] - 6s 58ms/step - loss: 16.4205 - val_loss: 20.9576\n",
            "Epoch 826/1200\n",
            "876/876 [==============================] - 2s 2ms/step\n",
            "110/110 [==============================] - 3s 27ms/step - loss: 16.3169 - val_loss: 20.8949\n",
            "Epoch 827/1200\n",
            "876/876 [==============================] - 2s 2ms/step\n",
            "110/110 [==============================] - 3s 31ms/step - loss: 16.2521 - val_loss: 21.2795\n",
            "Epoch 828/1200\n",
            "876/876 [==============================] - 2s 2ms/step\n",
            "110/110 [==============================] - 3s 29ms/step - loss: 16.3634 - val_loss: 20.8561\n",
            "Epoch 829/1200\n",
            "876/876 [==============================] - 2s 3ms/step\n",
            "110/110 [==============================] - 6s 57ms/step - loss: 16.0716 - val_loss: 21.3820\n",
            "Epoch 830/1200\n",
            "876/876 [==============================] - 2s 2ms/step\n",
            "110/110 [==============================] - 3s 31ms/step - loss: 16.2432 - val_loss: 21.3543\n",
            "Epoch 831/1200\n",
            "876/876 [==============================] - 2s 2ms/step\n",
            "110/110 [==============================] - 3s 29ms/step - loss: 16.1630 - val_loss: 21.4339\n",
            "Epoch 832/1200\n",
            "876/876 [==============================] - 2s 2ms/step\n",
            "110/110 [==============================] - 3s 31ms/step - loss: 15.7784 - val_loss: 20.8122\n",
            "Epoch 833/1200\n",
            "876/876 [==============================] - 2s 3ms/step\n",
            "110/110 [==============================] - 4s 38ms/step - loss: 15.7600 - val_loss: 21.1174\n",
            "Epoch 834/1200\n",
            "876/876 [==============================] - 2s 2ms/step\n",
            "110/110 [==============================] - 4s 33ms/step - loss: 16.1616 - val_loss: 22.1604\n",
            "Epoch 835/1200\n",
            "876/876 [==============================] - 2s 2ms/step\n",
            "110/110 [==============================] - 3s 31ms/step - loss: 16.6338 - val_loss: 20.8283\n",
            "Epoch 836/1200\n",
            "876/876 [==============================] - 2s 2ms/step\n",
            "110/110 [==============================] - 3s 27ms/step - loss: 15.7057 - val_loss: 20.8847\n",
            "Epoch 837/1200\n",
            "876/876 [==============================] - 2s 2ms/step\n",
            "110/110 [==============================] - 3s 31ms/step - loss: 16.5009 - val_loss: 20.6090\n",
            "Epoch 838/1200\n",
            "876/876 [==============================] - 2s 3ms/step\n",
            "110/110 [==============================] - 4s 38ms/step - loss: 15.9657 - val_loss: 21.1079\n",
            "Epoch 839/1200\n",
            "876/876 [==============================] - 2s 2ms/step\n",
            "110/110 [==============================] - 4s 35ms/step - loss: 16.0164 - val_loss: 20.9401\n",
            "Epoch 840/1200\n",
            "876/876 [==============================] - 2s 2ms/step\n",
            "110/110 [==============================] - 3s 28ms/step - loss: 15.4936 - val_loss: 20.8602\n",
            "Epoch 841/1200\n",
            "876/876 [==============================] - 2s 2ms/step\n",
            "110/110 [==============================] - 3s 27ms/step - loss: 15.8521 - val_loss: 20.7688\n",
            "Epoch 842/1200\n",
            "876/876 [==============================] - 2s 2ms/step\n",
            "110/110 [==============================] - 3s 32ms/step - loss: 15.5107 - val_loss: 20.3503\n",
            "Epoch 843/1200\n",
            "876/876 [==============================] - 2s 3ms/step\n",
            "110/110 [==============================] - 4s 38ms/step - loss: 15.3562 - val_loss: 20.3787\n",
            "Epoch 844/1200\n",
            "876/876 [==============================] - 2s 2ms/step\n",
            "110/110 [==============================] - 4s 35ms/step - loss: 15.7615 - val_loss: 20.2695\n",
            "Epoch 845/1200\n",
            "876/876 [==============================] - 2s 2ms/step\n",
            "110/110 [==============================] - 3s 31ms/step - loss: 15.7254 - val_loss: 19.9638\n",
            "Epoch 846/1200\n",
            "876/876 [==============================] - 2s 2ms/step\n",
            "110/110 [==============================] - 3s 31ms/step - loss: 16.6330 - val_loss: 20.2446\n",
            "Epoch 847/1200\n",
            "876/876 [==============================] - 2s 3ms/step\n",
            "110/110 [==============================] - 6s 56ms/step - loss: 15.3812 - val_loss: 20.3840\n",
            "Epoch 848/1200\n",
            "876/876 [==============================] - 2s 2ms/step\n",
            "110/110 [==============================] - 3s 28ms/step - loss: 16.1539 - val_loss: 20.3539\n",
            "Epoch 849/1200\n",
            "876/876 [==============================] - 2s 2ms/step\n",
            "110/110 [==============================] - 3s 31ms/step - loss: 15.5683 - val_loss: 19.7998\n",
            "Epoch 850/1200\n",
            "876/876 [==============================] - 2s 2ms/step\n",
            "110/110 [==============================] - 3s 31ms/step - loss: 15.5258 - val_loss: 19.5033\n",
            "Epoch 851/1200\n",
            "876/876 [==============================] - 2s 3ms/step\n",
            "110/110 [==============================] - 6s 58ms/step - loss: 15.4163 - val_loss: 20.0269\n",
            "Epoch 852/1200\n",
            "876/876 [==============================] - 2s 2ms/step\n",
            "110/110 [==============================] - 3s 27ms/step - loss: 15.3830 - val_loss: 19.5330\n",
            "Epoch 853/1200\n",
            "876/876 [==============================] - 2s 2ms/step\n",
            "110/110 [==============================] - 3s 27ms/step - loss: 15.3392 - val_loss: 20.1057\n",
            "Epoch 854/1200\n",
            "876/876 [==============================] - 2s 2ms/step\n",
            "110/110 [==============================] - 3s 31ms/step - loss: 15.3683 - val_loss: 20.1619\n",
            "Epoch 855/1200\n",
            "876/876 [==============================] - 2s 3ms/step\n",
            "110/110 [==============================] - 4s 38ms/step - loss: 15.3463 - val_loss: 19.8257\n",
            "Epoch 856/1200\n",
            "876/876 [==============================] - 2s 2ms/step\n",
            "110/110 [==============================] - 4s 33ms/step - loss: 15.1879 - val_loss: 19.8394\n",
            "Epoch 857/1200\n",
            "876/876 [==============================] - 2s 2ms/step\n",
            "110/110 [==============================] - 3s 28ms/step - loss: 15.2316 - val_loss: 20.4437\n",
            "Epoch 858/1200\n",
            "876/876 [==============================] - 2s 2ms/step\n",
            "110/110 [==============================] - 3s 27ms/step - loss: 15.4750 - val_loss: 20.2923\n",
            "Epoch 859/1200\n",
            "876/876 [==============================] - 2s 2ms/step\n",
            "110/110 [==============================] - 3s 32ms/step - loss: 15.6554 - val_loss: 19.8353\n",
            "Epoch 860/1200\n",
            "876/876 [==============================] - 2s 3ms/step\n",
            "110/110 [==============================] - 4s 38ms/step - loss: 15.0933 - val_loss: 19.3066\n",
            "Epoch 861/1200\n",
            "876/876 [==============================] - 2s 2ms/step\n",
            "110/110 [==============================] - 3s 31ms/step - loss: 15.3971 - val_loss: 19.6778\n",
            "Epoch 862/1200\n",
            "876/876 [==============================] - 2s 2ms/step\n",
            "110/110 [==============================] - 3s 31ms/step - loss: 15.2859 - val_loss: 19.3400\n",
            "Epoch 863/1200\n",
            "876/876 [==============================] - 2s 2ms/step\n",
            "110/110 [==============================] - 3s 31ms/step - loss: 15.2081 - val_loss: 19.7243\n",
            "Epoch 864/1200\n",
            "876/876 [==============================] - 2s 3ms/step\n",
            "110/110 [==============================] - 6s 54ms/step - loss: 15.5261 - val_loss: 19.4173\n",
            "Epoch 865/1200\n",
            "876/876 [==============================] - 2s 2ms/step\n",
            "110/110 [==============================] - 3s 28ms/step - loss: 15.0089 - val_loss: 19.5496\n",
            "Epoch 866/1200\n",
            "876/876 [==============================] - 2s 2ms/step\n",
            "110/110 [==============================] - 3s 32ms/step - loss: 15.4743 - val_loss: 19.9291\n",
            "Epoch 867/1200\n",
            "876/876 [==============================] - 2s 2ms/step\n",
            "110/110 [==============================] - 3s 29ms/step - loss: 15.4497 - val_loss: 19.2179\n",
            "Epoch 868/1200\n",
            "876/876 [==============================] - 2s 3ms/step\n",
            "110/110 [==============================] - 6s 58ms/step - loss: 15.4277 - val_loss: 21.4691\n",
            "Epoch 869/1200\n",
            "876/876 [==============================] - 2s 3ms/step\n",
            "110/110 [==============================] - 4s 38ms/step - loss: 18.8101 - val_loss: 20.4187\n",
            "Epoch 870/1200\n",
            "876/876 [==============================] - 2s 2ms/step\n",
            "110/110 [==============================] - 3s 32ms/step - loss: 16.3530 - val_loss: 20.6681\n",
            "Epoch 871/1200\n",
            "876/876 [==============================] - 2s 3ms/step\n",
            "110/110 [==============================] - 6s 55ms/step - loss: 15.8575 - val_loss: 18.9436\n",
            "Epoch 872/1200\n",
            "876/876 [==============================] - 2s 2ms/step\n",
            "110/110 [==============================] - 3s 28ms/step - loss: 15.5389 - val_loss: 18.8122\n",
            "Epoch 873/1200\n",
            "876/876 [==============================] - 2s 2ms/step\n",
            "110/110 [==============================] - 3s 31ms/step - loss: 14.8462 - val_loss: 19.7306\n",
            "Epoch 874/1200\n",
            "876/876 [==============================] - 2s 2ms/step\n",
            "110/110 [==============================] - 3s 32ms/step - loss: 14.9598 - val_loss: 19.3492\n",
            "Epoch 875/1200\n",
            "876/876 [==============================] - 2s 3ms/step\n",
            "110/110 [==============================] - 4s 37ms/step - loss: 15.6380 - val_loss: 18.9749\n",
            "Epoch 876/1200\n",
            "876/876 [==============================] - 2s 3ms/step\n",
            "110/110 [==============================] - 4s 35ms/step - loss: 14.9877 - val_loss: 19.1622\n",
            "Epoch 877/1200\n",
            "876/876 [==============================] - 2s 2ms/step\n",
            "110/110 [==============================] - 3s 32ms/step - loss: 15.2893 - val_loss: 19.2137\n",
            "Epoch 878/1200\n",
            "876/876 [==============================] - 2s 2ms/step\n",
            "110/110 [==============================] - 3s 27ms/step - loss: 14.9948 - val_loss: 19.3400\n",
            "Epoch 879/1200\n",
            "876/876 [==============================] - 2s 2ms/step\n",
            "110/110 [==============================] - 3s 31ms/step - loss: 15.0365 - val_loss: 19.3947\n",
            "Epoch 880/1200\n",
            "876/876 [==============================] - 2s 3ms/step\n",
            "110/110 [==============================] - 4s 38ms/step - loss: 15.1521 - val_loss: 19.3918\n",
            "Epoch 881/1200\n",
            "876/876 [==============================] - 2s 2ms/step\n",
            "110/110 [==============================] - 4s 34ms/step - loss: 15.5115 - val_loss: 18.9868\n",
            "Epoch 882/1200\n",
            "876/876 [==============================] - 2s 3ms/step\n",
            "110/110 [==============================] - 6s 59ms/step - loss: 14.8562 - val_loss: 19.7173\n",
            "Epoch 883/1200\n",
            "876/876 [==============================] - 2s 3ms/step\n",
            "110/110 [==============================] - 4s 33ms/step - loss: 15.1252 - val_loss: 19.5705\n",
            "Epoch 884/1200\n",
            "876/876 [==============================] - 3s 3ms/step\n",
            "110/110 [==============================] - 4s 40ms/step - loss: 14.9326 - val_loss: 20.8728\n",
            "Epoch 885/1200\n",
            "876/876 [==============================] - 2s 2ms/step\n",
            "110/110 [==============================] - 3s 31ms/step - loss: 15.0320 - val_loss: 18.8420\n",
            "Epoch 886/1200\n",
            "876/876 [==============================] - 2s 2ms/step\n",
            "110/110 [==============================] - 3s 31ms/step - loss: 14.9254 - val_loss: 20.1202\n",
            "Epoch 887/1200\n",
            "876/876 [==============================] - 2s 2ms/step\n",
            "110/110 [==============================] - 3s 31ms/step - loss: 15.1812 - val_loss: 19.3004\n",
            "Epoch 888/1200\n",
            "876/876 [==============================] - 2s 3ms/step\n",
            "110/110 [==============================] - 6s 55ms/step - loss: 15.1184 - val_loss: 19.2141\n",
            "Epoch 889/1200\n",
            "876/876 [==============================] - 2s 2ms/step\n",
            "110/110 [==============================] - 3s 31ms/step - loss: 15.0170 - val_loss: 19.1992\n",
            "Epoch 890/1200\n",
            "876/876 [==============================] - 2s 2ms/step\n",
            "110/110 [==============================] - 3s 31ms/step - loss: 15.0505 - val_loss: 19.1329\n",
            "Epoch 891/1200\n",
            "876/876 [==============================] - 2s 2ms/step\n",
            "110/110 [==============================] - 3s 31ms/step - loss: 14.8107 - val_loss: 19.8152\n",
            "Epoch 892/1200\n",
            "876/876 [==============================] - 2s 3ms/step\n",
            "110/110 [==============================] - 6s 58ms/step - loss: 15.1461 - val_loss: 19.8098\n",
            "Epoch 893/1200\n",
            "876/876 [==============================] - 2s 2ms/step\n",
            "110/110 [==============================] - 3s 27ms/step - loss: 15.9343 - val_loss: 19.1374\n",
            "Epoch 894/1200\n",
            "876/876 [==============================] - 2s 2ms/step\n",
            "110/110 [==============================] - 3s 31ms/step - loss: 15.4021 - val_loss: 19.1256\n",
            "Epoch 895/1200\n",
            "876/876 [==============================] - 2s 2ms/step\n",
            "110/110 [==============================] - 3s 31ms/step - loss: 15.2958 - val_loss: 19.3697\n",
            "Epoch 896/1200\n",
            "876/876 [==============================] - 2s 3ms/step\n",
            "110/110 [==============================] - 4s 38ms/step - loss: 14.7464 - val_loss: 19.6872\n",
            "Epoch 897/1200\n",
            "876/876 [==============================] - 2s 2ms/step\n",
            "110/110 [==============================] - 4s 32ms/step - loss: 15.0509 - val_loss: 19.2798\n",
            "Epoch 898/1200\n",
            "876/876 [==============================] - 2s 2ms/step\n",
            "110/110 [==============================] - 3s 28ms/step - loss: 17.1051 - val_loss: 20.5371\n",
            "Epoch 899/1200\n",
            "876/876 [==============================] - 2s 2ms/step\n",
            "110/110 [==============================] - 3s 28ms/step - loss: 15.0122 - val_loss: 21.0303\n",
            "Epoch 900/1200\n",
            "876/876 [==============================] - 2s 2ms/step\n",
            "110/110 [==============================] - 3s 31ms/step - loss: 14.9803 - val_loss: 19.8116\n",
            "Epoch 901/1200\n",
            "876/876 [==============================] - 2s 3ms/step\n",
            "110/110 [==============================] - 6s 57ms/step - loss: 14.7913 - val_loss: 19.6489\n",
            "Epoch 902/1200\n",
            "876/876 [==============================] - 2s 2ms/step\n",
            "110/110 [==============================] - 3s 29ms/step - loss: 14.9402 - val_loss: 19.9196\n",
            "Epoch 903/1200\n",
            "876/876 [==============================] - 2s 2ms/step\n",
            "110/110 [==============================] - 3s 31ms/step - loss: 15.0989 - val_loss: 19.1661\n",
            "Epoch 904/1200\n",
            "876/876 [==============================] - 2s 3ms/step\n",
            "110/110 [==============================] - 6s 55ms/step - loss: 15.0720 - val_loss: 19.1925\n",
            "Epoch 905/1200\n",
            "876/876 [==============================] - 2s 2ms/step\n",
            "110/110 [==============================] - 3s 29ms/step - loss: 15.0209 - val_loss: 19.1046\n",
            "Epoch 906/1200\n",
            "876/876 [==============================] - 2s 2ms/step\n",
            "110/110 [==============================] - 3s 29ms/step - loss: 14.8101 - val_loss: 20.3582\n",
            "Epoch 907/1200\n",
            "876/876 [==============================] - 2s 2ms/step\n",
            "110/110 [==============================] - 3s 31ms/step - loss: 15.4484 - val_loss: 19.5738\n",
            "Epoch 908/1200\n",
            "876/876 [==============================] - 2s 3ms/step\n",
            "110/110 [==============================] - 6s 56ms/step - loss: 15.0076 - val_loss: 19.2865\n",
            "Epoch 909/1200\n",
            "876/876 [==============================] - 2s 2ms/step\n",
            "110/110 [==============================] - 3s 31ms/step - loss: 14.8563 - val_loss: 19.4790\n",
            "Epoch 910/1200\n",
            "876/876 [==============================] - 2s 2ms/step\n",
            "110/110 [==============================] - 3s 31ms/step - loss: 14.7208 - val_loss: 20.1778\n",
            "Epoch 911/1200\n",
            "876/876 [==============================] - 2s 2ms/step\n",
            "110/110 [==============================] - 3s 32ms/step - loss: 15.1560 - val_loss: 19.4804\n",
            "Epoch 912/1200\n",
            "876/876 [==============================] - 2s 3ms/step\n",
            "110/110 [==============================] - 4s 36ms/step - loss: 15.3224 - val_loss: 19.6133\n",
            "Epoch 913/1200\n",
            "876/876 [==============================] - 2s 2ms/step\n",
            "110/110 [==============================] - 4s 34ms/step - loss: 14.8112 - val_loss: 19.2213\n",
            "Epoch 914/1200\n",
            "876/876 [==============================] - 2s 2ms/step\n",
            "110/110 [==============================] - 3s 28ms/step - loss: 15.0090 - val_loss: 19.2105\n",
            "Epoch 915/1200\n",
            "876/876 [==============================] - 2s 2ms/step\n",
            "110/110 [==============================] - 3s 27ms/step - loss: 15.0395 - val_loss: 19.0104\n",
            "Epoch 916/1200\n",
            "876/876 [==============================] - 2s 2ms/step\n",
            "110/110 [==============================] - 3s 31ms/step - loss: 14.7377 - val_loss: 19.4082\n",
            "Epoch 917/1200\n",
            "876/876 [==============================] - 2s 3ms/step\n",
            "110/110 [==============================] - 6s 57ms/step - loss: 14.9970 - val_loss: 19.5267\n",
            "Epoch 918/1200\n",
            "876/876 [==============================] - 2s 2ms/step\n",
            "110/110 [==============================] - 3s 31ms/step - loss: 14.8871 - val_loss: 18.7960\n",
            "Epoch 919/1200\n",
            "876/876 [==============================] - 2s 2ms/step\n",
            "110/110 [==============================] - 3s 32ms/step - loss: 15.3598 - val_loss: 19.0014\n",
            "Epoch 920/1200\n",
            "876/876 [==============================] - 2s 3ms/step\n",
            "110/110 [==============================] - 6s 54ms/step - loss: 14.7974 - val_loss: 19.7742\n",
            "Epoch 921/1200\n",
            "876/876 [==============================] - 2s 2ms/step\n",
            "110/110 [==============================] - 3s 28ms/step - loss: 15.2593 - val_loss: 19.4850\n",
            "Epoch 922/1200\n",
            "876/876 [==============================] - 2s 2ms/step\n",
            "110/110 [==============================] - 3s 27ms/step - loss: 14.6709 - val_loss: 19.0661\n",
            "Epoch 923/1200\n",
            "876/876 [==============================] - 2s 2ms/step\n",
            "110/110 [==============================] - 3s 27ms/step - loss: 14.7724 - val_loss: 19.2848\n",
            "Epoch 924/1200\n",
            "876/876 [==============================] - 2s 3ms/step\n",
            "110/110 [==============================] - 6s 58ms/step - loss: 14.8235 - val_loss: 19.0654\n",
            "Epoch 925/1200\n",
            "876/876 [==============================] - 2s 2ms/step\n",
            "110/110 [==============================] - 3s 28ms/step - loss: 15.3583 - val_loss: 19.1553\n",
            "Epoch 926/1200\n",
            "876/876 [==============================] - 2s 2ms/step\n",
            "110/110 [==============================] - 3s 28ms/step - loss: 15.3094 - val_loss: 18.4256\n",
            "Epoch 927/1200\n",
            "876/876 [==============================] - 2s 2ms/step\n",
            "110/110 [==============================] - 3s 30ms/step - loss: 14.9323 - val_loss: 19.1346\n",
            "Epoch 928/1200\n",
            "876/876 [==============================] - 2s 3ms/step\n",
            "110/110 [==============================] - 4s 39ms/step - loss: 14.8780 - val_loss: 19.2483\n",
            "Epoch 929/1200\n",
            "876/876 [==============================] - 2s 3ms/step\n",
            "110/110 [==============================] - 4s 34ms/step - loss: 14.8860 - val_loss: 18.2798\n",
            "Epoch 930/1200\n",
            "876/876 [==============================] - 2s 2ms/step\n",
            "110/110 [==============================] - 3s 31ms/step - loss: 15.0639 - val_loss: 18.3133\n",
            "Epoch 931/1200\n",
            "876/876 [==============================] - 2s 2ms/step\n",
            "110/110 [==============================] - 3s 28ms/step - loss: 14.8189 - val_loss: 19.5646\n",
            "Epoch 932/1200\n",
            "876/876 [==============================] - 2s 2ms/step\n",
            "110/110 [==============================] - 4s 34ms/step - loss: 14.9577 - val_loss: 19.1235\n",
            "Epoch 933/1200\n",
            "876/876 [==============================] - 3s 3ms/step\n",
            "110/110 [==============================] - 4s 39ms/step - loss: 15.4795 - val_loss: 18.9498\n",
            "Epoch 934/1200\n",
            "876/876 [==============================] - 2s 2ms/step\n",
            "110/110 [==============================] - 4s 36ms/step - loss: 15.2493 - val_loss: 18.8309\n",
            "Epoch 935/1200\n",
            "876/876 [==============================] - 2s 2ms/step\n",
            "110/110 [==============================] - 3s 31ms/step - loss: 14.8026 - val_loss: 18.6240\n",
            "Epoch 936/1200\n",
            "876/876 [==============================] - 2s 3ms/step\n",
            "110/110 [==============================] - 6s 56ms/step - loss: 14.7560 - val_loss: 18.5165\n",
            "Epoch 937/1200\n",
            "876/876 [==============================] - 3s 3ms/step\n",
            "110/110 [==============================] - 7s 60ms/step - loss: 14.6681 - val_loss: 18.5502\n",
            "Epoch 938/1200\n",
            "876/876 [==============================] - 2s 2ms/step\n",
            "110/110 [==============================] - 4s 32ms/step - loss: 14.9774 - val_loss: 19.3614\n",
            "Epoch 939/1200\n",
            "876/876 [==============================] - 2s 2ms/step\n",
            "110/110 [==============================] - 3s 28ms/step - loss: 14.7416 - val_loss: 19.2196\n",
            "Epoch 940/1200\n",
            "876/876 [==============================] - 2s 3ms/step\n",
            "110/110 [==============================] - 6s 55ms/step - loss: 14.6222 - val_loss: 18.5678\n",
            "Epoch 941/1200\n",
            "876/876 [==============================] - 2s 2ms/step\n",
            "110/110 [==============================] - 3s 28ms/step - loss: 14.9505 - val_loss: 19.5161\n",
            "Epoch 942/1200\n",
            "876/876 [==============================] - 2s 2ms/step\n",
            "110/110 [==============================] - 3s 31ms/step - loss: 14.8433 - val_loss: 19.0577\n",
            "Epoch 943/1200\n",
            "876/876 [==============================] - 2s 2ms/step\n",
            "110/110 [==============================] - 3s 29ms/step - loss: 22.5839 - val_loss: 25.7698\n",
            "Epoch 944/1200\n",
            "876/876 [==============================] - 2s 3ms/step\n",
            "110/110 [==============================] - 6s 57ms/step - loss: 23.6999 - val_loss: 23.4222\n",
            "Epoch 945/1200\n",
            "876/876 [==============================] - 2s 2ms/step\n",
            "110/110 [==============================] - 3s 28ms/step - loss: 22.8531 - val_loss: 23.1421\n",
            "Epoch 946/1200\n",
            "876/876 [==============================] - 2s 2ms/step\n",
            "110/110 [==============================] - 3s 29ms/step - loss: 22.5503 - val_loss: 22.9924\n",
            "Epoch 947/1200\n",
            "876/876 [==============================] - 2s 2ms/step\n",
            "110/110 [==============================] - 3s 32ms/step - loss: 22.4390 - val_loss: 22.7908\n",
            "Epoch 948/1200\n",
            "876/876 [==============================] - 2s 3ms/step\n",
            "110/110 [==============================] - 6s 58ms/step - loss: 21.9030 - val_loss: 21.9037\n",
            "Epoch 949/1200\n",
            "876/876 [==============================] - 2s 2ms/step\n",
            "110/110 [==============================] - 3s 29ms/step - loss: 20.7398 - val_loss: 19.8449\n",
            "Epoch 950/1200\n",
            "876/876 [==============================] - 2s 2ms/step\n",
            "110/110 [==============================] - 3s 31ms/step - loss: 19.5874 - val_loss: 18.4977\n",
            "Epoch 951/1200\n",
            "876/876 [==============================] - 2s 3ms/step\n",
            "110/110 [==============================] - 6s 55ms/step - loss: 18.7528 - val_loss: 19.7312\n",
            "Epoch 952/1200\n",
            "876/876 [==============================] - 2s 2ms/step\n",
            "110/110 [==============================] - 3s 28ms/step - loss: 18.8229 - val_loss: 20.1989\n",
            "Epoch 953/1200\n",
            "876/876 [==============================] - 2s 2ms/step\n",
            "110/110 [==============================] - 3s 31ms/step - loss: 19.0155 - val_loss: 19.6492\n",
            "Epoch 954/1200\n",
            "876/876 [==============================] - 2s 2ms/step\n",
            "110/110 [==============================] - 3s 31ms/step - loss: 18.1817 - val_loss: 18.3447\n",
            "Epoch 955/1200\n",
            "876/876 [==============================] - 2s 3ms/step\n",
            "110/110 [==============================] - 6s 58ms/step - loss: 17.7273 - val_loss: 19.2562\n",
            "Epoch 956/1200\n",
            "876/876 [==============================] - 2s 2ms/step\n",
            "110/110 [==============================] - 3s 28ms/step - loss: 17.0471 - val_loss: 20.4277\n",
            "Epoch 957/1200\n",
            "876/876 [==============================] - 2s 2ms/step\n",
            "110/110 [==============================] - 3s 31ms/step - loss: 17.6025 - val_loss: 19.5698\n",
            "Epoch 958/1200\n",
            "876/876 [==============================] - 2s 2ms/step\n",
            "110/110 [==============================] - 6s 55ms/step - loss: 16.5992 - val_loss: 18.1546\n",
            "Epoch 959/1200\n",
            "876/876 [==============================] - 2s 2ms/step\n",
            "110/110 [==============================] - 3s 31ms/step - loss: 16.4698 - val_loss: 16.6376\n",
            "Epoch 960/1200\n",
            "876/876 [==============================] - 2s 2ms/step\n",
            "110/110 [==============================] - 3s 28ms/step - loss: 16.3400 - val_loss: 20.0807\n",
            "Epoch 961/1200\n",
            "876/876 [==============================] - 2s 2ms/step\n",
            "110/110 [==============================] - 3s 32ms/step - loss: 16.3318 - val_loss: 18.8863\n",
            "Epoch 962/1200\n",
            "876/876 [==============================] - 2s 3ms/step\n",
            "110/110 [==============================] - 6s 59ms/step - loss: 15.9674 - val_loss: 17.4345\n",
            "Epoch 963/1200\n",
            "876/876 [==============================] - 2s 2ms/step\n",
            "110/110 [==============================] - 3s 31ms/step - loss: 16.1553 - val_loss: 19.8912\n",
            "Epoch 964/1200\n",
            "876/876 [==============================] - 2s 2ms/step\n",
            "110/110 [==============================] - 3s 31ms/step - loss: 16.0041 - val_loss: 19.7379\n",
            "Epoch 965/1200\n",
            "876/876 [==============================] - 2s 3ms/step\n",
            "110/110 [==============================] - 4s 32ms/step - loss: 17.7583 - val_loss: 35.2313\n",
            "Epoch 966/1200\n",
            "876/876 [==============================] - 2s 3ms/step\n",
            "110/110 [==============================] - 6s 57ms/step - loss: 23.7531 - val_loss: 19.3830\n",
            "Epoch 967/1200\n",
            "876/876 [==============================] - 2s 2ms/step\n",
            "110/110 [==============================] - 3s 32ms/step - loss: 18.3680 - val_loss: 19.9316\n",
            "Epoch 968/1200\n",
            "876/876 [==============================] - 2s 2ms/step\n",
            "110/110 [==============================] - 3s 27ms/step - loss: 18.0500 - val_loss: 18.8396\n",
            "Epoch 969/1200\n",
            "876/876 [==============================] - 2s 2ms/step\n",
            "110/110 [==============================] - 6s 54ms/step - loss: 16.5597 - val_loss: 18.8963\n",
            "Epoch 970/1200\n",
            "876/876 [==============================] - 2s 2ms/step\n",
            "110/110 [==============================] - 3s 31ms/step - loss: 16.0804 - val_loss: 18.6032\n",
            "Epoch 971/1200\n",
            "876/876 [==============================] - 2s 2ms/step\n",
            "110/110 [==============================] - 3s 27ms/step - loss: 16.0319 - val_loss: 17.4636\n",
            "Epoch 972/1200\n",
            "876/876 [==============================] - 2s 2ms/step\n",
            "110/110 [==============================] - 3s 28ms/step - loss: 16.0451 - val_loss: 18.5357\n",
            "Epoch 973/1200\n",
            "876/876 [==============================] - 2s 3ms/step\n",
            "110/110 [==============================] - 6s 58ms/step - loss: 15.8925 - val_loss: 18.7682\n",
            "Epoch 974/1200\n",
            "876/876 [==============================] - 2s 2ms/step\n",
            "110/110 [==============================] - 3s 31ms/step - loss: 16.1185 - val_loss: 19.0365\n",
            "Epoch 975/1200\n",
            "876/876 [==============================] - 2s 2ms/step\n",
            "110/110 [==============================] - 3s 28ms/step - loss: 16.0219 - val_loss: 18.4201\n",
            "Epoch 976/1200\n",
            "876/876 [==============================] - 2s 2ms/step\n",
            "110/110 [==============================] - 3s 31ms/step - loss: 16.2796 - val_loss: 18.5182\n",
            "Epoch 977/1200\n",
            "876/876 [==============================] - 2s 3ms/step\n",
            "110/110 [==============================] - 6s 57ms/step - loss: 18.6040 - val_loss: 19.3173\n",
            "Epoch 978/1200\n",
            "876/876 [==============================] - 2s 2ms/step\n",
            "110/110 [==============================] - 3s 31ms/step - loss: 16.1726 - val_loss: 18.3067\n",
            "Epoch 979/1200\n",
            "876/876 [==============================] - 2s 2ms/step\n",
            "110/110 [==============================] - 3s 28ms/step - loss: 15.7220 - val_loss: 18.7113\n",
            "Epoch 980/1200\n",
            "876/876 [==============================] - 2s 3ms/step\n",
            "110/110 [==============================] - 6s 55ms/step - loss: 15.3937 - val_loss: 17.9215\n",
            "Epoch 981/1200\n",
            "876/876 [==============================] - 2s 2ms/step\n",
            "110/110 [==============================] - 3s 27ms/step - loss: 15.5253 - val_loss: 17.4905\n",
            "Epoch 982/1200\n",
            "876/876 [==============================] - 2s 2ms/step\n",
            "110/110 [==============================] - 3s 31ms/step - loss: 16.0904 - val_loss: 17.8672\n",
            "Epoch 983/1200\n",
            "876/876 [==============================] - 2s 2ms/step\n",
            "110/110 [==============================] - 3s 30ms/step - loss: 15.4255 - val_loss: 18.9473\n",
            "Epoch 984/1200\n",
            "876/876 [==============================] - 2s 3ms/step\n",
            "110/110 [==============================] - 4s 37ms/step - loss: 15.5163 - val_loss: 18.3139\n",
            "Epoch 985/1200\n",
            "876/876 [==============================] - 2s 3ms/step\n",
            "110/110 [==============================] - 4s 37ms/step - loss: 15.4171 - val_loss: 17.7485\n",
            "Epoch 986/1200\n",
            "876/876 [==============================] - 2s 2ms/step\n",
            "110/110 [==============================] - 3s 28ms/step - loss: 15.4598 - val_loss: 17.3988\n",
            "Epoch 987/1200\n",
            "876/876 [==============================] - 2s 2ms/step\n",
            "110/110 [==============================] - 3s 28ms/step - loss: 15.5385 - val_loss: 18.1629\n",
            "Epoch 988/1200\n",
            "876/876 [==============================] - 2s 2ms/step\n",
            "110/110 [==============================] - 3s 31ms/step - loss: 15.4284 - val_loss: 17.7749\n",
            "Epoch 989/1200\n",
            "876/876 [==============================] - 2s 3ms/step\n",
            "110/110 [==============================] - 6s 58ms/step - loss: 15.5681 - val_loss: 17.5435\n",
            "Epoch 990/1200\n",
            "876/876 [==============================] - 2s 2ms/step\n",
            "110/110 [==============================] - 3s 28ms/step - loss: 15.4470 - val_loss: 17.8016\n",
            "Epoch 991/1200\n",
            "876/876 [==============================] - 2s 2ms/step\n",
            "110/110 [==============================] - 3s 29ms/step - loss: 15.1545 - val_loss: 19.4391\n",
            "Epoch 992/1200\n",
            "876/876 [==============================] - 2s 2ms/step\n",
            "110/110 [==============================] - 3s 31ms/step - loss: 15.5411 - val_loss: 18.0658\n",
            "Epoch 993/1200\n",
            "876/876 [==============================] - 2s 3ms/step\n",
            "110/110 [==============================] - 4s 37ms/step - loss: 15.2376 - val_loss: 18.1861\n",
            "Epoch 994/1200\n",
            "876/876 [==============================] - 3s 3ms/step\n",
            "110/110 [==============================] - 4s 38ms/step - loss: 16.1465 - val_loss: 18.8542\n",
            "Epoch 995/1200\n",
            "876/876 [==============================] - 3s 3ms/step\n",
            "110/110 [==============================] - 6s 58ms/step - loss: 15.0980 - val_loss: 18.5454\n",
            "Epoch 996/1200\n",
            "876/876 [==============================] - 2s 2ms/step\n",
            "110/110 [==============================] - 3s 28ms/step - loss: 15.2221 - val_loss: 17.4661\n",
            "Epoch 997/1200\n",
            "876/876 [==============================] - 2s 3ms/step\n",
            "110/110 [==============================] - 6s 54ms/step - loss: 15.2701 - val_loss: 17.8001\n",
            "Epoch 998/1200\n",
            "876/876 [==============================] - 2s 2ms/step\n",
            "110/110 [==============================] - 3s 28ms/step - loss: 15.3250 - val_loss: 18.1393\n",
            "Epoch 999/1200\n",
            "876/876 [==============================] - 2s 2ms/step\n",
            "110/110 [==============================] - 3s 31ms/step - loss: 19.0677 - val_loss: 23.5448\n",
            "Epoch 1000/1200\n",
            "876/876 [==============================] - 2s 2ms/step\n",
            "110/110 [==============================] - 3s 29ms/step - loss: 20.8880 - val_loss: 19.4357\n",
            "Epoch 1001/1200\n",
            "876/876 [==============================] - 2s 3ms/step\n",
            "110/110 [==============================] - 4s 36ms/step - loss: 17.0697 - val_loss: 19.0559\n",
            "Epoch 1002/1200\n",
            "876/876 [==============================] - 3s 3ms/step\n",
            "110/110 [==============================] - 4s 40ms/step - loss: 15.4989 - val_loss: 18.0438\n",
            "Epoch 1003/1200\n",
            "876/876 [==============================] - 3s 3ms/step\n",
            "110/110 [==============================] - 4s 38ms/step - loss: 15.6072 - val_loss: 19.2884\n",
            "Epoch 1004/1200\n",
            "876/876 [==============================] - 2s 2ms/step\n",
            "110/110 [==============================] - 3s 32ms/step - loss: 15.4532 - val_loss: 18.6617\n",
            "Epoch 1005/1200\n",
            "876/876 [==============================] - 2s 2ms/step\n",
            "110/110 [==============================] - 3s 31ms/step - loss: 15.2737 - val_loss: 18.3222\n",
            "Epoch 1006/1200\n",
            "876/876 [==============================] - 2s 3ms/step\n",
            "110/110 [==============================] - 6s 54ms/step - loss: 15.1387 - val_loss: 18.4854\n",
            "Epoch 1007/1200\n",
            "876/876 [==============================] - 2s 2ms/step\n",
            "110/110 [==============================] - 3s 32ms/step - loss: 14.9512 - val_loss: 17.6643\n",
            "Epoch 1008/1200\n",
            "876/876 [==============================] - 2s 2ms/step\n",
            "110/110 [==============================] - 3s 28ms/step - loss: 15.3042 - val_loss: 18.0445\n",
            "Epoch 1009/1200\n",
            "876/876 [==============================] - 2s 2ms/step\n",
            "110/110 [==============================] - 3s 31ms/step - loss: 14.9238 - val_loss: 17.6900\n",
            "Epoch 1010/1200\n",
            "876/876 [==============================] - 3s 3ms/step\n",
            "110/110 [==============================] - 4s 39ms/step - loss: 15.0304 - val_loss: 17.9531\n",
            "Epoch 1011/1200\n",
            "876/876 [==============================] - 2s 2ms/step\n",
            "110/110 [==============================] - 4s 32ms/step - loss: 15.1963 - val_loss: 18.3542\n",
            "Epoch 1012/1200\n",
            "876/876 [==============================] - 2s 2ms/step\n",
            "110/110 [==============================] - 3s 28ms/step - loss: 15.2399 - val_loss: 17.4167\n",
            "Epoch 1013/1200\n",
            "876/876 [==============================] - 2s 2ms/step\n",
            "110/110 [==============================] - 3s 28ms/step - loss: 15.0263 - val_loss: 17.7869\n",
            "Epoch 1014/1200\n",
            "876/876 [==============================] - 2s 2ms/step\n",
            "110/110 [==============================] - 3s 31ms/step - loss: 14.7562 - val_loss: 17.7160\n",
            "Epoch 1015/1200\n",
            "876/876 [==============================] - 2s 3ms/step\n",
            "110/110 [==============================] - 4s 37ms/step - loss: 15.1031 - val_loss: 17.8548\n",
            "Epoch 1016/1200\n",
            "876/876 [==============================] - 2s 3ms/step\n",
            "110/110 [==============================] - 6s 57ms/step - loss: 15.0722 - val_loss: 18.2445\n",
            "Epoch 1017/1200\n",
            "876/876 [==============================] - 2s 2ms/step\n",
            "110/110 [==============================] - 3s 31ms/step - loss: 15.3401 - val_loss: 17.1971\n",
            "Epoch 1018/1200\n",
            "876/876 [==============================] - 2s 2ms/step\n",
            "110/110 [==============================] - 3s 28ms/step - loss: 15.0473 - val_loss: 17.7085\n",
            "Epoch 1019/1200\n",
            "876/876 [==============================] - 2s 3ms/step\n",
            "110/110 [==============================] - 6s 56ms/step - loss: 14.8881 - val_loss: 17.1785\n",
            "Epoch 1020/1200\n",
            "876/876 [==============================] - 2s 2ms/step\n",
            "110/110 [==============================] - 3s 31ms/step - loss: 15.4207 - val_loss: 17.7136\n",
            "Epoch 1021/1200\n",
            "876/876 [==============================] - 2s 2ms/step\n",
            "110/110 [==============================] - 3s 31ms/step - loss: 14.8846 - val_loss: 17.7106\n",
            "Epoch 1022/1200\n",
            "876/876 [==============================] - 2s 2ms/step\n",
            "110/110 [==============================] - 3s 31ms/step - loss: 14.9068 - val_loss: 19.5800\n",
            "Epoch 1023/1200\n",
            "876/876 [==============================] - 2s 3ms/step\n",
            "110/110 [==============================] - 4s 38ms/step - loss: 15.0386 - val_loss: 18.2979\n",
            "Epoch 1024/1200\n",
            "876/876 [==============================] - 2s 2ms/step\n",
            "110/110 [==============================] - 4s 34ms/step - loss: 15.0154 - val_loss: 20.5098\n",
            "Epoch 1025/1200\n",
            "876/876 [==============================] - 2s 2ms/step\n",
            "110/110 [==============================] - 3s 31ms/step - loss: 15.7093 - val_loss: 18.2764\n",
            "Epoch 1026/1200\n",
            "876/876 [==============================] - 2s 2ms/step\n",
            "110/110 [==============================] - 3s 29ms/step - loss: 15.3116 - val_loss: 17.9324\n",
            "Epoch 1027/1200\n",
            "876/876 [==============================] - 2s 3ms/step\n",
            "110/110 [==============================] - 6s 55ms/step - loss: 15.1291 - val_loss: 17.7512\n",
            "Epoch 1028/1200\n",
            "876/876 [==============================] - 2s 2ms/step\n",
            "110/110 [==============================] - 3s 32ms/step - loss: 14.9490 - val_loss: 18.3306\n",
            "Epoch 1029/1200\n",
            "876/876 [==============================] - 2s 2ms/step\n",
            "110/110 [==============================] - 3s 28ms/step - loss: 15.1934 - val_loss: 17.9169\n",
            "Epoch 1030/1200\n",
            "876/876 [==============================] - 2s 2ms/step\n",
            "110/110 [==============================] - 3s 29ms/step - loss: 14.8951 - val_loss: 17.8744\n",
            "Epoch 1031/1200\n",
            "876/876 [==============================] - 2s 3ms/step\n",
            "110/110 [==============================] - 4s 35ms/step - loss: 14.8213 - val_loss: 17.8766\n",
            "Epoch 1032/1200\n",
            "876/876 [==============================] - 2s 3ms/step\n",
            "110/110 [==============================] - 6s 58ms/step - loss: 14.9608 - val_loss: 18.9111\n",
            "Epoch 1033/1200\n",
            "876/876 [==============================] - 2s 2ms/step\n",
            "110/110 [==============================] - 3s 31ms/step - loss: 14.7557 - val_loss: 18.2875\n",
            "Epoch 1034/1200\n",
            "876/876 [==============================] - 2s 2ms/step\n",
            "110/110 [==============================] - 3s 31ms/step - loss: 15.0061 - val_loss: 17.8567\n",
            "Epoch 1035/1200\n",
            "876/876 [==============================] - 2s 3ms/step\n",
            "110/110 [==============================] - 6s 55ms/step - loss: 14.7155 - val_loss: 17.8009\n",
            "Epoch 1036/1200\n",
            "876/876 [==============================] - 2s 2ms/step\n",
            "110/110 [==============================] - 3s 31ms/step - loss: 14.9200 - val_loss: 18.0588\n",
            "Epoch 1037/1200\n",
            "876/876 [==============================] - 2s 2ms/step\n",
            "110/110 [==============================] - 3s 28ms/step - loss: 14.9168 - val_loss: 18.6401\n",
            "Epoch 1038/1200\n",
            "876/876 [==============================] - 2s 2ms/step\n",
            "110/110 [==============================] - 3s 29ms/step - loss: 15.6084 - val_loss: 18.4029\n",
            "Epoch 1039/1200\n",
            "876/876 [==============================] - 2s 3ms/step\n",
            "110/110 [==============================] - 6s 56ms/step - loss: 14.9809 - val_loss: 18.2646\n",
            "Epoch 1040/1200\n",
            "876/876 [==============================] - 2s 2ms/step\n",
            "110/110 [==============================] - 3s 31ms/step - loss: 14.8769 - val_loss: 18.2757\n",
            "Epoch 1041/1200\n",
            "876/876 [==============================] - 2s 2ms/step\n",
            "110/110 [==============================] - 3s 28ms/step - loss: 14.8305 - val_loss: 17.4841\n",
            "Epoch 1042/1200\n",
            "876/876 [==============================] - 2s 2ms/step\n",
            "110/110 [==============================] - 3s 31ms/step - loss: 14.7900 - val_loss: 18.3718\n",
            "Epoch 1043/1200\n",
            "876/876 [==============================] - 2s 3ms/step\n",
            "110/110 [==============================] - 6s 59ms/step - loss: 15.1998 - val_loss: 17.9190\n",
            "Epoch 1044/1200\n",
            "876/876 [==============================] - 2s 2ms/step\n",
            "110/110 [==============================] - 3s 28ms/step - loss: 15.3973 - val_loss: 18.4594\n",
            "Epoch 1045/1200\n",
            "876/876 [==============================] - 2s 2ms/step\n",
            "110/110 [==============================] - 3s 28ms/step - loss: 14.8863 - val_loss: 17.6128\n",
            "Epoch 1046/1200\n",
            "876/876 [==============================] - 2s 2ms/step\n",
            "110/110 [==============================] - 3s 32ms/step - loss: 15.1218 - val_loss: 17.6448\n",
            "Epoch 1047/1200\n",
            "876/876 [==============================] - 2s 3ms/step\n",
            "110/110 [==============================] - 6s 58ms/step - loss: 14.6616 - val_loss: 17.9210\n",
            "Epoch 1048/1200\n",
            "876/876 [==============================] - 2s 3ms/step\n",
            "110/110 [==============================] - 4s 34ms/step - loss: 14.8270 - val_loss: 18.6810\n",
            "Epoch 1049/1200\n",
            "876/876 [==============================] - 2s 2ms/step\n",
            "110/110 [==============================] - 3s 31ms/step - loss: 14.7515 - val_loss: 17.8063\n",
            "Epoch 1050/1200\n",
            "876/876 [==============================] - 2s 2ms/step\n",
            "110/110 [==============================] - 3s 31ms/step - loss: 15.0694 - val_loss: 18.2235\n",
            "Epoch 1051/1200\n",
            "876/876 [==============================] - 2s 3ms/step\n",
            "110/110 [==============================] - 6s 56ms/step - loss: 15.1733 - val_loss: 17.6131\n",
            "Epoch 1052/1200\n",
            "876/876 [==============================] - 2s 2ms/step\n",
            "110/110 [==============================] - 3s 31ms/step - loss: 14.6188 - val_loss: 18.0970\n",
            "Epoch 1053/1200\n",
            "876/876 [==============================] - 2s 2ms/step\n",
            "110/110 [==============================] - 3s 32ms/step - loss: 15.2254 - val_loss: 18.1393\n",
            "Epoch 1054/1200\n",
            "876/876 [==============================] - 2s 3ms/step\n",
            "110/110 [==============================] - 6s 54ms/step - loss: 15.3440 - val_loss: 18.1077\n",
            "Epoch 1055/1200\n",
            "876/876 [==============================] - 2s 2ms/step\n",
            "110/110 [==============================] - 3s 29ms/step - loss: 14.9809 - val_loss: 17.6700\n",
            "Epoch 1056/1200\n",
            "876/876 [==============================] - 2s 2ms/step\n",
            "110/110 [==============================] - 3s 31ms/step - loss: 14.8629 - val_loss: 18.5449\n",
            "Epoch 1057/1200\n",
            "876/876 [==============================] - 2s 2ms/step\n",
            "110/110 [==============================] - 3s 31ms/step - loss: 15.2521 - val_loss: 18.7308\n",
            "Epoch 1058/1200\n",
            "876/876 [==============================] - 2s 3ms/step\n",
            "110/110 [==============================] - 6s 59ms/step - loss: 14.9111 - val_loss: 18.0350\n",
            "Epoch 1059/1200\n",
            "876/876 [==============================] - 2s 2ms/step\n",
            "110/110 [==============================] - 3s 31ms/step - loss: 14.7371 - val_loss: 18.0097\n",
            "Epoch 1060/1200\n",
            "876/876 [==============================] - 2s 2ms/step\n",
            "110/110 [==============================] - 3s 28ms/step - loss: 14.6243 - val_loss: 18.2313\n",
            "Epoch 1061/1200\n",
            "876/876 [==============================] - 2s 2ms/step\n",
            "110/110 [==============================] - 3s 31ms/step - loss: 14.7041 - val_loss: 17.7464\n",
            "Epoch 1062/1200\n",
            "876/876 [==============================] - 2s 2ms/step\n",
            "110/110 [==============================] - 6s 58ms/step - loss: 14.7383 - val_loss: 17.3569\n",
            "Epoch 1063/1200\n",
            "876/876 [==============================] - 2s 2ms/step\n",
            "110/110 [==============================] - 3s 28ms/step - loss: 14.7892 - val_loss: 18.1376\n",
            "Epoch 1064/1200\n",
            "876/876 [==============================] - 2s 2ms/step\n",
            "110/110 [==============================] - 3s 31ms/step - loss: 16.4789 - val_loss: 18.0644\n",
            "Epoch 1065/1200\n",
            "876/876 [==============================] - 2s 3ms/step\n",
            "110/110 [==============================] - 6s 57ms/step - loss: 15.7696 - val_loss: 17.9025\n",
            "Epoch 1066/1200\n",
            "876/876 [==============================] - 2s 2ms/step\n",
            "110/110 [==============================] - 4s 36ms/step - loss: 14.6361 - val_loss: 17.6906\n",
            "Epoch 1067/1200\n",
            "876/876 [==============================] - 2s 2ms/step\n",
            "110/110 [==============================] - 3s 31ms/step - loss: 15.0628 - val_loss: 18.2869\n",
            "Epoch 1068/1200\n",
            "876/876 [==============================] - 2s 2ms/step\n",
            "110/110 [==============================] - 3s 28ms/step - loss: 14.8296 - val_loss: 18.6106\n",
            "Epoch 1069/1200\n",
            "876/876 [==============================] - 2s 2ms/step\n",
            "110/110 [==============================] - 3s 32ms/step - loss: 15.1192 - val_loss: 18.4845\n",
            "Epoch 1070/1200\n",
            "876/876 [==============================] - 2s 3ms/step\n",
            "110/110 [==============================] - 4s 38ms/step - loss: 14.9602 - val_loss: 17.9826\n",
            "Epoch 1071/1200\n",
            "876/876 [==============================] - 2s 3ms/step\n",
            "110/110 [==============================] - 4s 34ms/step - loss: 14.8368 - val_loss: 17.5690\n",
            "Epoch 1072/1200\n",
            "876/876 [==============================] - 2s 2ms/step\n",
            "110/110 [==============================] - 3s 31ms/step - loss: 14.8151 - val_loss: 17.9863\n",
            "Epoch 1073/1200\n",
            "876/876 [==============================] - 2s 2ms/step\n",
            "110/110 [==============================] - 3s 28ms/step - loss: 14.7336 - val_loss: 17.4866\n",
            "Epoch 1074/1200\n",
            "876/876 [==============================] - 2s 3ms/step\n",
            "110/110 [==============================] - 4s 32ms/step - loss: 15.4268 - val_loss: 18.2189\n",
            "Epoch 1075/1200\n",
            "876/876 [==============================] - 2s 3ms/step\n",
            "110/110 [==============================] - 4s 38ms/step - loss: 14.6285 - val_loss: 17.8513\n",
            "Epoch 1076/1200\n",
            "876/876 [==============================] - 2s 3ms/step\n",
            "110/110 [==============================] - 4s 33ms/step - loss: 14.5316 - val_loss: 18.2454\n",
            "Epoch 1077/1200\n",
            "876/876 [==============================] - 2s 2ms/step\n",
            "110/110 [==============================] - 3s 31ms/step - loss: 14.6425 - val_loss: 18.0045\n",
            "Epoch 1078/1200\n",
            "876/876 [==============================] - 2s 2ms/step\n",
            "110/110 [==============================] - 3s 29ms/step - loss: 15.7986 - val_loss: 19.3461\n",
            "Epoch 1079/1200\n",
            "876/876 [==============================] - 2s 2ms/step\n",
            "110/110 [==============================] - 3s 32ms/step - loss: 15.4613 - val_loss: 18.0011\n",
            "Epoch 1080/1200\n",
            "876/876 [==============================] - 2s 3ms/step\n",
            "110/110 [==============================] - 6s 56ms/step - loss: 14.8552 - val_loss: 18.1322\n",
            "Epoch 1081/1200\n",
            "876/876 [==============================] - 2s 2ms/step\n",
            "110/110 [==============================] - 3s 31ms/step - loss: 14.7938 - val_loss: 17.9262\n",
            "Epoch 1082/1200\n",
            "876/876 [==============================] - 2s 2ms/step\n",
            "110/110 [==============================] - 3s 29ms/step - loss: 15.2691 - val_loss: 18.3933\n",
            "Epoch 1083/1200\n",
            "876/876 [==============================] - 2s 2ms/step\n",
            "110/110 [==============================] - 3s 31ms/step - loss: 14.7901 - val_loss: 18.2358\n",
            "Epoch 1084/1200\n",
            "876/876 [==============================] - 2s 3ms/step\n",
            "110/110 [==============================] - 6s 57ms/step - loss: 14.7999 - val_loss: 17.8995\n",
            "Epoch 1085/1200\n",
            "876/876 [==============================] - 2s 2ms/step\n",
            "110/110 [==============================] - 3s 28ms/step - loss: 14.4724 - val_loss: 18.0608\n",
            "Epoch 1086/1200\n",
            "876/876 [==============================] - 2s 2ms/step\n",
            "110/110 [==============================] - 3s 28ms/step - loss: 14.8796 - val_loss: 17.8581\n",
            "Epoch 1087/1200\n",
            "876/876 [==============================] - 2s 2ms/step\n",
            "110/110 [==============================] - 3s 31ms/step - loss: 15.3467 - val_loss: 18.0683\n",
            "Epoch 1088/1200\n",
            "876/876 [==============================] - 2s 3ms/step\n",
            "110/110 [==============================] - 6s 58ms/step - loss: 15.6469 - val_loss: 18.8871\n",
            "Epoch 1089/1200\n",
            "876/876 [==============================] - 2s 2ms/step\n",
            "110/110 [==============================] - 3s 31ms/step - loss: 14.9906 - val_loss: 17.9056\n",
            "Epoch 1090/1200\n",
            "876/876 [==============================] - 2s 2ms/step\n",
            "110/110 [==============================] - 3s 29ms/step - loss: 15.0742 - val_loss: 17.6756\n",
            "Epoch 1091/1200\n",
            "876/876 [==============================] - 2s 3ms/step\n",
            "110/110 [==============================] - 4s 32ms/step - loss: 14.7193 - val_loss: 17.7246\n",
            "Epoch 1092/1200\n",
            "876/876 [==============================] - 2s 3ms/step\n",
            "110/110 [==============================] - 4s 37ms/step - loss: 14.8699 - val_loss: 18.2398\n",
            "Epoch 1093/1200\n",
            "876/876 [==============================] - 2s 3ms/step\n",
            "110/110 [==============================] - 4s 35ms/step - loss: 14.5498 - val_loss: 17.8980\n",
            "Epoch 1094/1200\n",
            "876/876 [==============================] - 2s 2ms/step\n",
            "110/110 [==============================] - 3s 32ms/step - loss: 14.8766 - val_loss: 17.7139\n",
            "Epoch 1095/1200\n",
            "876/876 [==============================] - 2s 2ms/step\n",
            "110/110 [==============================] - 3s 31ms/step - loss: 14.9303 - val_loss: 17.6700\n",
            "Epoch 1096/1200\n",
            "876/876 [==============================] - 2s 3ms/step\n",
            "110/110 [==============================] - 6s 55ms/step - loss: 14.5143 - val_loss: 17.5171\n",
            "Epoch 1097/1200\n",
            "876/876 [==============================] - 2s 2ms/step\n",
            "110/110 [==============================] - 3s 32ms/step - loss: 14.9133 - val_loss: 18.1851\n",
            "Epoch 1098/1200\n",
            "876/876 [==============================] - 2s 2ms/step\n",
            "110/110 [==============================] - 3s 31ms/step - loss: 14.7722 - val_loss: 17.6471\n",
            "Epoch 1099/1200\n",
            "876/876 [==============================] - 2s 2ms/step\n",
            "110/110 [==============================] - 3s 31ms/step - loss: 14.6540 - val_loss: 17.9291\n",
            "Epoch 1100/1200\n",
            "876/876 [==============================] - 2s 3ms/step\n",
            "110/110 [==============================] - 6s 58ms/step - loss: 14.7053 - val_loss: 18.1244\n",
            "Epoch 1101/1200\n",
            "876/876 [==============================] - 2s 3ms/step\n",
            "110/110 [==============================] - 6s 57ms/step - loss: 14.5418 - val_loss: 17.8902\n",
            "Epoch 1102/1200\n",
            "876/876 [==============================] - 2s 2ms/step\n",
            "110/110 [==============================] - 3s 31ms/step - loss: 14.5321 - val_loss: 17.7461\n",
            "Epoch 1103/1200\n",
            "876/876 [==============================] - 2s 3ms/step\n",
            "110/110 [==============================] - 4s 35ms/step - loss: 14.5557 - val_loss: 17.8990\n",
            "Epoch 1104/1200\n",
            "876/876 [==============================] - 2s 3ms/step\n",
            "110/110 [==============================] - 6s 58ms/step - loss: 14.7663 - val_loss: 17.4110\n",
            "Epoch 1105/1200\n",
            "876/876 [==============================] - 2s 2ms/step\n",
            "110/110 [==============================] - 3s 32ms/step - loss: 14.7547 - val_loss: 17.6220\n",
            "Epoch 1106/1200\n",
            "876/876 [==============================] - 2s 2ms/step\n",
            "110/110 [==============================] - 3s 28ms/step - loss: 14.5761 - val_loss: 17.4626\n",
            "Epoch 1107/1200\n",
            "876/876 [==============================] - 2s 3ms/step\n",
            "110/110 [==============================] - 6s 56ms/step - loss: 14.6989 - val_loss: 17.6245\n",
            "Epoch 1108/1200\n",
            "876/876 [==============================] - 2s 2ms/step\n",
            "110/110 [==============================] - 3s 28ms/step - loss: 15.1068 - val_loss: 17.2681\n",
            "Epoch 1109/1200\n",
            "876/876 [==============================] - 2s 2ms/step\n",
            "110/110 [==============================] - 3s 28ms/step - loss: 15.5133 - val_loss: 21.0952\n",
            "Epoch 1110/1200\n",
            "876/876 [==============================] - 2s 2ms/step\n",
            "110/110 [==============================] - 3s 31ms/step - loss: 16.0129 - val_loss: 17.9358\n",
            "Epoch 1111/1200\n",
            "876/876 [==============================] - 2s 3ms/step\n",
            "110/110 [==============================] - 6s 58ms/step - loss: 14.5987 - val_loss: 18.0639\n",
            "Epoch 1112/1200\n",
            "876/876 [==============================] - 2s 2ms/step\n",
            "110/110 [==============================] - 3s 31ms/step - loss: 14.6969 - val_loss: 17.8904\n",
            "Epoch 1113/1200\n",
            "876/876 [==============================] - 2s 2ms/step\n",
            "110/110 [==============================] - 3s 28ms/step - loss: 14.6414 - val_loss: 18.1105\n",
            "Epoch 1114/1200\n",
            "876/876 [==============================] - 2s 2ms/step\n",
            "110/110 [==============================] - 3s 31ms/step - loss: 14.7831 - val_loss: 17.7842\n",
            "Epoch 1115/1200\n",
            "876/876 [==============================] - 2s 3ms/step\n",
            "110/110 [==============================] - 4s 38ms/step - loss: 15.3710 - val_loss: 17.8445\n",
            "Epoch 1116/1200\n",
            "876/876 [==============================] - 2s 3ms/step\n",
            "110/110 [==============================] - 4s 37ms/step - loss: 14.4282 - val_loss: 18.2605\n",
            "Epoch 1117/1200\n",
            "876/876 [==============================] - 2s 2ms/step\n",
            "110/110 [==============================] - 3s 31ms/step - loss: 14.8783 - val_loss: 19.2698\n",
            "Epoch 1118/1200\n",
            "876/876 [==============================] - 2s 2ms/step\n",
            "110/110 [==============================] - 3s 32ms/step - loss: 15.0918 - val_loss: 18.6439\n",
            "Epoch 1119/1200\n",
            "876/876 [==============================] - 2s 2ms/step\n",
            "110/110 [==============================] - 3s 31ms/step - loss: 15.3107 - val_loss: 18.4702\n",
            "Epoch 1120/1200\n",
            "876/876 [==============================] - 2s 3ms/step\n",
            "110/110 [==============================] - 4s 36ms/step - loss: 14.7300 - val_loss: 17.4867\n",
            "Epoch 1121/1200\n",
            "876/876 [==============================] - 2s 3ms/step\n",
            "110/110 [==============================] - 6s 58ms/step - loss: 15.1751 - val_loss: 18.7236\n",
            "Epoch 1122/1200\n",
            "876/876 [==============================] - 2s 2ms/step\n",
            "110/110 [==============================] - 3s 29ms/step - loss: 15.0332 - val_loss: 18.2268\n",
            "Epoch 1123/1200\n",
            "876/876 [==============================] - 2s 2ms/step\n",
            "110/110 [==============================] - 3s 28ms/step - loss: 14.8106 - val_loss: 17.6819\n",
            "Epoch 1124/1200\n",
            "876/876 [==============================] - 2s 3ms/step\n",
            "110/110 [==============================] - 6s 55ms/step - loss: 14.5975 - val_loss: 17.2887\n",
            "Epoch 1125/1200\n",
            "876/876 [==============================] - 2s 2ms/step\n",
            "110/110 [==============================] - 3s 31ms/step - loss: 14.5314 - val_loss: 18.3750\n",
            "Epoch 1126/1200\n",
            "876/876 [==============================] - 2s 2ms/step\n",
            "110/110 [==============================] - 3s 31ms/step - loss: 14.8366 - val_loss: 18.2736\n",
            "Epoch 1127/1200\n",
            "876/876 [==============================] - 2s 3ms/step\n",
            "110/110 [==============================] - 6s 55ms/step - loss: 14.5639 - val_loss: 17.8936\n",
            "Epoch 1128/1200\n",
            "876/876 [==============================] - 3s 3ms/step\n",
            "110/110 [==============================] - 6s 58ms/step - loss: 14.5300 - val_loss: 18.6976\n",
            "Epoch 1129/1200\n",
            "876/876 [==============================] - 2s 2ms/step\n",
            "110/110 [==============================] - 3s 31ms/step - loss: 14.6790 - val_loss: 17.8700\n",
            "Epoch 1130/1200\n",
            "876/876 [==============================] - 2s 2ms/step\n",
            "110/110 [==============================] - 3s 32ms/step - loss: 15.3015 - val_loss: 18.2352\n",
            "Epoch 1131/1200\n",
            "876/876 [==============================] - 2s 3ms/step\n",
            "110/110 [==============================] - 4s 33ms/step - loss: 14.8607 - val_loss: 18.8037\n",
            "Epoch 1132/1200\n",
            "876/876 [==============================] - 3s 3ms/step\n",
            "110/110 [==============================] - 4s 37ms/step - loss: 14.7266 - val_loss: 17.4723\n",
            "Epoch 1133/1200\n",
            "876/876 [==============================] - 2s 2ms/step\n",
            "110/110 [==============================] - 4s 33ms/step - loss: 14.6083 - val_loss: 18.2892\n",
            "Epoch 1134/1200\n",
            "876/876 [==============================] - 2s 2ms/step\n",
            "110/110 [==============================] - 3s 29ms/step - loss: 14.7289 - val_loss: 18.5021\n",
            "Epoch 1135/1200\n",
            "876/876 [==============================] - 2s 2ms/step\n",
            "110/110 [==============================] - 3s 31ms/step - loss: 14.9648 - val_loss: 17.9924\n",
            "Epoch 1136/1200\n",
            "876/876 [==============================] - 2s 3ms/step\n",
            "110/110 [==============================] - 6s 55ms/step - loss: 14.6804 - val_loss: 18.1325\n",
            "Epoch 1137/1200\n",
            "876/876 [==============================] - 2s 2ms/step\n",
            "110/110 [==============================] - 3s 29ms/step - loss: 14.5798 - val_loss: 18.2811\n",
            "Epoch 1138/1200\n",
            "876/876 [==============================] - 2s 2ms/step\n",
            "110/110 [==============================] - 3s 32ms/step - loss: 14.5143 - val_loss: 17.7101\n",
            "Epoch 1139/1200\n",
            "876/876 [==============================] - 2s 2ms/step\n",
            "110/110 [==============================] - 3s 32ms/step - loss: 14.9543 - val_loss: 17.0885\n",
            "Epoch 1140/1200\n",
            "876/876 [==============================] - 2s 3ms/step\n",
            "110/110 [==============================] - 4s 38ms/step - loss: 15.1919 - val_loss: 18.1654\n",
            "Epoch 1141/1200\n",
            "876/876 [==============================] - 2s 3ms/step\n",
            "110/110 [==============================] - 6s 59ms/step - loss: 15.4938 - val_loss: 18.1175\n",
            "Epoch 1142/1200\n",
            "876/876 [==============================] - 2s 2ms/step\n",
            "110/110 [==============================] - 3s 31ms/step - loss: 14.5718 - val_loss: 17.6397\n",
            "Epoch 1143/1200\n",
            "876/876 [==============================] - 2s 2ms/step\n",
            "110/110 [==============================] - 3s 32ms/step - loss: 14.8449 - val_loss: 19.1506\n",
            "Epoch 1144/1200\n",
            "876/876 [==============================] - 2s 3ms/step\n",
            "110/110 [==============================] - 4s 37ms/step - loss: 15.0822 - val_loss: 17.5977\n",
            "Epoch 1145/1200\n",
            "876/876 [==============================] - 2s 3ms/step\n",
            "110/110 [==============================] - 6s 59ms/step - loss: 14.8301 - val_loss: 18.1461\n",
            "Epoch 1146/1200\n",
            "876/876 [==============================] - 2s 2ms/step\n",
            "110/110 [==============================] - 3s 31ms/step - loss: 14.8731 - val_loss: 19.3352\n",
            "Epoch 1147/1200\n",
            "876/876 [==============================] - 2s 2ms/step\n",
            "110/110 [==============================] - 3s 30ms/step - loss: 19.1781 - val_loss: 19.6586\n",
            "Epoch 1148/1200\n",
            "876/876 [==============================] - 2s 3ms/step\n",
            "110/110 [==============================] - 6s 58ms/step - loss: 15.8016 - val_loss: 18.8350\n",
            "Epoch 1149/1200\n",
            "876/876 [==============================] - 2s 2ms/step\n",
            "110/110 [==============================] - 3s 29ms/step - loss: 14.4388 - val_loss: 18.9297\n",
            "Epoch 1150/1200\n",
            "876/876 [==============================] - 2s 2ms/step\n",
            "110/110 [==============================] - 3s 31ms/step - loss: 14.4499 - val_loss: 18.3938\n",
            "Epoch 1151/1200\n",
            "876/876 [==============================] - 2s 2ms/step\n",
            "110/110 [==============================] - 4s 32ms/step - loss: 14.8098 - val_loss: 17.9045\n",
            "Epoch 1152/1200\n",
            "876/876 [==============================] - 3s 3ms/step\n",
            "110/110 [==============================] - 4s 40ms/step - loss: 14.5279 - val_loss: 17.9761\n",
            "Epoch 1153/1200\n",
            "876/876 [==============================] - 2s 3ms/step\n",
            "110/110 [==============================] - 6s 59ms/step - loss: 14.3771 - val_loss: 17.9285\n",
            "Epoch 1154/1200\n",
            "876/876 [==============================] - 2s 2ms/step\n",
            "110/110 [==============================] - 3s 31ms/step - loss: 14.3788 - val_loss: 17.0879\n",
            "Epoch 1155/1200\n",
            "876/876 [==============================] - 2s 2ms/step\n",
            "110/110 [==============================] - 3s 29ms/step - loss: 14.7935 - val_loss: 18.2454\n",
            "Epoch 1156/1200\n",
            "876/876 [==============================] - 2s 2ms/step\n",
            "110/110 [==============================] - 3s 31ms/step - loss: 14.9167 - val_loss: 18.8347\n",
            "Epoch 1157/1200\n",
            "876/876 [==============================] - 2s 3ms/step\n",
            "110/110 [==============================] - 6s 57ms/step - loss: 15.0375 - val_loss: 17.3674\n",
            "Epoch 1158/1200\n",
            "876/876 [==============================] - 2s 2ms/step\n",
            "110/110 [==============================] - 3s 29ms/step - loss: 14.5817 - val_loss: 17.8122\n",
            "Epoch 1159/1200\n",
            "876/876 [==============================] - 2s 2ms/step\n",
            "110/110 [==============================] - 3s 30ms/step - loss: 14.5762 - val_loss: 17.5465\n",
            "Epoch 1160/1200\n",
            "876/876 [==============================] - 2s 2ms/step\n",
            "110/110 [==============================] - 6s 55ms/step - loss: 16.5991 - val_loss: 18.5585\n",
            "Epoch 1161/1200\n",
            "876/876 [==============================] - 2s 2ms/step\n",
            "110/110 [==============================] - 3s 32ms/step - loss: 14.6029 - val_loss: 17.8942\n",
            "Epoch 1162/1200\n",
            "876/876 [==============================] - 2s 2ms/step\n",
            "110/110 [==============================] - 3s 32ms/step - loss: 14.6042 - val_loss: 18.0997\n",
            "Epoch 1163/1200\n",
            "876/876 [==============================] - 2s 2ms/step\n",
            "110/110 [==============================] - 3s 31ms/step - loss: 14.6288 - val_loss: 18.2899\n",
            "Epoch 1164/1200\n",
            "876/876 [==============================] - 2s 3ms/step\n",
            "110/110 [==============================] - 4s 38ms/step - loss: 14.6878 - val_loss: 17.8644\n",
            "Epoch 1165/1200\n",
            "876/876 [==============================] - 2s 3ms/step\n",
            "110/110 [==============================] - 6s 58ms/step - loss: 14.9568 - val_loss: 18.0226\n",
            "Epoch 1166/1200\n",
            "876/876 [==============================] - 2s 2ms/step\n",
            "110/110 [==============================] - 3s 29ms/step - loss: 14.8876 - val_loss: 18.2017\n",
            "Epoch 1167/1200\n",
            "876/876 [==============================] - 2s 2ms/step\n",
            "110/110 [==============================] - 3s 29ms/step - loss: 14.5988 - val_loss: 17.4227\n",
            "Epoch 1168/1200\n",
            "876/876 [==============================] - 2s 3ms/step\n",
            "110/110 [==============================] - 6s 56ms/step - loss: 14.4869 - val_loss: 17.6393\n",
            "Epoch 1169/1200\n",
            "876/876 [==============================] - 2s 2ms/step\n",
            "110/110 [==============================] - 3s 29ms/step - loss: 14.3361 - val_loss: 17.0565\n",
            "Epoch 1170/1200\n",
            "876/876 [==============================] - 2s 2ms/step\n",
            "110/110 [==============================] - 3s 30ms/step - loss: 14.6122 - val_loss: 18.1092\n",
            "Epoch 1171/1200\n",
            "876/876 [==============================] - 2s 2ms/step\n",
            "110/110 [==============================] - 3s 31ms/step - loss: 15.0744 - val_loss: 17.1072\n",
            "Epoch 1172/1200\n",
            "876/876 [==============================] - 2s 3ms/step\n",
            "110/110 [==============================] - 6s 59ms/step - loss: 14.4435 - val_loss: 17.5044\n",
            "Epoch 1173/1200\n",
            "876/876 [==============================] - 2s 2ms/step\n",
            "110/110 [==============================] - 3s 30ms/step - loss: 14.5057 - val_loss: 17.2562\n",
            "Epoch 1174/1200\n",
            "876/876 [==============================] - 2s 2ms/step\n",
            "110/110 [==============================] - 3s 28ms/step - loss: 14.8694 - val_loss: 18.0084\n",
            "Epoch 1175/1200\n",
            "876/876 [==============================] - 2s 2ms/step\n",
            "110/110 [==============================] - 3s 32ms/step - loss: 14.4125 - val_loss: 17.7835\n",
            "Epoch 1176/1200\n",
            "876/876 [==============================] - 2s 3ms/step\n",
            "110/110 [==============================] - 4s 37ms/step - loss: 14.8111 - val_loss: 17.6427\n",
            "Epoch 1177/1200\n",
            "876/876 [==============================] - 2s 3ms/step\n",
            "110/110 [==============================] - 6s 59ms/step - loss: 14.9552 - val_loss: 17.2218\n",
            "Epoch 1178/1200\n",
            "876/876 [==============================] - 2s 2ms/step\n",
            "110/110 [==============================] - 3s 29ms/step - loss: 14.4322 - val_loss: 17.9347\n",
            "Epoch 1179/1200\n",
            "876/876 [==============================] - 2s 2ms/step\n",
            "110/110 [==============================] - 3s 31ms/step - loss: 14.5549 - val_loss: 17.8896\n",
            "Epoch 1180/1200\n",
            "876/876 [==============================] - 2s 3ms/step\n",
            "110/110 [==============================] - 4s 37ms/step - loss: 14.4802 - val_loss: 18.2715\n",
            "Epoch 1181/1200\n",
            "876/876 [==============================] - 2s 3ms/step\n",
            "110/110 [==============================] - 7s 60ms/step - loss: 14.5032 - val_loss: 18.5017\n",
            "Epoch 1182/1200\n",
            "876/876 [==============================] - 2s 2ms/step\n",
            "110/110 [==============================] - 3s 32ms/step - loss: 14.5635 - val_loss: 18.4761\n",
            "Epoch 1183/1200\n",
            "876/876 [==============================] - 2s 2ms/step\n",
            "110/110 [==============================] - 3s 32ms/step - loss: 15.6860 - val_loss: 18.9522\n",
            "Epoch 1184/1200\n",
            "876/876 [==============================] - 2s 3ms/step\n",
            "110/110 [==============================] - 4s 35ms/step - loss: 15.6807 - val_loss: 17.7150\n",
            "Epoch 1185/1200\n",
            "876/876 [==============================] - 2s 3ms/step\n",
            "110/110 [==============================] - 4s 36ms/step - loss: 14.5259 - val_loss: 18.0085\n",
            "Epoch 1186/1200\n",
            "876/876 [==============================] - 2s 2ms/step\n",
            "110/110 [==============================] - 4s 34ms/step - loss: 14.9873 - val_loss: 17.9843\n",
            "Epoch 1187/1200\n",
            "876/876 [==============================] - 2s 3ms/step\n",
            "110/110 [==============================] - 6s 56ms/step - loss: 14.4799 - val_loss: 18.3939\n",
            "Epoch 1188/1200\n",
            "876/876 [==============================] - 2s 3ms/step\n",
            "110/110 [==============================] - 6s 56ms/step - loss: 14.3710 - val_loss: 17.2529\n",
            "Epoch 1189/1200\n",
            "876/876 [==============================] - 2s 2ms/step\n",
            "110/110 [==============================] - 3s 32ms/step - loss: 14.3984 - val_loss: 17.8220\n",
            "Epoch 1190/1200\n",
            "876/876 [==============================] - 2s 2ms/step\n",
            "110/110 [==============================] - 3s 29ms/step - loss: 14.9203 - val_loss: 18.2117\n",
            "Epoch 1191/1200\n",
            "876/876 [==============================] - 2s 2ms/step\n",
            "110/110 [==============================] - 3s 31ms/step - loss: 15.0695 - val_loss: 17.1959\n",
            "Epoch 1192/1200\n",
            "876/876 [==============================] - 2s 3ms/step\n",
            "110/110 [==============================] - 4s 36ms/step - loss: 14.7753 - val_loss: 17.7640\n",
            "Epoch 1193/1200\n",
            "876/876 [==============================] - 2s 3ms/step\n",
            "110/110 [==============================] - 6s 58ms/step - loss: 15.1172 - val_loss: 17.2308\n",
            "Epoch 1194/1200\n",
            "876/876 [==============================] - 2s 2ms/step\n",
            "110/110 [==============================] - 3s 32ms/step - loss: 17.7623 - val_loss: 19.7327\n",
            "Epoch 1195/1200\n",
            "876/876 [==============================] - 2s 2ms/step\n",
            "110/110 [==============================] - 3s 29ms/step - loss: 15.5568 - val_loss: 20.4113\n",
            "Epoch 1196/1200\n",
            "876/876 [==============================] - 2s 3ms/step\n",
            "110/110 [==============================] - 6s 56ms/step - loss: 15.5059 - val_loss: 19.6978\n",
            "Epoch 1197/1200\n",
            "876/876 [==============================] - 2s 2ms/step\n",
            "110/110 [==============================] - 3s 29ms/step - loss: 14.6463 - val_loss: 19.1480\n",
            "Epoch 1198/1200\n",
            "876/876 [==============================] - 2s 2ms/step\n",
            "110/110 [==============================] - 4s 32ms/step - loss: 14.4343 - val_loss: 19.0126\n",
            "Epoch 1199/1200\n",
            "876/876 [==============================] - 2s 2ms/step\n",
            "110/110 [==============================] - 3s 31ms/step - loss: 14.6284 - val_loss: 19.2881\n",
            "Epoch 1200/1200\n",
            "876/876 [==============================] - 2s 3ms/step\n",
            "110/110 [==============================] - 4s 37ms/step - loss: 14.3618 - val_loss: 19.3143\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.src.callbacks.History at 0x7e62f607d1e0>"
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model_RNN.save('/content/drive/MyDrive/Task2/model/RNN_model.keras')"
      ],
      "metadata": {
        "id": "7QUkm0uC-W0Y"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "Y_pred = model_RNN.predict(X_test)\n",
        "mse, rmse, r_squared = calculate_metrics(Y_test, Y_pred)\n",
        "print(\"Metric for RNN\")\n",
        "print(\"MSE = \"+str(mse))\n",
        "print(\"RMSE = \"+str(rmse))\n",
        "print(\"R^2 = \"+str(r_squared))"
      ],
      "metadata": {
        "id": "Jzq7n-9xRJLG",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "acc41575-4abd-409c-d4a8-5c361a1083a3"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "219/219 [==============================] - 0s 2ms/step\n",
            "Metric for RNN\n",
            "MSE = 19.31426599458422\n",
            "RMSE = 4.3947998810621876\n",
            "R^2 = 0.9828158195374795\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model_LSTM = keras.Sequential()\n",
        "model_LSTM.add(keras.layers.LSTM(units = 64, input_shape=(X_train.shape[1], X_train.shape[2])))\n",
        "model_LSTM.add(keras.layers.Dense(units=1))\n",
        "model_LSTM.compile(optimizer='adam', loss='mse')\n",
        "metrics_history_callback = MetricsHistory(X_train, Y_train,['Metrics over Epochs on LSTM','Loss over Epochs on LSTM'],['/content/drive/MyDrive/Task2/metricsLSTM.png', '/content/drive/MyDrive/Task2/lossLSTM.png'] )\n",
        "model_LSTM.fit(X_train, Y_train,validation_data =(X_test, Y_test), epochs= 1500, batch_size= 256, callbacks=[metrics_history_callback])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "4IR0smxjzF5m",
        "outputId": "b7a2727a-90e0-4d48-9c3a-65bec347c345"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/1500\n",
            "876/876 [==============================] - 3s 3ms/step\n",
            "110/110 [==============================] - 12s 90ms/step - loss: 1509.0731 - val_loss: 1249.4718\n",
            "Epoch 2/1500\n",
            "876/876 [==============================] - 2s 3ms/step\n",
            "110/110 [==============================] - 5s 46ms/step - loss: 1074.2380 - val_loss: 928.9753\n",
            "Epoch 3/1500\n",
            "876/876 [==============================] - 3s 4ms/step\n",
            "110/110 [==============================] - 7s 63ms/step - loss: 818.3519 - val_loss: 725.4814\n",
            "Epoch 4/1500\n",
            "876/876 [==============================] - 2s 3ms/step\n",
            "110/110 [==============================] - 5s 46ms/step - loss: 642.9771 - val_loss: 576.1326\n",
            "Epoch 5/1500\n",
            "876/876 [==============================] - 2s 3ms/step\n",
            "110/110 [==============================] - 7s 69ms/step - loss: 514.9670 - val_loss: 465.3762\n",
            "Epoch 6/1500\n",
            "876/876 [==============================] - 2s 3ms/step\n",
            "110/110 [==============================] - 5s 46ms/step - loss: 420.1598 - val_loss: 385.1001\n",
            "Epoch 7/1500\n",
            "876/876 [==============================] - 2s 3ms/step\n",
            "110/110 [==============================] - 5s 48ms/step - loss: 347.9165 - val_loss: 319.5042\n",
            "Epoch 8/1500\n",
            "876/876 [==============================] - 2s 3ms/step\n",
            "110/110 [==============================] - 7s 64ms/step - loss: 292.7372 - val_loss: 270.8737\n",
            "Epoch 9/1500\n",
            "876/876 [==============================] - 2s 3ms/step\n",
            "110/110 [==============================] - 8s 70ms/step - loss: 245.5832 - val_loss: 227.4552\n",
            "Epoch 10/1500\n",
            "876/876 [==============================] - 2s 3ms/step\n",
            "110/110 [==============================] - 7s 65ms/step - loss: 208.8599 - val_loss: 194.7282\n",
            "Epoch 11/1500\n",
            "876/876 [==============================] - 2s 3ms/step\n",
            "110/110 [==============================] - 5s 46ms/step - loss: 180.6216 - val_loss: 170.2601\n",
            "Epoch 12/1500\n",
            "876/876 [==============================] - 3s 4ms/step\n",
            "110/110 [==============================] - 8s 75ms/step - loss: 158.3727 - val_loss: 148.8604\n",
            "Epoch 13/1500\n",
            "876/876 [==============================] - 2s 3ms/step\n",
            "110/110 [==============================] - 5s 46ms/step - loss: 137.8254 - val_loss: 128.6307\n",
            "Epoch 14/1500\n",
            "876/876 [==============================] - 3s 3ms/step\n",
            "110/110 [==============================] - 6s 52ms/step - loss: 118.9777 - val_loss: 111.1439\n",
            "Epoch 15/1500\n",
            "876/876 [==============================] - 2s 3ms/step\n",
            "110/110 [==============================] - 6s 58ms/step - loss: 102.8907 - val_loss: 96.5657\n",
            "Epoch 16/1500\n",
            "876/876 [==============================] - 2s 3ms/step\n",
            "110/110 [==============================] - 5s 47ms/step - loss: 88.6535 - val_loss: 83.5712\n",
            "Epoch 17/1500\n",
            "876/876 [==============================] - 3s 3ms/step\n",
            "110/110 [==============================] - 9s 80ms/step - loss: 76.8684 - val_loss: 72.7535\n",
            "Epoch 18/1500\n",
            "876/876 [==============================] - 2s 3ms/step\n",
            "110/110 [==============================] - 5s 48ms/step - loss: 67.0653 - val_loss: 63.0953\n",
            "Epoch 19/1500\n",
            "876/876 [==============================] - 3s 4ms/step\n",
            "110/110 [==============================] - 6s 58ms/step - loss: 58.7171 - val_loss: 56.1475\n",
            "Epoch 20/1500\n",
            "876/876 [==============================] - 2s 3ms/step\n",
            "110/110 [==============================] - 6s 50ms/step - loss: 51.6886 - val_loss: 49.7299\n",
            "Epoch 21/1500\n",
            "876/876 [==============================] - 2s 3ms/step\n",
            "110/110 [==============================] - 5s 46ms/step - loss: 46.6576 - val_loss: 48.3339\n",
            "Epoch 22/1500\n",
            "876/876 [==============================] - 2s 3ms/step\n",
            "110/110 [==============================] - 7s 68ms/step - loss: 42.1599 - val_loss: 39.7062\n",
            "Epoch 23/1500\n",
            "876/876 [==============================] - 2s 3ms/step\n",
            "110/110 [==============================] - 5s 46ms/step - loss: 37.4116 - val_loss: 34.9939\n",
            "Epoch 24/1500\n",
            "876/876 [==============================] - 3s 4ms/step\n",
            "110/110 [==============================] - 8s 70ms/step - loss: 32.6994 - val_loss: 30.8534\n",
            "Epoch 25/1500\n",
            "876/876 [==============================] - 3s 3ms/step\n",
            "110/110 [==============================] - 9s 81ms/step - loss: 28.5628 - val_loss: 29.9208\n",
            "Epoch 26/1500\n",
            "876/876 [==============================] - 3s 3ms/step\n",
            "110/110 [==============================] - 10s 88ms/step - loss: 25.9081 - val_loss: 23.8350\n",
            "Epoch 27/1500\n",
            "876/876 [==============================] - 2s 3ms/step\n",
            "110/110 [==============================] - 5s 46ms/step - loss: 23.0539 - val_loss: 21.3969\n",
            "Epoch 28/1500\n",
            "876/876 [==============================] - 3s 4ms/step\n",
            "110/110 [==============================] - 8s 75ms/step - loss: 20.5543 - val_loss: 20.0901\n",
            "Epoch 29/1500\n",
            "876/876 [==============================] - 2s 3ms/step\n",
            "110/110 [==============================] - 6s 58ms/step - loss: 17.8655 - val_loss: 16.6510\n",
            "Epoch 30/1500\n",
            "876/876 [==============================] - 3s 3ms/step\n",
            "110/110 [==============================] - 6s 52ms/step - loss: 16.4110 - val_loss: 15.2491\n",
            "Epoch 31/1500\n",
            "876/876 [==============================] - 2s 3ms/step\n",
            "110/110 [==============================] - 7s 59ms/step - loss: 14.6943 - val_loss: 14.5483\n",
            "Epoch 32/1500\n",
            "876/876 [==============================] - 2s 3ms/step\n",
            "110/110 [==============================] - 5s 47ms/step - loss: 13.4786 - val_loss: 12.1623\n",
            "Epoch 33/1500\n",
            "876/876 [==============================] - 3s 4ms/step\n",
            "110/110 [==============================] - 7s 65ms/step - loss: 12.0764 - val_loss: 14.4433\n",
            "Epoch 34/1500\n",
            "876/876 [==============================] - 2s 3ms/step\n",
            "110/110 [==============================] - 5s 47ms/step - loss: 11.8989 - val_loss: 11.7497\n",
            "Epoch 35/1500\n",
            "876/876 [==============================] - 3s 3ms/step\n",
            "110/110 [==============================] - 8s 69ms/step - loss: 10.2136 - val_loss: 9.9589\n",
            "Epoch 36/1500\n",
            "876/876 [==============================] - 2s 3ms/step\n",
            "110/110 [==============================] - 5s 47ms/step - loss: 10.0076 - val_loss: 8.8452\n",
            "Epoch 37/1500\n",
            "876/876 [==============================] - 2s 3ms/step\n",
            "110/110 [==============================] - 8s 69ms/step - loss: 9.6916 - val_loss: 8.6769\n",
            "Epoch 38/1500\n",
            "876/876 [==============================] - 2s 3ms/step\n",
            "110/110 [==============================] - 5s 46ms/step - loss: 8.7826 - val_loss: 8.9643\n",
            "Epoch 39/1500\n",
            "876/876 [==============================] - 2s 3ms/step\n",
            "110/110 [==============================] - 8s 70ms/step - loss: 9.0072 - val_loss: 7.5627\n",
            "Epoch 40/1500\n",
            "876/876 [==============================] - 2s 3ms/step\n",
            "110/110 [==============================] - 5s 47ms/step - loss: 8.0058 - val_loss: 7.2018\n",
            "Epoch 41/1500\n",
            "876/876 [==============================] - 2s 3ms/step\n",
            "110/110 [==============================] - 8s 70ms/step - loss: 6.7580 - val_loss: 6.8378\n",
            "Epoch 42/1500\n",
            "876/876 [==============================] - 2s 3ms/step\n",
            "110/110 [==============================] - 5s 47ms/step - loss: 6.2827 - val_loss: 6.8874\n",
            "Epoch 43/1500\n",
            "876/876 [==============================] - 3s 3ms/step\n",
            "110/110 [==============================] - 5s 50ms/step - loss: 5.9252 - val_loss: 5.8930\n",
            "Epoch 44/1500\n",
            "876/876 [==============================] - 2s 3ms/step\n",
            "110/110 [==============================] - 7s 66ms/step - loss: 5.4354 - val_loss: 4.8233\n",
            "Epoch 45/1500\n",
            "876/876 [==============================] - 2s 3ms/step\n",
            "110/110 [==============================] - 5s 47ms/step - loss: 5.9216 - val_loss: 4.5695\n",
            "Epoch 46/1500\n",
            "876/876 [==============================] - 3s 4ms/step\n",
            "110/110 [==============================] - 6s 56ms/step - loss: 4.8587 - val_loss: 4.2192\n",
            "Epoch 47/1500\n",
            "876/876 [==============================] - 2s 3ms/step\n",
            "110/110 [==============================] - 6s 50ms/step - loss: 5.7683 - val_loss: 6.2926\n",
            "Epoch 48/1500\n",
            "876/876 [==============================] - 2s 3ms/step\n",
            "110/110 [==============================] - 8s 70ms/step - loss: 4.5262 - val_loss: 5.1666\n",
            "Epoch 49/1500\n",
            "876/876 [==============================] - 2s 3ms/step\n",
            "110/110 [==============================] - 5s 48ms/step - loss: 4.1276 - val_loss: 4.0634\n",
            "Epoch 50/1500\n",
            "876/876 [==============================] - 2s 3ms/step\n",
            "110/110 [==============================] - 5s 48ms/step - loss: 3.6253 - val_loss: 6.4894\n",
            "Epoch 51/1500\n",
            "876/876 [==============================] - 3s 3ms/step\n",
            "110/110 [==============================] - 7s 68ms/step - loss: 3.8259 - val_loss: 3.7770\n",
            "Epoch 52/1500\n",
            "876/876 [==============================] - 2s 3ms/step\n",
            "110/110 [==============================] - 8s 71ms/step - loss: 3.5313 - val_loss: 3.6442\n",
            "Epoch 53/1500\n",
            "876/876 [==============================] - 2s 3ms/step\n",
            "110/110 [==============================] - 10s 91ms/step - loss: 3.5669 - val_loss: 7.8505\n",
            "Epoch 54/1500\n",
            "876/876 [==============================] - 2s 3ms/step\n",
            "110/110 [==============================] - 8s 70ms/step - loss: 3.3469 - val_loss: 4.4390\n",
            "Epoch 55/1500\n",
            "876/876 [==============================] - 2s 3ms/step\n",
            "110/110 [==============================] - 5s 47ms/step - loss: 3.0914 - val_loss: 2.6238\n",
            "Epoch 56/1500\n",
            "876/876 [==============================] - 2s 3ms/step\n",
            "110/110 [==============================] - 5s 48ms/step - loss: 3.1952 - val_loss: 2.6951\n",
            "Epoch 57/1500\n",
            "876/876 [==============================] - 2s 3ms/step\n",
            "110/110 [==============================] - 7s 67ms/step - loss: 3.8774 - val_loss: 5.3713\n",
            "Epoch 58/1500\n",
            "876/876 [==============================] - 2s 3ms/step\n",
            "110/110 [==============================] - 5s 47ms/step - loss: 3.1500 - val_loss: 2.2689\n",
            "Epoch 59/1500\n",
            "876/876 [==============================] - 3s 4ms/step\n",
            "110/110 [==============================] - 6s 57ms/step - loss: 2.7914 - val_loss: 5.4345\n",
            "Epoch 60/1500\n",
            "876/876 [==============================] - 2s 3ms/step\n",
            "110/110 [==============================] - 8s 74ms/step - loss: 2.7246 - val_loss: 2.7082\n",
            "Epoch 61/1500\n",
            "876/876 [==============================] - 3s 4ms/step\n",
            "110/110 [==============================] - 8s 77ms/step - loss: 2.7590 - val_loss: 2.5670\n",
            "Epoch 62/1500\n",
            "876/876 [==============================] - 2s 3ms/step\n",
            "110/110 [==============================] - 6s 54ms/step - loss: 2.3621 - val_loss: 2.3550\n",
            "Epoch 63/1500\n",
            "876/876 [==============================] - 3s 4ms/step\n",
            "110/110 [==============================] - 8s 69ms/step - loss: 2.8361 - val_loss: 2.4072\n",
            "Epoch 64/1500\n",
            "876/876 [==============================] - 2s 3ms/step\n",
            "110/110 [==============================] - 7s 63ms/step - loss: 2.4480 - val_loss: 1.9543\n",
            "Epoch 65/1500\n",
            "876/876 [==============================] - 2s 3ms/step\n",
            "110/110 [==============================] - 5s 47ms/step - loss: 2.4125 - val_loss: 6.8372\n",
            "Epoch 66/1500\n",
            "876/876 [==============================] - 3s 4ms/step\n",
            "110/110 [==============================] - 7s 63ms/step - loss: 2.6507 - val_loss: 1.8378\n",
            "Epoch 67/1500\n",
            "876/876 [==============================] - 2s 3ms/step\n",
            "110/110 [==============================] - 5s 47ms/step - loss: 2.5346 - val_loss: 6.6983\n",
            "Epoch 68/1500\n",
            "876/876 [==============================] - 2s 3ms/step\n",
            "110/110 [==============================] - 5s 48ms/step - loss: 3.9202 - val_loss: 4.7236\n",
            "Epoch 69/1500\n",
            "876/876 [==============================] - 2s 3ms/step\n",
            "110/110 [==============================] - 10s 89ms/step - loss: 2.3346 - val_loss: 1.8121\n",
            "Epoch 70/1500\n",
            "876/876 [==============================] - 2s 3ms/step\n",
            "110/110 [==============================] - 5s 47ms/step - loss: 2.4889 - val_loss: 4.0207\n",
            "Epoch 71/1500\n",
            "876/876 [==============================] - 3s 3ms/step\n",
            "110/110 [==============================] - 7s 66ms/step - loss: 2.0261 - val_loss: 1.6156\n",
            "Epoch 72/1500\n",
            "876/876 [==============================] - 2s 3ms/step\n",
            "110/110 [==============================] - 5s 48ms/step - loss: 2.4844 - val_loss: 4.0283\n",
            "Epoch 73/1500\n",
            "876/876 [==============================] - 3s 3ms/step\n",
            "110/110 [==============================] - 6s 55ms/step - loss: 2.0982 - val_loss: 2.0073\n",
            "Epoch 74/1500\n",
            "876/876 [==============================] - 2s 3ms/step\n",
            "110/110 [==============================] - 6s 59ms/step - loss: 1.9138 - val_loss: 1.5542\n",
            "Epoch 75/1500\n",
            "876/876 [==============================] - 2s 3ms/step\n",
            "110/110 [==============================] - 5s 48ms/step - loss: 1.7543 - val_loss: 1.7963\n",
            "Epoch 76/1500\n",
            "876/876 [==============================] - 3s 3ms/step\n",
            "110/110 [==============================] - 9s 83ms/step - loss: 1.9845 - val_loss: 1.8619\n",
            "Epoch 77/1500\n",
            "876/876 [==============================] - 2s 3ms/step\n",
            "110/110 [==============================] - 8s 70ms/step - loss: 2.5609 - val_loss: 1.8242\n",
            "Epoch 78/1500\n",
            "876/876 [==============================] - 2s 3ms/step\n",
            "110/110 [==============================] - 7s 62ms/step - loss: 1.8248 - val_loss: 1.9087\n",
            "Epoch 79/1500\n",
            "876/876 [==============================] - 2s 3ms/step\n",
            "110/110 [==============================] - 5s 47ms/step - loss: 1.7219 - val_loss: 1.3685\n",
            "Epoch 80/1500\n",
            "876/876 [==============================] - 3s 4ms/step\n",
            "110/110 [==============================] - 8s 77ms/step - loss: 2.3254 - val_loss: 2.2377\n",
            "Epoch 81/1500\n",
            "876/876 [==============================] - 2s 3ms/step\n",
            "110/110 [==============================] - 5s 48ms/step - loss: 2.7028 - val_loss: 2.1138\n",
            "Epoch 82/1500\n",
            "876/876 [==============================] - 3s 3ms/step\n",
            "110/110 [==============================] - 6s 53ms/step - loss: 1.9201 - val_loss: 2.0102\n",
            "Epoch 83/1500\n",
            "876/876 [==============================] - 2s 3ms/step\n",
            "110/110 [==============================] - 7s 60ms/step - loss: 1.5253 - val_loss: 1.8407\n",
            "Epoch 84/1500\n",
            "876/876 [==============================] - 2s 3ms/step\n",
            "110/110 [==============================] - 5s 48ms/step - loss: 1.9206 - val_loss: 1.3436\n",
            "Epoch 85/1500\n",
            "876/876 [==============================] - 3s 4ms/step\n",
            "110/110 [==============================] - 7s 65ms/step - loss: 2.0379 - val_loss: 2.8262\n",
            "Epoch 86/1500\n",
            "876/876 [==============================] - 2s 3ms/step\n",
            "110/110 [==============================] - 8s 70ms/step - loss: 2.3632 - val_loss: 1.4441\n",
            "Epoch 87/1500\n",
            "876/876 [==============================] - 3s 4ms/step\n",
            "110/110 [==============================] - 6s 59ms/step - loss: 2.0660 - val_loss: 1.8365\n",
            "Epoch 88/1500\n",
            "876/876 [==============================] - 2s 3ms/step\n",
            "110/110 [==============================] - 6s 51ms/step - loss: 1.5193 - val_loss: 1.2453\n",
            "Epoch 89/1500\n",
            "876/876 [==============================] - 2s 3ms/step\n",
            "110/110 [==============================] - 8s 70ms/step - loss: 2.1559 - val_loss: 2.3204\n",
            "Epoch 90/1500\n",
            "876/876 [==============================] - 2s 3ms/step\n",
            "110/110 [==============================] - 5s 46ms/step - loss: 2.4145 - val_loss: 1.9509\n",
            "Epoch 91/1500\n",
            "876/876 [==============================] - 2s 3ms/step\n",
            "110/110 [==============================] - 8s 70ms/step - loss: 1.6836 - val_loss: 1.5881\n",
            "Epoch 92/1500\n",
            "876/876 [==============================] - 3s 3ms/step\n",
            "110/110 [==============================] - 6s 53ms/step - loss: 1.9491 - val_loss: 2.1854\n",
            "Epoch 93/1500\n",
            "876/876 [==============================] - 3s 3ms/step\n",
            "110/110 [==============================] - 9s 81ms/step - loss: 1.6839 - val_loss: 1.7766\n",
            "Epoch 94/1500\n",
            "876/876 [==============================] - 2s 3ms/step\n",
            "110/110 [==============================] - 5s 46ms/step - loss: 1.3820 - val_loss: 1.2514\n",
            "Epoch 95/1500\n",
            "876/876 [==============================] - 3s 3ms/step\n",
            "110/110 [==============================] - 8s 70ms/step - loss: 2.6646 - val_loss: 7.7934\n",
            "Epoch 96/1500\n",
            "876/876 [==============================] - 2s 3ms/step\n",
            "110/110 [==============================] - 5s 48ms/step - loss: 2.1176 - val_loss: 2.3300\n",
            "Epoch 97/1500\n",
            "876/876 [==============================] - 3s 3ms/step\n",
            "110/110 [==============================] - 5s 50ms/step - loss: 1.6673 - val_loss: 2.1630\n",
            "Epoch 98/1500\n",
            "876/876 [==============================] - 2s 3ms/step\n",
            "110/110 [==============================] - 7s 66ms/step - loss: 1.5724 - val_loss: 1.2274\n",
            "Epoch 99/1500\n",
            "876/876 [==============================] - 2s 3ms/step\n",
            "110/110 [==============================] - 5s 47ms/step - loss: 1.3603 - val_loss: 2.1713\n",
            "Epoch 100/1500\n",
            "876/876 [==============================] - 3s 4ms/step\n",
            "110/110 [==============================] - 8s 74ms/step - loss: 1.7696 - val_loss: 1.4595\n",
            "Epoch 101/1500\n",
            "876/876 [==============================] - 2s 3ms/step\n",
            "110/110 [==============================] - 6s 57ms/step - loss: 1.8831 - val_loss: 1.7369\n",
            "Epoch 102/1500\n",
            "876/876 [==============================] - 3s 3ms/step\n",
            "110/110 [==============================] - 6s 51ms/step - loss: 1.3182 - val_loss: 1.1014\n",
            "Epoch 103/1500\n",
            "876/876 [==============================] - 2s 3ms/step\n",
            "110/110 [==============================] - 10s 88ms/step - loss: 1.3051 - val_loss: 1.7002\n",
            "Epoch 104/1500\n",
            "876/876 [==============================] - 3s 3ms/step\n",
            "110/110 [==============================] - 6s 50ms/step - loss: 1.5664 - val_loss: 1.2334\n",
            "Epoch 105/1500\n",
            "876/876 [==============================] - 2s 3ms/step\n",
            "110/110 [==============================] - 7s 66ms/step - loss: 1.6846 - val_loss: 1.4113\n",
            "Epoch 106/1500\n",
            "876/876 [==============================] - 2s 3ms/step\n",
            "110/110 [==============================] - 5s 47ms/step - loss: 1.3255 - val_loss: 4.1119\n",
            "Epoch 107/1500\n",
            "876/876 [==============================] - 3s 4ms/step\n",
            "110/110 [==============================] - 7s 64ms/step - loss: 1.8703 - val_loss: 1.1813\n",
            "Epoch 108/1500\n",
            "876/876 [==============================] - 2s 3ms/step\n",
            "110/110 [==============================] - 5s 47ms/step - loss: 1.7008 - val_loss: 1.8504\n",
            "Epoch 109/1500\n",
            "876/876 [==============================] - 2s 3ms/step\n",
            "110/110 [==============================] - 5s 48ms/step - loss: 1.7895 - val_loss: 4.3098\n",
            "Epoch 110/1500\n",
            "876/876 [==============================] - 2s 3ms/step\n",
            "110/110 [==============================] - 7s 67ms/step - loss: 1.7819 - val_loss: 2.1697\n",
            "Epoch 111/1500\n",
            "876/876 [==============================] - 2s 3ms/step\n",
            "110/110 [==============================] - 5s 47ms/step - loss: 1.2399 - val_loss: 1.4812\n",
            "Epoch 112/1500\n",
            "876/876 [==============================] - 3s 4ms/step\n",
            "110/110 [==============================] - 6s 56ms/step - loss: 1.7999 - val_loss: 1.2847\n",
            "Epoch 113/1500\n",
            "876/876 [==============================] - 2s 3ms/step\n",
            "110/110 [==============================] - 6s 54ms/step - loss: 1.6370 - val_loss: 1.5406\n",
            "Epoch 114/1500\n",
            "876/876 [==============================] - 2s 3ms/step\n",
            "110/110 [==============================] - 5s 48ms/step - loss: 1.4458 - val_loss: 2.2653\n",
            "Epoch 115/1500\n",
            "876/876 [==============================] - 3s 3ms/step\n",
            "110/110 [==============================] - 7s 67ms/step - loss: 1.7574 - val_loss: 1.8817\n",
            "Epoch 116/1500\n",
            "876/876 [==============================] - 2s 3ms/step\n",
            "110/110 [==============================] - 5s 47ms/step - loss: 1.3202 - val_loss: 1.2481\n",
            "Epoch 117/1500\n",
            "876/876 [==============================] - 3s 3ms/step\n",
            "110/110 [==============================] - 6s 54ms/step - loss: 1.6242 - val_loss: 1.3839\n",
            "Epoch 118/1500\n",
            "876/876 [==============================] - 2s 3ms/step\n",
            "110/110 [==============================] - 6s 59ms/step - loss: 1.3683 - val_loss: 2.2084\n",
            "Epoch 119/1500\n",
            "876/876 [==============================] - 2s 3ms/step\n",
            "110/110 [==============================] - 5s 47ms/step - loss: 1.4538 - val_loss: 2.7839\n",
            "Epoch 120/1500\n",
            "876/876 [==============================] - 3s 4ms/step\n",
            "110/110 [==============================] - 9s 82ms/step - loss: 1.8568 - val_loss: 10.4730\n",
            "Epoch 121/1500\n",
            "876/876 [==============================] - 2s 3ms/step\n",
            "110/110 [==============================] - 5s 47ms/step - loss: 2.4712 - val_loss: 1.9505\n",
            "Epoch 122/1500\n",
            "876/876 [==============================] - 3s 3ms/step\n",
            "110/110 [==============================] - 8s 72ms/step - loss: 1.5956 - val_loss: 1.0100\n",
            "Epoch 123/1500\n",
            "876/876 [==============================] - 2s 3ms/step\n",
            "110/110 [==============================] - 5s 47ms/step - loss: 1.2873 - val_loss: 1.1296\n",
            "Epoch 124/1500\n",
            "876/876 [==============================] - 3s 3ms/step\n",
            "110/110 [==============================] - 8s 70ms/step - loss: 1.3712 - val_loss: 1.3812\n",
            "Epoch 125/1500\n",
            "876/876 [==============================] - 2s 3ms/step\n",
            "110/110 [==============================] - 7s 65ms/step - loss: 1.4121 - val_loss: 1.2627\n",
            "Epoch 126/1500\n",
            "876/876 [==============================] - 3s 3ms/step\n",
            "110/110 [==============================] - 6s 52ms/step - loss: 1.3070 - val_loss: 5.8868\n",
            "Epoch 127/1500\n",
            "876/876 [==============================] - 2s 3ms/step\n",
            "110/110 [==============================] - 9s 85ms/step - loss: 1.4747 - val_loss: 1.3976\n",
            "Epoch 128/1500\n",
            "876/876 [==============================] - 3s 3ms/step\n",
            "110/110 [==============================] - 8s 70ms/step - loss: 1.1495 - val_loss: 0.9634\n",
            "Epoch 129/1500\n",
            "876/876 [==============================] - 2s 3ms/step\n",
            "110/110 [==============================] - 8s 70ms/step - loss: 1.3162 - val_loss: 1.0963\n",
            "Epoch 130/1500\n",
            "876/876 [==============================] - 3s 4ms/step\n",
            "110/110 [==============================] - 9s 78ms/step - loss: 1.2160 - val_loss: 1.0567\n",
            "Epoch 131/1500\n",
            "876/876 [==============================] - 2s 3ms/step\n",
            "110/110 [==============================] - 5s 48ms/step - loss: 1.8196 - val_loss: 1.3160\n",
            "Epoch 132/1500\n",
            "876/876 [==============================] - 3s 3ms/step\n",
            "110/110 [==============================] - 8s 70ms/step - loss: 1.3807 - val_loss: 1.5734\n",
            "Epoch 133/1500\n",
            "876/876 [==============================] - 2s 3ms/step\n",
            "110/110 [==============================] - 5s 48ms/step - loss: 1.1276 - val_loss: 1.5874\n",
            "Epoch 134/1500\n",
            "876/876 [==============================] - 3s 3ms/step\n",
            "110/110 [==============================] - 6s 52ms/step - loss: 1.3921 - val_loss: 1.0766\n",
            "Epoch 135/1500\n",
            "876/876 [==============================] - 2s 3ms/step\n",
            "110/110 [==============================] - 10s 88ms/step - loss: 1.4297 - val_loss: 1.0289\n",
            "Epoch 136/1500\n",
            "876/876 [==============================] - 3s 3ms/step\n",
            "110/110 [==============================] - 5s 50ms/step - loss: 1.7483 - val_loss: 1.7484\n",
            "Epoch 137/1500\n",
            "876/876 [==============================] - 3s 4ms/step\n",
            "110/110 [==============================] - 10s 93ms/step - loss: 1.4525 - val_loss: 1.9273\n",
            "Epoch 138/1500\n",
            "876/876 [==============================] - 2s 3ms/step\n",
            "110/110 [==============================] - 8s 70ms/step - loss: 1.2230 - val_loss: 1.0609\n",
            "Epoch 139/1500\n",
            "876/876 [==============================] - 2s 3ms/step\n",
            "110/110 [==============================] - 7s 60ms/step - loss: 1.4297 - val_loss: 8.6900\n",
            "Epoch 140/1500\n",
            "876/876 [==============================] - 2s 3ms/step\n",
            "110/110 [==============================] - 5s 47ms/step - loss: 1.5469 - val_loss: 1.3328\n",
            "Epoch 141/1500\n",
            "876/876 [==============================] - 3s 3ms/step\n",
            "110/110 [==============================] - 9s 83ms/step - loss: 1.8202 - val_loss: 1.6199\n",
            "Epoch 142/1500\n",
            "876/876 [==============================] - 2s 3ms/step\n",
            "110/110 [==============================] - 5s 47ms/step - loss: 1.4363 - val_loss: 1.1993\n",
            "Epoch 143/1500\n",
            "876/876 [==============================] - 3s 4ms/step\n",
            "110/110 [==============================] - 8s 75ms/step - loss: 1.2536 - val_loss: 1.4154\n",
            "Epoch 144/1500\n",
            "876/876 [==============================] - 2s 3ms/step\n",
            "110/110 [==============================] - 5s 47ms/step - loss: 1.4594 - val_loss: 2.6060\n",
            "Epoch 145/1500\n",
            "876/876 [==============================] - 3s 3ms/step\n",
            "110/110 [==============================] - 8s 70ms/step - loss: 1.2336 - val_loss: 1.1227\n",
            "Epoch 146/1500\n",
            "876/876 [==============================] - 2s 3ms/step\n",
            "110/110 [==============================] - 5s 48ms/step - loss: 1.2973 - val_loss: 1.3647\n",
            "Epoch 147/1500\n",
            "876/876 [==============================] - 2s 3ms/step\n",
            "110/110 [==============================] - 5s 49ms/step - loss: 0.9468 - val_loss: 0.8232\n",
            "Epoch 148/1500\n",
            "876/876 [==============================] - 2s 3ms/step\n",
            "110/110 [==============================] - 7s 64ms/step - loss: 1.3063 - val_loss: 1.1846\n",
            "Epoch 149/1500\n",
            "876/876 [==============================] - 2s 3ms/step\n",
            "110/110 [==============================] - 5s 46ms/step - loss: 1.3124 - val_loss: 5.9741\n",
            "Epoch 150/1500\n",
            "876/876 [==============================] - 3s 3ms/step\n",
            "110/110 [==============================] - 7s 60ms/step - loss: 1.9638 - val_loss: 1.8733\n",
            "Epoch 151/1500\n",
            "876/876 [==============================] - 2s 3ms/step\n",
            "110/110 [==============================] - 5s 48ms/step - loss: 1.8785 - val_loss: 0.9358\n",
            "Epoch 152/1500\n",
            "876/876 [==============================] - 2s 3ms/step\n",
            "110/110 [==============================] - 8s 70ms/step - loss: 1.6227 - val_loss: 1.6303\n",
            "Epoch 153/1500\n",
            "876/876 [==============================] - 2s 3ms/step\n",
            "110/110 [==============================] - 5s 46ms/step - loss: 1.2430 - val_loss: 0.9802\n",
            "Epoch 154/1500\n",
            "876/876 [==============================] - 3s 3ms/step\n",
            "110/110 [==============================] - 8s 70ms/step - loss: 1.1376 - val_loss: 0.9218\n",
            "Epoch 155/1500\n",
            "876/876 [==============================] - 2s 3ms/step\n",
            "110/110 [==============================] - 7s 64ms/step - loss: 1.1830 - val_loss: 0.9834\n",
            "Epoch 156/1500\n",
            "876/876 [==============================] - 2s 3ms/step\n",
            "110/110 [==============================] - 5s 48ms/step - loss: 1.3700 - val_loss: 2.2906\n",
            "Epoch 157/1500\n",
            "876/876 [==============================] - 3s 4ms/step\n",
            "110/110 [==============================] - 9s 78ms/step - loss: 1.1402 - val_loss: 1.0336\n",
            "Epoch 158/1500\n",
            "876/876 [==============================] - 2s 3ms/step\n",
            "110/110 [==============================] - 5s 47ms/step - loss: 1.3493 - val_loss: 1.4245\n",
            "Epoch 159/1500\n",
            "876/876 [==============================] - 3s 4ms/step\n",
            "110/110 [==============================] - 8s 70ms/step - loss: 1.4223 - val_loss: 1.0621\n",
            "Epoch 160/1500\n",
            "876/876 [==============================] - 2s 3ms/step\n",
            "110/110 [==============================] - 5s 48ms/step - loss: 1.0032 - val_loss: 0.7880\n",
            "Epoch 161/1500\n",
            "876/876 [==============================] - 3s 3ms/step\n",
            "110/110 [==============================] - 8s 70ms/step - loss: 1.4747 - val_loss: 1.2258\n",
            "Epoch 162/1500\n",
            "876/876 [==============================] - 2s 3ms/step\n",
            "110/110 [==============================] - 5s 48ms/step - loss: 1.2389 - val_loss: 0.9997\n",
            "Epoch 163/1500\n",
            "876/876 [==============================] - 3s 3ms/step\n",
            "110/110 [==============================] - 8s 70ms/step - loss: 1.1365 - val_loss: 1.4573\n",
            "Epoch 164/1500\n",
            "876/876 [==============================] - 2s 3ms/step\n",
            "110/110 [==============================] - 5s 48ms/step - loss: 1.3425 - val_loss: 1.2456\n",
            "Epoch 165/1500\n",
            "876/876 [==============================] - 2s 3ms/step\n",
            "110/110 [==============================] - 5s 50ms/step - loss: 0.9607 - val_loss: 0.8391\n",
            "Epoch 166/1500\n",
            "876/876 [==============================] - 2s 3ms/step\n",
            "110/110 [==============================] - 7s 66ms/step - loss: 1.1344 - val_loss: 1.2010\n",
            "Epoch 167/1500\n",
            "876/876 [==============================] - 2s 3ms/step\n",
            "110/110 [==============================] - 5s 47ms/step - loss: 1.9356 - val_loss: 1.4124\n",
            "Epoch 168/1500\n",
            "876/876 [==============================] - 3s 4ms/step\n",
            "110/110 [==============================] - 8s 74ms/step - loss: 1.6017 - val_loss: 2.0757\n",
            "Epoch 169/1500\n",
            "876/876 [==============================] - 2s 3ms/step\n",
            "110/110 [==============================] - 8s 70ms/step - loss: 1.9230 - val_loss: 1.3393\n",
            "Epoch 170/1500\n",
            "876/876 [==============================] - 3s 4ms/step\n",
            "110/110 [==============================] - 7s 66ms/step - loss: 1.5856 - val_loss: 0.9910\n",
            "Epoch 171/1500\n",
            "876/876 [==============================] - 2s 3ms/step\n",
            "110/110 [==============================] - 8s 71ms/step - loss: 0.9281 - val_loss: 0.9515\n",
            "Epoch 172/1500\n",
            "876/876 [==============================] - 3s 4ms/step\n",
            "110/110 [==============================] - 8s 76ms/step - loss: 1.3239 - val_loss: 0.9910\n",
            "Epoch 173/1500\n",
            "876/876 [==============================] - 2s 3ms/step\n",
            "110/110 [==============================] - 6s 58ms/step - loss: 1.1822 - val_loss: 1.8943\n",
            "Epoch 174/1500\n",
            "876/876 [==============================] - 3s 4ms/step\n",
            "110/110 [==============================] - 8s 72ms/step - loss: 1.1407 - val_loss: 1.7003\n",
            "Epoch 175/1500\n",
            "876/876 [==============================] - 2s 3ms/step\n",
            "110/110 [==============================] - 8s 71ms/step - loss: 1.1524 - val_loss: 1.0611\n",
            "Epoch 176/1500\n",
            "876/876 [==============================] - 3s 3ms/step\n",
            "110/110 [==============================] - 7s 63ms/step - loss: 1.1269 - val_loss: 1.6479\n",
            "Epoch 177/1500\n",
            "876/876 [==============================] - 2s 3ms/step\n",
            "110/110 [==============================] - 5s 47ms/step - loss: 1.5586 - val_loss: 0.9118\n",
            "Epoch 178/1500\n",
            "876/876 [==============================] - 3s 3ms/step\n",
            "110/110 [==============================] - 8s 70ms/step - loss: 1.0179 - val_loss: 0.9338\n",
            "Epoch 179/1500\n",
            "876/876 [==============================] - 2s 3ms/step\n",
            "110/110 [==============================] - 5s 46ms/step - loss: 1.4932 - val_loss: 1.3782\n",
            "Epoch 180/1500\n",
            "876/876 [==============================] - 2s 3ms/step\n",
            "110/110 [==============================] - 5s 49ms/step - loss: 1.2490 - val_loss: 0.9243\n",
            "Epoch 181/1500\n",
            "876/876 [==============================] - 2s 3ms/step\n",
            "110/110 [==============================] - 7s 67ms/step - loss: 1.3301 - val_loss: 1.1638\n",
            "Epoch 182/1500\n",
            "876/876 [==============================] - 2s 3ms/step\n",
            "110/110 [==============================] - 5s 47ms/step - loss: 0.8423 - val_loss: 1.0933\n",
            "Epoch 183/1500\n",
            "876/876 [==============================] - 3s 4ms/step\n",
            "110/110 [==============================] - 6s 58ms/step - loss: 1.4708 - val_loss: 2.0237\n",
            "Epoch 184/1500\n",
            "876/876 [==============================] - 3s 3ms/step\n",
            "110/110 [==============================] - 6s 56ms/step - loss: 1.0676 - val_loss: 1.9053\n",
            "Epoch 185/1500\n",
            "876/876 [==============================] - 3s 3ms/step\n",
            "110/110 [==============================] - 9s 85ms/step - loss: 0.9797 - val_loss: 0.8643\n",
            "Epoch 186/1500\n",
            "876/876 [==============================] - 2s 3ms/step\n",
            "110/110 [==============================] - 5s 46ms/step - loss: 0.8944 - val_loss: 1.7055\n",
            "Epoch 187/1500\n",
            "876/876 [==============================] - 3s 3ms/step\n",
            "110/110 [==============================] - 8s 70ms/step - loss: 1.2264 - val_loss: 1.8700\n",
            "Epoch 188/1500\n",
            "876/876 [==============================] - 2s 3ms/step\n",
            "110/110 [==============================] - 8s 70ms/step - loss: 1.0701 - val_loss: 2.1082\n",
            "Epoch 189/1500\n",
            "876/876 [==============================] - 3s 4ms/step\n",
            "110/110 [==============================] - 7s 61ms/step - loss: 1.1272 - val_loss: 1.8522\n",
            "Epoch 190/1500\n",
            "876/876 [==============================] - 2s 3ms/step\n",
            "110/110 [==============================] - 5s 49ms/step - loss: 1.1671 - val_loss: 1.3699\n",
            "Epoch 191/1500\n",
            "876/876 [==============================] - 2s 3ms/step\n",
            "110/110 [==============================] - 5s 48ms/step - loss: 1.0771 - val_loss: 0.7441\n",
            "Epoch 192/1500\n",
            "876/876 [==============================] - 2s 3ms/step\n",
            "110/110 [==============================] - 10s 89ms/step - loss: 1.0997 - val_loss: 1.2898\n",
            "Epoch 193/1500\n",
            "876/876 [==============================] - 2s 3ms/step\n",
            "110/110 [==============================] - 5s 47ms/step - loss: 0.8821 - val_loss: 1.2375\n",
            "Epoch 194/1500\n",
            "876/876 [==============================] - 3s 3ms/step\n",
            "110/110 [==============================] - 7s 67ms/step - loss: 1.3580 - val_loss: 0.9137\n",
            "Epoch 195/1500\n",
            "876/876 [==============================] - 2s 3ms/step\n",
            "110/110 [==============================] - 8s 70ms/step - loss: 0.8863 - val_loss: 1.7997\n",
            "Epoch 196/1500\n",
            "876/876 [==============================] - 3s 3ms/step\n",
            "110/110 [==============================] - 10s 87ms/step - loss: 1.2654 - val_loss: 1.3295\n",
            "Epoch 197/1500\n",
            "876/876 [==============================] - 2s 3ms/step\n",
            "110/110 [==============================] - 8s 70ms/step - loss: 1.2189 - val_loss: 1.4473\n",
            "Epoch 198/1500\n",
            "876/876 [==============================] - 2s 3ms/step\n",
            "110/110 [==============================] - 8s 74ms/step - loss: 1.8950 - val_loss: 1.1374\n",
            "Epoch 199/1500\n",
            "876/876 [==============================] - 3s 3ms/step\n",
            "110/110 [==============================] - 8s 70ms/step - loss: 1.0371 - val_loss: 0.9195\n",
            "Epoch 200/1500\n",
            "876/876 [==============================] - 2s 3ms/step\n",
            "110/110 [==============================] - 5s 48ms/step - loss: 0.9087 - val_loss: 1.1561\n",
            "Epoch 201/1500\n",
            "876/876 [==============================] - 3s 3ms/step\n",
            "110/110 [==============================] - 6s 51ms/step - loss: 1.3849 - val_loss: 1.1382\n",
            "Epoch 202/1500\n",
            "876/876 [==============================] - 2s 3ms/step\n",
            "110/110 [==============================] - 7s 63ms/step - loss: 0.8572 - val_loss: 0.9552\n",
            "Epoch 203/1500\n",
            "876/876 [==============================] - 2s 3ms/step\n",
            "110/110 [==============================] - 5s 47ms/step - loss: 1.2474 - val_loss: 0.8874\n",
            "Epoch 204/1500\n",
            "876/876 [==============================] - 3s 3ms/step\n",
            "110/110 [==============================] - 8s 74ms/step - loss: 0.9206 - val_loss: 1.1202\n",
            "Epoch 205/1500\n",
            "876/876 [==============================] - 2s 3ms/step\n",
            "110/110 [==============================] - 5s 47ms/step - loss: 1.1884 - val_loss: 1.3713\n",
            "Epoch 206/1500\n",
            "876/876 [==============================] - 3s 3ms/step\n",
            "110/110 [==============================] - 6s 52ms/step - loss: 1.1281 - val_loss: 1.2851\n",
            "Epoch 207/1500\n",
            "876/876 [==============================] - 2s 3ms/step\n",
            "110/110 [==============================] - 7s 61ms/step - loss: 1.6027 - val_loss: 1.5726\n",
            "Epoch 208/1500\n",
            "876/876 [==============================] - 3s 4ms/step\n",
            "110/110 [==============================] - 7s 63ms/step - loss: 0.9440 - val_loss: 1.8623\n",
            "Epoch 209/1500\n",
            "876/876 [==============================] - 2s 3ms/step\n",
            "110/110 [==============================] - 10s 92ms/step - loss: 1.4169 - val_loss: 1.3518\n",
            "Epoch 210/1500\n",
            "876/876 [==============================] - 2s 3ms/step\n",
            "110/110 [==============================] - 5s 48ms/step - loss: 0.9615 - val_loss: 0.9844\n",
            "Epoch 211/1500\n",
            "876/876 [==============================] - 3s 3ms/step\n",
            "110/110 [==============================] - 10s 89ms/step - loss: 1.1242 - val_loss: 1.4044\n",
            "Epoch 212/1500\n",
            "876/876 [==============================] - 2s 3ms/step\n",
            "110/110 [==============================] - 5s 47ms/step - loss: 1.1911 - val_loss: 1.1971\n",
            "Epoch 213/1500\n",
            "876/876 [==============================] - 3s 4ms/step\n",
            "110/110 [==============================] - 9s 79ms/step - loss: 1.2401 - val_loss: 1.3136\n",
            "Epoch 214/1500\n",
            "876/876 [==============================] - 2s 3ms/step\n",
            "110/110 [==============================] - 6s 57ms/step - loss: 0.8767 - val_loss: 1.3941\n",
            "Epoch 215/1500\n",
            "876/876 [==============================] - 3s 3ms/step\n",
            "110/110 [==============================] - 6s 53ms/step - loss: 0.8422 - val_loss: 1.0725\n",
            "Epoch 216/1500\n",
            "876/876 [==============================] - 2s 3ms/step\n",
            "110/110 [==============================] - 6s 58ms/step - loss: 1.3059 - val_loss: 1.0901\n",
            "Epoch 217/1500\n",
            "876/876 [==============================] - 2s 3ms/step\n",
            "110/110 [==============================] - 5s 48ms/step - loss: 1.1720 - val_loss: 2.9635\n",
            "Epoch 218/1500\n",
            "876/876 [==============================] - 3s 3ms/step\n",
            "110/110 [==============================] - 7s 63ms/step - loss: 1.1022 - val_loss: 1.3042\n",
            "Epoch 219/1500\n",
            "876/876 [==============================] - 2s 3ms/step\n",
            "110/110 [==============================] - 8s 70ms/step - loss: 0.8981 - val_loss: 1.1675\n",
            "Epoch 220/1500\n",
            "876/876 [==============================] - 3s 3ms/step\n",
            "110/110 [==============================] - 8s 76ms/step - loss: 0.9217 - val_loss: 0.7344\n",
            "Epoch 221/1500\n",
            "876/876 [==============================] - 2s 3ms/step\n",
            "110/110 [==============================] - 5s 47ms/step - loss: 0.9073 - val_loss: 0.9024\n",
            "Epoch 222/1500\n",
            "876/876 [==============================] - 3s 3ms/step\n",
            "110/110 [==============================] - 8s 70ms/step - loss: 1.9061 - val_loss: 0.8418\n",
            "Epoch 223/1500\n",
            "876/876 [==============================] - 2s 3ms/step\n",
            "110/110 [==============================] - 5s 46ms/step - loss: 1.7328 - val_loss: 2.3868\n",
            "Epoch 224/1500\n",
            "876/876 [==============================] - 3s 3ms/step\n",
            "110/110 [==============================] - 8s 70ms/step - loss: 1.1023 - val_loss: 0.7346\n",
            "Epoch 225/1500\n",
            "876/876 [==============================] - 2s 3ms/step\n",
            "110/110 [==============================] - 5s 47ms/step - loss: 0.9552 - val_loss: 0.8369\n",
            "Epoch 226/1500\n",
            "876/876 [==============================] - 2s 3ms/step\n",
            "110/110 [==============================] - 8s 70ms/step - loss: 0.7845 - val_loss: 0.8067\n",
            "Epoch 227/1500\n",
            "876/876 [==============================] - 2s 3ms/step\n",
            "110/110 [==============================] - 5s 46ms/step - loss: 0.8654 - val_loss: 1.1867\n",
            "Epoch 228/1500\n",
            "876/876 [==============================] - 2s 3ms/step\n",
            "110/110 [==============================] - 5s 49ms/step - loss: 0.9846 - val_loss: 0.8195\n",
            "Epoch 229/1500\n",
            "876/876 [==============================] - 2s 3ms/step\n",
            "110/110 [==============================] - 7s 67ms/step - loss: 0.7584 - val_loss: 1.0474\n",
            "Epoch 230/1500\n",
            "876/876 [==============================] - 2s 3ms/step\n",
            "110/110 [==============================] - 5s 46ms/step - loss: 1.3547 - val_loss: 1.6747\n",
            "Epoch 231/1500\n",
            "876/876 [==============================] - 3s 4ms/step\n",
            "110/110 [==============================] - 6s 57ms/step - loss: 1.0183 - val_loss: 2.8330\n",
            "Epoch 232/1500\n",
            "876/876 [==============================] - 2s 3ms/step\n",
            "110/110 [==============================] - 6s 52ms/step - loss: 1.0121 - val_loss: 1.4438\n",
            "Epoch 233/1500\n",
            "876/876 [==============================] - 2s 3ms/step\n",
            "110/110 [==============================] - 5s 47ms/step - loss: 0.9594 - val_loss: 0.7360\n",
            "Epoch 234/1500\n",
            "876/876 [==============================] - 3s 3ms/step\n",
            "110/110 [==============================] - 9s 87ms/step - loss: 0.9378 - val_loss: 0.7448\n",
            "Epoch 235/1500\n",
            "876/876 [==============================] - 2s 3ms/step\n",
            "110/110 [==============================] - 8s 70ms/step - loss: 1.2561 - val_loss: 0.8617\n",
            "Epoch 236/1500\n",
            "876/876 [==============================] - 2s 3ms/step\n",
            "110/110 [==============================] - 6s 59ms/step - loss: 1.3287 - val_loss: 2.3061\n",
            "Epoch 237/1500\n",
            "876/876 [==============================] - 2s 3ms/step\n",
            "110/110 [==============================] - 5s 47ms/step - loss: 1.2162 - val_loss: 0.7365\n",
            "Epoch 238/1500\n",
            "876/876 [==============================] - 3s 3ms/step\n",
            "110/110 [==============================] - 9s 80ms/step - loss: 1.4786 - val_loss: 1.2174\n",
            "Epoch 239/1500\n",
            "876/876 [==============================] - 2s 3ms/step\n",
            "110/110 [==============================] - 5s 47ms/step - loss: 1.4925 - val_loss: 1.2633\n",
            "Epoch 240/1500\n",
            "876/876 [==============================] - 3s 3ms/step\n",
            "110/110 [==============================] - 8s 71ms/step - loss: 0.8321 - val_loss: 0.9831\n",
            "Epoch 241/1500\n",
            "876/876 [==============================] - 2s 3ms/step\n",
            "110/110 [==============================] - 8s 70ms/step - loss: 0.9552 - val_loss: 0.7733\n",
            "Epoch 242/1500\n",
            "876/876 [==============================] - 3s 3ms/step\n",
            "110/110 [==============================] - 9s 78ms/step - loss: 0.9724 - val_loss: 0.9231\n",
            "Epoch 243/1500\n",
            "876/876 [==============================] - 3s 4ms/step\n",
            "110/110 [==============================] - 8s 71ms/step - loss: 1.6958 - val_loss: 0.8572\n",
            "Epoch 244/1500\n",
            "876/876 [==============================] - 3s 3ms/step\n",
            "110/110 [==============================] - 10s 92ms/step - loss: 1.0614 - val_loss: 0.7608\n",
            "Epoch 245/1500\n",
            "876/876 [==============================] - 2s 3ms/step\n",
            "110/110 [==============================] - 8s 70ms/step - loss: 0.7688 - val_loss: 0.8525\n",
            "Epoch 246/1500\n",
            "876/876 [==============================] - 2s 3ms/step\n",
            "110/110 [==============================] - 7s 66ms/step - loss: 1.1161 - val_loss: 0.8921\n",
            "Epoch 247/1500\n",
            "876/876 [==============================] - 2s 3ms/step\n",
            "110/110 [==============================] - 5s 47ms/step - loss: 1.1296 - val_loss: 1.0843\n",
            "Epoch 248/1500\n",
            "876/876 [==============================] - 3s 4ms/step\n",
            "110/110 [==============================] - 8s 74ms/step - loss: 0.7903 - val_loss: 1.0892\n",
            "Epoch 249/1500\n",
            "876/876 [==============================] - 2s 3ms/step\n",
            "110/110 [==============================] - 5s 47ms/step - loss: 1.5055 - val_loss: 4.6937\n",
            "Epoch 250/1500\n",
            "876/876 [==============================] - 3s 3ms/step\n",
            "110/110 [==============================] - 8s 70ms/step - loss: 1.3637 - val_loss: 3.4522\n",
            "Epoch 251/1500\n",
            "876/876 [==============================] - 2s 3ms/step\n",
            "110/110 [==============================] - 5s 47ms/step - loss: 1.1493 - val_loss: 0.8361\n",
            "Epoch 252/1500\n",
            "876/876 [==============================] - 3s 3ms/step\n",
            "110/110 [==============================] - 5s 49ms/step - loss: 0.8271 - val_loss: 1.6521\n",
            "Epoch 253/1500\n",
            "876/876 [==============================] - 2s 3ms/step\n",
            "110/110 [==============================] - 7s 66ms/step - loss: 1.1800 - val_loss: 1.2347\n",
            "Epoch 254/1500\n",
            "876/876 [==============================] - 2s 3ms/step\n",
            "110/110 [==============================] - 5s 48ms/step - loss: 0.9208 - val_loss: 1.1027\n",
            "Epoch 255/1500\n",
            "876/876 [==============================] - 3s 3ms/step\n",
            "110/110 [==============================] - 8s 72ms/step - loss: 0.9251 - val_loss: 3.9078\n",
            "Epoch 256/1500\n",
            "876/876 [==============================] - 2s 3ms/step\n",
            "110/110 [==============================] - 5s 48ms/step - loss: 1.2847 - val_loss: 1.1330\n",
            "Epoch 257/1500\n",
            "876/876 [==============================] - 3s 3ms/step\n",
            "110/110 [==============================] - 8s 70ms/step - loss: 0.8938 - val_loss: 2.9871\n",
            "Epoch 258/1500\n",
            "876/876 [==============================] - 2s 3ms/step\n",
            "110/110 [==============================] - 5s 48ms/step - loss: 0.8535 - val_loss: 0.7274\n",
            "Epoch 259/1500\n",
            "876/876 [==============================] - 3s 3ms/step\n",
            "110/110 [==============================] - 8s 70ms/step - loss: 0.9981 - val_loss: 1.2992\n",
            "Epoch 260/1500\n",
            "876/876 [==============================] - 2s 3ms/step\n",
            "110/110 [==============================] - 8s 70ms/step - loss: 0.6981 - val_loss: 1.1220\n",
            "Epoch 261/1500\n",
            "876/876 [==============================] - 3s 4ms/step\n",
            "110/110 [==============================] - 7s 65ms/step - loss: 0.9098 - val_loss: 1.2782\n",
            "Epoch 262/1500\n",
            "876/876 [==============================] - 2s 3ms/step\n",
            "110/110 [==============================] - 5s 48ms/step - loss: 1.5760 - val_loss: 0.9004\n",
            "Epoch 263/1500\n",
            "876/876 [==============================] - 3s 3ms/step\n",
            "110/110 [==============================] - 8s 70ms/step - loss: 1.2701 - val_loss: 0.7447\n",
            "Epoch 264/1500\n",
            "876/876 [==============================] - 2s 3ms/step\n",
            "110/110 [==============================] - 5s 48ms/step - loss: 1.3057 - val_loss: 1.3149\n",
            "Epoch 265/1500\n",
            "876/876 [==============================] - 3s 3ms/step\n",
            "110/110 [==============================] - 8s 71ms/step - loss: 0.9210 - val_loss: 0.9548\n",
            "Epoch 266/1500\n",
            "876/876 [==============================] - 2s 3ms/step\n",
            "110/110 [==============================] - 5s 48ms/step - loss: 1.2354 - val_loss: 0.8249\n",
            "Epoch 267/1500\n",
            "876/876 [==============================] - 3s 3ms/step\n",
            "110/110 [==============================] - 8s 70ms/step - loss: 0.7600 - val_loss: 2.9815\n",
            "Epoch 268/1500\n",
            "876/876 [==============================] - 2s 3ms/step\n",
            "110/110 [==============================] - 5s 48ms/step - loss: 0.9028 - val_loss: 1.4782\n",
            "Epoch 269/1500\n",
            "876/876 [==============================] - 2s 3ms/step\n",
            "110/110 [==============================] - 8s 70ms/step - loss: 1.0136 - val_loss: 0.6964\n",
            "Epoch 270/1500\n",
            "876/876 [==============================] - 2s 3ms/step\n",
            "110/110 [==============================] - 5s 48ms/step - loss: 1.3987 - val_loss: 1.3662\n",
            "Epoch 271/1500\n",
            "876/876 [==============================] - 3s 3ms/step\n",
            "110/110 [==============================] - 8s 70ms/step - loss: 0.7418 - val_loss: 1.3859\n",
            "Epoch 272/1500\n",
            "876/876 [==============================] - 2s 3ms/step\n",
            "110/110 [==============================] - 5s 48ms/step - loss: 0.7399 - val_loss: 0.9544\n",
            "Epoch 273/1500\n",
            "876/876 [==============================] - 3s 3ms/step\n",
            "110/110 [==============================] - 8s 70ms/step - loss: 0.8639 - val_loss: 1.1282\n",
            "Epoch 274/1500\n",
            "876/876 [==============================] - 3s 3ms/step\n",
            "110/110 [==============================] - 8s 70ms/step - loss: 0.9763 - val_loss: 1.4694\n",
            "Epoch 275/1500\n",
            "876/876 [==============================] - 3s 4ms/step\n",
            "110/110 [==============================] - 7s 61ms/step - loss: 1.2446 - val_loss: 0.8617\n",
            "Epoch 276/1500\n",
            "876/876 [==============================] - 2s 3ms/step\n",
            "110/110 [==============================] - 8s 73ms/step - loss: 0.8945 - val_loss: 1.6479\n",
            "Epoch 277/1500\n",
            "876/876 [==============================] - 3s 3ms/step\n",
            "110/110 [==============================] - 8s 70ms/step - loss: 0.8545 - val_loss: 0.6521\n",
            "Epoch 278/1500\n",
            "876/876 [==============================] - 2s 3ms/step\n",
            "110/110 [==============================] - 5s 48ms/step - loss: 0.8031 - val_loss: 1.4014\n",
            "Epoch 279/1500\n",
            "876/876 [==============================] - 3s 4ms/step\n",
            "110/110 [==============================] - 9s 87ms/step - loss: 0.9234 - val_loss: 0.8537\n",
            "Epoch 280/1500\n",
            "876/876 [==============================] - 2s 3ms/step\n",
            "110/110 [==============================] - 5s 48ms/step - loss: 0.8393 - val_loss: 0.9315\n",
            "Epoch 281/1500\n",
            "876/876 [==============================] - 3s 3ms/step\n",
            "110/110 [==============================] - 8s 70ms/step - loss: 0.9776 - val_loss: 0.9855\n",
            "Epoch 282/1500\n",
            "876/876 [==============================] - 2s 3ms/step\n",
            "110/110 [==============================] - 5s 48ms/step - loss: 0.8849 - val_loss: 0.8046\n",
            "Epoch 283/1500\n",
            "876/876 [==============================] - 3s 3ms/step\n",
            "110/110 [==============================] - 6s 50ms/step - loss: 1.0674 - val_loss: 0.8819\n",
            "Epoch 284/1500\n",
            "876/876 [==============================] - 2s 3ms/step\n",
            "110/110 [==============================] - 10s 89ms/step - loss: 0.8794 - val_loss: 2.3420\n",
            "Epoch 285/1500\n",
            "876/876 [==============================] - 2s 3ms/step\n",
            "110/110 [==============================] - 5s 50ms/step - loss: 1.3531 - val_loss: 0.9634\n",
            "Epoch 286/1500\n",
            "876/876 [==============================] - 2s 3ms/step\n",
            "110/110 [==============================] - 7s 65ms/step - loss: 0.7312 - val_loss: 0.7686\n",
            "Epoch 287/1500\n",
            "876/876 [==============================] - 2s 3ms/step\n",
            "110/110 [==============================] - 5s 47ms/step - loss: 1.1965 - val_loss: 0.7766\n",
            "Epoch 288/1500\n",
            "876/876 [==============================] - 3s 4ms/step\n",
            "110/110 [==============================] - 8s 76ms/step - loss: 0.7585 - val_loss: 0.6511\n",
            "Epoch 289/1500\n",
            "876/876 [==============================] - 2s 3ms/step\n",
            "110/110 [==============================] - 5s 48ms/step - loss: 0.9617 - val_loss: 0.7989\n",
            "Epoch 290/1500\n",
            "876/876 [==============================] - 3s 3ms/step\n",
            "110/110 [==============================] - 6s 54ms/step - loss: 0.9429 - val_loss: 0.6964\n",
            "Epoch 291/1500\n",
            "876/876 [==============================] - 2s 3ms/step\n",
            "110/110 [==============================] - 9s 83ms/step - loss: 2.0345 - val_loss: 0.8177\n",
            "Epoch 292/1500\n",
            "876/876 [==============================] - 3s 3ms/step\n",
            "110/110 [==============================] - 8s 71ms/step - loss: 0.8742 - val_loss: 0.8871\n",
            "Epoch 293/1500\n",
            "876/876 [==============================] - 2s 3ms/step\n",
            "110/110 [==============================] - 8s 70ms/step - loss: 0.6943 - val_loss: 0.7006\n",
            "Epoch 294/1500\n",
            "876/876 [==============================] - 3s 4ms/step\n",
            "110/110 [==============================] - 7s 62ms/step - loss: 1.3630 - val_loss: 1.3907\n",
            "Epoch 295/1500\n",
            "876/876 [==============================] - 2s 3ms/step\n",
            "110/110 [==============================] - 8s 72ms/step - loss: 0.9818 - val_loss: 1.4034\n",
            "Epoch 296/1500\n",
            "876/876 [==============================] - 3s 3ms/step\n",
            "110/110 [==============================] - 6s 56ms/step - loss: 1.0629 - val_loss: 0.8716\n",
            "Epoch 297/1500\n",
            "876/876 [==============================] - 2s 3ms/step\n",
            "110/110 [==============================] - 6s 58ms/step - loss: 0.7584 - val_loss: 1.1787\n",
            "Epoch 298/1500\n",
            "876/876 [==============================] - 2s 3ms/step\n",
            "110/110 [==============================] - 5s 48ms/step - loss: 1.0854 - val_loss: 0.7588\n",
            "Epoch 299/1500\n",
            "876/876 [==============================] - 3s 3ms/step\n",
            "110/110 [==============================] - 9s 83ms/step - loss: 0.8976 - val_loss: 1.2648\n",
            "Epoch 300/1500\n",
            "876/876 [==============================] - 2s 3ms/step\n",
            "110/110 [==============================] - 5s 48ms/step - loss: 1.3613 - val_loss: 1.7489\n",
            "Epoch 301/1500\n",
            "876/876 [==============================] - 3s 3ms/step\n",
            "110/110 [==============================] - 6s 56ms/step - loss: 1.8567 - val_loss: 1.3546\n",
            "Epoch 302/1500\n",
            "876/876 [==============================] - 2s 3ms/step\n",
            "110/110 [==============================] - 6s 57ms/step - loss: 0.7348 - val_loss: 0.6638\n",
            "Epoch 303/1500\n",
            "876/876 [==============================] - 3s 4ms/step\n",
            "110/110 [==============================] - 8s 71ms/step - loss: 0.6428 - val_loss: 0.7794\n",
            "Epoch 304/1500\n",
            "876/876 [==============================] - 2s 3ms/step\n",
            "110/110 [==============================] - 7s 65ms/step - loss: 0.7175 - val_loss: 0.8236\n",
            "Epoch 305/1500\n",
            "876/876 [==============================] - 2s 3ms/step\n",
            "110/110 [==============================] - 8s 71ms/step - loss: 1.2058 - val_loss: 1.1944\n",
            "Epoch 306/1500\n",
            "876/876 [==============================] - 2s 3ms/step\n",
            "110/110 [==============================] - 7s 63ms/step - loss: 0.6108 - val_loss: 2.2475\n",
            "Epoch 307/1500\n",
            "876/876 [==============================] - 2s 3ms/step\n",
            "110/110 [==============================] - 8s 70ms/step - loss: 1.1873 - val_loss: 0.9325\n",
            "Epoch 308/1500\n",
            "876/876 [==============================] - 2s 3ms/step\n",
            "110/110 [==============================] - 10s 87ms/step - loss: 0.8875 - val_loss: 0.7906\n",
            "Epoch 309/1500\n",
            "876/876 [==============================] - 3s 3ms/step\n",
            "110/110 [==============================] - 8s 71ms/step - loss: 1.5298 - val_loss: 1.0472\n",
            "Epoch 310/1500\n",
            "876/876 [==============================] - 2s 3ms/step\n",
            "110/110 [==============================] - 5s 48ms/step - loss: 1.0162 - val_loss: 2.1031\n",
            "Epoch 311/1500\n",
            "876/876 [==============================] - 3s 3ms/step\n",
            "110/110 [==============================] - 6s 51ms/step - loss: 1.0765 - val_loss: 0.7622\n",
            "Epoch 312/1500\n",
            "876/876 [==============================] - 3s 3ms/step\n",
            "110/110 [==============================] - 10s 89ms/step - loss: 0.7490 - val_loss: 0.8628\n",
            "Epoch 313/1500\n",
            "876/876 [==============================] - 2s 3ms/step\n",
            "110/110 [==============================] - 5s 48ms/step - loss: 0.8150 - val_loss: 1.1778\n",
            "Epoch 314/1500\n",
            "876/876 [==============================] - 3s 3ms/step\n",
            "110/110 [==============================] - 8s 69ms/step - loss: 0.7727 - val_loss: 2.3680\n",
            "Epoch 315/1500\n",
            "876/876 [==============================] - 2s 3ms/step\n",
            "110/110 [==============================] - 5s 47ms/step - loss: 0.7940 - val_loss: 0.7895\n",
            "Epoch 316/1500\n",
            "876/876 [==============================] - 3s 3ms/step\n",
            "110/110 [==============================] - 6s 54ms/step - loss: 0.9726 - val_loss: 1.2871\n",
            "Epoch 317/1500\n",
            "876/876 [==============================] - 2s 3ms/step\n",
            "110/110 [==============================] - 9s 79ms/step - loss: 0.6886 - val_loss: 1.1983\n",
            "Epoch 318/1500\n",
            "876/876 [==============================] - 3s 3ms/step\n",
            "110/110 [==============================] - 8s 70ms/step - loss: 0.7998 - val_loss: 1.0395\n",
            "Epoch 319/1500\n",
            "876/876 [==============================] - 2s 3ms/step\n",
            "110/110 [==============================] - 5s 48ms/step - loss: 1.8219 - val_loss: 0.7452\n",
            "Epoch 320/1500\n",
            "876/876 [==============================] - 3s 3ms/step\n",
            "110/110 [==============================] - 6s 51ms/step - loss: 0.7891 - val_loss: 1.0163\n",
            "Epoch 321/1500\n",
            "876/876 [==============================] - 2s 3ms/step\n",
            "110/110 [==============================] - 7s 66ms/step - loss: 0.8495 - val_loss: 0.6505\n",
            "Epoch 322/1500\n",
            "876/876 [==============================] - 2s 3ms/step\n",
            "110/110 [==============================] - 8s 70ms/step - loss: 0.6709 - val_loss: 0.6634\n",
            "Epoch 323/1500\n",
            "876/876 [==============================] - 2s 3ms/step\n",
            "110/110 [==============================] - 10s 91ms/step - loss: 0.8650 - val_loss: 2.0760\n",
            "Epoch 324/1500\n",
            "876/876 [==============================] - 2s 3ms/step\n",
            "110/110 [==============================] - 8s 70ms/step - loss: 0.9916 - val_loss: 1.2653\n",
            "Epoch 325/1500\n",
            "876/876 [==============================] - 2s 3ms/step\n",
            "110/110 [==============================] - 8s 70ms/step - loss: 1.0161 - val_loss: 1.2599\n",
            "Epoch 326/1500\n",
            "876/876 [==============================] - 3s 4ms/step\n",
            "110/110 [==============================] - 8s 75ms/step - loss: 0.8179 - val_loss: 1.1865\n",
            "Epoch 327/1500\n",
            "876/876 [==============================] - 2s 3ms/step\n",
            "110/110 [==============================] - 5s 47ms/step - loss: 1.1450 - val_loss: 1.0132\n",
            "Epoch 328/1500\n",
            "876/876 [==============================] - 3s 3ms/step\n",
            "110/110 [==============================] - 8s 70ms/step - loss: 1.0262 - val_loss: 0.9695\n",
            "Epoch 329/1500\n",
            "876/876 [==============================] - 2s 3ms/step\n",
            "110/110 [==============================] - 5s 47ms/step - loss: 0.7977 - val_loss: 1.4323\n",
            "Epoch 330/1500\n",
            "876/876 [==============================] - 3s 3ms/step\n",
            "110/110 [==============================] - 6s 52ms/step - loss: 0.7995 - val_loss: 2.7057\n",
            "Epoch 331/1500\n",
            "876/876 [==============================] - 3s 4ms/step\n",
            "110/110 [==============================] - 10s 93ms/step - loss: 1.3658 - val_loss: 0.7398\n",
            "Epoch 332/1500\n",
            "876/876 [==============================] - 2s 3ms/step\n",
            "110/110 [==============================] - 5s 48ms/step - loss: 0.9518 - val_loss: 1.0259\n",
            "Epoch 333/1500\n",
            "876/876 [==============================] - 3s 3ms/step\n",
            "110/110 [==============================] - 8s 71ms/step - loss: 1.2154 - val_loss: 2.9923\n",
            "Epoch 334/1500\n",
            "876/876 [==============================] - 2s 3ms/step\n",
            "110/110 [==============================] - 5s 48ms/step - loss: 0.8141 - val_loss: 0.6848\n",
            "Epoch 335/1500\n",
            "876/876 [==============================] - 3s 3ms/step\n",
            "110/110 [==============================] - 6s 51ms/step - loss: 0.9266 - val_loss: 1.0990\n",
            "Epoch 336/1500\n",
            "876/876 [==============================] - 2s 3ms/step\n",
            "110/110 [==============================] - 7s 64ms/step - loss: 0.8829 - val_loss: 1.1671\n",
            "Epoch 337/1500\n",
            "876/876 [==============================] - 2s 3ms/step\n",
            "110/110 [==============================] - 5s 48ms/step - loss: 0.7952 - val_loss: 0.7499\n",
            "Epoch 338/1500\n",
            "876/876 [==============================] - 3s 3ms/step\n",
            "110/110 [==============================] - 8s 76ms/step - loss: 0.7650 - val_loss: 0.6658\n",
            "Epoch 339/1500\n",
            "876/876 [==============================] - 2s 3ms/step\n",
            "110/110 [==============================] - 5s 48ms/step - loss: 0.9213 - val_loss: 1.4146\n",
            "Epoch 340/1500\n",
            "876/876 [==============================] - 3s 3ms/step\n",
            "110/110 [==============================] - 6s 53ms/step - loss: 1.6813 - val_loss: 0.7322\n",
            "Epoch 341/1500\n",
            "876/876 [==============================] - 2s 3ms/step\n",
            "110/110 [==============================] - 7s 61ms/step - loss: 0.8608 - val_loss: 1.5199\n",
            "Epoch 342/1500\n",
            "876/876 [==============================] - 2s 3ms/step\n",
            "110/110 [==============================] - 5s 48ms/step - loss: 0.7666 - val_loss: 1.3809\n",
            "Epoch 343/1500\n",
            "876/876 [==============================] - 3s 3ms/step\n",
            "110/110 [==============================] - 7s 63ms/step - loss: 1.0232 - val_loss: 1.1258\n",
            "Epoch 344/1500\n",
            "876/876 [==============================] - 2s 3ms/step\n",
            "110/110 [==============================] - 5s 50ms/step - loss: 0.9815 - val_loss: 0.7348\n",
            "Epoch 345/1500\n",
            "876/876 [==============================] - 2s 3ms/step\n",
            "110/110 [==============================] - 8s 71ms/step - loss: 1.0668 - val_loss: 1.3595\n",
            "Epoch 346/1500\n",
            "876/876 [==============================] - 2s 3ms/step\n",
            "110/110 [==============================] - 5s 48ms/step - loss: 1.2966 - val_loss: 0.8910\n",
            "Epoch 347/1500\n",
            "876/876 [==============================] - 3s 4ms/step\n",
            "110/110 [==============================] - 9s 81ms/step - loss: 1.1671 - val_loss: 1.0370\n",
            "Epoch 348/1500\n",
            "876/876 [==============================] - 2s 3ms/step\n",
            "110/110 [==============================] - 6s 56ms/step - loss: 0.9051 - val_loss: 1.7087\n",
            "Epoch 349/1500\n",
            "876/876 [==============================] - 2s 3ms/step\n",
            "110/110 [==============================] - 5s 48ms/step - loss: 1.0999 - val_loss: 0.6515\n",
            "Epoch 350/1500\n",
            "876/876 [==============================] - 3s 3ms/step\n",
            "110/110 [==============================] - 9s 84ms/step - loss: 0.5903 - val_loss: 1.3273\n",
            "Epoch 351/1500\n",
            "876/876 [==============================] - 2s 3ms/step\n",
            "110/110 [==============================] - 5s 48ms/step - loss: 0.7623 - val_loss: 0.7000\n",
            "Epoch 352/1500\n",
            "876/876 [==============================] - 3s 3ms/step\n",
            "110/110 [==============================] - 7s 60ms/step - loss: 0.7078 - val_loss: 0.7094\n",
            "Epoch 353/1500\n",
            "876/876 [==============================] - 2s 3ms/step\n",
            "110/110 [==============================] - 6s 51ms/step - loss: 1.8049 - val_loss: 2.1683\n",
            "Epoch 354/1500\n",
            "876/876 [==============================] - 2s 3ms/step\n",
            "110/110 [==============================] - 8s 71ms/step - loss: 0.9940 - val_loss: 1.0929\n",
            "Epoch 355/1500\n",
            "876/876 [==============================] - 2s 3ms/step\n",
            "110/110 [==============================] - 5s 48ms/step - loss: 0.6836 - val_loss: 0.7621\n",
            "Epoch 356/1500\n",
            "876/876 [==============================] - 2s 3ms/step\n",
            "110/110 [==============================] - 5s 50ms/step - loss: 0.8379 - val_loss: 0.9940\n",
            "Epoch 357/1500\n",
            "876/876 [==============================] - 2s 3ms/step\n",
            "110/110 [==============================] - 10s 89ms/step - loss: 0.7476 - val_loss: 0.9570\n",
            "Epoch 358/1500\n",
            "876/876 [==============================] - 2s 3ms/step\n",
            "110/110 [==============================] - 8s 70ms/step - loss: 0.6861 - val_loss: 0.8200\n",
            "Epoch 359/1500\n",
            "876/876 [==============================] - 2s 3ms/step\n",
            "110/110 [==============================] - 5s 48ms/step - loss: 1.7338 - val_loss: 0.8696\n",
            "Epoch 360/1500\n",
            "876/876 [==============================] - 3s 4ms/step\n",
            "110/110 [==============================] - 8s 78ms/step - loss: 0.6180 - val_loss: 0.8386\n",
            "Epoch 361/1500\n",
            "876/876 [==============================] - 2s 3ms/step\n",
            "110/110 [==============================] - 6s 59ms/step - loss: 0.8354 - val_loss: 1.0185\n",
            "Epoch 362/1500\n",
            "876/876 [==============================] - 2s 3ms/step\n",
            "110/110 [==============================] - 5s 48ms/step - loss: 0.6887 - val_loss: 1.3014\n",
            "Epoch 363/1500\n",
            "876/876 [==============================] - 3s 4ms/step\n",
            "110/110 [==============================] - 7s 66ms/step - loss: 1.1352 - val_loss: 0.8997\n",
            "Epoch 364/1500\n",
            "876/876 [==============================] - 2s 3ms/step\n",
            "110/110 [==============================] - 5s 48ms/step - loss: 0.8321 - val_loss: 0.6785\n",
            "Epoch 365/1500\n",
            "876/876 [==============================] - 3s 3ms/step\n",
            "110/110 [==============================] - 6s 52ms/step - loss: 0.8200 - val_loss: 0.8398\n",
            "Epoch 366/1500\n",
            "876/876 [==============================] - 2s 3ms/step\n",
            "110/110 [==============================] - 7s 65ms/step - loss: 0.8978 - val_loss: 0.9028\n",
            "Epoch 367/1500\n",
            "876/876 [==============================] - 2s 3ms/step\n",
            "110/110 [==============================] - 5s 48ms/step - loss: 0.7777 - val_loss: 1.5287\n",
            "Epoch 368/1500\n",
            "876/876 [==============================] - 3s 3ms/step\n",
            "110/110 [==============================] - 7s 61ms/step - loss: 0.9069 - val_loss: 1.1798\n",
            "Epoch 369/1500\n",
            "876/876 [==============================] - 2s 3ms/step\n",
            "110/110 [==============================] - 6s 52ms/step - loss: 0.9574 - val_loss: 0.6072\n",
            "Epoch 370/1500\n",
            "876/876 [==============================] - 2s 3ms/step\n",
            "110/110 [==============================] - 8s 70ms/step - loss: 0.6508 - val_loss: 1.3009\n",
            "Epoch 371/1500\n",
            "876/876 [==============================] - 2s 3ms/step\n",
            "110/110 [==============================] - 5s 48ms/step - loss: 1.2472 - val_loss: 0.9695\n",
            "Epoch 372/1500\n",
            "876/876 [==============================] - 3s 3ms/step\n",
            "110/110 [==============================] - 8s 72ms/step - loss: 0.7740 - val_loss: 0.6863\n",
            "Epoch 373/1500\n",
            "876/876 [==============================] - 2s 3ms/step\n",
            "110/110 [==============================] - 5s 47ms/step - loss: 1.0338 - val_loss: 0.7108\n",
            "Epoch 374/1500\n",
            "876/876 [==============================] - 2s 3ms/step\n",
            "110/110 [==============================] - 5s 49ms/step - loss: 0.9655 - val_loss: 0.7116\n",
            "Epoch 375/1500\n",
            "876/876 [==============================] - 3s 3ms/step\n",
            "110/110 [==============================] - 7s 67ms/step - loss: 0.7380 - val_loss: 0.5912\n",
            "Epoch 376/1500\n",
            "876/876 [==============================] - 2s 3ms/step\n",
            "110/110 [==============================] - 5s 48ms/step - loss: 0.7443 - val_loss: 0.7487\n",
            "Epoch 377/1500\n",
            "876/876 [==============================] - 3s 3ms/step\n",
            "110/110 [==============================] - 8s 72ms/step - loss: 1.8127 - val_loss: 0.9781\n",
            "Epoch 378/1500\n",
            "876/876 [==============================] - 2s 3ms/step\n",
            "110/110 [==============================] - 8s 70ms/step - loss: 0.6498 - val_loss: 1.0244\n",
            "Epoch 379/1500\n",
            "876/876 [==============================] - 3s 3ms/step\n",
            "110/110 [==============================] - 7s 63ms/step - loss: 0.6950 - val_loss: 2.4817\n",
            "Epoch 380/1500\n",
            "876/876 [==============================] - 2s 3ms/step\n",
            "110/110 [==============================] - 5s 49ms/step - loss: 1.0058 - val_loss: 0.9730\n",
            "Epoch 381/1500\n",
            "876/876 [==============================] - 2s 3ms/step\n",
            "110/110 [==============================] - 5s 49ms/step - loss: 1.1580 - val_loss: 1.0493\n",
            "Epoch 382/1500\n",
            "876/876 [==============================] - 3s 4ms/step\n",
            "110/110 [==============================] - 10s 91ms/step - loss: 0.7022 - val_loss: 0.7433\n",
            "Epoch 383/1500\n",
            "876/876 [==============================] - 2s 3ms/step\n",
            "110/110 [==============================] - 5s 47ms/step - loss: 0.6691 - val_loss: 1.7423\n",
            "Epoch 384/1500\n",
            "876/876 [==============================] - 3s 3ms/step\n",
            "110/110 [==============================] - 6s 54ms/step - loss: 0.8299 - val_loss: 0.7523\n",
            "Epoch 385/1500\n",
            "876/876 [==============================] - 2s 3ms/step\n",
            "110/110 [==============================] - 7s 61ms/step - loss: 0.6763 - val_loss: 0.5904\n",
            "Epoch 386/1500\n",
            "876/876 [==============================] - 2s 3ms/step\n",
            "110/110 [==============================] - 5s 48ms/step - loss: 1.2901 - val_loss: 1.4837\n",
            "Epoch 387/1500\n",
            "876/876 [==============================] - 3s 3ms/step\n",
            "110/110 [==============================] - 7s 64ms/step - loss: 0.8034 - val_loss: 1.9291\n",
            "Epoch 388/1500\n",
            "876/876 [==============================] - 2s 3ms/step\n",
            "110/110 [==============================] - 5s 48ms/step - loss: 0.9395 - val_loss: 1.0941\n",
            "Epoch 389/1500\n",
            "876/876 [==============================] - 2s 3ms/step\n",
            "110/110 [==============================] - 5s 49ms/step - loss: 0.7758 - val_loss: 0.9255\n",
            "Epoch 390/1500\n",
            "876/876 [==============================] - 3s 3ms/step\n",
            "110/110 [==============================] - 8s 71ms/step - loss: 0.8988 - val_loss: 3.0456\n",
            "Epoch 391/1500\n",
            "876/876 [==============================] - 2s 3ms/step\n",
            "110/110 [==============================] - 7s 65ms/step - loss: 1.5142 - val_loss: 1.9821\n",
            "Epoch 392/1500\n",
            "876/876 [==============================] - 3s 3ms/step\n",
            "110/110 [==============================] - 7s 69ms/step - loss: 0.6899 - val_loss: 0.6553\n",
            "Epoch 393/1500\n",
            "876/876 [==============================] - 2s 3ms/step\n",
            "110/110 [==============================] - 5s 47ms/step - loss: 1.0924 - val_loss: 0.7155\n",
            "Epoch 394/1500\n",
            "876/876 [==============================] - 3s 3ms/step\n",
            "110/110 [==============================] - 6s 51ms/step - loss: 0.6965 - val_loss: 1.2956\n",
            "Epoch 395/1500\n",
            "876/876 [==============================] - 2s 3ms/step\n",
            "110/110 [==============================] - 7s 64ms/step - loss: 0.8864 - val_loss: 0.6638\n",
            "Epoch 396/1500\n",
            "876/876 [==============================] - 2s 3ms/step\n",
            "110/110 [==============================] - 8s 71ms/step - loss: 0.9323 - val_loss: 1.2472\n",
            "Epoch 397/1500\n",
            "876/876 [==============================] - 2s 3ms/step\n",
            "110/110 [==============================] - 7s 67ms/step - loss: 0.5865 - val_loss: 1.4433\n",
            "Epoch 398/1500\n",
            "876/876 [==============================] - 2s 3ms/step\n",
            "110/110 [==============================] - 5s 48ms/step - loss: 1.4215 - val_loss: 0.9922\n",
            "Epoch 399/1500\n",
            "876/876 [==============================] - 3s 4ms/step\n",
            "110/110 [==============================] - 7s 64ms/step - loss: 0.6920 - val_loss: 1.0640\n",
            "Epoch 400/1500\n",
            "876/876 [==============================] - 2s 3ms/step\n",
            "110/110 [==============================] - 6s 51ms/step - loss: 1.6757 - val_loss: 0.8254\n",
            "Epoch 401/1500\n",
            "876/876 [==============================] - 2s 3ms/step\n",
            "110/110 [==============================] - 5s 49ms/step - loss: 0.5948 - val_loss: 1.1178\n",
            "Epoch 402/1500\n",
            "876/876 [==============================] - 3s 3ms/step\n",
            "110/110 [==============================] - 8s 70ms/step - loss: 0.6060 - val_loss: 0.9212\n",
            "Epoch 403/1500\n",
            "876/876 [==============================] - 2s 3ms/step\n",
            "110/110 [==============================] - 5s 48ms/step - loss: 0.6436 - val_loss: 1.2738\n",
            "Epoch 404/1500\n",
            "876/876 [==============================] - 3s 3ms/step\n",
            "110/110 [==============================] - 6s 56ms/step - loss: 0.6905 - val_loss: 0.7085\n",
            "Epoch 405/1500\n",
            "876/876 [==============================] - 2s 3ms/step\n",
            "110/110 [==============================] - 6s 58ms/step - loss: 1.4768 - val_loss: 0.9245\n",
            "Epoch 406/1500\n",
            "876/876 [==============================] - 2s 3ms/step\n",
            "110/110 [==============================] - 8s 70ms/step - loss: 0.7268 - val_loss: 0.5971\n",
            "Epoch 407/1500\n",
            "876/876 [==============================] - 2s 3ms/step\n",
            "110/110 [==============================] - 6s 57ms/step - loss: 1.1516 - val_loss: 0.6693\n",
            "Epoch 408/1500\n",
            "876/876 [==============================] - 2s 3ms/step\n",
            "110/110 [==============================] - 5s 48ms/step - loss: 0.8755 - val_loss: 0.7451\n",
            "Epoch 409/1500\n",
            "876/876 [==============================] - 3s 3ms/step\n",
            "110/110 [==============================] - 9s 81ms/step - loss: 0.7074 - val_loss: 0.6793\n",
            "Epoch 410/1500\n",
            "876/876 [==============================] - 2s 3ms/step\n",
            "110/110 [==============================] - 5s 48ms/step - loss: 0.8103 - val_loss: 1.2068\n",
            "Epoch 411/1500\n",
            "876/876 [==============================] - 3s 3ms/step\n",
            "110/110 [==============================] - 8s 70ms/step - loss: 0.8407 - val_loss: 1.4188\n",
            "Epoch 412/1500\n",
            "876/876 [==============================] - 2s 3ms/step\n",
            "110/110 [==============================] - 5s 48ms/step - loss: 1.0363 - val_loss: 1.3507\n",
            "Epoch 413/1500\n",
            "876/876 [==============================] - 3s 3ms/step\n",
            "110/110 [==============================] - 6s 51ms/step - loss: 0.8360 - val_loss: 0.6698\n",
            "Epoch 414/1500\n",
            "876/876 [==============================] - 2s 3ms/step\n",
            "110/110 [==============================] - 7s 65ms/step - loss: 0.6887 - val_loss: 2.1203\n",
            "Epoch 415/1500\n",
            "876/876 [==============================] - 2s 3ms/step\n",
            "110/110 [==============================] - 8s 71ms/step - loss: 0.8284 - val_loss: 0.6593\n",
            "Epoch 416/1500\n",
            "876/876 [==============================] - 3s 3ms/step\n",
            "110/110 [==============================] - 10s 91ms/step - loss: 0.6769 - val_loss: 0.6492\n",
            "Epoch 417/1500\n",
            "876/876 [==============================] - 2s 3ms/step\n",
            "110/110 [==============================] - 8s 70ms/step - loss: 0.8005 - val_loss: 0.7729\n",
            "Epoch 418/1500\n",
            "876/876 [==============================] - 2s 3ms/step\n",
            "110/110 [==============================] - 8s 71ms/step - loss: 0.9221 - val_loss: 0.9243\n",
            "Epoch 419/1500\n",
            "876/876 [==============================] - 3s 4ms/step\n",
            "110/110 [==============================] - 8s 77ms/step - loss: 1.0618 - val_loss: 0.7476\n",
            "Epoch 420/1500\n",
            "876/876 [==============================] - 2s 3ms/step\n",
            "110/110 [==============================] - 9s 80ms/step - loss: 0.9289 - val_loss: 2.5866\n",
            "Epoch 421/1500\n",
            "876/876 [==============================] - 3s 4ms/step\n",
            "110/110 [==============================] - 8s 74ms/step - loss: 0.7855 - val_loss: 2.4193\n",
            "Epoch 422/1500\n",
            "876/876 [==============================] - 2s 3ms/step\n",
            "110/110 [==============================] - 5s 48ms/step - loss: 0.7451 - val_loss: 0.7898\n",
            "Epoch 423/1500\n",
            "876/876 [==============================] - 3s 3ms/step\n",
            "110/110 [==============================] - 8s 71ms/step - loss: 0.7055 - val_loss: 0.6561\n",
            "Epoch 424/1500\n",
            "876/876 [==============================] - 2s 3ms/step\n",
            "110/110 [==============================] - 5s 48ms/step - loss: 0.8985 - val_loss: 1.2471\n",
            "Epoch 425/1500\n",
            "876/876 [==============================] - 2s 3ms/step\n",
            "110/110 [==============================] - 8s 70ms/step - loss: 0.7548 - val_loss: 0.5862\n",
            "Epoch 426/1500\n",
            "876/876 [==============================] - 2s 3ms/step\n",
            "110/110 [==============================] - 8s 70ms/step - loss: 1.1082 - val_loss: 0.9553\n",
            "Epoch 427/1500\n",
            "876/876 [==============================] - 3s 4ms/step\n",
            "110/110 [==============================] - 7s 60ms/step - loss: 0.9194 - val_loss: 1.2601\n",
            "Epoch 428/1500\n",
            "876/876 [==============================] - 2s 3ms/step\n",
            "110/110 [==============================] - 6s 54ms/step - loss: 0.7609 - val_loss: 0.9927\n",
            "Epoch 429/1500\n",
            "876/876 [==============================] - 2s 3ms/step\n",
            "110/110 [==============================] - 8s 70ms/step - loss: 0.8564 - val_loss: 0.5987\n",
            "Epoch 430/1500\n",
            "876/876 [==============================] - 2s 3ms/step\n",
            "110/110 [==============================] - 6s 52ms/step - loss: 0.6025 - val_loss: 0.7453\n",
            "Epoch 431/1500\n",
            "876/876 [==============================] - 2s 3ms/step\n",
            "110/110 [==============================] - 5s 50ms/step - loss: 0.7456 - val_loss: 1.4765\n",
            "Epoch 432/1500\n",
            "876/876 [==============================] - 3s 3ms/step\n",
            "110/110 [==============================] - 8s 69ms/step - loss: 1.4867 - val_loss: 0.8424\n",
            "Epoch 433/1500\n",
            "876/876 [==============================] - 2s 3ms/step\n",
            "110/110 [==============================] - 8s 70ms/step - loss: 0.6384 - val_loss: 1.0484\n",
            "Epoch 434/1500\n",
            "876/876 [==============================] - 3s 3ms/step\n",
            "110/110 [==============================] - 9s 86ms/step - loss: 0.8479 - val_loss: 0.8773\n",
            "Epoch 435/1500\n",
            "876/876 [==============================] - 2s 3ms/step\n",
            "110/110 [==============================] - 5s 48ms/step - loss: 0.6453 - val_loss: 0.6881\n",
            "Epoch 436/1500\n",
            "876/876 [==============================] - 3s 4ms/step\n",
            "110/110 [==============================] - 7s 64ms/step - loss: 0.7678 - val_loss: 0.6854\n",
            "Epoch 437/1500\n",
            "876/876 [==============================] - 2s 3ms/step\n",
            "110/110 [==============================] - 8s 73ms/step - loss: 0.8804 - val_loss: 1.6898\n",
            "Epoch 438/1500\n",
            "876/876 [==============================] - 3s 3ms/step\n",
            "110/110 [==============================] - 8s 71ms/step - loss: 0.7234 - val_loss: 0.9786\n",
            "Epoch 439/1500\n",
            "876/876 [==============================] - 2s 3ms/step\n",
            "110/110 [==============================] - 5s 48ms/step - loss: 1.5340 - val_loss: 0.8250\n",
            "Epoch 440/1500\n",
            "876/876 [==============================] - 3s 3ms/step\n",
            "110/110 [==============================] - 8s 71ms/step - loss: 0.9234 - val_loss: 0.7198\n",
            "Epoch 441/1500\n",
            "876/876 [==============================] - 2s 3ms/step\n",
            "110/110 [==============================] - 5s 48ms/step - loss: 0.8902 - val_loss: 3.0087\n",
            "Epoch 442/1500\n",
            "876/876 [==============================] - 3s 3ms/step\n",
            "110/110 [==============================] - 8s 71ms/step - loss: 0.7807 - val_loss: 2.0915\n",
            "Epoch 443/1500\n",
            "876/876 [==============================] - 2s 3ms/step\n",
            "110/110 [==============================] - 5s 48ms/step - loss: 0.9131 - val_loss: 1.1141\n",
            "Epoch 444/1500\n",
            "876/876 [==============================] - 3s 3ms/step\n",
            "110/110 [==============================] - 6s 52ms/step - loss: 0.6002 - val_loss: 0.6731\n",
            "Epoch 445/1500\n",
            "876/876 [==============================] - 2s 3ms/step\n",
            "110/110 [==============================] - 10s 88ms/step - loss: 0.9554 - val_loss: 0.8429\n",
            "Epoch 446/1500\n",
            "876/876 [==============================] - 2s 3ms/step\n",
            "110/110 [==============================] - 5s 50ms/step - loss: 0.7538 - val_loss: 0.9653\n",
            "Epoch 447/1500\n",
            "876/876 [==============================] - 3s 4ms/step\n",
            "110/110 [==============================] - 10s 92ms/step - loss: 0.8784 - val_loss: 0.9130\n",
            "Epoch 448/1500\n",
            "876/876 [==============================] - 3s 3ms/step\n",
            "110/110 [==============================] - 6s 56ms/step - loss: 0.8117 - val_loss: 0.7253\n",
            "Epoch 449/1500\n",
            "876/876 [==============================] - 3s 4ms/step\n",
            "110/110 [==============================] - 10s 93ms/step - loss: 0.7273 - val_loss: 2.0927\n",
            "Epoch 450/1500\n",
            "876/876 [==============================] - 2s 3ms/step\n",
            "110/110 [==============================] - 5s 48ms/step - loss: 0.8669 - val_loss: 0.7394\n",
            "Epoch 451/1500\n",
            "876/876 [==============================] - 3s 3ms/step\n",
            "110/110 [==============================] - 6s 55ms/step - loss: 0.7399 - val_loss: 1.3243\n",
            "Epoch 452/1500\n",
            "876/876 [==============================] - 2s 3ms/step\n",
            "110/110 [==============================] - 9s 85ms/step - loss: 0.7539 - val_loss: 0.6622\n",
            "Epoch 453/1500\n",
            "876/876 [==============================] - 3s 3ms/step\n",
            "110/110 [==============================] - 8s 70ms/step - loss: 1.3488 - val_loss: 0.9566\n",
            "Epoch 454/1500\n",
            "876/876 [==============================] - 2s 3ms/step\n",
            "110/110 [==============================] - 5s 48ms/step - loss: 0.9246 - val_loss: 1.8458\n",
            "Epoch 455/1500\n",
            "876/876 [==============================] - 3s 3ms/step\n",
            "110/110 [==============================] - 5s 50ms/step - loss: 1.1024 - val_loss: 2.5138\n",
            "Epoch 456/1500\n",
            "876/876 [==============================] - 2s 3ms/step\n",
            "110/110 [==============================] - 10s 88ms/step - loss: 0.9824 - val_loss: 0.8656\n",
            "Epoch 457/1500\n",
            "876/876 [==============================] - 2s 3ms/step\n",
            "110/110 [==============================] - 6s 50ms/step - loss: 0.5755 - val_loss: 0.8231\n",
            "Epoch 458/1500\n",
            "876/876 [==============================] - 2s 3ms/step\n",
            "110/110 [==============================] - 10s 88ms/step - loss: 0.5777 - val_loss: 0.7768\n",
            "Epoch 459/1500\n",
            "876/876 [==============================] - 2s 3ms/step\n",
            "110/110 [==============================] - 5s 49ms/step - loss: 0.9370 - val_loss: 1.2419\n",
            "Epoch 460/1500\n",
            "876/876 [==============================] - 3s 3ms/step\n",
            "110/110 [==============================] - 10s 87ms/step - loss: 1.0305 - val_loss: 0.9191\n",
            "Epoch 461/1500\n",
            "876/876 [==============================] - 2s 3ms/step\n",
            "110/110 [==============================] - 5s 47ms/step - loss: 0.7372 - val_loss: 0.7243\n",
            "Epoch 462/1500\n",
            "876/876 [==============================] - 3s 4ms/step\n",
            "110/110 [==============================] - 7s 67ms/step - loss: 0.8614 - val_loss: 0.8637\n",
            "Epoch 463/1500\n",
            "876/876 [==============================] - 2s 3ms/step\n",
            "110/110 [==============================] - 5s 48ms/step - loss: 0.7605 - val_loss: 0.9714\n",
            "Epoch 464/1500\n",
            "876/876 [==============================] - 2s 3ms/step\n",
            "110/110 [==============================] - 6s 50ms/step - loss: 0.5107 - val_loss: 1.6916\n",
            "Epoch 465/1500\n",
            "876/876 [==============================] - 2s 3ms/step\n",
            "110/110 [==============================] - 7s 67ms/step - loss: 0.8171 - val_loss: 0.6650\n",
            "Epoch 466/1500\n",
            "876/876 [==============================] - 2s 3ms/step\n",
            "110/110 [==============================] - 8s 70ms/step - loss: 0.6045 - val_loss: 0.6161\n",
            "Epoch 467/1500\n",
            "876/876 [==============================] - 3s 3ms/step\n",
            "110/110 [==============================] - 7s 68ms/step - loss: 1.2171 - val_loss: 1.7486\n",
            "Epoch 468/1500\n",
            "876/876 [==============================] - 2s 3ms/step\n",
            "110/110 [==============================] - 5s 48ms/step - loss: 0.9665 - val_loss: 0.7457\n",
            "Epoch 469/1500\n",
            "876/876 [==============================] - 3s 3ms/step\n",
            "110/110 [==============================] - 8s 75ms/step - loss: 0.8528 - val_loss: 0.7857\n",
            "Epoch 470/1500\n",
            "876/876 [==============================] - 2s 3ms/step\n",
            "110/110 [==============================] - 5s 48ms/step - loss: 0.7700 - val_loss: 0.6517\n",
            "Epoch 471/1500\n",
            "876/876 [==============================] - 3s 3ms/step\n",
            "110/110 [==============================] - 8s 70ms/step - loss: 0.7193 - val_loss: 0.7492\n",
            "Epoch 472/1500\n",
            "876/876 [==============================] - 2s 3ms/step\n",
            "110/110 [==============================] - 5s 48ms/step - loss: 0.5651 - val_loss: 1.6907\n",
            "Epoch 473/1500\n",
            "876/876 [==============================] - 3s 3ms/step\n",
            "110/110 [==============================] - 8s 71ms/step - loss: 0.9061 - val_loss: 0.6174\n",
            "Epoch 474/1500\n",
            "876/876 [==============================] - 3s 3ms/step\n",
            "110/110 [==============================] - 10s 87ms/step - loss: 0.5214 - val_loss: 0.8156\n",
            "Epoch 475/1500\n",
            "876/876 [==============================] - 3s 3ms/step\n",
            "110/110 [==============================] - 8s 71ms/step - loss: 0.6358 - val_loss: 2.1745\n",
            "Epoch 476/1500\n",
            "876/876 [==============================] - 2s 3ms/step\n",
            "110/110 [==============================] - 5s 48ms/step - loss: 0.7163 - val_loss: 0.7130\n",
            "Epoch 477/1500\n",
            "876/876 [==============================] - 3s 3ms/step\n",
            "110/110 [==============================] - 8s 72ms/step - loss: 0.9548 - val_loss: 1.0827\n",
            "Epoch 478/1500\n",
            "876/876 [==============================] - 2s 3ms/step\n",
            "110/110 [==============================] - 8s 72ms/step - loss: 1.5393 - val_loss: 1.2534\n",
            "Epoch 479/1500\n",
            "876/876 [==============================] - 3s 4ms/step\n",
            "110/110 [==============================] - 7s 64ms/step - loss: 0.6633 - val_loss: 0.9946\n",
            "Epoch 480/1500\n",
            "876/876 [==============================] - 3s 3ms/step\n",
            "110/110 [==============================] - 10s 89ms/step - loss: 0.6015 - val_loss: 0.8604\n",
            "Epoch 481/1500\n",
            "876/876 [==============================] - 3s 4ms/step\n",
            "110/110 [==============================] - 8s 73ms/step - loss: 0.6467 - val_loss: 0.8524\n",
            "Epoch 482/1500\n",
            "876/876 [==============================] - 2s 3ms/step\n",
            "110/110 [==============================] - 5s 49ms/step - loss: 1.4037 - val_loss: 1.5197\n",
            "Epoch 483/1500\n",
            "876/876 [==============================] - 3s 3ms/step\n",
            "110/110 [==============================] - 8s 71ms/step - loss: 0.8256 - val_loss: 0.7053\n",
            "Epoch 484/1500\n",
            "876/876 [==============================] - 2s 3ms/step\n",
            "110/110 [==============================] - 8s 70ms/step - loss: 0.5587 - val_loss: 0.7147\n",
            "Epoch 485/1500\n",
            "876/876 [==============================] - 3s 4ms/step\n",
            "110/110 [==============================] - 8s 77ms/step - loss: 1.0403 - val_loss: 4.7409\n",
            "Epoch 486/1500\n",
            "876/876 [==============================] - 2s 3ms/step\n",
            "110/110 [==============================] - 8s 71ms/step - loss: 0.7135 - val_loss: 3.2102\n",
            "Epoch 487/1500\n",
            "876/876 [==============================] - 3s 4ms/step\n",
            "110/110 [==============================] - 8s 69ms/step - loss: 1.3176 - val_loss: 0.7872\n",
            "Epoch 488/1500\n",
            "876/876 [==============================] - 2s 3ms/step\n",
            "110/110 [==============================] - 5s 48ms/step - loss: 0.7708 - val_loss: 1.5399\n",
            "Epoch 489/1500\n",
            "876/876 [==============================] - 3s 3ms/step\n",
            "110/110 [==============================] - 6s 51ms/step - loss: 0.6877 - val_loss: 0.8662\n",
            "Epoch 490/1500\n",
            "876/876 [==============================] - 3s 3ms/step\n",
            "110/110 [==============================] - 7s 68ms/step - loss: 0.6503 - val_loss: 0.6808\n",
            "Epoch 491/1500\n",
            "876/876 [==============================] - 2s 3ms/step\n",
            "110/110 [==============================] - 8s 71ms/step - loss: 0.5689 - val_loss: 1.2562\n",
            "Epoch 492/1500\n",
            "876/876 [==============================] - 3s 3ms/step\n",
            "110/110 [==============================] - 10s 90ms/step - loss: 0.8819 - val_loss: 1.3628\n",
            "Epoch 493/1500\n",
            "876/876 [==============================] - 2s 3ms/step\n",
            "110/110 [==============================] - 5s 49ms/step - loss: 0.6198 - val_loss: 0.6842\n",
            "Epoch 494/1500\n",
            "876/876 [==============================] - 3s 4ms/step\n",
            "110/110 [==============================] - 8s 70ms/step - loss: 0.7683 - val_loss: 0.8364\n",
            "Epoch 495/1500\n",
            "876/876 [==============================] - 2s 3ms/step\n",
            "110/110 [==============================] - 8s 71ms/step - loss: 1.4528 - val_loss: 1.2543\n",
            "Epoch 496/1500\n",
            "876/876 [==============================] - 3s 3ms/step\n",
            "110/110 [==============================] - 7s 61ms/step - loss: 0.8589 - val_loss: 0.6755\n",
            "Epoch 497/1500\n",
            "876/876 [==============================] - 2s 3ms/step\n",
            "110/110 [==============================] - 6s 55ms/step - loss: 0.8793 - val_loss: 3.2533\n",
            "Epoch 498/1500\n",
            "876/876 [==============================] - 2s 3ms/step\n",
            "110/110 [==============================] - 5s 49ms/step - loss: 0.8215 - val_loss: 0.6430\n",
            "Epoch 499/1500\n",
            "876/876 [==============================] - 3s 3ms/step\n",
            "110/110 [==============================] - 10s 90ms/step - loss: 0.5901 - val_loss: 0.7925\n",
            "Epoch 500/1500\n",
            "876/876 [==============================] - 2s 3ms/step\n",
            "110/110 [==============================] - 5s 50ms/step - loss: 0.6792 - val_loss: 0.8997\n",
            "Epoch 501/1500\n",
            "876/876 [==============================] - 3s 3ms/step\n",
            "110/110 [==============================] - 6s 54ms/step - loss: 1.4325 - val_loss: 0.8860\n",
            "Epoch 502/1500\n",
            "876/876 [==============================] - 2s 3ms/step\n",
            "110/110 [==============================] - 9s 85ms/step - loss: 0.6300 - val_loss: 1.0002\n",
            "Epoch 503/1500\n",
            "876/876 [==============================] - 3s 3ms/step\n",
            "110/110 [==============================] - 6s 52ms/step - loss: 0.5885 - val_loss: 0.5647\n",
            "Epoch 504/1500\n",
            "876/876 [==============================] - 2s 3ms/step\n",
            "110/110 [==============================] - 7s 67ms/step - loss: 0.6853 - val_loss: 0.7769\n",
            "Epoch 505/1500\n",
            "876/876 [==============================] - 2s 3ms/step\n",
            "110/110 [==============================] - 8s 71ms/step - loss: 1.1139 - val_loss: 0.7801\n",
            "Epoch 506/1500\n",
            "876/876 [==============================] - 3s 3ms/step\n",
            "110/110 [==============================] - 8s 69ms/step - loss: 0.6862 - val_loss: 0.6989\n",
            "Epoch 507/1500\n",
            "876/876 [==============================] - 2s 3ms/step\n",
            "110/110 [==============================] - 5s 49ms/step - loss: 0.6470 - val_loss: 1.0664\n",
            "Epoch 508/1500\n",
            "876/876 [==============================] - 3s 4ms/step\n",
            "110/110 [==============================] - 6s 56ms/step - loss: 0.7541 - val_loss: 1.1393\n",
            "Epoch 509/1500\n",
            "876/876 [==============================] - 2s 3ms/step\n",
            "110/110 [==============================] - 7s 61ms/step - loss: 0.9139 - val_loss: 0.9046\n",
            "Epoch 510/1500\n",
            "876/876 [==============================] - 3s 3ms/step\n",
            "110/110 [==============================] - 8s 71ms/step - loss: 0.8974 - val_loss: 0.7265\n",
            "Epoch 511/1500\n",
            "876/876 [==============================] - 2s 3ms/step\n",
            "110/110 [==============================] - 7s 67ms/step - loss: 0.6544 - val_loss: 0.5586\n",
            "Epoch 512/1500\n",
            "876/876 [==============================] - 2s 3ms/step\n",
            "110/110 [==============================] - 8s 71ms/step - loss: 0.6893 - val_loss: 0.6406\n",
            "Epoch 513/1500\n",
            "876/876 [==============================] - 3s 3ms/step\n",
            "110/110 [==============================] - 7s 67ms/step - loss: 0.6903 - val_loss: 0.6439\n",
            "Epoch 514/1500\n",
            "876/876 [==============================] - 2s 3ms/step\n",
            "110/110 [==============================] - 5s 47ms/step - loss: 0.8961 - val_loss: 0.6655\n",
            "Epoch 515/1500\n",
            "876/876 [==============================] - 3s 3ms/step\n",
            "110/110 [==============================] - 8s 71ms/step - loss: 0.8535 - val_loss: 0.8565\n",
            "Epoch 516/1500\n",
            "876/876 [==============================] - 2s 3ms/step\n",
            "110/110 [==============================] - 5s 49ms/step - loss: 0.9353 - val_loss: 0.7262\n",
            "Epoch 517/1500\n",
            "876/876 [==============================] - 3s 3ms/step\n",
            "110/110 [==============================] - 8s 72ms/step - loss: 0.8076 - val_loss: 0.9460\n",
            "Epoch 518/1500\n",
            "876/876 [==============================] - 2s 3ms/step\n",
            "110/110 [==============================] - 5s 48ms/step - loss: 0.5192 - val_loss: 0.6159\n",
            "Epoch 519/1500\n",
            "876/876 [==============================] - 3s 3ms/step\n",
            "110/110 [==============================] - 8s 71ms/step - loss: 1.0097 - val_loss: 4.1026\n",
            "Epoch 520/1500\n",
            "876/876 [==============================] - 2s 3ms/step\n",
            "110/110 [==============================] - 5s 49ms/step - loss: 0.8698 - val_loss: 0.7056\n",
            "Epoch 521/1500\n",
            "876/876 [==============================] - 3s 3ms/step\n",
            "110/110 [==============================] - 8s 72ms/step - loss: 0.6822 - val_loss: 0.6708\n",
            "Epoch 522/1500\n",
            "876/876 [==============================] - 2s 3ms/step\n",
            "110/110 [==============================] - 8s 71ms/step - loss: 0.5181 - val_loss: 1.5537\n",
            "Epoch 523/1500\n",
            "876/876 [==============================] - 3s 4ms/step\n",
            "110/110 [==============================] - 7s 62ms/step - loss: 0.8092 - val_loss: 0.8081\n",
            "Epoch 524/1500\n",
            "876/876 [==============================] - 2s 3ms/step\n",
            "110/110 [==============================] - 8s 77ms/step - loss: 0.5310 - val_loss: 1.1786\n",
            "Epoch 525/1500\n",
            "876/876 [==============================] - 3s 3ms/step\n",
            "110/110 [==============================] - 6s 57ms/step - loss: 0.8618 - val_loss: 1.0268\n",
            "Epoch 526/1500\n",
            "876/876 [==============================] - 3s 4ms/step\n",
            "110/110 [==============================] - 9s 81ms/step - loss: 0.6842 - val_loss: 0.6305\n",
            "Epoch 527/1500\n",
            "876/876 [==============================] - 2s 3ms/step\n",
            "110/110 [==============================] - 5s 49ms/step - loss: 0.7942 - val_loss: 0.7607\n",
            "Epoch 528/1500\n",
            "876/876 [==============================] - 3s 4ms/step\n",
            "110/110 [==============================] - 9s 81ms/step - loss: 0.7497 - val_loss: 0.7410\n",
            "Epoch 529/1500\n",
            "876/876 [==============================] - 2s 3ms/step\n",
            "110/110 [==============================] - 5s 49ms/step - loss: 0.7648 - val_loss: 0.6381\n",
            "Epoch 530/1500\n",
            "876/876 [==============================] - 3s 3ms/step\n",
            "110/110 [==============================] - 6s 55ms/step - loss: 0.6727 - val_loss: 0.7427\n",
            "Epoch 531/1500\n",
            "876/876 [==============================] - 2s 3ms/step\n",
            "110/110 [==============================] - 9s 86ms/step - loss: 0.5761 - val_loss: 0.6015\n",
            "Epoch 532/1500\n",
            "876/876 [==============================] - 3s 3ms/step\n",
            "110/110 [==============================] - 8s 71ms/step - loss: 0.5724 - val_loss: 0.7606\n",
            "Epoch 533/1500\n",
            "876/876 [==============================] - 2s 3ms/step\n",
            "110/110 [==============================] - 8s 71ms/step - loss: 0.7739 - val_loss: 0.8664\n",
            "Epoch 534/1500\n",
            "876/876 [==============================] - 3s 3ms/step\n",
            "110/110 [==============================] - 7s 61ms/step - loss: 0.7417 - val_loss: 0.5937\n",
            "Epoch 535/1500\n",
            "876/876 [==============================] - 2s 3ms/step\n",
            "110/110 [==============================] - 9s 79ms/step - loss: 0.7693 - val_loss: 1.2004\n",
            "Epoch 536/1500\n",
            "876/876 [==============================] - 3s 3ms/step\n",
            "110/110 [==============================] - 6s 56ms/step - loss: 0.9762 - val_loss: 0.9500\n",
            "Epoch 537/1500\n",
            "876/876 [==============================] - 2s 3ms/step\n",
            "110/110 [==============================] - 9s 86ms/step - loss: 0.5702 - val_loss: 0.7569\n",
            "Epoch 538/1500\n",
            "876/876 [==============================] - 3s 3ms/step\n",
            "110/110 [==============================] - 8s 71ms/step - loss: 0.9742 - val_loss: 1.2997\n",
            "Epoch 539/1500\n",
            "876/876 [==============================] - 2s 3ms/step\n",
            "110/110 [==============================] - 5s 50ms/step - loss: 0.6890 - val_loss: 0.8727\n",
            "Epoch 540/1500\n",
            "876/876 [==============================] - 3s 3ms/step\n",
            "110/110 [==============================] - 8s 71ms/step - loss: 0.6164 - val_loss: 1.5791\n",
            "Epoch 541/1500\n",
            "876/876 [==============================] - 3s 3ms/step\n",
            "110/110 [==============================] - 10s 93ms/step - loss: 0.6638 - val_loss: 2.0126\n",
            "Epoch 542/1500\n",
            "876/876 [==============================] - 3s 4ms/step\n",
            "110/110 [==============================] - 8s 75ms/step - loss: 0.6855 - val_loss: 0.6061\n",
            "Epoch 543/1500\n",
            "876/876 [==============================] - 2s 3ms/step\n",
            "110/110 [==============================] - 5s 50ms/step - loss: 0.6361 - val_loss: 0.5843\n",
            "Epoch 544/1500\n",
            "876/876 [==============================] - 3s 3ms/step\n",
            "110/110 [==============================] - 6s 53ms/step - loss: 0.7109 - val_loss: 0.7631\n",
            "Epoch 545/1500\n",
            "876/876 [==============================] - 3s 3ms/step\n",
            "110/110 [==============================] - 10s 90ms/step - loss: 0.7129 - val_loss: 1.1489\n",
            "Epoch 546/1500\n",
            "876/876 [==============================] - 3s 3ms/step\n",
            "110/110 [==============================] - 8s 73ms/step - loss: 0.8774 - val_loss: 0.7987\n",
            "Epoch 547/1500\n",
            "876/876 [==============================] - 2s 3ms/step\n",
            "110/110 [==============================] - 6s 54ms/step - loss: 0.6191 - val_loss: 3.5164\n",
            "Epoch 548/1500\n",
            "876/876 [==============================] - 3s 3ms/step\n",
            "110/110 [==============================] - 6s 53ms/step - loss: 0.8431 - val_loss: 2.3800\n",
            "Epoch 549/1500\n",
            "876/876 [==============================] - 3s 3ms/step\n",
            "110/110 [==============================] - 10s 91ms/step - loss: 1.1192 - val_loss: 1.0391\n",
            "Epoch 550/1500\n",
            "876/876 [==============================] - 3s 3ms/step\n",
            "110/110 [==============================] - 8s 74ms/step - loss: 0.8699 - val_loss: 0.7022\n",
            "Epoch 551/1500\n",
            "876/876 [==============================] - 3s 3ms/step\n",
            "110/110 [==============================] - 8s 76ms/step - loss: 0.7212 - val_loss: 3.0962\n",
            "Epoch 552/1500\n",
            "876/876 [==============================] - 3s 3ms/step\n",
            "110/110 [==============================] - 8s 75ms/step - loss: 1.0113 - val_loss: 0.6441\n",
            "Epoch 553/1500\n",
            "876/876 [==============================] - 3s 3ms/step\n",
            "110/110 [==============================] - 8s 71ms/step - loss: 0.5887 - val_loss: 0.5927\n",
            "Epoch 554/1500\n",
            "876/876 [==============================] - 3s 3ms/step\n",
            "110/110 [==============================] - 6s 55ms/step - loss: 0.6175 - val_loss: 1.2566\n",
            "Epoch 555/1500\n",
            "876/876 [==============================] - 3s 4ms/step\n",
            "110/110 [==============================] - 9s 84ms/step - loss: 0.9723 - val_loss: 0.9374\n",
            "Epoch 556/1500\n",
            "876/876 [==============================] - 3s 3ms/step\n",
            "110/110 [==============================] - 8s 75ms/step - loss: 0.6628 - val_loss: 0.6253\n",
            "Epoch 557/1500\n",
            "876/876 [==============================] - 3s 4ms/step\n",
            "110/110 [==============================] - 8s 75ms/step - loss: 1.2835 - val_loss: 0.9330\n",
            "Epoch 558/1500\n",
            "876/876 [==============================] - 3s 3ms/step\n",
            "110/110 [==============================] - 8s 74ms/step - loss: 0.7969 - val_loss: 0.6106\n",
            "Epoch 559/1500\n",
            "876/876 [==============================] - 3s 4ms/step\n",
            "110/110 [==============================] - 9s 82ms/step - loss: 0.6284 - val_loss: 1.1137\n",
            "Epoch 560/1500\n",
            "876/876 [==============================] - 3s 3ms/step\n",
            "110/110 [==============================] - 6s 51ms/step - loss: 0.7117 - val_loss: 2.2260\n",
            "Epoch 561/1500\n",
            "876/876 [==============================] - 3s 4ms/step\n",
            "110/110 [==============================] - 7s 60ms/step - loss: 0.6252 - val_loss: 0.6956\n",
            "Epoch 562/1500\n",
            "876/876 [==============================] - 3s 3ms/step\n",
            "110/110 [==============================] - 8s 71ms/step - loss: 0.5897 - val_loss: 0.8949\n",
            "Epoch 563/1500\n",
            "876/876 [==============================] - 2s 3ms/step\n",
            "110/110 [==============================] - 6s 53ms/step - loss: 0.5398 - val_loss: 0.6892\n",
            "Epoch 564/1500\n",
            "876/876 [==============================] - 3s 4ms/step\n",
            "110/110 [==============================] - 9s 84ms/step - loss: 1.0360 - val_loss: 0.8574\n",
            "Epoch 565/1500\n",
            "876/876 [==============================] - 3s 3ms/step\n",
            "110/110 [==============================] - 6s 54ms/step - loss: 0.6028 - val_loss: 1.0642\n",
            "Epoch 566/1500\n",
            "876/876 [==============================] - 3s 4ms/step\n",
            "110/110 [==============================] - 7s 63ms/step - loss: 1.3049 - val_loss: 0.6642\n",
            "Epoch 567/1500\n",
            "876/876 [==============================] - 3s 3ms/step\n",
            "110/110 [==============================] - 7s 61ms/step - loss: 0.5997 - val_loss: 1.1712\n",
            "Epoch 568/1500\n",
            "876/876 [==============================] - 3s 3ms/step\n",
            "110/110 [==============================] - 8s 72ms/step - loss: 0.5875 - val_loss: 0.7537\n",
            "Epoch 569/1500\n",
            "876/876 [==============================] - 3s 3ms/step\n",
            "110/110 [==============================] - 8s 75ms/step - loss: 1.0933 - val_loss: 4.0914\n",
            "Epoch 570/1500\n",
            "876/876 [==============================] - 3s 3ms/step\n",
            "110/110 [==============================] - 9s 78ms/step - loss: 0.6966 - val_loss: 1.5990\n",
            "Epoch 571/1500\n",
            "876/876 [==============================] - 3s 3ms/step\n",
            "110/110 [==============================] - 8s 73ms/step - loss: 0.8291 - val_loss: 0.7058\n",
            "Epoch 572/1500\n",
            "876/876 [==============================] - 3s 4ms/step\n",
            "110/110 [==============================] - 9s 78ms/step - loss: 0.7674 - val_loss: 1.6931\n",
            "Epoch 573/1500\n",
            "876/876 [==============================] - 3s 3ms/step\n",
            "110/110 [==============================] - 6s 55ms/step - loss: 0.6254 - val_loss: 0.7620\n",
            "Epoch 574/1500\n",
            "876/876 [==============================] - 3s 3ms/step\n",
            "110/110 [==============================] - 6s 58ms/step - loss: 1.0146 - val_loss: 3.5690\n",
            "Epoch 575/1500\n",
            "876/876 [==============================] - 3s 4ms/step\n",
            "110/110 [==============================] - 9s 80ms/step - loss: 0.7472 - val_loss: 0.9098\n",
            "Epoch 576/1500\n",
            "876/876 [==============================] - 2s 3ms/step\n",
            "110/110 [==============================] - 9s 79ms/step - loss: 0.6673 - val_loss: 0.5710\n",
            "Epoch 577/1500\n",
            "876/876 [==============================] - 3s 3ms/step\n",
            "110/110 [==============================] - 8s 69ms/step - loss: 0.4660 - val_loss: 0.5934\n",
            "Epoch 578/1500\n",
            "876/876 [==============================] - 2s 3ms/step\n",
            "110/110 [==============================] - 8s 73ms/step - loss: 1.0411 - val_loss: 1.1926\n",
            "Epoch 579/1500\n",
            "876/876 [==============================] - 3s 3ms/step\n",
            "110/110 [==============================] - 10s 89ms/step - loss: 0.8186 - val_loss: 1.2550\n",
            "Epoch 580/1500\n",
            "876/876 [==============================] - 3s 3ms/step\n",
            "110/110 [==============================] - 6s 52ms/step - loss: 0.5886 - val_loss: 1.5163\n",
            "Epoch 581/1500\n",
            "876/876 [==============================] - 3s 4ms/step\n",
            "110/110 [==============================] - 9s 86ms/step - loss: 0.5885 - val_loss: 1.0240\n",
            "Epoch 582/1500\n",
            "876/876 [==============================] - 3s 3ms/step\n",
            "110/110 [==============================] - 6s 54ms/step - loss: 0.5559 - val_loss: 1.7520\n",
            "Epoch 583/1500\n",
            "876/876 [==============================] - 3s 4ms/step\n",
            "110/110 [==============================] - 8s 72ms/step - loss: 0.9160 - val_loss: 1.2495\n",
            "Epoch 584/1500\n",
            "876/876 [==============================] - 3s 3ms/step\n",
            "110/110 [==============================] - 8s 73ms/step - loss: 0.8537 - val_loss: 0.7446\n",
            "Epoch 585/1500\n",
            "876/876 [==============================] - 3s 4ms/step\n",
            "110/110 [==============================] - 9s 83ms/step - loss: 0.8523 - val_loss: 1.4844\n",
            "Epoch 586/1500\n",
            "876/876 [==============================] - 2s 3ms/step\n",
            "110/110 [==============================] - 8s 73ms/step - loss: 0.4719 - val_loss: 1.0049\n",
            "Epoch 587/1500\n",
            "876/876 [==============================] - 3s 4ms/step\n",
            "110/110 [==============================] - 8s 72ms/step - loss: 0.9168 - val_loss: 1.0040\n",
            "Epoch 588/1500\n",
            "876/876 [==============================] - 3s 3ms/step\n",
            "110/110 [==============================] - 6s 55ms/step - loss: 0.8980 - val_loss: 1.8940\n",
            "Epoch 589/1500\n",
            "876/876 [==============================] - 3s 3ms/step\n",
            "110/110 [==============================] - 6s 55ms/step - loss: 0.8967 - val_loss: 0.7271\n",
            "Epoch 590/1500\n",
            "876/876 [==============================] - 2s 3ms/step\n",
            "110/110 [==============================] - 10s 90ms/step - loss: 0.5823 - val_loss: 0.5768\n",
            "Epoch 591/1500\n",
            "876/876 [==============================] - 3s 3ms/step\n",
            "110/110 [==============================] - 8s 73ms/step - loss: 0.5213 - val_loss: 0.6763\n",
            "Epoch 592/1500\n",
            "876/876 [==============================] - 3s 3ms/step\n",
            "110/110 [==============================] - 6s 52ms/step - loss: 1.0421 - val_loss: 2.1088\n",
            "Epoch 593/1500\n",
            "876/876 [==============================] - 3s 3ms/step\n",
            "110/110 [==============================] - 8s 74ms/step - loss: 0.9105 - val_loss: 1.2255\n",
            "Epoch 594/1500\n",
            "876/876 [==============================] - 2s 3ms/step\n",
            "110/110 [==============================] - 8s 72ms/step - loss: 0.9027 - val_loss: 2.1077\n",
            "Epoch 595/1500\n",
            "876/876 [==============================] - 3s 4ms/step\n",
            "110/110 [==============================] - 7s 60ms/step - loss: 0.5821 - val_loss: 0.5882\n",
            "Epoch 596/1500\n",
            "876/876 [==============================] - 2s 3ms/step\n",
            "110/110 [==============================] - 7s 61ms/step - loss: 0.6726 - val_loss: 0.8798\n",
            "Epoch 597/1500\n",
            "876/876 [==============================] - 3s 4ms/step\n",
            "110/110 [==============================] - 7s 67ms/step - loss: 1.0143 - val_loss: 0.7728\n",
            "Epoch 598/1500\n",
            "876/876 [==============================] - 3s 4ms/step\n",
            "110/110 [==============================] - 8s 77ms/step - loss: 0.5786 - val_loss: 0.8046\n",
            "Epoch 599/1500\n",
            "876/876 [==============================] - 3s 3ms/step\n",
            "110/110 [==============================] - 10s 92ms/step - loss: 0.6474 - val_loss: 0.6804\n",
            "Epoch 600/1500\n",
            "876/876 [==============================] - 3s 4ms/step\n",
            "110/110 [==============================] - 7s 68ms/step - loss: 0.5357 - val_loss: 1.9442\n",
            "Epoch 601/1500\n",
            "876/876 [==============================] - 3s 3ms/step\n",
            "110/110 [==============================] - 8s 73ms/step - loss: 0.7855 - val_loss: 0.6949\n",
            "Epoch 602/1500\n",
            "876/876 [==============================] - 3s 4ms/step\n",
            "110/110 [==============================] - 7s 64ms/step - loss: 0.6813 - val_loss: 0.6590\n",
            "Epoch 603/1500\n",
            "876/876 [==============================] - 3s 3ms/step\n",
            "110/110 [==============================] - 7s 61ms/step - loss: 0.5420 - val_loss: 0.8870\n",
            "Epoch 604/1500\n",
            "876/876 [==============================] - 2s 3ms/step\n",
            "110/110 [==============================] - 8s 74ms/step - loss: 0.8922 - val_loss: 1.9010\n",
            "Epoch 605/1500\n",
            "876/876 [==============================] - 3s 3ms/step\n",
            "110/110 [==============================] - 8s 73ms/step - loss: 0.9749 - val_loss: 0.6568\n",
            "Epoch 606/1500\n",
            "876/876 [==============================] - 3s 4ms/step\n",
            "110/110 [==============================] - 7s 64ms/step - loss: 0.5966 - val_loss: 0.7067\n",
            "Epoch 607/1500\n",
            "876/876 [==============================] - 3s 3ms/step\n",
            "110/110 [==============================] - 7s 60ms/step - loss: 0.9288 - val_loss: 0.8245\n",
            "Epoch 608/1500\n",
            "876/876 [==============================] - 2s 3ms/step\n",
            "110/110 [==============================] - 8s 73ms/step - loss: 0.6659 - val_loss: 0.8695\n",
            "Epoch 609/1500\n",
            "876/876 [==============================] - 3s 3ms/step\n",
            "110/110 [==============================] - 6s 54ms/step - loss: 0.6589 - val_loss: 0.7461\n",
            "Epoch 610/1500\n",
            "876/876 [==============================] - 3s 3ms/step\n",
            "110/110 [==============================] - 8s 73ms/step - loss: 0.7177 - val_loss: 0.6056\n",
            "Epoch 611/1500\n",
            "876/876 [==============================] - 2s 3ms/step\n",
            "110/110 [==============================] - 8s 73ms/step - loss: 0.6639 - val_loss: 1.9906\n",
            "Epoch 612/1500\n",
            "876/876 [==============================] - 3s 4ms/step\n",
            "110/110 [==============================] - 9s 79ms/step - loss: 0.7445 - val_loss: 0.8994\n",
            "Epoch 613/1500\n",
            "876/876 [==============================] - 3s 3ms/step\n",
            "110/110 [==============================] - 8s 73ms/step - loss: 0.8772 - val_loss: 2.1379\n",
            "Epoch 614/1500\n",
            "876/876 [==============================] - 3s 4ms/step\n",
            "110/110 [==============================] - 7s 65ms/step - loss: 0.6758 - val_loss: 0.9254\n",
            "Epoch 615/1500\n",
            "876/876 [==============================] - 3s 3ms/step\n",
            "110/110 [==============================] - 6s 59ms/step - loss: 0.6266 - val_loss: 0.6615\n",
            "Epoch 616/1500\n",
            "876/876 [==============================] - 3s 3ms/step\n",
            "110/110 [==============================] - 6s 59ms/step - loss: 0.5407 - val_loss: 0.6319\n",
            "Epoch 617/1500\n",
            "876/876 [==============================] - 3s 3ms/step\n",
            "110/110 [==============================] - 10s 89ms/step - loss: 0.8839 - val_loss: 1.6292\n",
            "Epoch 618/1500\n",
            "876/876 [==============================] - 3s 3ms/step\n",
            "110/110 [==============================] - 8s 74ms/step - loss: 0.9997 - val_loss: 0.7238\n",
            "Epoch 619/1500\n",
            "876/876 [==============================] - 3s 3ms/step\n",
            "110/110 [==============================] - 9s 82ms/step - loss: 0.7453 - val_loss: 0.6291\n",
            "Epoch 620/1500\n",
            "876/876 [==============================] - 3s 3ms/step\n",
            "110/110 [==============================] - 8s 71ms/step - loss: 0.5119 - val_loss: 1.1001\n",
            "Epoch 621/1500\n",
            "876/876 [==============================] - 2s 3ms/step\n",
            "110/110 [==============================] - 5s 49ms/step - loss: 0.9711 - val_loss: 1.0878\n",
            "Epoch 622/1500\n",
            "876/876 [==============================] - 3s 3ms/step\n",
            "110/110 [==============================] - 8s 75ms/step - loss: 1.1101 - val_loss: 0.7075\n",
            "Epoch 623/1500\n",
            "876/876 [==============================] - 2s 3ms/step\n",
            "110/110 [==============================] - 8s 72ms/step - loss: 0.8247 - val_loss: 1.6586\n",
            "Epoch 624/1500\n",
            "876/876 [==============================] - 3s 4ms/step\n",
            "110/110 [==============================] - 9s 80ms/step - loss: 0.7762 - val_loss: 2.2993\n",
            "Epoch 625/1500\n",
            "876/876 [==============================] - 3s 3ms/step\n",
            "110/110 [==============================] - 6s 59ms/step - loss: 0.6638 - val_loss: 0.6834\n",
            "Epoch 626/1500\n",
            "876/876 [==============================] - 3s 3ms/step\n",
            "110/110 [==============================] - 10s 88ms/step - loss: 1.2467 - val_loss: 0.7380\n",
            "Epoch 627/1500\n",
            "876/876 [==============================] - 2s 3ms/step\n",
            "110/110 [==============================] - 8s 72ms/step - loss: 0.5535 - val_loss: 1.1083\n",
            "Epoch 628/1500\n",
            "876/876 [==============================] - 3s 3ms/step\n",
            "110/110 [==============================] - 7s 62ms/step - loss: 0.4902 - val_loss: 0.5796\n",
            "Epoch 629/1500\n",
            "876/876 [==============================] - 2s 3ms/step\n",
            "110/110 [==============================] - 9s 79ms/step - loss: 0.9138 - val_loss: 0.7577\n",
            "Epoch 630/1500\n",
            "876/876 [==============================] - 3s 3ms/step\n",
            "110/110 [==============================] - 6s 56ms/step - loss: 0.4454 - val_loss: 0.9437\n",
            "Epoch 631/1500\n",
            "876/876 [==============================] - 3s 3ms/step\n",
            "110/110 [==============================] - 7s 67ms/step - loss: 0.6812 - val_loss: 0.8383\n",
            "Epoch 632/1500\n",
            "876/876 [==============================] - 2s 3ms/step\n",
            "110/110 [==============================] - 8s 72ms/step - loss: 0.6662 - val_loss: 1.1735\n",
            "Epoch 633/1500\n",
            "876/876 [==============================] - 2s 3ms/step\n",
            "110/110 [==============================] - 7s 66ms/step - loss: 0.6225 - val_loss: 0.6988\n",
            "Epoch 634/1500\n",
            "876/876 [==============================] - 2s 3ms/step\n",
            "110/110 [==============================] - 5s 49ms/step - loss: 0.6773 - val_loss: 0.5940\n",
            "Epoch 635/1500\n",
            "876/876 [==============================] - 3s 4ms/step\n",
            "110/110 [==============================] - 9s 78ms/step - loss: 0.6086 - val_loss: 0.5676\n",
            "Epoch 636/1500\n",
            "876/876 [==============================] - 2s 3ms/step\n",
            "110/110 [==============================] - 8s 72ms/step - loss: 0.7490 - val_loss: 0.6854\n",
            "Epoch 637/1500\n",
            "876/876 [==============================] - 3s 4ms/step\n",
            "110/110 [==============================] - 9s 83ms/step - loss: 0.6995 - val_loss: 0.7212\n",
            "Epoch 638/1500\n",
            "876/876 [==============================] - 2s 3ms/step\n",
            "110/110 [==============================] - 5s 50ms/step - loss: 0.5016 - val_loss: 0.6845\n",
            "Epoch 639/1500\n",
            "876/876 [==============================] - 3s 4ms/step\n",
            "110/110 [==============================] - 6s 57ms/step - loss: 0.6046 - val_loss: 0.7214\n",
            "Epoch 640/1500\n",
            "876/876 [==============================] - 3s 3ms/step\n",
            "110/110 [==============================] - 9s 85ms/step - loss: 0.6440 - val_loss: 0.6766\n",
            "Epoch 641/1500\n",
            "876/876 [==============================] - 3s 3ms/step\n",
            "110/110 [==============================] - 8s 71ms/step - loss: 0.6677 - val_loss: 0.6423\n",
            "Epoch 642/1500\n",
            "876/876 [==============================] - 3s 3ms/step\n",
            "110/110 [==============================] - 5s 50ms/step - loss: 0.6323 - val_loss: 1.5078\n",
            "Epoch 643/1500\n",
            "876/876 [==============================] - 3s 3ms/step\n",
            "110/110 [==============================] - 8s 72ms/step - loss: 0.6682 - val_loss: 0.8858\n",
            "Epoch 644/1500\n",
            "876/876 [==============================] - 3s 3ms/step\n",
            "110/110 [==============================] - 8s 72ms/step - loss: 0.8225 - val_loss: 2.1242\n",
            "Epoch 645/1500\n",
            "876/876 [==============================] - 3s 3ms/step\n",
            "110/110 [==============================] - 7s 65ms/step - loss: 1.4096 - val_loss: 1.5203\n",
            "Epoch 646/1500\n",
            "876/876 [==============================] - 2s 3ms/step\n",
            "110/110 [==============================] - 6s 57ms/step - loss: 0.6666 - val_loss: 0.6433\n",
            "Epoch 647/1500\n",
            "876/876 [==============================] - 2s 3ms/step\n",
            "110/110 [==============================] - 8s 72ms/step - loss: 0.6726 - val_loss: 1.7293\n",
            "Epoch 648/1500\n",
            "876/876 [==============================] - 3s 3ms/step\n",
            "110/110 [==============================] - 6s 53ms/step - loss: 0.7714 - val_loss: 0.5780\n",
            "Epoch 649/1500\n",
            "876/876 [==============================] - 3s 4ms/step\n",
            "110/110 [==============================] - 10s 88ms/step - loss: 0.5440 - val_loss: 0.8412\n",
            "Epoch 650/1500\n",
            "876/876 [==============================] - 3s 3ms/step\n",
            "110/110 [==============================] - 6s 50ms/step - loss: 0.7442 - val_loss: 0.6071\n",
            "Epoch 651/1500\n",
            "876/876 [==============================] - 3s 3ms/step\n",
            "110/110 [==============================] - 6s 54ms/step - loss: 0.6264 - val_loss: 0.9767\n",
            "Epoch 652/1500\n",
            "876/876 [==============================] - 3s 3ms/step\n",
            "110/110 [==============================] - 8s 69ms/step - loss: 0.4962 - val_loss: 0.6386\n",
            "Epoch 653/1500\n",
            "876/876 [==============================] - 2s 3ms/step\n",
            "110/110 [==============================] - 6s 51ms/step - loss: 0.7747 - val_loss: 1.2583\n",
            "Epoch 654/1500\n",
            "876/876 [==============================] - 3s 3ms/step\n",
            "110/110 [==============================] - 8s 75ms/step - loss: 0.7899 - val_loss: 1.8790\n",
            "Epoch 655/1500\n",
            "876/876 [==============================] - 3s 4ms/step\n",
            "110/110 [==============================] - 10s 88ms/step - loss: 0.7622 - val_loss: 0.8891\n",
            "Epoch 656/1500\n",
            "876/876 [==============================] - 3s 3ms/step\n",
            "110/110 [==============================] - 10s 91ms/step - loss: 0.9140 - val_loss: 0.9433\n",
            "Epoch 657/1500\n",
            "876/876 [==============================] - 3s 3ms/step\n",
            "110/110 [==============================] - 6s 51ms/step - loss: 0.9432 - val_loss: 1.3205\n",
            "Epoch 658/1500\n",
            "876/876 [==============================] - 3s 3ms/step\n",
            "110/110 [==============================] - 10s 91ms/step - loss: 0.9585 - val_loss: 0.5804\n",
            "Epoch 659/1500\n",
            "876/876 [==============================] - 3s 3ms/step\n",
            "110/110 [==============================] - 6s 51ms/step - loss: 0.5695 - val_loss: 0.8025\n",
            "Epoch 660/1500\n",
            "876/876 [==============================] - 3s 3ms/step\n",
            "110/110 [==============================] - 8s 70ms/step - loss: 0.6763 - val_loss: 0.7228\n",
            "Epoch 661/1500\n",
            "876/876 [==============================] - 2s 3ms/step\n",
            "110/110 [==============================] - 8s 73ms/step - loss: 0.5751 - val_loss: 1.1084\n",
            "Epoch 662/1500\n",
            "876/876 [==============================] - 3s 4ms/step\n",
            "110/110 [==============================] - 7s 63ms/step - loss: 0.7014 - val_loss: 0.7178\n",
            "Epoch 663/1500\n",
            "876/876 [==============================] - 3s 3ms/step\n",
            "110/110 [==============================] - 9s 78ms/step - loss: 0.4808 - val_loss: 0.7318\n",
            "Epoch 664/1500\n",
            "876/876 [==============================] - 3s 3ms/step\n",
            "110/110 [==============================] - 6s 57ms/step - loss: 0.6364 - val_loss: 0.5724\n",
            "Epoch 665/1500\n",
            "876/876 [==============================] - 3s 3ms/step\n",
            "110/110 [==============================] - 7s 66ms/step - loss: 0.7192 - val_loss: 0.7565\n",
            "Epoch 666/1500\n",
            "876/876 [==============================] - 3s 3ms/step\n",
            "110/110 [==============================] - 8s 72ms/step - loss: 0.7161 - val_loss: 0.8177\n",
            "Epoch 667/1500\n",
            "876/876 [==============================] - 2s 3ms/step\n",
            "110/110 [==============================] - 7s 66ms/step - loss: 0.6380 - val_loss: 0.9189\n",
            "Epoch 668/1500\n",
            "876/876 [==============================] - 2s 3ms/step\n",
            "110/110 [==============================] - 5s 49ms/step - loss: 0.5473 - val_loss: 1.3230\n",
            "Epoch 669/1500\n",
            "876/876 [==============================] - 3s 4ms/step\n",
            "110/110 [==============================] - 7s 66ms/step - loss: 0.8580 - val_loss: 0.7248\n",
            "Epoch 670/1500\n",
            "876/876 [==============================] - 3s 3ms/step\n",
            "110/110 [==============================] - 8s 75ms/step - loss: 0.5951 - val_loss: 0.6239\n",
            "Epoch 671/1500\n",
            "876/876 [==============================] - 3s 3ms/step\n",
            "110/110 [==============================] - 8s 72ms/step - loss: 1.6531 - val_loss: 0.9531\n",
            "Epoch 672/1500\n",
            "876/876 [==============================] - 2s 3ms/step\n",
            "110/110 [==============================] - 5s 50ms/step - loss: 0.5967 - val_loss: 0.7593\n",
            "Epoch 673/1500\n",
            "876/876 [==============================] - 3s 4ms/step\n",
            "110/110 [==============================] - 8s 74ms/step - loss: 0.7364 - val_loss: 1.0017\n",
            "Epoch 674/1500\n",
            "876/876 [==============================] - 3s 3ms/step\n",
            "110/110 [==============================] - 8s 69ms/step - loss: 0.5781 - val_loss: 0.6003\n",
            "Epoch 675/1500\n",
            "876/876 [==============================] - 2s 3ms/step\n",
            "110/110 [==============================] - 6s 51ms/step - loss: 0.5399 - val_loss: 0.7916\n",
            "Epoch 676/1500\n",
            "876/876 [==============================] - 3s 4ms/step\n",
            "110/110 [==============================] - 7s 66ms/step - loss: 0.8014 - val_loss: 0.9252\n",
            "Epoch 677/1500\n",
            "876/876 [==============================] - 2s 3ms/step\n",
            "110/110 [==============================] - 6s 56ms/step - loss: 0.5883 - val_loss: 0.7224\n",
            "Epoch 678/1500\n",
            "876/876 [==============================] - 3s 3ms/step\n",
            "110/110 [==============================] - 8s 72ms/step - loss: 0.8981 - val_loss: 0.9088\n",
            "Epoch 679/1500\n",
            "876/876 [==============================] - 2s 3ms/step\n",
            "110/110 [==============================] - 6s 51ms/step - loss: 0.5318 - val_loss: 0.6161\n",
            "Epoch 680/1500\n",
            "876/876 [==============================] - 3s 3ms/step\n",
            "110/110 [==============================] - 6s 54ms/step - loss: 0.8133 - val_loss: 0.9422\n",
            "Epoch 681/1500\n",
            "876/876 [==============================] - 3s 3ms/step\n",
            "110/110 [==============================] - 10s 89ms/step - loss: 0.9946 - val_loss: 0.7498\n",
            "Epoch 682/1500\n",
            "876/876 [==============================] - 2s 3ms/step\n",
            "110/110 [==============================] - 8s 73ms/step - loss: 0.5868 - val_loss: 0.9410\n",
            "Epoch 683/1500\n",
            "876/876 [==============================] - 3s 3ms/step\n",
            "110/110 [==============================] - 6s 52ms/step - loss: 0.5729 - val_loss: 0.5780\n",
            "Epoch 684/1500\n",
            "876/876 [==============================] - 3s 3ms/step\n",
            "110/110 [==============================] - 9s 85ms/step - loss: 0.7689 - val_loss: 0.6825\n",
            "Epoch 685/1500\n",
            "876/876 [==============================] - 2s 3ms/step\n",
            "110/110 [==============================] - 6s 59ms/step - loss: 1.1572 - val_loss: 0.9303\n",
            "Epoch 686/1500\n",
            "876/876 [==============================] - 3s 3ms/step\n",
            "110/110 [==============================] - 8s 72ms/step - loss: 0.9147 - val_loss: 1.4686\n",
            "Epoch 687/1500\n",
            "876/876 [==============================] - 3s 3ms/step\n",
            "110/110 [==============================] - 6s 56ms/step - loss: 0.6057 - val_loss: 0.7720\n",
            "Epoch 688/1500\n",
            "876/876 [==============================] - 3s 3ms/step\n",
            "110/110 [==============================] - 6s 53ms/step - loss: 0.5334 - val_loss: 1.0962\n",
            "Epoch 689/1500\n",
            "876/876 [==============================] - 3s 3ms/step\n",
            "110/110 [==============================] - 10s 89ms/step - loss: 0.4637 - val_loss: 0.8214\n",
            "Epoch 690/1500\n",
            "876/876 [==============================] - 2s 3ms/step\n",
            "110/110 [==============================] - 6s 51ms/step - loss: 0.5923 - val_loss: 0.9956\n",
            "Epoch 691/1500\n",
            "876/876 [==============================] - 3s 4ms/step\n",
            "110/110 [==============================] - 7s 67ms/step - loss: 0.7151 - val_loss: 0.5780\n",
            "Epoch 692/1500\n",
            "876/876 [==============================] - 2s 3ms/step\n",
            "110/110 [==============================] - 6s 55ms/step - loss: 0.7488 - val_loss: 1.7596\n",
            "Epoch 693/1500\n",
            "876/876 [==============================] - 3s 3ms/step\n",
            "110/110 [==============================] - 8s 72ms/step - loss: 0.7118 - val_loss: 1.4024\n",
            "Epoch 694/1500\n",
            "876/876 [==============================] - 2s 3ms/step\n",
            "110/110 [==============================] - 8s 72ms/step - loss: 0.9556 - val_loss: 0.8283\n",
            "Epoch 695/1500\n",
            "876/876 [==============================] - 3s 3ms/step\n",
            "110/110 [==============================] - 7s 61ms/step - loss: 1.0090 - val_loss: 4.0584\n",
            "Epoch 696/1500\n",
            "876/876 [==============================] - 2s 3ms/step\n",
            "110/110 [==============================] - 9s 78ms/step - loss: 0.8234 - val_loss: 0.7686\n",
            "Epoch 697/1500\n",
            "876/876 [==============================] - 3s 3ms/step\n",
            "110/110 [==============================] - 6s 56ms/step - loss: 0.5369 - val_loss: 0.6162\n",
            "Epoch 698/1500\n",
            "876/876 [==============================] - 3s 3ms/step\n",
            "110/110 [==============================] - 10s 89ms/step - loss: 1.7097 - val_loss: 1.1800\n",
            "Epoch 699/1500\n",
            "876/876 [==============================] - 3s 3ms/step\n",
            "110/110 [==============================] - 8s 73ms/step - loss: 0.8026 - val_loss: 0.6670\n",
            "Epoch 700/1500\n",
            "876/876 [==============================] - 3s 3ms/step\n",
            "110/110 [==============================] - 6s 51ms/step - loss: 0.5634 - val_loss: 1.2008\n",
            "Epoch 701/1500\n",
            "876/876 [==============================] - 3s 3ms/step\n",
            "110/110 [==============================] - 8s 73ms/step - loss: 1.2387 - val_loss: 0.6855\n",
            "Epoch 702/1500\n",
            "876/876 [==============================] - 3s 3ms/step\n",
            "110/110 [==============================] - 8s 72ms/step - loss: 0.5138 - val_loss: 1.0345\n",
            "Epoch 703/1500\n",
            "876/876 [==============================] - 3s 4ms/step\n",
            "110/110 [==============================] - 8s 76ms/step - loss: 0.6557 - val_loss: 0.6239\n",
            "Epoch 704/1500\n",
            "876/876 [==============================] - 3s 3ms/step\n",
            "110/110 [==============================] - 8s 73ms/step - loss: 0.5061 - val_loss: 0.7758\n",
            "Epoch 705/1500\n",
            "876/876 [==============================] - 3s 4ms/step\n",
            "110/110 [==============================] - 9s 85ms/step - loss: 0.7952 - val_loss: 0.8326\n",
            "Epoch 706/1500\n",
            "876/876 [==============================] - 3s 3ms/step\n",
            "110/110 [==============================] - 6s 51ms/step - loss: 0.5338 - val_loss: 0.7348\n",
            "Epoch 707/1500\n",
            "876/876 [==============================] - 3s 4ms/step\n",
            "110/110 [==============================] - 6s 57ms/step - loss: 0.7029 - val_loss: 0.6138\n",
            "Epoch 708/1500\n",
            "876/876 [==============================] - 2s 3ms/step\n",
            "110/110 [==============================] - 10s 87ms/step - loss: 0.4664 - val_loss: 0.6627\n",
            "Epoch 709/1500\n",
            "876/876 [==============================] - 3s 3ms/step\n",
            "110/110 [==============================] - 8s 73ms/step - loss: 0.5891 - val_loss: 0.7073\n",
            "Epoch 710/1500\n",
            "876/876 [==============================] - 2s 3ms/step\n",
            "110/110 [==============================] - 5s 50ms/step - loss: 0.4652 - val_loss: 0.6212\n",
            "Epoch 711/1500\n",
            "876/876 [==============================] - 3s 3ms/step\n",
            "110/110 [==============================] - 6s 55ms/step - loss: 0.7540 - val_loss: 0.9112\n",
            "Epoch 712/1500\n",
            "876/876 [==============================] - 3s 4ms/step\n",
            "110/110 [==============================] - 10s 90ms/step - loss: 0.6818 - val_loss: 0.6647\n",
            "Epoch 713/1500\n",
            "876/876 [==============================] - 3s 3ms/step\n",
            "110/110 [==============================] - 6s 50ms/step - loss: 0.5996 - val_loss: 0.8151\n",
            "Epoch 714/1500\n",
            "876/876 [==============================] - 3s 3ms/step\n",
            "110/110 [==============================] - 8s 72ms/step - loss: 0.6335 - val_loss: 0.8920\n",
            "Epoch 715/1500\n",
            "876/876 [==============================] - 2s 3ms/step\n",
            "110/110 [==============================] - 5s 50ms/step - loss: 0.5916 - val_loss: 0.9457\n",
            "Epoch 716/1500\n",
            "876/876 [==============================] - 3s 3ms/step\n",
            "110/110 [==============================] - 8s 73ms/step - loss: 1.1503 - val_loss: 3.0048\n",
            "Epoch 717/1500\n",
            "876/876 [==============================] - 3s 3ms/step\n",
            "110/110 [==============================] - 8s 72ms/step - loss: 0.6354 - val_loss: 0.6642\n",
            "Epoch 718/1500\n",
            "876/876 [==============================] - 3s 4ms/step\n",
            "110/110 [==============================] - 9s 78ms/step - loss: 0.7143 - val_loss: 0.6894\n",
            "Epoch 719/1500\n",
            "876/876 [==============================] - 3s 3ms/step\n",
            "110/110 [==============================] - 6s 52ms/step - loss: 0.5565 - val_loss: 0.6310\n",
            "Epoch 720/1500\n",
            "876/876 [==============================] - 3s 3ms/step\n",
            "110/110 [==============================] - 8s 73ms/step - loss: 0.4706 - val_loss: 1.1295\n",
            "Epoch 721/1500\n",
            "876/876 [==============================] - 3s 3ms/step\n",
            "110/110 [==============================] - 6s 52ms/step - loss: 0.5363 - val_loss: 2.8377\n",
            "Epoch 722/1500\n",
            "876/876 [==============================] - 3s 4ms/step\n",
            "110/110 [==============================] - 8s 73ms/step - loss: 0.7168 - val_loss: 0.7581\n",
            "Epoch 723/1500\n",
            "876/876 [==============================] - 3s 3ms/step\n",
            "110/110 [==============================] - 10s 94ms/step - loss: 0.6432 - val_loss: 0.8097\n",
            "Epoch 724/1500\n",
            "876/876 [==============================] - 3s 3ms/step\n",
            "110/110 [==============================] - 8s 73ms/step - loss: 0.6231 - val_loss: 0.9173\n",
            "Epoch 725/1500\n",
            "876/876 [==============================] - 3s 3ms/step\n",
            "110/110 [==============================] - 6s 51ms/step - loss: 0.6940 - val_loss: 2.2120\n",
            "Epoch 726/1500\n",
            "876/876 [==============================] - 3s 3ms/step\n",
            "110/110 [==============================] - 6s 54ms/step - loss: 0.6449 - val_loss: 1.0092\n",
            "Epoch 727/1500\n",
            "876/876 [==============================] - 3s 3ms/step\n",
            "110/110 [==============================] - 8s 70ms/step - loss: 0.6005 - val_loss: 0.6739\n",
            "Epoch 728/1500\n",
            "876/876 [==============================] - 3s 3ms/step\n",
            "110/110 [==============================] - 8s 73ms/step - loss: 0.5817 - val_loss: 0.6061\n",
            "Epoch 729/1500\n",
            "876/876 [==============================] - 3s 3ms/step\n",
            "110/110 [==============================] - 10s 89ms/step - loss: 0.7621 - val_loss: 0.6644\n",
            "Epoch 730/1500\n",
            "876/876 [==============================] - 3s 3ms/step\n",
            "110/110 [==============================] - 8s 72ms/step - loss: 1.1034 - val_loss: 0.7339\n",
            "Epoch 731/1500\n",
            "876/876 [==============================] - 3s 3ms/step\n",
            "110/110 [==============================] - 7s 63ms/step - loss: 0.6646 - val_loss: 0.6883\n",
            "Epoch 732/1500\n",
            "876/876 [==============================] - 3s 3ms/step\n",
            "110/110 [==============================] - 6s 51ms/step - loss: 0.5103 - val_loss: 0.8323\n",
            "Epoch 733/1500\n",
            "876/876 [==============================] - 3s 3ms/step\n",
            "110/110 [==============================] - 9s 85ms/step - loss: 0.5001 - val_loss: 0.5863\n",
            "Epoch 734/1500\n",
            "876/876 [==============================] - 2s 3ms/step\n",
            "110/110 [==============================] - 6s 52ms/step - loss: 0.4480 - val_loss: 0.6515\n",
            "Epoch 735/1500\n",
            "876/876 [==============================] - 3s 3ms/step\n",
            "110/110 [==============================] - 8s 75ms/step - loss: 1.0204 - val_loss: 0.8826\n",
            "Epoch 736/1500\n",
            "876/876 [==============================] - 3s 3ms/step\n",
            "110/110 [==============================] - 8s 73ms/step - loss: 1.4558 - val_loss: 0.8517\n",
            "Epoch 737/1500\n",
            "876/876 [==============================] - 3s 4ms/step\n",
            "110/110 [==============================] - 8s 69ms/step - loss: 0.5498 - val_loss: 0.9120\n",
            "Epoch 738/1500\n",
            "876/876 [==============================] - 2s 3ms/step\n",
            "110/110 [==============================] - 6s 53ms/step - loss: 0.6617 - val_loss: 0.8842\n",
            "Epoch 739/1500\n",
            "876/876 [==============================] - 3s 3ms/step\n",
            "110/110 [==============================] - 8s 73ms/step - loss: 0.6829 - val_loss: 1.4407\n",
            "Epoch 740/1500\n",
            "876/876 [==============================] - 3s 3ms/step\n",
            "110/110 [==============================] - 8s 73ms/step - loss: 1.0162 - val_loss: 1.0335\n",
            "Epoch 741/1500\n",
            "876/876 [==============================] - 3s 4ms/step\n",
            "110/110 [==============================] - 9s 78ms/step - loss: 0.5555 - val_loss: 0.6631\n",
            "Epoch 742/1500\n",
            "876/876 [==============================] - 3s 3ms/step\n",
            "110/110 [==============================] - 6s 52ms/step - loss: 0.6347 - val_loss: 0.6350\n",
            "Epoch 743/1500\n",
            "876/876 [==============================] - 3s 3ms/step\n",
            "110/110 [==============================] - 6s 56ms/step - loss: 0.7991 - val_loss: 0.7306\n",
            "Epoch 744/1500\n",
            "876/876 [==============================] - 3s 3ms/step\n",
            "110/110 [==============================] - 8s 69ms/step - loss: 0.4201 - val_loss: 0.5690\n",
            "Epoch 745/1500\n",
            "876/876 [==============================] - 3s 3ms/step\n",
            "110/110 [==============================] - 8s 73ms/step - loss: 0.5644 - val_loss: 0.7292\n",
            "Epoch 746/1500\n",
            "876/876 [==============================] - 3s 3ms/step\n",
            "110/110 [==============================] - 8s 77ms/step - loss: 0.6742 - val_loss: 1.4484\n",
            "Epoch 747/1500\n",
            "876/876 [==============================] - 2s 3ms/step\n",
            "110/110 [==============================] - 9s 85ms/step - loss: 0.6473 - val_loss: 1.3144\n",
            "Epoch 748/1500\n",
            "876/876 [==============================] - 2s 3ms/step\n",
            "110/110 [==============================] - 7s 60ms/step - loss: 0.6375 - val_loss: 0.5985\n",
            "Epoch 749/1500\n",
            "876/876 [==============================] - 3s 3ms/step\n",
            "110/110 [==============================] - 6s 51ms/step - loss: 0.4849 - val_loss: 0.7395\n",
            "Epoch 750/1500\n",
            "876/876 [==============================] - 3s 3ms/step\n",
            "110/110 [==============================] - 8s 69ms/step - loss: 0.7902 - val_loss: 1.5010\n",
            "Epoch 751/1500\n",
            "876/876 [==============================] - 3s 3ms/step\n",
            "110/110 [==============================] - 6s 51ms/step - loss: 0.6060 - val_loss: 0.6026\n",
            "Epoch 752/1500\n",
            "876/876 [==============================] - 3s 3ms/step\n",
            "110/110 [==============================] - 6s 55ms/step - loss: 0.6748 - val_loss: 0.7604\n",
            "Epoch 753/1500\n",
            "876/876 [==============================] - 3s 3ms/step\n",
            "110/110 [==============================] - 7s 68ms/step - loss: 0.4676 - val_loss: 0.8079\n",
            "Epoch 754/1500\n",
            "876/876 [==============================] - 2s 3ms/step\n",
            "110/110 [==============================] - 6s 50ms/step - loss: 0.5225 - val_loss: 0.8055\n",
            "Epoch 755/1500\n",
            "876/876 [==============================] - 3s 4ms/step\n",
            "110/110 [==============================] - 9s 78ms/step - loss: 0.7491 - val_loss: 2.8895\n",
            "Epoch 756/1500\n",
            "876/876 [==============================] - 3s 3ms/step\n",
            "110/110 [==============================] - 8s 72ms/step - loss: 1.1162 - val_loss: 1.0035\n",
            "Epoch 757/1500\n",
            "876/876 [==============================] - 3s 4ms/step\n",
            "110/110 [==============================] - 8s 69ms/step - loss: 0.5332 - val_loss: 0.6399\n",
            "Epoch 758/1500\n",
            "876/876 [==============================] - 2s 3ms/step\n",
            "110/110 [==============================] - 8s 73ms/step - loss: 0.8325 - val_loss: 0.8371\n",
            "Epoch 759/1500\n",
            "876/876 [==============================] - 3s 4ms/step\n",
            "110/110 [==============================] - 7s 66ms/step - loss: 0.7347 - val_loss: 0.6380\n",
            "Epoch 760/1500\n",
            "876/876 [==============================] - 3s 3ms/step\n",
            "110/110 [==============================] - 9s 79ms/step - loss: 0.4908 - val_loss: 0.5795\n",
            "Epoch 761/1500\n",
            "876/876 [==============================] - 3s 3ms/step\n",
            "110/110 [==============================] - 6s 57ms/step - loss: 0.7754 - val_loss: 3.0006\n",
            "Epoch 762/1500\n",
            "876/876 [==============================] - 3s 3ms/step\n",
            "110/110 [==============================] - 7s 65ms/step - loss: 0.6088 - val_loss: 0.7311\n",
            "Epoch 763/1500\n",
            "876/876 [==============================] - 2s 3ms/step\n",
            "110/110 [==============================] - 6s 51ms/step - loss: 0.7413 - val_loss: 0.7033\n",
            "Epoch 764/1500\n",
            "876/876 [==============================] - 3s 4ms/step\n",
            "110/110 [==============================] - 9s 85ms/step - loss: 0.5702 - val_loss: 0.5827\n",
            "Epoch 765/1500\n",
            "876/876 [==============================] - 3s 3ms/step\n",
            "110/110 [==============================] - 8s 72ms/step - loss: 0.5079 - val_loss: 1.8481\n",
            "Epoch 766/1500\n",
            "876/876 [==============================] - 3s 4ms/step\n",
            "110/110 [==============================] - 8s 72ms/step - loss: 0.9275 - val_loss: 0.7525\n",
            "Epoch 767/1500\n",
            "876/876 [==============================] - 2s 3ms/step\n",
            "110/110 [==============================] - 6s 51ms/step - loss: 0.6299 - val_loss: 0.5847\n",
            "Epoch 768/1500\n",
            "876/876 [==============================] - 3s 3ms/step\n",
            "110/110 [==============================] - 8s 72ms/step - loss: 0.5686 - val_loss: 1.0152\n",
            "Epoch 769/1500\n",
            "876/876 [==============================] - 3s 3ms/step\n",
            "110/110 [==============================] - 8s 69ms/step - loss: 0.5136 - val_loss: 0.8669\n",
            "Epoch 770/1500\n",
            "876/876 [==============================] - 3s 3ms/step\n",
            "110/110 [==============================] - 8s 73ms/step - loss: 0.6116 - val_loss: 1.5367\n",
            "Epoch 771/1500\n",
            "876/876 [==============================] - 3s 3ms/step\n",
            "110/110 [==============================] - 8s 72ms/step - loss: 0.5541 - val_loss: 0.7783\n",
            "Epoch 772/1500\n",
            "876/876 [==============================] - 3s 3ms/step\n",
            "110/110 [==============================] - 8s 73ms/step - loss: 0.8292 - val_loss: 1.1699\n",
            "Epoch 773/1500\n",
            "876/876 [==============================] - 3s 4ms/step\n",
            "110/110 [==============================] - 9s 83ms/step - loss: 0.7542 - val_loss: 1.9310\n",
            "Epoch 774/1500\n",
            "876/876 [==============================] - 3s 3ms/step\n",
            "110/110 [==============================] - 8s 73ms/step - loss: 0.4624 - val_loss: 0.7236\n",
            "Epoch 775/1500\n",
            "876/876 [==============================] - 3s 4ms/step\n",
            "110/110 [==============================] - 8s 70ms/step - loss: 1.1169 - val_loss: 0.9334\n",
            "Epoch 776/1500\n",
            "876/876 [==============================] - 3s 3ms/step\n",
            "110/110 [==============================] - 6s 54ms/step - loss: 0.5177 - val_loss: 0.6322\n",
            "Epoch 777/1500\n",
            "876/876 [==============================] - 3s 3ms/step\n",
            "110/110 [==============================] - 6s 54ms/step - loss: 0.4146 - val_loss: 0.6055\n",
            "Epoch 778/1500\n",
            "876/876 [==============================] - 3s 3ms/step\n",
            "110/110 [==============================] - 8s 71ms/step - loss: 0.7895 - val_loss: 0.7278\n",
            "Epoch 779/1500\n",
            "876/876 [==============================] - 3s 3ms/step\n",
            "110/110 [==============================] - 8s 73ms/step - loss: 0.6011 - val_loss: 0.5778\n",
            "Epoch 780/1500\n",
            "876/876 [==============================] - 3s 3ms/step\n",
            "110/110 [==============================] - 8s 72ms/step - loss: 0.7504 - val_loss: 0.7496\n",
            "Epoch 781/1500\n",
            "876/876 [==============================] - 3s 3ms/step\n",
            "110/110 [==============================] - 6s 52ms/step - loss: 0.5931 - val_loss: 0.8902\n",
            "Epoch 782/1500\n",
            "876/876 [==============================] - 3s 3ms/step\n",
            "110/110 [==============================] - 8s 73ms/step - loss: 0.6141 - val_loss: 0.6489\n",
            "Epoch 783/1500\n",
            "876/876 [==============================] - 3s 3ms/step\n",
            "110/110 [==============================] - 8s 73ms/step - loss: 0.7718 - val_loss: 1.6610\n",
            "Epoch 784/1500\n",
            "876/876 [==============================] - 3s 4ms/step\n",
            "110/110 [==============================] - 7s 65ms/step - loss: 0.7852 - val_loss: 0.9751\n",
            "Epoch 785/1500\n",
            "876/876 [==============================] - 3s 3ms/step\n",
            "110/110 [==============================] - 7s 61ms/step - loss: 1.0204 - val_loss: 0.6153\n",
            "Epoch 786/1500\n",
            "876/876 [==============================] - 3s 3ms/step\n",
            "110/110 [==============================] - 8s 73ms/step - loss: 0.4700 - val_loss: 0.5998\n",
            "Epoch 787/1500\n",
            "876/876 [==============================] - 3s 3ms/step\n",
            "110/110 [==============================] - 8s 75ms/step - loss: 0.5817 - val_loss: 1.2507\n",
            "Epoch 788/1500\n",
            "876/876 [==============================] - 3s 3ms/step\n",
            "110/110 [==============================] - 7s 64ms/step - loss: 0.6047 - val_loss: 0.7620\n",
            "Epoch 789/1500\n",
            "876/876 [==============================] - 3s 3ms/step\n",
            "110/110 [==============================] - 7s 60ms/step - loss: 0.9889 - val_loss: 1.3230\n",
            "Epoch 790/1500\n",
            "876/876 [==============================] - 3s 3ms/step\n",
            "110/110 [==============================] - 6s 51ms/step - loss: 0.5702 - val_loss: 0.8793\n",
            "Epoch 791/1500\n",
            "876/876 [==============================] - 3s 3ms/step\n",
            "110/110 [==============================] - 8s 72ms/step - loss: 0.4380 - val_loss: 0.7229\n",
            "Epoch 792/1500\n",
            "876/876 [==============================] - 3s 3ms/step\n",
            "110/110 [==============================] - 8s 73ms/step - loss: 0.5831 - val_loss: 1.2042\n",
            "Epoch 793/1500\n",
            "876/876 [==============================] - 3s 4ms/step\n",
            "110/110 [==============================] - 8s 75ms/step - loss: 0.8687 - val_loss: 0.6804\n",
            "Epoch 794/1500\n",
            "876/876 [==============================] - 3s 3ms/step\n",
            "110/110 [==============================] - 8s 70ms/step - loss: 0.5925 - val_loss: 2.4450\n",
            "Epoch 795/1500\n",
            "876/876 [==============================] - 2s 3ms/step\n",
            "110/110 [==============================] - 6s 52ms/step - loss: 0.6995 - val_loss: 0.7394\n",
            "Epoch 796/1500\n",
            "876/876 [==============================] - 3s 4ms/step\n",
            "110/110 [==============================] - 10s 91ms/step - loss: 0.4844 - val_loss: 0.6917\n",
            "Epoch 797/1500\n",
            "876/876 [==============================] - 2s 3ms/step\n",
            "110/110 [==============================] - 8s 73ms/step - loss: 0.6466 - val_loss: 0.7158\n",
            "Epoch 798/1500\n",
            "876/876 [==============================] - 3s 3ms/step\n",
            "110/110 [==============================] - 10s 90ms/step - loss: 0.5138 - val_loss: 0.6697\n",
            "Epoch 799/1500\n",
            "876/876 [==============================] - 3s 3ms/step\n",
            "110/110 [==============================] - 8s 73ms/step - loss: 0.9251 - val_loss: 0.9376\n",
            "Epoch 800/1500\n",
            "876/876 [==============================] - 3s 3ms/step\n",
            "110/110 [==============================] - 10s 89ms/step - loss: 0.6466 - val_loss: 1.4832\n",
            "Epoch 801/1500\n",
            "876/876 [==============================] - 3s 3ms/step\n",
            "110/110 [==============================] - 6s 52ms/step - loss: 1.1056 - val_loss: 0.8546\n",
            "Epoch 802/1500\n",
            "876/876 [==============================] - 3s 3ms/step\n",
            "110/110 [==============================] - 10s 91ms/step - loss: 0.5709 - val_loss: 0.6730\n",
            "Epoch 803/1500\n",
            "876/876 [==============================] - 3s 3ms/step\n",
            "110/110 [==============================] - 8s 74ms/step - loss: 0.4161 - val_loss: 0.8397\n",
            "Epoch 804/1500\n",
            "876/876 [==============================] - 3s 3ms/step\n",
            "110/110 [==============================] - 10s 89ms/step - loss: 0.6305 - val_loss: 0.8622\n",
            "Epoch 805/1500\n",
            "876/876 [==============================] - 3s 3ms/step\n",
            "110/110 [==============================] - 6s 55ms/step - loss: 0.5755 - val_loss: 0.5518\n",
            "Epoch 806/1500\n",
            "876/876 [==============================] - 3s 3ms/step\n",
            "110/110 [==============================] - 10s 92ms/step - loss: 0.7716 - val_loss: 0.6691\n",
            "Epoch 807/1500\n",
            "876/876 [==============================] - 3s 3ms/step\n",
            "110/110 [==============================] - 8s 73ms/step - loss: 0.4601 - val_loss: 0.7617\n",
            "Epoch 808/1500\n",
            "876/876 [==============================] - 3s 3ms/step\n",
            "110/110 [==============================] - 6s 53ms/step - loss: 1.3116 - val_loss: 0.7222\n",
            "Epoch 809/1500\n",
            "876/876 [==============================] - 3s 3ms/step\n",
            "110/110 [==============================] - 8s 73ms/step - loss: 0.4974 - val_loss: 0.6713\n",
            "Epoch 810/1500\n",
            "876/876 [==============================] - 3s 3ms/step\n",
            "110/110 [==============================] - 8s 74ms/step - loss: 0.5949 - val_loss: 1.5522\n",
            "Epoch 811/1500\n",
            "876/876 [==============================] - 3s 4ms/step\n",
            "110/110 [==============================] - 7s 66ms/step - loss: 0.6203 - val_loss: 0.8025\n",
            "Epoch 812/1500\n",
            "876/876 [==============================] - 3s 3ms/step\n",
            "110/110 [==============================] - 7s 61ms/step - loss: 0.5334 - val_loss: 0.8245\n",
            "Epoch 813/1500\n",
            "876/876 [==============================] - 3s 3ms/step\n",
            "110/110 [==============================] - 6s 56ms/step - loss: 0.4614 - val_loss: 0.7590\n",
            "Epoch 814/1500\n",
            "876/876 [==============================] - 3s 4ms/step\n",
            "110/110 [==============================] - 10s 95ms/step - loss: 0.4751 - val_loss: 0.7020\n",
            "Epoch 815/1500\n",
            "876/876 [==============================] - 3s 3ms/step\n",
            "110/110 [==============================] - 6s 54ms/step - loss: 0.7209 - val_loss: 0.9554\n",
            "Epoch 816/1500\n",
            "876/876 [==============================] - 3s 3ms/step\n",
            "110/110 [==============================] - 8s 74ms/step - loss: 0.4554 - val_loss: 0.7580\n",
            "Epoch 817/1500\n",
            "876/876 [==============================] - 3s 3ms/step\n",
            "110/110 [==============================] - 6s 53ms/step - loss: 1.2330 - val_loss: 2.3116\n",
            "Epoch 818/1500\n",
            "876/876 [==============================] - 3s 3ms/step\n",
            "110/110 [==============================] - 8s 73ms/step - loss: 0.6771 - val_loss: 0.5829\n",
            "Epoch 819/1500\n",
            "876/876 [==============================] - 3s 3ms/step\n",
            "110/110 [==============================] - 6s 53ms/step - loss: 0.7688 - val_loss: 0.6517\n",
            "Epoch 820/1500\n",
            "876/876 [==============================] - 3s 3ms/step\n",
            "110/110 [==============================] - 8s 75ms/step - loss: 0.8710 - val_loss: 0.9128\n",
            "Epoch 821/1500\n",
            "876/876 [==============================] - 3s 3ms/step\n",
            "110/110 [==============================] - 8s 73ms/step - loss: 0.6599 - val_loss: 0.6907\n",
            "Epoch 822/1500\n",
            "876/876 [==============================] - 3s 3ms/step\n",
            "110/110 [==============================] - 8s 74ms/step - loss: 0.4370 - val_loss: 0.7324\n",
            "Epoch 823/1500\n",
            "876/876 [==============================] - 3s 3ms/step\n",
            "110/110 [==============================] - 10s 91ms/step - loss: 0.6330 - val_loss: 0.6597\n",
            "Epoch 824/1500\n",
            "876/876 [==============================] - 3s 3ms/step\n",
            "110/110 [==============================] - 6s 53ms/step - loss: 0.5080 - val_loss: 0.6640\n",
            "Epoch 825/1500\n",
            "876/876 [==============================] - 3s 4ms/step\n",
            "110/110 [==============================] - 8s 73ms/step - loss: 0.7207 - val_loss: 0.9626\n",
            "Epoch 826/1500\n",
            "876/876 [==============================] - 3s 3ms/step\n",
            "110/110 [==============================] - 6s 54ms/step - loss: 0.8179 - val_loss: 1.2413\n",
            "Epoch 827/1500\n",
            "876/876 [==============================] - 3s 3ms/step\n",
            "110/110 [==============================] - 6s 57ms/step - loss: 0.4965 - val_loss: 0.8627\n",
            "Epoch 828/1500\n",
            "876/876 [==============================] - 3s 3ms/step\n",
            "110/110 [==============================] - 8s 70ms/step - loss: 0.4910 - val_loss: 0.6010\n",
            "Epoch 829/1500\n",
            "876/876 [==============================] - 3s 3ms/step\n",
            "110/110 [==============================] - 8s 74ms/step - loss: 0.7628 - val_loss: 1.0136\n",
            "Epoch 830/1500\n",
            "876/876 [==============================] - 3s 4ms/step\n",
            "110/110 [==============================] - 10s 90ms/step - loss: 0.4766 - val_loss: 0.6729\n",
            "Epoch 831/1500\n",
            "876/876 [==============================] - 3s 3ms/step\n",
            "110/110 [==============================] - 8s 74ms/step - loss: 0.8581 - val_loss: 0.7537\n",
            "Epoch 832/1500\n",
            "876/876 [==============================] - 3s 3ms/step\n",
            "110/110 [==============================] - 10s 91ms/step - loss: 0.8935 - val_loss: 1.3237\n",
            "Epoch 833/1500\n",
            "876/876 [==============================] - 3s 3ms/step\n",
            "110/110 [==============================] - 8s 75ms/step - loss: 0.5628 - val_loss: 0.6603\n",
            "Epoch 834/1500\n",
            "876/876 [==============================] - 3s 4ms/step\n",
            "110/110 [==============================] - 9s 82ms/step - loss: 0.5441 - val_loss: 0.6454\n",
            "Epoch 835/1500\n",
            "876/876 [==============================] - 3s 3ms/step\n",
            "110/110 [==============================] - 7s 66ms/step - loss: 0.3878 - val_loss: 1.4820\n",
            "Epoch 836/1500\n",
            "876/876 [==============================] - 3s 3ms/step\n",
            "110/110 [==============================] - 7s 59ms/step - loss: 0.6279 - val_loss: 0.6615\n",
            "Epoch 837/1500\n",
            "876/876 [==============================] - 3s 3ms/step\n",
            "110/110 [==============================] - 8s 76ms/step - loss: 0.5970 - val_loss: 1.0699\n",
            "Epoch 838/1500\n",
            "876/876 [==============================] - 3s 3ms/step\n",
            "110/110 [==============================] - 8s 75ms/step - loss: 0.5394 - val_loss: 0.6390\n",
            "Epoch 839/1500\n",
            "876/876 [==============================] - 3s 3ms/step\n",
            "110/110 [==============================] - 9s 80ms/step - loss: 0.8496 - val_loss: 1.1241\n",
            "Epoch 840/1500\n",
            "876/876 [==============================] - 3s 3ms/step\n",
            "110/110 [==============================] - 8s 74ms/step - loss: 0.7851 - val_loss: 1.6931\n",
            "Epoch 841/1500\n",
            "876/876 [==============================] - 3s 4ms/step\n",
            "110/110 [==============================] - 8s 75ms/step - loss: 0.5974 - val_loss: 0.6463\n",
            "Epoch 842/1500\n",
            "876/876 [==============================] - 3s 3ms/step\n",
            "110/110 [==============================] - 8s 76ms/step - loss: 0.6603 - val_loss: 2.0966\n",
            "Epoch 843/1500\n",
            "876/876 [==============================] - 3s 4ms/step\n",
            "110/110 [==============================] - 9s 85ms/step - loss: 0.6455 - val_loss: 1.2701\n",
            "Epoch 844/1500\n",
            "876/876 [==============================] - 3s 3ms/step\n",
            "110/110 [==============================] - 10s 88ms/step - loss: 0.7063 - val_loss: 0.8382\n",
            "Epoch 845/1500\n",
            "876/876 [==============================] - 3s 3ms/step\n",
            "110/110 [==============================] - 10s 91ms/step - loss: 0.5694 - val_loss: 0.6572\n",
            "Epoch 846/1500\n",
            "876/876 [==============================] - 3s 3ms/step\n",
            "110/110 [==============================] - 8s 75ms/step - loss: 0.5020 - val_loss: 0.9422\n",
            "Epoch 847/1500\n",
            "876/876 [==============================] - 3s 3ms/step\n",
            "110/110 [==============================] - 7s 68ms/step - loss: 0.5852 - val_loss: 0.6195\n",
            "Epoch 848/1500\n",
            "876/876 [==============================] - 3s 3ms/step\n",
            "110/110 [==============================] - 8s 74ms/step - loss: 0.6417 - val_loss: 0.7747\n",
            "Epoch 849/1500\n",
            "876/876 [==============================] - 3s 3ms/step\n",
            "110/110 [==============================] - 8s 69ms/step - loss: 0.5656 - val_loss: 0.6643\n",
            "Epoch 850/1500\n",
            "876/876 [==============================] - 3s 3ms/step\n",
            "110/110 [==============================] - 6s 54ms/step - loss: 0.9685 - val_loss: 1.2448\n",
            "Epoch 851/1500\n",
            "876/876 [==============================] - 3s 4ms/step\n",
            "110/110 [==============================] - 8s 71ms/step - loss: 0.6036 - val_loss: 1.2286\n",
            "Epoch 852/1500\n",
            "876/876 [==============================] - 3s 3ms/step\n",
            "110/110 [==============================] - 6s 54ms/step - loss: 0.7716 - val_loss: 0.8849\n",
            "Epoch 853/1500\n",
            "876/876 [==============================] - 3s 4ms/step\n",
            "110/110 [==============================] - 7s 60ms/step - loss: 0.7176 - val_loss: 0.7548\n",
            "Epoch 854/1500\n",
            "876/876 [==============================] - 3s 4ms/step\n",
            "110/110 [==============================] - 10s 94ms/step - loss: 0.5495 - val_loss: 1.4787\n",
            "Epoch 855/1500\n",
            "876/876 [==============================] - 3s 3ms/step\n",
            "110/110 [==============================] - 8s 74ms/step - loss: 0.6481 - val_loss: 2.9522\n",
            "Epoch 856/1500\n",
            "876/876 [==============================] - 3s 4ms/step\n",
            "110/110 [==============================] - 9s 85ms/step - loss: 0.4889 - val_loss: 1.0738\n",
            "Epoch 857/1500\n",
            "876/876 [==============================] - 3s 3ms/step\n",
            "110/110 [==============================] - 6s 55ms/step - loss: 0.4839 - val_loss: 1.6733\n",
            "Epoch 858/1500\n",
            "876/876 [==============================] - 3s 3ms/step\n",
            "110/110 [==============================] - 8s 77ms/step - loss: 0.6021 - val_loss: 1.0306\n",
            "Epoch 859/1500\n",
            "876/876 [==============================] - 3s 3ms/step\n",
            "110/110 [==============================] - 8s 75ms/step - loss: 0.4234 - val_loss: 0.5512\n",
            "Epoch 860/1500\n",
            "876/876 [==============================] - 3s 4ms/step\n",
            "110/110 [==============================] - 9s 85ms/step - loss: 0.5439 - val_loss: 0.8138\n",
            "Epoch 861/1500\n",
            "876/876 [==============================] - 3s 3ms/step\n",
            "110/110 [==============================] - 6s 55ms/step - loss: 0.5003 - val_loss: 1.4128\n",
            "Epoch 862/1500\n",
            "876/876 [==============================] - 3s 3ms/step\n",
            "110/110 [==============================] - 7s 63ms/step - loss: 0.7379 - val_loss: 0.7743\n",
            "Epoch 863/1500\n",
            "876/876 [==============================] - 3s 3ms/step\n",
            "110/110 [==============================] - 7s 64ms/step - loss: 0.6585 - val_loss: 0.6827\n",
            "Epoch 864/1500\n",
            "876/876 [==============================] - 3s 3ms/step\n",
            "110/110 [==============================] - 6s 53ms/step - loss: 0.5960 - val_loss: 0.6537\n",
            "Epoch 865/1500\n",
            "876/876 [==============================] - 3s 4ms/step\n",
            "110/110 [==============================] - 8s 73ms/step - loss: 0.4385 - val_loss: 0.8087\n",
            "Epoch 866/1500\n",
            "876/876 [==============================] - 3s 3ms/step\n",
            "110/110 [==============================] - 8s 75ms/step - loss: 0.6470 - val_loss: 2.8546\n",
            "Epoch 867/1500\n",
            "876/876 [==============================] - 3s 3ms/step\n",
            "110/110 [==============================] - 9s 82ms/step - loss: 0.5939 - val_loss: 0.7666\n",
            "Epoch 868/1500\n",
            "876/876 [==============================] - 3s 3ms/step\n",
            "110/110 [==============================] - 6s 52ms/step - loss: 0.6957 - val_loss: 0.6932\n",
            "Epoch 869/1500\n",
            "876/876 [==============================] - 3s 4ms/step\n",
            "110/110 [==============================] - 7s 60ms/step - loss: 0.5006 - val_loss: 0.7699\n",
            "Epoch 870/1500\n",
            "876/876 [==============================] - 3s 3ms/step\n",
            "110/110 [==============================] - 7s 67ms/step - loss: 0.7777 - val_loss: 0.8086\n",
            "Epoch 871/1500\n",
            "876/876 [==============================] - 3s 3ms/step\n",
            "110/110 [==============================] - 6s 54ms/step - loss: 0.6128 - val_loss: 2.4811\n",
            "Epoch 872/1500\n",
            "876/876 [==============================] - 3s 3ms/step\n",
            "110/110 [==============================] - 7s 67ms/step - loss: 0.7002 - val_loss: 0.6724\n",
            "Epoch 873/1500\n",
            "876/876 [==============================] - 3s 3ms/step\n",
            "110/110 [==============================] - 7s 63ms/step - loss: 0.5117 - val_loss: 1.0523\n",
            "Epoch 874/1500\n",
            "876/876 [==============================] - 3s 3ms/step\n",
            "110/110 [==============================] - 10s 89ms/step - loss: 0.6080 - val_loss: 0.6412\n",
            "Epoch 875/1500\n",
            "876/876 [==============================] - 3s 3ms/step\n",
            "110/110 [==============================] - 8s 74ms/step - loss: 1.5221 - val_loss: 1.2163\n",
            "Epoch 876/1500\n",
            "876/876 [==============================] - 3s 4ms/step\n",
            "110/110 [==============================] - 9s 82ms/step - loss: 0.4531 - val_loss: 0.9177\n",
            "Epoch 877/1500\n",
            "876/876 [==============================] - 3s 3ms/step\n",
            "110/110 [==============================] - 8s 75ms/step - loss: 0.4626 - val_loss: 0.6842\n",
            "Epoch 878/1500\n",
            "876/876 [==============================] - 3s 4ms/step\n",
            "110/110 [==============================] - 8s 72ms/step - loss: 0.5302 - val_loss: 0.6349\n",
            "Epoch 879/1500\n",
            "876/876 [==============================] - 3s 3ms/step\n",
            "110/110 [==============================] - 8s 76ms/step - loss: 0.5831 - val_loss: 0.8204\n",
            "Epoch 880/1500\n",
            "876/876 [==============================] - 3s 3ms/step\n",
            "110/110 [==============================] - 9s 78ms/step - loss: 0.6132 - val_loss: 0.7297\n",
            "Epoch 881/1500\n",
            "876/876 [==============================] - 3s 3ms/step\n",
            "110/110 [==============================] - 6s 55ms/step - loss: 0.7523 - val_loss: 1.1978\n",
            "Epoch 882/1500\n",
            "876/876 [==============================] - 3s 3ms/step\n",
            "110/110 [==============================] - 7s 59ms/step - loss: 0.6031 - val_loss: 1.0568\n",
            "Epoch 883/1500\n",
            "876/876 [==============================] - 3s 3ms/step\n",
            "110/110 [==============================] - 10s 89ms/step - loss: 0.7207 - val_loss: 0.8889\n",
            "Epoch 884/1500\n",
            "876/876 [==============================] - 3s 3ms/step\n",
            "110/110 [==============================] - 6s 56ms/step - loss: 0.5670 - val_loss: 0.7548\n",
            "Epoch 885/1500\n",
            "876/876 [==============================] - 3s 3ms/step\n",
            "110/110 [==============================] - 10s 90ms/step - loss: 0.7436 - val_loss: 1.0321\n",
            "Epoch 886/1500\n",
            "876/876 [==============================] - 3s 3ms/step\n",
            "110/110 [==============================] - 6s 57ms/step - loss: 0.7248 - val_loss: 1.2231\n",
            "Epoch 887/1500\n",
            "876/876 [==============================] - 3s 3ms/step\n",
            "110/110 [==============================] - 8s 73ms/step - loss: 1.0668 - val_loss: 0.7039\n",
            "Epoch 888/1500\n",
            "876/876 [==============================] - 3s 3ms/step\n",
            "110/110 [==============================] - 6s 54ms/step - loss: 0.4205 - val_loss: 0.7469\n",
            "Epoch 889/1500\n",
            "876/876 [==============================] - 3s 4ms/step\n",
            "110/110 [==============================] - 8s 75ms/step - loss: 0.5479 - val_loss: 1.1310\n",
            "Epoch 890/1500\n",
            "876/876 [==============================] - 3s 3ms/step\n",
            "110/110 [==============================] - 10s 93ms/step - loss: 0.7613 - val_loss: 0.7497\n",
            "Epoch 891/1500\n",
            "876/876 [==============================] - 3s 3ms/step\n",
            "110/110 [==============================] - 6s 57ms/step - loss: 0.4094 - val_loss: 0.7206\n",
            "Epoch 892/1500\n",
            "876/876 [==============================] - 3s 4ms/step\n",
            "110/110 [==============================] - 8s 77ms/step - loss: 0.8214 - val_loss: 0.9083\n",
            "Epoch 893/1500\n",
            "876/876 [==============================] - 3s 3ms/step\n",
            "110/110 [==============================] - 10s 88ms/step - loss: 0.5234 - val_loss: 0.6369\n",
            "Epoch 894/1500\n",
            "876/876 [==============================] - 3s 4ms/step\n",
            "110/110 [==============================] - 7s 63ms/step - loss: 0.4645 - val_loss: 0.9397\n",
            "Epoch 895/1500\n",
            "876/876 [==============================] - 3s 3ms/step\n",
            "110/110 [==============================] - 7s 67ms/step - loss: 0.4828 - val_loss: 0.5923\n",
            "Epoch 896/1500\n",
            "876/876 [==============================] - 3s 3ms/step\n",
            "110/110 [==============================] - 8s 74ms/step - loss: 0.7657 - val_loss: 1.9118\n",
            "Epoch 897/1500\n",
            "876/876 [==============================] - 3s 3ms/step\n",
            "110/110 [==============================] - 9s 86ms/step - loss: 0.4548 - val_loss: 0.6047\n",
            "Epoch 898/1500\n",
            "876/876 [==============================] - 3s 3ms/step\n",
            "110/110 [==============================] - 6s 59ms/step - loss: 0.6504 - val_loss: 1.0680\n",
            "Epoch 899/1500\n",
            "876/876 [==============================] - 3s 3ms/step\n",
            "110/110 [==============================] - 8s 70ms/step - loss: 0.7271 - val_loss: 0.7756\n",
            "Epoch 900/1500\n",
            "876/876 [==============================] - 3s 3ms/step\n",
            "110/110 [==============================] - 8s 75ms/step - loss: 0.4436 - val_loss: 0.6553\n",
            "Epoch 901/1500\n",
            "876/876 [==============================] - 3s 4ms/step\n",
            "110/110 [==============================] - 8s 75ms/step - loss: 0.6946 - val_loss: 0.9137\n",
            "Epoch 902/1500\n",
            "876/876 [==============================] - 3s 3ms/step\n",
            "110/110 [==============================] - 8s 75ms/step - loss: 0.7632 - val_loss: 0.7316\n",
            "Epoch 903/1500\n",
            "876/876 [==============================] - 3s 4ms/step\n",
            "110/110 [==============================] - 9s 84ms/step - loss: 0.8753 - val_loss: 0.8733\n",
            "Epoch 904/1500\n",
            "876/876 [==============================] - 3s 3ms/step\n",
            "110/110 [==============================] - 6s 53ms/step - loss: 0.7743 - val_loss: 0.6648\n",
            "Epoch 905/1500\n",
            "876/876 [==============================] - 3s 4ms/step\n",
            "110/110 [==============================] - 7s 61ms/step - loss: 0.6221 - val_loss: 0.6707\n",
            "Epoch 906/1500\n",
            "876/876 [==============================] - 3s 3ms/step\n",
            "110/110 [==============================] - 7s 67ms/step - loss: 0.7354 - val_loss: 0.8350\n",
            "Epoch 907/1500\n",
            "876/876 [==============================] - 3s 3ms/step\n",
            "110/110 [==============================] - 6s 54ms/step - loss: 0.4810 - val_loss: 0.8656\n",
            "Epoch 908/1500\n",
            "876/876 [==============================] - 3s 4ms/step\n",
            "110/110 [==============================] - 8s 70ms/step - loss: 0.7419 - val_loss: 0.8852\n",
            "Epoch 909/1500\n",
            "876/876 [==============================] - 3s 3ms/step\n",
            "110/110 [==============================] - 9s 78ms/step - loss: 0.4442 - val_loss: 0.7624\n",
            "Epoch 910/1500\n",
            "876/876 [==============================] - 3s 4ms/step\n",
            "110/110 [==============================] - 7s 66ms/step - loss: 0.6611 - val_loss: 0.8497\n",
            "Epoch 911/1500\n",
            "876/876 [==============================] - 3s 3ms/step\n",
            "110/110 [==============================] - 8s 76ms/step - loss: 0.5736 - val_loss: 0.6480\n",
            "Epoch 912/1500\n",
            "876/876 [==============================] - 3s 4ms/step\n",
            "110/110 [==============================] - 9s 80ms/step - loss: 0.4977 - val_loss: 0.7699\n",
            "Epoch 913/1500\n",
            "876/876 [==============================] - 3s 3ms/step\n",
            "110/110 [==============================] - 10s 92ms/step - loss: 0.4199 - val_loss: 0.5560\n",
            "Epoch 914/1500\n",
            "876/876 [==============================] - 3s 3ms/step\n",
            "110/110 [==============================] - 8s 75ms/step - loss: 0.5382 - val_loss: 1.0526\n",
            "Epoch 915/1500\n",
            "876/876 [==============================] - 3s 3ms/step\n",
            "110/110 [==============================] - 6s 55ms/step - loss: 0.6497 - val_loss: 1.1580\n",
            "Epoch 916/1500\n",
            "876/876 [==============================] - 3s 3ms/step\n",
            "110/110 [==============================] - 8s 74ms/step - loss: 0.6585 - val_loss: 0.6519\n",
            "Epoch 917/1500\n",
            "876/876 [==============================] - 3s 3ms/step\n",
            "110/110 [==============================] - 6s 54ms/step - loss: 1.2604 - val_loss: 2.8440\n",
            "Epoch 918/1500\n",
            "876/876 [==============================] - 3s 3ms/step\n",
            "110/110 [==============================] - 6s 56ms/step - loss: 0.8383 - val_loss: 0.7995\n",
            "Epoch 919/1500\n",
            "876/876 [==============================] - 2s 3ms/step\n",
            "110/110 [==============================] - 10s 92ms/step - loss: 0.4408 - val_loss: 0.8839\n",
            "Epoch 920/1500\n",
            "876/876 [==============================] - 3s 3ms/step\n",
            "110/110 [==============================] - 6s 56ms/step - loss: 0.6715 - val_loss: 1.1181\n",
            "Epoch 921/1500\n",
            "876/876 [==============================] - 3s 3ms/step\n",
            "110/110 [==============================] - 8s 70ms/step - loss: 0.5142 - val_loss: 0.6137\n",
            "Epoch 922/1500\n",
            "876/876 [==============================] - 2s 3ms/step\n",
            "110/110 [==============================] - 8s 75ms/step - loss: 0.4107 - val_loss: 0.7301\n",
            "Epoch 923/1500\n",
            "876/876 [==============================] - 3s 4ms/step\n",
            "110/110 [==============================] - 10s 88ms/step - loss: 0.7334 - val_loss: 0.7831\n",
            "Epoch 924/1500\n",
            "876/876 [==============================] - 3s 3ms/step\n",
            "110/110 [==============================] - 8s 76ms/step - loss: 0.5417 - val_loss: 0.6741\n",
            "Epoch 925/1500\n",
            "876/876 [==============================] - 3s 3ms/step\n",
            "110/110 [==============================] - 8s 72ms/step - loss: 0.8975 - val_loss: 0.7825\n",
            "Epoch 926/1500\n",
            "876/876 [==============================] - 2s 3ms/step\n",
            "110/110 [==============================] - 8s 74ms/step - loss: 0.5000 - val_loss: 0.6878\n",
            "Epoch 927/1500\n",
            "876/876 [==============================] - 3s 4ms/step\n",
            "110/110 [==============================] - 8s 71ms/step - loss: 0.7176 - val_loss: 3.4466\n",
            "Epoch 928/1500\n",
            "876/876 [==============================] - 3s 4ms/step\n",
            "110/110 [==============================] - 9s 85ms/step - loss: 0.9538 - val_loss: 0.6703\n",
            "Epoch 929/1500\n",
            "876/876 [==============================] - 3s 4ms/step\n",
            "110/110 [==============================] - 9s 81ms/step - loss: 0.6130 - val_loss: 1.6184\n",
            "Epoch 930/1500\n",
            "876/876 [==============================] - 3s 3ms/step\n",
            "110/110 [==============================] - 8s 74ms/step - loss: 0.7144 - val_loss: 0.6996\n",
            "Epoch 931/1500\n",
            "876/876 [==============================] - 3s 3ms/step\n",
            "110/110 [==============================] - 8s 70ms/step - loss: 0.6222 - val_loss: 1.3569\n",
            "Epoch 932/1500\n",
            "876/876 [==============================] - 3s 3ms/step\n",
            "110/110 [==============================] - 10s 92ms/step - loss: 0.5391 - val_loss: 0.6676\n",
            "Epoch 933/1500\n",
            "876/876 [==============================] - 3s 3ms/step\n",
            "110/110 [==============================] - 7s 65ms/step - loss: 0.4058 - val_loss: 1.9378\n",
            "Epoch 934/1500\n",
            "876/876 [==============================] - 3s 3ms/step\n",
            "110/110 [==============================] - 7s 60ms/step - loss: 1.1545 - val_loss: 0.6264\n",
            "Epoch 935/1500\n",
            "876/876 [==============================] - 3s 3ms/step\n",
            "110/110 [==============================] - 6s 53ms/step - loss: 0.5779 - val_loss: 0.7687\n",
            "Epoch 936/1500\n",
            "876/876 [==============================] - 3s 3ms/step\n",
            "110/110 [==============================] - 10s 90ms/step - loss: 0.5663 - val_loss: 0.7327\n",
            "Epoch 937/1500\n",
            "876/876 [==============================] - 2s 3ms/step\n",
            "110/110 [==============================] - 6s 53ms/step - loss: 0.4674 - val_loss: 1.0542\n",
            "Epoch 938/1500\n",
            "876/876 [==============================] - 3s 3ms/step\n",
            "110/110 [==============================] - 9s 82ms/step - loss: 0.5070 - val_loss: 0.8286\n",
            "Epoch 939/1500\n",
            "876/876 [==============================] - 3s 3ms/step\n",
            "110/110 [==============================] - 8s 75ms/step - loss: 0.7254 - val_loss: 1.1168\n",
            "Epoch 940/1500\n",
            "876/876 [==============================] - 3s 4ms/step\n",
            "110/110 [==============================] - 10s 87ms/step - loss: 0.7180 - val_loss: 0.6851\n",
            "Epoch 941/1500\n",
            "876/876 [==============================] - 3s 3ms/step\n",
            "110/110 [==============================] - 8s 74ms/step - loss: 0.8474 - val_loss: 1.3150\n",
            "Epoch 942/1500\n",
            "876/876 [==============================] - 3s 3ms/step\n",
            "110/110 [==============================] - 10s 90ms/step - loss: 0.4525 - val_loss: 0.7023\n",
            "Epoch 943/1500\n",
            "876/876 [==============================] - 2s 3ms/step\n",
            "110/110 [==============================] - 6s 53ms/step - loss: 1.3383 - val_loss: 0.8868\n",
            "Epoch 944/1500\n",
            "876/876 [==============================] - 3s 4ms/step\n",
            "110/110 [==============================] - 9s 81ms/step - loss: 0.4986 - val_loss: 0.8096\n",
            "Epoch 945/1500\n",
            "876/876 [==============================] - 3s 3ms/step\n",
            "110/110 [==============================] - 10s 88ms/step - loss: 0.3600 - val_loss: 0.6657\n",
            "Epoch 946/1500\n",
            "876/876 [==============================] - 3s 4ms/step\n",
            "110/110 [==============================] - 8s 74ms/step - loss: 0.4208 - val_loss: 0.6033\n",
            "Epoch 947/1500\n",
            "876/876 [==============================] - 3s 3ms/step\n",
            "110/110 [==============================] - 6s 54ms/step - loss: 0.9331 - val_loss: 1.0213\n",
            "Epoch 948/1500\n",
            "876/876 [==============================] - 3s 3ms/step\n",
            "110/110 [==============================] - 8s 74ms/step - loss: 0.5597 - val_loss: 1.7992\n",
            "Epoch 949/1500\n",
            "876/876 [==============================] - 3s 3ms/step\n",
            "110/110 [==============================] - 8s 74ms/step - loss: 0.6506 - val_loss: 1.1214\n",
            "Epoch 950/1500\n",
            "876/876 [==============================] - 3s 3ms/step\n",
            "110/110 [==============================] - 9s 82ms/step - loss: 0.6501 - val_loss: 0.7235\n",
            "Epoch 951/1500\n",
            "876/876 [==============================] - 3s 4ms/step\n",
            "110/110 [==============================] - 9s 79ms/step - loss: 0.4903 - val_loss: 0.9058\n",
            "Epoch 952/1500\n",
            "876/876 [==============================] - 3s 4ms/step\n",
            "110/110 [==============================] - 8s 73ms/step - loss: 0.7663 - val_loss: 0.7186\n",
            "Epoch 953/1500\n",
            "876/876 [==============================] - 3s 3ms/step\n",
            "110/110 [==============================] - 8s 75ms/step - loss: 0.4855 - val_loss: 0.7441\n",
            "Epoch 954/1500\n",
            "876/876 [==============================] - 3s 4ms/step\n",
            "110/110 [==============================] - 9s 84ms/step - loss: 0.4766 - val_loss: 3.0664\n",
            "Epoch 955/1500\n",
            "876/876 [==============================] - 3s 3ms/step\n",
            "110/110 [==============================] - 6s 54ms/step - loss: 0.7418 - val_loss: 1.1249\n",
            "Epoch 956/1500\n",
            "876/876 [==============================] - 3s 3ms/step\n",
            "110/110 [==============================] - 8s 74ms/step - loss: 0.4771 - val_loss: 0.5698\n",
            "Epoch 957/1500\n",
            "876/876 [==============================] - 3s 3ms/step\n",
            "110/110 [==============================] - 8s 75ms/step - loss: 0.7311 - val_loss: 0.5820\n",
            "Epoch 958/1500\n",
            "876/876 [==============================] - 3s 4ms/step\n",
            "110/110 [==============================] - 9s 83ms/step - loss: 0.4666 - val_loss: 0.6371\n",
            "Epoch 959/1500\n",
            "876/876 [==============================] - 2s 3ms/step\n",
            "110/110 [==============================] - 6s 52ms/step - loss: 0.4046 - val_loss: 0.6159\n",
            "Epoch 960/1500\n",
            "876/876 [==============================] - 3s 3ms/step\n",
            "110/110 [==============================] - 8s 74ms/step - loss: 0.6704 - val_loss: 0.5913\n",
            "Epoch 961/1500\n",
            "876/876 [==============================] - 3s 3ms/step\n",
            "110/110 [==============================] - 10s 89ms/step - loss: 0.5241 - val_loss: 0.5718\n",
            "Epoch 962/1500\n",
            "876/876 [==============================] - 3s 3ms/step\n",
            "110/110 [==============================] - 8s 72ms/step - loss: 1.0663 - val_loss: 0.8104\n",
            "Epoch 963/1500\n",
            "876/876 [==============================] - 3s 3ms/step\n",
            "110/110 [==============================] - 8s 75ms/step - loss: 0.4131 - val_loss: 0.6260\n",
            "Epoch 964/1500\n",
            "876/876 [==============================] - 3s 3ms/step\n",
            "110/110 [==============================] - 9s 82ms/step - loss: 0.5269 - val_loss: 2.2514\n",
            "Epoch 965/1500\n",
            "876/876 [==============================] - 3s 3ms/step\n",
            "110/110 [==============================] - 6s 54ms/step - loss: 0.8617 - val_loss: 2.2597\n",
            "Epoch 966/1500\n",
            "876/876 [==============================] - 3s 3ms/step\n",
            "110/110 [==============================] - 7s 61ms/step - loss: 0.4696 - val_loss: 1.0446\n",
            "Epoch 967/1500\n",
            "876/876 [==============================] - 3s 3ms/step\n",
            "110/110 [==============================] - 10s 89ms/step - loss: 0.8812 - val_loss: 1.0619\n",
            "Epoch 968/1500\n",
            "876/876 [==============================] - 3s 3ms/step\n",
            "110/110 [==============================] - 6s 57ms/step - loss: 0.4863 - val_loss: 0.6464\n",
            "Epoch 969/1500\n",
            "876/876 [==============================] - 3s 3ms/step\n",
            "110/110 [==============================] - 8s 70ms/step - loss: 0.4470 - val_loss: 0.6973\n",
            "Epoch 970/1500\n",
            "876/876 [==============================] - 3s 3ms/step\n",
            "110/110 [==============================] - 8s 75ms/step - loss: 0.4824 - val_loss: 1.0441\n",
            "Epoch 971/1500\n",
            "876/876 [==============================] - 3s 4ms/step\n",
            "110/110 [==============================] - 10s 90ms/step - loss: 0.4401 - val_loss: 0.7182\n",
            "Epoch 972/1500\n",
            "876/876 [==============================] - 3s 3ms/step\n",
            "110/110 [==============================] - 8s 74ms/step - loss: 1.1722 - val_loss: 0.6650\n",
            "Epoch 973/1500\n",
            "876/876 [==============================] - 3s 4ms/step\n",
            "110/110 [==============================] - 9s 87ms/step - loss: 0.6356 - val_loss: 1.1471\n",
            "Epoch 974/1500\n",
            "876/876 [==============================] - 3s 3ms/step\n",
            "110/110 [==============================] - 6s 54ms/step - loss: 0.6887 - val_loss: 0.7786\n",
            "Epoch 975/1500\n",
            "876/876 [==============================] - 3s 4ms/step\n",
            "110/110 [==============================] - 9s 79ms/step - loss: 0.4031 - val_loss: 1.2380\n",
            "Epoch 976/1500\n",
            "876/876 [==============================] - 3s 3ms/step\n",
            "110/110 [==============================] - 8s 75ms/step - loss: 0.6053 - val_loss: 0.7540\n",
            "Epoch 977/1500\n",
            "876/876 [==============================] - 3s 4ms/step\n",
            "110/110 [==============================] - 8s 77ms/step - loss: 0.6040 - val_loss: 1.0635\n",
            "Epoch 978/1500\n",
            "876/876 [==============================] - 3s 3ms/step\n",
            "110/110 [==============================] - 9s 79ms/step - loss: 0.9166 - val_loss: 1.0597\n",
            "Epoch 979/1500\n",
            "876/876 [==============================] - 3s 4ms/step\n",
            "110/110 [==============================] - 8s 75ms/step - loss: 0.5285 - val_loss: 1.0538\n",
            "Epoch 980/1500\n",
            "876/876 [==============================] - 3s 3ms/step\n",
            "110/110 [==============================] - 6s 56ms/step - loss: 0.4148 - val_loss: 0.5547\n",
            "Epoch 981/1500\n",
            "876/876 [==============================] - 3s 3ms/step\n",
            "110/110 [==============================] - 6s 58ms/step - loss: 0.4264 - val_loss: 0.8095\n",
            "Epoch 982/1500\n",
            "876/876 [==============================] - 3s 3ms/step\n",
            "110/110 [==============================] - 8s 71ms/step - loss: 0.7582 - val_loss: 1.7021\n",
            "Epoch 983/1500\n",
            "876/876 [==============================] - 3s 3ms/step\n",
            "110/110 [==============================] - 6s 56ms/step - loss: 0.7760 - val_loss: 1.2775\n",
            "Epoch 984/1500\n",
            "876/876 [==============================] - 3s 3ms/step\n",
            "110/110 [==============================] - 7s 67ms/step - loss: 0.5953 - val_loss: 0.5840\n",
            "Epoch 985/1500\n",
            "876/876 [==============================] - 3s 3ms/step\n",
            "110/110 [==============================] - 7s 64ms/step - loss: 0.4669 - val_loss: 0.7430\n",
            "Epoch 986/1500\n",
            "876/876 [==============================] - 3s 3ms/step\n",
            "110/110 [==============================] - 6s 54ms/step - loss: 0.4192 - val_loss: 1.3886\n",
            "Epoch 987/1500\n",
            "876/876 [==============================] - 3s 3ms/step\n",
            "110/110 [==============================] - 10s 91ms/step - loss: 0.7851 - val_loss: 0.8404\n",
            "Epoch 988/1500\n",
            "876/876 [==============================] - 3s 3ms/step\n",
            "110/110 [==============================] - 6s 56ms/step - loss: 0.5433 - val_loss: 0.8827\n",
            "Epoch 989/1500\n",
            "876/876 [==============================] - 3s 3ms/step\n",
            "110/110 [==============================] - 9s 86ms/step - loss: 0.5377 - val_loss: 0.6596\n",
            "Epoch 990/1500\n",
            "876/876 [==============================] - 3s 4ms/step\n",
            "110/110 [==============================] - 8s 72ms/step - loss: 0.5233 - val_loss: 0.6236\n",
            "Epoch 991/1500\n",
            "876/876 [==============================] - 3s 4ms/step\n",
            "110/110 [==============================] - 8s 72ms/step - loss: 0.5280 - val_loss: 0.8563\n",
            "Epoch 992/1500\n",
            "876/876 [==============================] - 3s 3ms/step\n",
            "110/110 [==============================] - 8s 77ms/step - loss: 0.6470 - val_loss: 0.7719\n",
            "Epoch 993/1500\n",
            "876/876 [==============================] - 3s 4ms/step\n",
            "110/110 [==============================] - 10s 88ms/step - loss: 0.4403 - val_loss: 1.5453\n",
            "Epoch 994/1500\n",
            "876/876 [==============================] - 3s 3ms/step\n",
            "110/110 [==============================] - 9s 82ms/step - loss: 0.6101 - val_loss: 0.6857\n",
            "Epoch 995/1500\n",
            "876/876 [==============================] - 3s 3ms/step\n",
            "110/110 [==============================] - 7s 60ms/step - loss: 0.7553 - val_loss: 0.6924\n",
            "Epoch 996/1500\n",
            "876/876 [==============================] - 3s 3ms/step\n",
            "110/110 [==============================] - 10s 89ms/step - loss: 0.4502 - val_loss: 0.5907\n",
            "Epoch 997/1500\n",
            "876/876 [==============================] - 3s 3ms/step\n",
            "110/110 [==============================] - 6s 57ms/step - loss: 0.8701 - val_loss: 0.8070\n",
            "Epoch 998/1500\n",
            "876/876 [==============================] - 3s 3ms/step\n",
            "110/110 [==============================] - 8s 70ms/step - loss: 0.5469 - val_loss: 1.1285\n",
            "Epoch 999/1500\n",
            "876/876 [==============================] - 3s 3ms/step\n",
            "110/110 [==============================] - 8s 75ms/step - loss: 0.4497 - val_loss: 0.6725\n",
            "Epoch 1000/1500\n",
            "876/876 [==============================] - 3s 3ms/step\n",
            "110/110 [==============================] - 10s 88ms/step - loss: 0.4548 - val_loss: 0.6443\n",
            "Epoch 1001/1500\n",
            "876/876 [==============================] - 3s 3ms/step\n",
            "110/110 [==============================] - 8s 75ms/step - loss: 0.7977 - val_loss: 0.7692\n",
            "Epoch 1002/1500\n",
            "876/876 [==============================] - 3s 3ms/step\n",
            "110/110 [==============================] - 10s 92ms/step - loss: 0.5494 - val_loss: 1.6138\n",
            "Epoch 1003/1500\n",
            "876/876 [==============================] - 3s 3ms/step\n",
            "110/110 [==============================] - 6s 57ms/step - loss: 0.7097 - val_loss: 0.5994\n",
            "Epoch 1004/1500\n",
            "876/876 [==============================] - 3s 3ms/step\n",
            "110/110 [==============================] - 10s 87ms/step - loss: 0.3682 - val_loss: 1.9616\n",
            "Epoch 1005/1500\n",
            "876/876 [==============================] - 3s 3ms/step\n",
            "110/110 [==============================] - 8s 74ms/step - loss: 0.5198 - val_loss: 0.6445\n",
            "Epoch 1006/1500\n",
            "876/876 [==============================] - 3s 3ms/step\n",
            "110/110 [==============================] - 9s 83ms/step - loss: 0.7589 - val_loss: 0.6644\n",
            "Epoch 1007/1500\n",
            "876/876 [==============================] - 3s 3ms/step\n",
            "110/110 [==============================] - 7s 59ms/step - loss: 0.5689 - val_loss: 0.8944\n",
            "Epoch 1008/1500\n",
            "876/876 [==============================] - 3s 4ms/step\n",
            "110/110 [==============================] - 10s 90ms/step - loss: 0.9062 - val_loss: 0.8858\n",
            "Epoch 1009/1500\n",
            "876/876 [==============================] - 3s 3ms/step\n",
            "110/110 [==============================] - 8s 71ms/step - loss: 0.4277 - val_loss: 0.6511\n",
            "Epoch 1010/1500\n",
            "876/876 [==============================] - 3s 3ms/step\n",
            "110/110 [==============================] - 7s 67ms/step - loss: 0.7964 - val_loss: 0.6233\n",
            "Epoch 1011/1500\n",
            "876/876 [==============================] - 3s 3ms/step\n",
            "110/110 [==============================] - 9s 80ms/step - loss: 0.6013 - val_loss: 0.5880\n",
            "Epoch 1012/1500\n",
            "876/876 [==============================] - 3s 3ms/step\n",
            "110/110 [==============================] - 6s 58ms/step - loss: 0.5028 - val_loss: 0.7325\n",
            "Epoch 1013/1500\n",
            "876/876 [==============================] - 3s 3ms/step\n",
            "110/110 [==============================] - 10s 88ms/step - loss: 0.8403 - val_loss: 1.0188\n",
            "Epoch 1014/1500\n",
            "876/876 [==============================] - 3s 3ms/step\n",
            "110/110 [==============================] - 8s 74ms/step - loss: 0.5898 - val_loss: 1.0784\n",
            "Epoch 1015/1500\n",
            "876/876 [==============================] - 3s 3ms/step\n",
            "110/110 [==============================] - 8s 75ms/step - loss: 0.4779 - val_loss: 1.0261\n",
            "Epoch 1016/1500\n",
            "876/876 [==============================] - 3s 4ms/step\n",
            "110/110 [==============================] - 7s 68ms/step - loss: 0.8498 - val_loss: 0.6185\n",
            "Epoch 1017/1500\n",
            "876/876 [==============================] - 3s 3ms/step\n",
            "110/110 [==============================] - 6s 58ms/step - loss: 0.6207 - val_loss: 0.7325\n",
            "Epoch 1018/1500\n",
            "876/876 [==============================] - 3s 3ms/step\n",
            "110/110 [==============================] - 8s 75ms/step - loss: 0.5609 - val_loss: 1.0462\n",
            "Epoch 1019/1500\n",
            "876/876 [==============================] - 3s 3ms/step\n",
            "110/110 [==============================] - 8s 75ms/step - loss: 0.6070 - val_loss: 0.5966\n",
            "Epoch 1020/1500\n",
            "876/876 [==============================] - 3s 4ms/step\n",
            "110/110 [==============================] - 7s 68ms/step - loss: 0.3882 - val_loss: 1.6121\n",
            "Epoch 1021/1500\n",
            "876/876 [==============================] - 3s 3ms/step\n",
            "110/110 [==============================] - 9s 82ms/step - loss: 0.8055 - val_loss: 1.8068\n",
            "Epoch 1022/1500\n",
            "876/876 [==============================] - 3s 4ms/step\n",
            "110/110 [==============================] - 8s 76ms/step - loss: 0.6855 - val_loss: 0.9562\n",
            "Epoch 1023/1500\n",
            "876/876 [==============================] - 3s 3ms/step\n",
            "110/110 [==============================] - 8s 74ms/step - loss: 0.5750 - val_loss: 0.6105\n",
            "Epoch 1024/1500\n",
            "876/876 [==============================] - 3s 4ms/step\n",
            "110/110 [==============================] - 9s 81ms/step - loss: 0.4746 - val_loss: 0.9375\n",
            "Epoch 1025/1500\n",
            "876/876 [==============================] - 3s 3ms/step\n",
            "110/110 [==============================] - 6s 55ms/step - loss: 0.5920 - val_loss: 1.1373\n",
            "Epoch 1026/1500\n",
            "876/876 [==============================] - 3s 3ms/step\n",
            "110/110 [==============================] - 10s 88ms/step - loss: 0.4224 - val_loss: 0.5970\n",
            "Epoch 1027/1500\n",
            "876/876 [==============================] - 3s 3ms/step\n",
            "110/110 [==============================] - 9s 79ms/step - loss: 0.4986 - val_loss: 0.5813\n",
            "Epoch 1028/1500\n",
            "876/876 [==============================] - 3s 3ms/step\n",
            "110/110 [==============================] - 7s 62ms/step - loss: 0.4195 - val_loss: 0.6933\n",
            "Epoch 1029/1500\n",
            "876/876 [==============================] - 3s 3ms/step\n",
            "110/110 [==============================] - 9s 86ms/step - loss: 0.5202 - val_loss: 0.8640\n",
            "Epoch 1030/1500\n",
            "876/876 [==============================] - 3s 3ms/step\n",
            "110/110 [==============================] - 6s 58ms/step - loss: 0.5208 - val_loss: 0.5821\n",
            "Epoch 1031/1500\n",
            "876/876 [==============================] - 3s 3ms/step\n",
            "110/110 [==============================] - 8s 70ms/step - loss: 1.8728 - val_loss: 0.9226\n",
            "Epoch 1032/1500\n",
            "876/876 [==============================] - 3s 3ms/step\n",
            "110/110 [==============================] - 6s 54ms/step - loss: 0.6187 - val_loss: 1.9158\n",
            "Epoch 1033/1500\n",
            "876/876 [==============================] - 3s 4ms/step\n",
            "110/110 [==============================] - 8s 70ms/step - loss: 0.5596 - val_loss: 0.6580\n",
            "Epoch 1034/1500\n",
            "876/876 [==============================] - 3s 3ms/step\n",
            "110/110 [==============================] - 6s 57ms/step - loss: 0.5973 - val_loss: 0.8862\n",
            "Epoch 1035/1500\n",
            "876/876 [==============================] - 3s 3ms/step\n",
            "110/110 [==============================] - 6s 57ms/step - loss: 0.4418 - val_loss: 0.7854\n",
            "Epoch 1036/1500\n",
            "876/876 [==============================] - 3s 3ms/step\n",
            "110/110 [==============================] - 10s 89ms/step - loss: 0.7187 - val_loss: 0.9902\n",
            "Epoch 1037/1500\n",
            "876/876 [==============================] - 3s 3ms/step\n",
            "110/110 [==============================] - 8s 76ms/step - loss: 1.0237 - val_loss: 0.6418\n",
            "Epoch 1038/1500\n",
            "876/876 [==============================] - 3s 3ms/step\n",
            "110/110 [==============================] - 8s 75ms/step - loss: 0.4433 - val_loss: 0.7758\n",
            "Epoch 1039/1500\n",
            "876/876 [==============================] - 3s 3ms/step\n",
            "110/110 [==============================] - 7s 66ms/step - loss: 0.5707 - val_loss: 0.8055\n",
            "Epoch 1040/1500\n",
            "876/876 [==============================] - 3s 3ms/step\n",
            "110/110 [==============================] - 7s 61ms/step - loss: 0.3654 - val_loss: 0.9942\n",
            "Epoch 1041/1500\n",
            "876/876 [==============================] - 3s 3ms/step\n",
            "110/110 [==============================] - 6s 56ms/step - loss: 0.5492 - val_loss: 0.6072\n",
            "Epoch 1042/1500\n",
            "876/876 [==============================] - 3s 3ms/step\n",
            "110/110 [==============================] - 8s 71ms/step - loss: 0.4069 - val_loss: 0.7875\n",
            "Epoch 1043/1500\n",
            "876/876 [==============================] - 3s 3ms/step\n",
            "110/110 [==============================] - 8s 75ms/step - loss: 0.4513 - val_loss: 0.6793\n",
            "Epoch 1044/1500\n",
            "876/876 [==============================] - 3s 4ms/step\n",
            "110/110 [==============================] - 9s 78ms/step - loss: 0.5081 - val_loss: 0.6621\n",
            "Epoch 1045/1500\n",
            "876/876 [==============================] - 3s 3ms/step\n",
            "110/110 [==============================] - 8s 69ms/step - loss: 0.5055 - val_loss: 0.7497\n",
            "Epoch 1046/1500\n",
            "876/876 [==============================] - 3s 3ms/step\n",
            "110/110 [==============================] - 6s 56ms/step - loss: 0.7828 - val_loss: 0.7400\n",
            "Epoch 1047/1500\n",
            "876/876 [==============================] - 3s 3ms/step\n",
            "110/110 [==============================] - 8s 72ms/step - loss: 0.6178 - val_loss: 0.9253\n",
            "Epoch 1048/1500\n",
            "876/876 [==============================] - 3s 3ms/step\n",
            "110/110 [==============================] - 8s 76ms/step - loss: 0.3690 - val_loss: 0.6026\n",
            "Epoch 1049/1500\n",
            "876/876 [==============================] - 3s 4ms/step\n",
            "110/110 [==============================] - 9s 86ms/step - loss: 0.4704 - val_loss: 0.7462\n",
            "Epoch 1050/1500\n",
            "876/876 [==============================] - 3s 3ms/step\n",
            "110/110 [==============================] - 6s 54ms/step - loss: 0.4446 - val_loss: 0.6617\n",
            "Epoch 1051/1500\n",
            "876/876 [==============================] - 3s 4ms/step\n",
            "110/110 [==============================] - 7s 62ms/step - loss: 0.6090 - val_loss: 0.6048\n",
            "Epoch 1052/1500\n",
            "876/876 [==============================] - 3s 3ms/step\n",
            "110/110 [==============================] - 7s 65ms/step - loss: 0.4598 - val_loss: 0.7478\n",
            "Epoch 1053/1500\n",
            "876/876 [==============================] - 3s 3ms/step\n",
            "110/110 [==============================] - 6s 58ms/step - loss: 0.6372 - val_loss: 0.6013\n",
            "Epoch 1054/1500\n",
            "876/876 [==============================] - 3s 4ms/step\n",
            "110/110 [==============================] - 9s 78ms/step - loss: 0.5890 - val_loss: 0.8466\n",
            "Epoch 1055/1500\n",
            "876/876 [==============================] - 3s 3ms/step\n",
            "110/110 [==============================] - 10s 88ms/step - loss: 0.3965 - val_loss: 0.6272\n",
            "Epoch 1056/1500\n",
            "876/876 [==============================] - 3s 3ms/step\n",
            "110/110 [==============================] - 8s 76ms/step - loss: 0.7375 - val_loss: 0.6600\n",
            "Epoch 1057/1500\n",
            "876/876 [==============================] - 3s 3ms/step\n",
            "110/110 [==============================] - 8s 76ms/step - loss: 0.5051 - val_loss: 2.8938\n",
            "Epoch 1058/1500\n",
            "876/876 [==============================] - 3s 4ms/step\n",
            "110/110 [==============================] - 8s 69ms/step - loss: 1.1956 - val_loss: 0.6843\n",
            "Epoch 1059/1500\n",
            "876/876 [==============================] - 3s 3ms/step\n",
            "110/110 [==============================] - 7s 61ms/step - loss: 0.4495 - val_loss: 0.5804\n",
            "Epoch 1060/1500\n",
            "876/876 [==============================] - 3s 3ms/step\n",
            "110/110 [==============================] - 8s 76ms/step - loss: 0.5448 - val_loss: 0.7922\n",
            "Epoch 1061/1500\n",
            "876/876 [==============================] - 3s 3ms/step\n",
            "110/110 [==============================] - 7s 59ms/step - loss: 0.7705 - val_loss: 0.5506\n",
            "Epoch 1062/1500\n",
            "876/876 [==============================] - 3s 3ms/step\n",
            "110/110 [==============================] - 8s 74ms/step - loss: 0.4520 - val_loss: 0.5868\n",
            "Epoch 1063/1500\n",
            "876/876 [==============================] - 3s 3ms/step\n",
            "110/110 [==============================] - 10s 89ms/step - loss: 0.4032 - val_loss: 0.8690\n",
            "Epoch 1064/1500\n",
            "876/876 [==============================] - 3s 3ms/step\n",
            "110/110 [==============================] - 6s 57ms/step - loss: 0.6250 - val_loss: 2.8116\n",
            "Epoch 1065/1500\n",
            "876/876 [==============================] - 3s 3ms/step\n",
            "110/110 [==============================] - 8s 73ms/step - loss: 0.7712 - val_loss: 0.7609\n",
            "Epoch 1066/1500\n",
            "876/876 [==============================] - 3s 3ms/step\n",
            "110/110 [==============================] - 6s 54ms/step - loss: 0.7225 - val_loss: 0.5995\n",
            "Epoch 1067/1500\n",
            "876/876 [==============================] - 3s 4ms/step\n",
            "110/110 [==============================] - 8s 69ms/step - loss: 0.4751 - val_loss: 1.3981\n",
            "Epoch 1068/1500\n",
            "876/876 [==============================] - 3s 4ms/step\n",
            "110/110 [==============================] - 8s 70ms/step - loss: 0.5698 - val_loss: 0.8017\n",
            "Epoch 1069/1500\n",
            "876/876 [==============================] - 3s 3ms/step\n",
            "110/110 [==============================] - 8s 70ms/step - loss: 0.3820 - val_loss: 0.5365\n",
            "Epoch 1070/1500\n",
            "876/876 [==============================] - 3s 3ms/step\n",
            "110/110 [==============================] - 10s 88ms/step - loss: 0.5162 - val_loss: 1.3799\n",
            "Epoch 1071/1500\n",
            "876/876 [==============================] - 3s 3ms/step\n",
            "110/110 [==============================] - 8s 76ms/step - loss: 0.5136 - val_loss: 0.6935\n",
            "Epoch 1072/1500\n",
            "876/876 [==============================] - 3s 3ms/step\n",
            "110/110 [==============================] - 8s 75ms/step - loss: 0.3819 - val_loss: 0.5791\n",
            "Epoch 1073/1500\n",
            "876/876 [==============================] - 3s 3ms/step\n",
            "110/110 [==============================] - 7s 66ms/step - loss: 0.7445 - val_loss: 0.5520\n",
            "Epoch 1074/1500\n",
            "876/876 [==============================] - 3s 3ms/step\n",
            "110/110 [==============================] - 7s 65ms/step - loss: 0.3479 - val_loss: 0.6788\n",
            "Epoch 1075/1500\n",
            "876/876 [==============================] - 3s 3ms/step\n",
            "110/110 [==============================] - 6s 58ms/step - loss: 0.6891 - val_loss: 0.8385\n",
            "Epoch 1076/1500\n",
            "876/876 [==============================] - 3s 3ms/step\n",
            "110/110 [==============================] - 8s 73ms/step - loss: 0.5868 - val_loss: 0.6215\n",
            "Epoch 1077/1500\n",
            "876/876 [==============================] - 3s 3ms/step\n",
            "110/110 [==============================] - 8s 77ms/step - loss: 0.9426 - val_loss: 0.7883\n",
            "Epoch 1078/1500\n",
            "876/876 [==============================] - 3s 3ms/step\n",
            "110/110 [==============================] - 9s 85ms/step - loss: 0.6055 - val_loss: 0.7794\n",
            "Epoch 1079/1500\n",
            "876/876 [==============================] - 3s 3ms/step\n",
            "110/110 [==============================] - 7s 68ms/step - loss: 0.5108 - val_loss: 0.6306\n",
            "Epoch 1080/1500\n",
            "876/876 [==============================] - 3s 4ms/step\n",
            "110/110 [==============================] - 7s 67ms/step - loss: 0.6747 - val_loss: 0.5594\n",
            "Epoch 1081/1500\n",
            "876/876 [==============================] - 3s 3ms/step\n",
            "110/110 [==============================] - 7s 61ms/step - loss: 0.5399 - val_loss: 0.6150\n",
            "Epoch 1082/1500\n",
            "876/876 [==============================] - 3s 4ms/step\n",
            "110/110 [==============================] - 7s 64ms/step - loss: 0.4485 - val_loss: 0.7735\n",
            "Epoch 1083/1500\n",
            "876/876 [==============================] - 3s 4ms/step\n",
            "110/110 [==============================] - 9s 79ms/step - loss: 0.6358 - val_loss: 1.1255\n",
            "Epoch 1084/1500\n",
            "876/876 [==============================] - 3s 3ms/step\n",
            "110/110 [==============================] - 9s 82ms/step - loss: 0.6280 - val_loss: 0.9054\n",
            "Epoch 1085/1500\n",
            "876/876 [==============================] - 3s 3ms/step\n",
            "110/110 [==============================] - 7s 67ms/step - loss: 0.3675 - val_loss: 0.5853\n",
            "Epoch 1086/1500\n",
            "876/876 [==============================] - 3s 3ms/step\n",
            "110/110 [==============================] - 7s 62ms/step - loss: 0.4910 - val_loss: 0.9000\n",
            "Epoch 1087/1500\n",
            "876/876 [==============================] - 3s 3ms/step\n",
            "110/110 [==============================] - 8s 76ms/step - loss: 0.4986 - val_loss: 0.5830\n",
            "Epoch 1088/1500\n",
            "876/876 [==============================] - 3s 3ms/step\n",
            "110/110 [==============================] - 8s 77ms/step - loss: 0.9910 - val_loss: 2.7309\n",
            "Epoch 1089/1500\n",
            "876/876 [==============================] - 3s 3ms/step\n",
            "110/110 [==============================] - 9s 82ms/step - loss: 0.5861 - val_loss: 0.7795\n",
            "Epoch 1090/1500\n",
            "876/876 [==============================] - 3s 3ms/step\n",
            "110/110 [==============================] - 8s 75ms/step - loss: 0.3723 - val_loss: 0.9621\n",
            "Epoch 1091/1500\n",
            "876/876 [==============================] - 3s 4ms/step\n",
            "110/110 [==============================] - 8s 72ms/step - loss: 0.4084 - val_loss: 3.0788\n",
            "Epoch 1092/1500\n",
            "876/876 [==============================] - 3s 3ms/step\n",
            "110/110 [==============================] - 7s 60ms/step - loss: 1.2027 - val_loss: 1.0610\n",
            "Epoch 1093/1500\n",
            "876/876 [==============================] - 3s 3ms/step\n",
            "110/110 [==============================] - 8s 76ms/step - loss: 0.4390 - val_loss: 0.5590\n",
            "Epoch 1094/1500\n",
            "876/876 [==============================] - 3s 3ms/step\n",
            "110/110 [==============================] - 6s 56ms/step - loss: 0.5928 - val_loss: 0.7667\n",
            "Epoch 1095/1500\n",
            "876/876 [==============================] - 3s 3ms/step\n",
            "110/110 [==============================] - 8s 76ms/step - loss: 0.4893 - val_loss: 0.6761\n",
            "Epoch 1096/1500\n",
            "876/876 [==============================] - 3s 4ms/step\n",
            "110/110 [==============================] - 10s 92ms/step - loss: 0.4628 - val_loss: 1.0842\n",
            "Epoch 1097/1500\n",
            "876/876 [==============================] - 3s 3ms/step\n",
            "110/110 [==============================] - 9s 79ms/step - loss: 1.2468 - val_loss: 1.1445\n",
            "Epoch 1098/1500\n",
            "876/876 [==============================] - 3s 3ms/step\n",
            "110/110 [==============================] - 8s 76ms/step - loss: 0.5222 - val_loss: 0.6194\n",
            "Epoch 1099/1500\n",
            "876/876 [==============================] - 3s 4ms/step\n",
            "110/110 [==============================] - 9s 83ms/step - loss: 0.4404 - val_loss: 1.1939\n",
            "Epoch 1100/1500\n",
            "876/876 [==============================] - 3s 3ms/step\n",
            "110/110 [==============================] - 6s 55ms/step - loss: 0.6377 - val_loss: 0.5661\n",
            "Epoch 1101/1500\n",
            "876/876 [==============================] - 3s 3ms/step\n",
            "110/110 [==============================] - 8s 77ms/step - loss: 0.4922 - val_loss: 3.7167\n",
            "Epoch 1102/1500\n",
            "876/876 [==============================] - 3s 3ms/step\n",
            "110/110 [==============================] - 6s 54ms/step - loss: 0.4689 - val_loss: 0.5264\n",
            "Epoch 1103/1500\n",
            "876/876 [==============================] - 3s 3ms/step\n",
            "110/110 [==============================] - 8s 76ms/step - loss: 0.9003 - val_loss: 0.5684\n",
            "Epoch 1104/1500\n",
            "876/876 [==============================] - 3s 3ms/step\n",
            "110/110 [==============================] - 8s 75ms/step - loss: 0.3979 - val_loss: 0.9412\n",
            "Epoch 1105/1500\n",
            "876/876 [==============================] - 3s 4ms/step\n",
            "110/110 [==============================] - 9s 83ms/step - loss: 0.5892 - val_loss: 1.4251\n",
            "Epoch 1106/1500\n",
            "876/876 [==============================] - 3s 3ms/step\n",
            "110/110 [==============================] - 8s 75ms/step - loss: 0.3857 - val_loss: 0.7739\n",
            "Epoch 1107/1500\n",
            "876/876 [==============================] - 3s 4ms/step\n",
            "110/110 [==============================] - 9s 86ms/step - loss: 0.7717 - val_loss: 0.5854\n",
            "Epoch 1108/1500\n",
            "876/876 [==============================] - 3s 3ms/step\n",
            "110/110 [==============================] - 8s 76ms/step - loss: 0.3929 - val_loss: 0.6174\n",
            "Epoch 1109/1500\n",
            "876/876 [==============================] - 3s 4ms/step\n",
            "110/110 [==============================] - 9s 78ms/step - loss: 0.3759 - val_loss: 0.6604\n",
            "Epoch 1110/1500\n",
            "876/876 [==============================] - 3s 3ms/step\n",
            "110/110 [==============================] - 10s 92ms/step - loss: 0.5553 - val_loss: 0.5922\n",
            "Epoch 1111/1500\n",
            "876/876 [==============================] - 3s 4ms/step\n",
            "110/110 [==============================] - 8s 75ms/step - loss: 0.4836 - val_loss: 2.6542\n",
            "Epoch 1112/1500\n",
            "876/876 [==============================] - 3s 3ms/step\n",
            "110/110 [==============================] - 8s 73ms/step - loss: 0.9391 - val_loss: 0.8703\n",
            "Epoch 1113/1500\n",
            "876/876 [==============================] - 3s 3ms/step\n",
            "110/110 [==============================] - 6s 55ms/step - loss: 0.9203 - val_loss: 1.2296\n",
            "Epoch 1114/1500\n",
            "876/876 [==============================] - 3s 4ms/step\n",
            "110/110 [==============================] - 8s 74ms/step - loss: 0.5546 - val_loss: 0.5847\n",
            "Epoch 1115/1500\n",
            "876/876 [==============================] - 3s 3ms/step\n",
            "110/110 [==============================] - 8s 77ms/step - loss: 0.4398 - val_loss: 0.7214\n",
            "Epoch 1116/1500\n",
            "876/876 [==============================] - 3s 4ms/step\n",
            "110/110 [==============================] - 7s 67ms/step - loss: 0.4703 - val_loss: 0.8403\n",
            "Epoch 1117/1500\n",
            "876/876 [==============================] - 3s 3ms/step\n",
            "110/110 [==============================] - 9s 83ms/step - loss: 0.5897 - val_loss: 1.0338\n",
            "Epoch 1118/1500\n",
            "876/876 [==============================] - 3s 4ms/step\n",
            "110/110 [==============================] - 8s 77ms/step - loss: 0.3981 - val_loss: 1.0280\n",
            "Epoch 1119/1500\n",
            "876/876 [==============================] - 3s 3ms/step\n",
            "110/110 [==============================] - 6s 57ms/step - loss: 0.4522 - val_loss: 0.6411\n",
            "Epoch 1120/1500\n",
            "876/876 [==============================] - 3s 3ms/step\n",
            "110/110 [==============================] - 8s 76ms/step - loss: 0.8506 - val_loss: 0.6538\n",
            "Epoch 1121/1500\n",
            "876/876 [==============================] - 3s 3ms/step\n",
            "110/110 [==============================] - 8s 77ms/step - loss: 0.4557 - val_loss: 1.0091\n",
            "Epoch 1122/1500\n",
            "876/876 [==============================] - 3s 4ms/step\n",
            "110/110 [==============================] - 9s 85ms/step - loss: 0.6260 - val_loss: 0.5700\n",
            "Epoch 1123/1500\n",
            "876/876 [==============================] - 3s 3ms/step\n",
            "110/110 [==============================] - 9s 86ms/step - loss: 0.4708 - val_loss: 1.0706\n",
            "Epoch 1124/1500\n",
            "876/876 [==============================] - 3s 4ms/step\n",
            "110/110 [==============================] - 9s 82ms/step - loss: 0.4269 - val_loss: 0.8327\n",
            "Epoch 1125/1500\n",
            "876/876 [==============================] - 3s 3ms/step\n",
            "110/110 [==============================] - 6s 54ms/step - loss: 0.6672 - val_loss: 0.9653\n",
            "Epoch 1126/1500\n",
            "876/876 [==============================] - 3s 4ms/step\n",
            "110/110 [==============================] - 8s 75ms/step - loss: 0.6587 - val_loss: 0.6865\n",
            "Epoch 1127/1500\n",
            "876/876 [==============================] - 3s 3ms/step\n",
            "110/110 [==============================] - 8s 73ms/step - loss: 0.3802 - val_loss: 0.5661\n",
            "Epoch 1128/1500\n",
            "876/876 [==============================] - 3s 3ms/step\n",
            "110/110 [==============================] - 6s 56ms/step - loss: 0.6187 - val_loss: 0.6646\n",
            "Epoch 1129/1500\n",
            "876/876 [==============================] - 3s 3ms/step\n",
            "110/110 [==============================] - 8s 71ms/step - loss: 0.3869 - val_loss: 1.3093\n",
            "Epoch 1130/1500\n",
            "876/876 [==============================] - 3s 3ms/step\n",
            "110/110 [==============================] - 6s 56ms/step - loss: 0.5294 - val_loss: 0.6596\n",
            "Epoch 1131/1500\n",
            "876/876 [==============================] - 3s 3ms/step\n",
            "110/110 [==============================] - 9s 82ms/step - loss: 0.4986 - val_loss: 0.6028\n",
            "Epoch 1132/1500\n",
            "876/876 [==============================] - 3s 3ms/step\n",
            "110/110 [==============================] - 6s 55ms/step - loss: 0.4003 - val_loss: 0.6058\n",
            "Epoch 1133/1500\n",
            "876/876 [==============================] - 3s 3ms/step\n",
            "110/110 [==============================] - 7s 63ms/step - loss: 0.6494 - val_loss: 0.5971\n",
            "Epoch 1134/1500\n",
            "876/876 [==============================] - 3s 3ms/step\n",
            "110/110 [==============================] - 7s 66ms/step - loss: 0.5845 - val_loss: 0.5904\n",
            "Epoch 1135/1500\n",
            "876/876 [==============================] - 3s 3ms/step\n",
            "110/110 [==============================] - 8s 76ms/step - loss: 0.5776 - val_loss: 0.6011\n",
            "Epoch 1136/1500\n",
            "876/876 [==============================] - 3s 4ms/step\n",
            "110/110 [==============================] - 10s 90ms/step - loss: 0.5299 - val_loss: 0.7959\n",
            "Epoch 1137/1500\n",
            "876/876 [==============================] - 3s 4ms/step\n",
            "110/110 [==============================] - 8s 69ms/step - loss: 0.5507 - val_loss: 0.6811\n",
            "Epoch 1138/1500\n",
            "876/876 [==============================] - 3s 3ms/step\n",
            "110/110 [==============================] - 7s 62ms/step - loss: 0.3812 - val_loss: 1.1068\n",
            "Epoch 1139/1500\n",
            "876/876 [==============================] - 3s 3ms/step\n",
            "110/110 [==============================] - 6s 56ms/step - loss: 0.6531 - val_loss: 0.8968\n",
            "Epoch 1140/1500\n",
            "876/876 [==============================] - 3s 3ms/step\n",
            "110/110 [==============================] - 10s 90ms/step - loss: 0.4386 - val_loss: 0.8518\n",
            "Epoch 1141/1500\n",
            "876/876 [==============================] - 3s 3ms/step\n",
            "110/110 [==============================] - 8s 75ms/step - loss: 0.6008 - val_loss: 0.8511\n",
            "Epoch 1142/1500\n",
            "876/876 [==============================] - 3s 3ms/step\n",
            "110/110 [==============================] - 9s 79ms/step - loss: 0.7843 - val_loss: 0.6506\n",
            "Epoch 1143/1500\n",
            "876/876 [==============================] - 3s 3ms/step\n",
            "110/110 [==============================] - 7s 60ms/step - loss: 0.7415 - val_loss: 1.1451\n",
            "Epoch 1144/1500\n",
            "876/876 [==============================] - 3s 3ms/step\n",
            "110/110 [==============================] - 9s 86ms/step - loss: 0.5210 - val_loss: 1.1085\n",
            "Epoch 1145/1500\n",
            "876/876 [==============================] - 3s 3ms/step\n",
            "110/110 [==============================] - 6s 59ms/step - loss: 0.3789 - val_loss: 0.7732\n",
            "Epoch 1146/1500\n",
            "876/876 [==============================] - 3s 3ms/step\n",
            "110/110 [==============================] - 10s 87ms/step - loss: 0.5164 - val_loss: 0.9889\n",
            "Epoch 1147/1500\n",
            "876/876 [==============================] - 3s 3ms/step\n",
            "110/110 [==============================] - 8s 75ms/step - loss: 0.6061 - val_loss: 1.0515\n",
            "Epoch 1148/1500\n",
            "876/876 [==============================] - 3s 3ms/step\n",
            "110/110 [==============================] - 10s 88ms/step - loss: 0.4709 - val_loss: 0.7865\n",
            "Epoch 1149/1500\n",
            "876/876 [==============================] - 3s 4ms/step\n",
            "110/110 [==============================] - 7s 63ms/step - loss: 0.6711 - val_loss: 0.5883\n",
            "Epoch 1150/1500\n",
            "876/876 [==============================] - 3s 3ms/step\n",
            "110/110 [==============================] - 10s 88ms/step - loss: 0.5567 - val_loss: 0.8870\n",
            "Epoch 1151/1500\n",
            "876/876 [==============================] - 3s 3ms/step\n",
            "110/110 [==============================] - 6s 59ms/step - loss: 0.4772 - val_loss: 0.5901\n",
            "Epoch 1152/1500\n",
            "876/876 [==============================] - 3s 3ms/step\n",
            "110/110 [==============================] - 8s 72ms/step - loss: 0.4709 - val_loss: 1.5656\n",
            "Epoch 1153/1500\n",
            "876/876 [==============================] - 3s 3ms/step\n",
            "110/110 [==============================] - 8s 76ms/step - loss: 0.6128 - val_loss: 0.6998\n",
            "Epoch 1154/1500\n",
            "876/876 [==============================] - 3s 3ms/step\n",
            "110/110 [==============================] - 8s 74ms/step - loss: 0.6067 - val_loss: 0.8005\n",
            "Epoch 1155/1500\n",
            "876/876 [==============================] - 3s 3ms/step\n",
            "110/110 [==============================] - 6s 57ms/step - loss: 0.3628 - val_loss: 0.6296\n",
            "Epoch 1156/1500\n",
            "876/876 [==============================] - 3s 3ms/step\n",
            "110/110 [==============================] - 7s 59ms/step - loss: 1.0060 - val_loss: 0.9165\n",
            "Epoch 1157/1500\n",
            "876/876 [==============================] - 3s 3ms/step\n",
            "110/110 [==============================] - 8s 69ms/step - loss: 0.4351 - val_loss: 0.6036\n",
            "Epoch 1158/1500\n",
            "876/876 [==============================] - 3s 4ms/step\n",
            "110/110 [==============================] - 10s 88ms/step - loss: 0.5791 - val_loss: 1.3122\n",
            "Epoch 1159/1500\n",
            "876/876 [==============================] - 3s 3ms/step\n",
            "110/110 [==============================] - 7s 65ms/step - loss: 0.3651 - val_loss: 0.8510\n",
            "Epoch 1160/1500\n",
            "876/876 [==============================] - 3s 3ms/step\n",
            "110/110 [==============================] - 6s 55ms/step - loss: 0.5236 - val_loss: 0.8608\n",
            "Epoch 1161/1500\n",
            "876/876 [==============================] - 3s 4ms/step\n",
            "110/110 [==============================] - 8s 77ms/step - loss: 0.9650 - val_loss: 0.8304\n",
            "Epoch 1162/1500\n",
            "876/876 [==============================] - 3s 3ms/step\n",
            "110/110 [==============================] - 8s 74ms/step - loss: 0.3948 - val_loss: 0.8596\n",
            "Epoch 1163/1500\n",
            "876/876 [==============================] - 3s 3ms/step\n",
            "110/110 [==============================] - 8s 77ms/step - loss: 0.5814 - val_loss: 0.5961\n",
            "Epoch 1164/1500\n",
            "876/876 [==============================] - 3s 3ms/step\n",
            "110/110 [==============================] - 6s 56ms/step - loss: 0.5622 - val_loss: 0.5448\n",
            "Epoch 1165/1500\n",
            "876/876 [==============================] - 3s 3ms/step\n",
            "110/110 [==============================] - 7s 61ms/step - loss: 0.4355 - val_loss: 0.6489\n",
            "Epoch 1166/1500\n",
            "876/876 [==============================] - 3s 3ms/step\n",
            "110/110 [==============================] - 8s 71ms/step - loss: 0.4534 - val_loss: 0.6446\n",
            "Epoch 1167/1500\n",
            "876/876 [==============================] - 3s 3ms/step\n",
            "110/110 [==============================] - 8s 77ms/step - loss: 0.5585 - val_loss: 6.6754\n",
            "Epoch 1168/1500\n",
            "876/876 [==============================] - 3s 3ms/step\n",
            "110/110 [==============================] - 10s 88ms/step - loss: 0.7877 - val_loss: 0.7940\n",
            "Epoch 1169/1500\n",
            "876/876 [==============================] - 3s 3ms/step\n",
            "110/110 [==============================] - 8s 75ms/step - loss: 0.4341 - val_loss: 0.6185\n",
            "Epoch 1170/1500\n",
            "876/876 [==============================] - 3s 3ms/step\n",
            "110/110 [==============================] - 6s 55ms/step - loss: 0.5150 - val_loss: 0.8418\n",
            "Epoch 1171/1500\n",
            "876/876 [==============================] - 3s 3ms/step\n",
            "110/110 [==============================] - 7s 60ms/step - loss: 0.3717 - val_loss: 1.4845\n",
            "Epoch 1172/1500\n",
            "876/876 [==============================] - 3s 3ms/step\n",
            "110/110 [==============================] - 10s 89ms/step - loss: 0.7035 - val_loss: 0.5674\n",
            "Epoch 1173/1500\n",
            "876/876 [==============================] - 3s 3ms/step\n",
            "110/110 [==============================] - 9s 82ms/step - loss: 0.8587 - val_loss: 0.9105\n",
            "Epoch 1174/1500\n",
            "876/876 [==============================] - 3s 3ms/step\n",
            "110/110 [==============================] - 8s 77ms/step - loss: 0.6976 - val_loss: 0.6052\n",
            "Epoch 1175/1500\n",
            "876/876 [==============================] - 3s 3ms/step\n",
            "110/110 [==============================] - 10s 88ms/step - loss: 0.9749 - val_loss: 0.6221\n",
            "Epoch 1176/1500\n",
            "876/876 [==============================] - 3s 4ms/step\n",
            "110/110 [==============================] - 8s 74ms/step - loss: 0.4250 - val_loss: 0.9944\n",
            "Epoch 1177/1500\n",
            "876/876 [==============================] - 3s 3ms/step\n",
            "110/110 [==============================] - 6s 57ms/step - loss: 0.5051 - val_loss: 0.8246\n",
            "Epoch 1178/1500\n",
            "876/876 [==============================] - 3s 3ms/step\n",
            "110/110 [==============================] - 7s 61ms/step - loss: 0.3345 - val_loss: 0.5642\n",
            "Epoch 1179/1500\n",
            "876/876 [==============================] - 3s 3ms/step\n",
            "110/110 [==============================] - 8s 69ms/step - loss: 0.4729 - val_loss: 0.6159\n",
            "Epoch 1180/1500\n",
            "876/876 [==============================] - 3s 3ms/step\n",
            "110/110 [==============================] - 8s 76ms/step - loss: 0.6049 - val_loss: 0.8888\n",
            "Epoch 1181/1500\n",
            "876/876 [==============================] - 3s 3ms/step\n",
            "110/110 [==============================] - 10s 87ms/step - loss: 0.5477 - val_loss: 0.8849\n",
            "Epoch 1182/1500\n",
            "876/876 [==============================] - 3s 3ms/step\n",
            "110/110 [==============================] - 6s 59ms/step - loss: 0.5765 - val_loss: 0.9964\n",
            "Epoch 1183/1500\n",
            "876/876 [==============================] - 3s 3ms/step\n",
            "110/110 [==============================] - 10s 90ms/step - loss: 0.9215 - val_loss: 0.6470\n",
            "Epoch 1184/1500\n",
            "876/876 [==============================] - 3s 3ms/step\n",
            "110/110 [==============================] - 8s 75ms/step - loss: 0.3317 - val_loss: 0.7009\n",
            "Epoch 1185/1500\n",
            "876/876 [==============================] - 3s 3ms/step\n",
            "110/110 [==============================] - 9s 84ms/step - loss: 0.5208 - val_loss: 0.9380\n",
            "Epoch 1186/1500\n",
            "876/876 [==============================] - 3s 4ms/step\n",
            "110/110 [==============================] - 7s 62ms/step - loss: 0.4094 - val_loss: 0.6003\n",
            "Epoch 1187/1500\n",
            "876/876 [==============================] - 3s 3ms/step\n",
            "110/110 [==============================] - 8s 75ms/step - loss: 0.6347 - val_loss: 1.0004\n",
            "Epoch 1188/1500\n",
            "876/876 [==============================] - 3s 4ms/step\n",
            "110/110 [==============================] - 10s 90ms/step - loss: 0.3209 - val_loss: 0.5389\n",
            "Epoch 1189/1500\n",
            "876/876 [==============================] - 3s 4ms/step\n",
            "110/110 [==============================] - 8s 74ms/step - loss: 0.3772 - val_loss: 1.0265\n",
            "Epoch 1190/1500\n",
            "876/876 [==============================] - 3s 3ms/step\n",
            "110/110 [==============================] - 9s 80ms/step - loss: 0.8065 - val_loss: 0.6323\n",
            "Epoch 1191/1500\n",
            "876/876 [==============================] - 3s 3ms/step\n",
            "110/110 [==============================] - 9s 81ms/step - loss: 0.4477 - val_loss: 0.8177\n",
            "Epoch 1192/1500\n",
            "876/876 [==============================] - 3s 3ms/step\n",
            "110/110 [==============================] - 6s 55ms/step - loss: 0.4495 - val_loss: 0.6071\n",
            "Epoch 1193/1500\n",
            "876/876 [==============================] - 3s 4ms/step\n",
            "110/110 [==============================] - 8s 78ms/step - loss: 0.5613 - val_loss: 1.1764\n",
            "Epoch 1194/1500\n",
            "876/876 [==============================] - 3s 3ms/step\n",
            "110/110 [==============================] - 8s 77ms/step - loss: 0.5513 - val_loss: 1.7201\n",
            "Epoch 1195/1500\n",
            "876/876 [==============================] - 3s 3ms/step\n",
            "110/110 [==============================] - 9s 84ms/step - loss: 0.4620 - val_loss: 0.6327\n",
            "Epoch 1196/1500\n",
            "876/876 [==============================] - 3s 3ms/step\n",
            "110/110 [==============================] - 6s 55ms/step - loss: 0.3934 - val_loss: 1.7867\n",
            "Epoch 1197/1500\n",
            "876/876 [==============================] - 3s 3ms/step\n",
            "110/110 [==============================] - 7s 63ms/step - loss: 0.6807 - val_loss: 0.5373\n",
            "Epoch 1198/1500\n",
            "876/876 [==============================] - 3s 3ms/step\n",
            "110/110 [==============================] - 8s 72ms/step - loss: 0.6267 - val_loss: 0.6865\n",
            "Epoch 1199/1500\n",
            "876/876 [==============================] - 3s 3ms/step\n",
            "110/110 [==============================] - 8s 72ms/step - loss: 0.3764 - val_loss: 0.9308\n",
            "Epoch 1200/1500\n",
            "876/876 [==============================] - 3s 3ms/step\n",
            "110/110 [==============================] - 10s 90ms/step - loss: 0.4928 - val_loss: 0.9151\n",
            "Epoch 1201/1500\n",
            "876/876 [==============================] - 3s 3ms/step\n",
            "110/110 [==============================] - 8s 77ms/step - loss: 0.3600 - val_loss: 0.6795\n",
            "Epoch 1202/1500\n",
            "876/876 [==============================] - 3s 4ms/step\n",
            "110/110 [==============================] - 9s 78ms/step - loss: 1.0809 - val_loss: 0.8867\n",
            "Epoch 1203/1500\n",
            "876/876 [==============================] - 3s 3ms/step\n",
            "110/110 [==============================] - 7s 64ms/step - loss: 0.4285 - val_loss: 0.6842\n",
            "Epoch 1204/1500\n",
            "876/876 [==============================] - 3s 4ms/step\n",
            "110/110 [==============================] - 8s 75ms/step - loss: 0.5455 - val_loss: 0.8257\n",
            "Epoch 1205/1500\n",
            "876/876 [==============================] - 3s 3ms/step\n",
            "110/110 [==============================] - 6s 56ms/step - loss: 0.3418 - val_loss: 0.5928\n",
            "Epoch 1206/1500\n",
            "876/876 [==============================] - 3s 3ms/step\n",
            "110/110 [==============================] - 9s 79ms/step - loss: 0.5237 - val_loss: 0.5607\n",
            "Epoch 1207/1500\n",
            "876/876 [==============================] - 3s 3ms/step\n",
            "110/110 [==============================] - 6s 57ms/step - loss: 0.4981 - val_loss: 0.8713\n",
            "Epoch 1208/1500\n",
            "876/876 [==============================] - 3s 3ms/step\n",
            "110/110 [==============================] - 7s 61ms/step - loss: 0.5231 - val_loss: 0.7636\n",
            "Epoch 1209/1500\n",
            "876/876 [==============================] - 3s 3ms/step\n",
            "110/110 [==============================] - 8s 69ms/step - loss: 0.3887 - val_loss: 0.7476\n",
            "Epoch 1210/1500\n",
            "876/876 [==============================] - 3s 3ms/step\n",
            "110/110 [==============================] - 9s 78ms/step - loss: 0.5927 - val_loss: 1.3858\n",
            "Epoch 1211/1500\n",
            "876/876 [==============================] - 3s 3ms/step\n",
            "110/110 [==============================] - 10s 94ms/step - loss: 0.4625 - val_loss: 0.6126\n",
            "Epoch 1212/1500\n",
            "876/876 [==============================] - 3s 3ms/step\n",
            "110/110 [==============================] - 8s 77ms/step - loss: 0.3785 - val_loss: 0.7491\n",
            "Epoch 1213/1500\n",
            "876/876 [==============================] - 3s 3ms/step\n",
            "110/110 [==============================] - 7s 65ms/step - loss: 0.3554 - val_loss: 0.7656\n",
            "Epoch 1214/1500\n",
            "876/876 [==============================] - 3s 3ms/step\n",
            "110/110 [==============================] - 6s 58ms/step - loss: 0.4715 - val_loss: 0.6398\n",
            "Epoch 1215/1500\n",
            "876/876 [==============================] - 3s 3ms/step\n",
            "110/110 [==============================] - 10s 89ms/step - loss: 0.4815 - val_loss: 1.4953\n",
            "Epoch 1216/1500\n",
            "876/876 [==============================] - 3s 3ms/step\n",
            "110/110 [==============================] - 6s 58ms/step - loss: 0.5426 - val_loss: 0.8659\n",
            "Epoch 1217/1500\n",
            "876/876 [==============================] - 3s 4ms/step\n",
            "110/110 [==============================] - 8s 77ms/step - loss: 0.5334 - val_loss: 0.6404\n",
            "Epoch 1218/1500\n",
            "876/876 [==============================] - 3s 3ms/step\n",
            "110/110 [==============================] - 10s 90ms/step - loss: 0.7508 - val_loss: 0.6622\n",
            "Epoch 1219/1500\n",
            "876/876 [==============================] - 3s 3ms/step\n",
            "110/110 [==============================] - 7s 63ms/step - loss: 0.5261 - val_loss: 0.7177\n",
            "Epoch 1220/1500\n",
            "876/876 [==============================] - 3s 3ms/step\n",
            "110/110 [==============================] - 8s 70ms/step - loss: 0.7019 - val_loss: 0.6760\n",
            "Epoch 1221/1500\n",
            "876/876 [==============================] - 3s 3ms/step\n",
            "110/110 [==============================] - 6s 57ms/step - loss: 0.3297 - val_loss: 0.7121\n",
            "Epoch 1222/1500\n",
            "876/876 [==============================] - 3s 4ms/step\n",
            "110/110 [==============================] - 9s 83ms/step - loss: 0.4662 - val_loss: 0.5625\n",
            "Epoch 1223/1500\n",
            "876/876 [==============================] - 3s 3ms/step\n",
            "110/110 [==============================] - 8s 70ms/step - loss: 0.5164 - val_loss: 3.1628\n",
            "Epoch 1224/1500\n",
            "876/876 [==============================] - 3s 3ms/step\n",
            "110/110 [==============================] - 8s 77ms/step - loss: 0.5207 - val_loss: 0.6859\n",
            "Epoch 1225/1500\n",
            "876/876 [==============================] - 3s 3ms/step\n",
            "110/110 [==============================] - 8s 77ms/step - loss: 0.5134 - val_loss: 0.6800\n",
            "Epoch 1226/1500\n",
            "876/876 [==============================] - 3s 4ms/step\n",
            "110/110 [==============================] - 9s 84ms/step - loss: 0.4363 - val_loss: 1.0061\n",
            "Epoch 1227/1500\n",
            "876/876 [==============================] - 3s 3ms/step\n",
            "110/110 [==============================] - 6s 58ms/step - loss: 0.5301 - val_loss: 0.7070\n",
            "Epoch 1228/1500\n",
            "876/876 [==============================] - 3s 3ms/step\n",
            "110/110 [==============================] - 7s 63ms/step - loss: 0.3730 - val_loss: 0.5609\n",
            "Epoch 1229/1500\n",
            "876/876 [==============================] - 3s 3ms/step\n",
            "110/110 [==============================] - 10s 88ms/step - loss: 0.5130 - val_loss: 0.8330\n",
            "Epoch 1230/1500\n",
            "876/876 [==============================] - 3s 3ms/step\n",
            "110/110 [==============================] - 7s 61ms/step - loss: 0.5703 - val_loss: 0.5783\n",
            "Epoch 1231/1500\n",
            "876/876 [==============================] - 3s 4ms/step\n",
            "110/110 [==============================] - 8s 76ms/step - loss: 0.4684 - val_loss: 0.7811\n",
            "Epoch 1232/1500\n",
            "876/876 [==============================] - 3s 3ms/step\n",
            "110/110 [==============================] - 10s 87ms/step - loss: 0.3882 - val_loss: 0.5971\n",
            "Epoch 1233/1500\n",
            "876/876 [==============================] - 3s 3ms/step\n",
            "110/110 [==============================] - 10s 88ms/step - loss: 0.6512 - val_loss: 0.6346\n",
            "Epoch 1234/1500\n",
            "876/876 [==============================] - 3s 3ms/step\n",
            "110/110 [==============================] - 7s 66ms/step - loss: 0.4787 - val_loss: 0.9602\n",
            "Epoch 1235/1500\n",
            "876/876 [==============================] - 3s 3ms/step\n",
            "110/110 [==============================] - 9s 86ms/step - loss: 1.0695 - val_loss: 1.9062\n",
            "Epoch 1236/1500\n",
            "876/876 [==============================] - 3s 3ms/step\n",
            "110/110 [==============================] - 8s 76ms/step - loss: 0.6447 - val_loss: 0.8665\n",
            "Epoch 1237/1500\n",
            "876/876 [==============================] - 3s 3ms/step\n",
            "110/110 [==============================] - 8s 71ms/step - loss: 0.5291 - val_loss: 0.6164\n",
            "Epoch 1238/1500\n",
            "876/876 [==============================] - 3s 3ms/step\n",
            "110/110 [==============================] - 9s 79ms/step - loss: 0.3893 - val_loss: 1.0235\n",
            "Epoch 1239/1500\n",
            "876/876 [==============================] - 3s 3ms/step\n",
            "110/110 [==============================] - 7s 66ms/step - loss: 0.5634 - val_loss: 1.3849\n",
            "Epoch 1240/1500\n",
            "876/876 [==============================] - 3s 3ms/step\n",
            "110/110 [==============================] - 9s 84ms/step - loss: 0.5831 - val_loss: 0.6227\n",
            "Epoch 1241/1500\n",
            "876/876 [==============================] - 3s 4ms/step\n",
            "110/110 [==============================] - 9s 82ms/step - loss: 0.4318 - val_loss: 1.2950\n",
            "Epoch 1242/1500\n",
            "876/876 [==============================] - 3s 3ms/step\n",
            "110/110 [==============================] - 8s 77ms/step - loss: 0.7879 - val_loss: 0.8781\n",
            "Epoch 1243/1500\n",
            "876/876 [==============================] - 3s 4ms/step\n",
            "110/110 [==============================] - 8s 70ms/step - loss: 0.3469 - val_loss: 0.5910\n",
            "Epoch 1244/1500\n",
            "876/876 [==============================] - 3s 3ms/step\n",
            "110/110 [==============================] - 8s 75ms/step - loss: 0.4262 - val_loss: 0.6049\n",
            "Epoch 1245/1500\n",
            "876/876 [==============================] - 3s 4ms/step\n",
            "110/110 [==============================] - 9s 87ms/step - loss: 0.6845 - val_loss: 0.6182\n",
            "Epoch 1246/1500\n",
            "876/876 [==============================] - 3s 3ms/step\n",
            "110/110 [==============================] - 8s 71ms/step - loss: 0.3863 - val_loss: 0.5930\n",
            "Epoch 1247/1500\n",
            "876/876 [==============================] - 3s 3ms/step\n",
            "110/110 [==============================] - 8s 77ms/step - loss: 0.5559 - val_loss: 0.6032\n",
            "Epoch 1248/1500\n",
            "876/876 [==============================] - 3s 3ms/step\n",
            "110/110 [==============================] - 6s 58ms/step - loss: 0.6180 - val_loss: 0.6358\n",
            "Epoch 1249/1500\n",
            "876/876 [==============================] - 3s 3ms/step\n",
            "110/110 [==============================] - 8s 77ms/step - loss: 0.3172 - val_loss: 0.6078\n",
            "Epoch 1250/1500\n",
            "876/876 [==============================] - 3s 3ms/step\n",
            "110/110 [==============================] - 6s 56ms/step - loss: 0.4722 - val_loss: 0.6432\n",
            "Epoch 1251/1500\n",
            "876/876 [==============================] - 3s 3ms/step\n",
            "110/110 [==============================] - 7s 60ms/step - loss: 0.4415 - val_loss: 0.6232\n",
            "Epoch 1252/1500\n",
            "876/876 [==============================] - 3s 3ms/step\n",
            "110/110 [==============================] - 8s 72ms/step - loss: 0.6159 - val_loss: 0.5999\n",
            "Epoch 1253/1500\n",
            "876/876 [==============================] - 3s 3ms/step\n",
            "110/110 [==============================] - 6s 57ms/step - loss: 0.5554 - val_loss: 0.6413\n",
            "Epoch 1254/1500\n",
            "876/876 [==============================] - 3s 4ms/step\n",
            "110/110 [==============================] - 9s 83ms/step - loss: 0.4524 - val_loss: 0.9554\n",
            "Epoch 1255/1500\n",
            "876/876 [==============================] - 3s 3ms/step\n",
            "110/110 [==============================] - 6s 57ms/step - loss: 0.4866 - val_loss: 0.5295\n",
            "Epoch 1256/1500\n",
            "876/876 [==============================] - 3s 3ms/step\n",
            "110/110 [==============================] - 9s 80ms/step - loss: 0.4768 - val_loss: 0.7081\n",
            "Epoch 1257/1500\n",
            "876/876 [==============================] - 3s 3ms/step\n",
            "110/110 [==============================] - 6s 56ms/step - loss: 0.6411 - val_loss: 1.3436\n",
            "Epoch 1258/1500\n",
            "876/876 [==============================] - 3s 3ms/step\n",
            "110/110 [==============================] - 9s 78ms/step - loss: 0.4264 - val_loss: 0.8293\n",
            "Epoch 1259/1500\n",
            "876/876 [==============================] - 3s 4ms/step\n",
            "110/110 [==============================] - 10s 91ms/step - loss: 0.5205 - val_loss: 0.5681\n",
            "Epoch 1260/1500\n",
            "876/876 [==============================] - 3s 4ms/step\n",
            "110/110 [==============================] - 10s 91ms/step - loss: 0.3392 - val_loss: 0.5421\n",
            "Epoch 1261/1500\n",
            "876/876 [==============================] - 3s 3ms/step\n",
            "110/110 [==============================] - 6s 56ms/step - loss: 0.6426 - val_loss: 0.7350\n",
            "Epoch 1262/1500\n",
            "876/876 [==============================] - 3s 3ms/step\n",
            "110/110 [==============================] - 9s 80ms/step - loss: 0.3869 - val_loss: 0.6570\n",
            "Epoch 1263/1500\n",
            "876/876 [==============================] - 3s 3ms/step\n",
            "110/110 [==============================] - 8s 77ms/step - loss: 0.4245 - val_loss: 0.5700\n",
            "Epoch 1264/1500\n",
            "876/876 [==============================] - 3s 4ms/step\n",
            "110/110 [==============================] - 9s 85ms/step - loss: 0.3177 - val_loss: 0.9587\n",
            "Epoch 1265/1500\n",
            "876/876 [==============================] - 3s 3ms/step\n",
            "110/110 [==============================] - 8s 77ms/step - loss: 0.6474 - val_loss: 0.8773\n",
            "Epoch 1266/1500\n",
            "876/876 [==============================] - 3s 3ms/step\n",
            "110/110 [==============================] - 8s 72ms/step - loss: 0.4121 - val_loss: 1.5947\n",
            "Epoch 1267/1500\n",
            "876/876 [==============================] - 3s 3ms/step\n",
            "110/110 [==============================] - 9s 82ms/step - loss: 0.4887 - val_loss: 0.6279\n",
            "Epoch 1268/1500\n",
            "876/876 [==============================] - 3s 3ms/step\n",
            "110/110 [==============================] - 9s 82ms/step - loss: 0.5672 - val_loss: 0.6079\n",
            "Epoch 1269/1500\n",
            "876/876 [==============================] - 3s 3ms/step\n",
            "110/110 [==============================] - 6s 57ms/step - loss: 0.5517 - val_loss: 1.1707\n",
            "Epoch 1270/1500\n",
            "876/876 [==============================] - 3s 4ms/step\n",
            "110/110 [==============================] - 7s 65ms/step - loss: 0.6026 - val_loss: 0.7466\n",
            "Epoch 1271/1500\n",
            "876/876 [==============================] - 3s 4ms/step\n",
            "110/110 [==============================] - 8s 77ms/step - loss: 0.4268 - val_loss: 1.9811\n",
            "Epoch 1272/1500\n",
            "876/876 [==============================] - 3s 3ms/step\n",
            "110/110 [==============================] - 10s 87ms/step - loss: 0.6861 - val_loss: 0.6467\n",
            "Epoch 1273/1500\n",
            "876/876 [==============================] - 3s 4ms/step\n",
            "110/110 [==============================] - 10s 92ms/step - loss: 0.3891 - val_loss: 0.9795\n",
            "Epoch 1274/1500\n",
            "876/876 [==============================] - 3s 3ms/step\n",
            "110/110 [==============================] - 7s 60ms/step - loss: 0.3054 - val_loss: 0.7451\n",
            "Epoch 1275/1500\n",
            "876/876 [==============================] - 3s 4ms/step\n",
            "110/110 [==============================] - 8s 74ms/step - loss: 0.8431 - val_loss: 0.7868\n",
            "Epoch 1276/1500\n",
            "876/876 [==============================] - 3s 3ms/step\n",
            "110/110 [==============================] - 9s 79ms/step - loss: 0.8689 - val_loss: 0.7703\n",
            "Epoch 1277/1500\n",
            "876/876 [==============================] - 3s 4ms/step\n",
            "110/110 [==============================] - 9s 84ms/step - loss: 0.5805 - val_loss: 0.6801\n",
            "Epoch 1278/1500\n",
            "876/876 [==============================] - 3s 3ms/step\n",
            "110/110 [==============================] - 6s 57ms/step - loss: 0.4801 - val_loss: 0.6557\n",
            "Epoch 1279/1500\n",
            "876/876 [==============================] - 3s 3ms/step\n",
            "110/110 [==============================] - 7s 64ms/step - loss: 0.3922 - val_loss: 0.8130\n",
            "Epoch 1280/1500\n",
            "876/876 [==============================] - 3s 3ms/step\n",
            "110/110 [==============================] - 10s 88ms/step - loss: 0.5063 - val_loss: 1.0217\n",
            "Epoch 1281/1500\n",
            "876/876 [==============================] - 3s 4ms/step\n",
            "110/110 [==============================] - 7s 64ms/step - loss: 0.6333 - val_loss: 0.5779\n",
            "Epoch 1282/1500\n",
            "876/876 [==============================] - 3s 3ms/step\n",
            "110/110 [==============================] - 10s 93ms/step - loss: 0.4166 - val_loss: 0.5487\n",
            "Epoch 1283/1500\n",
            "876/876 [==============================] - 3s 3ms/step\n",
            "110/110 [==============================] - 9s 79ms/step - loss: 0.6039 - val_loss: 0.6860\n",
            "Epoch 1284/1500\n",
            "876/876 [==============================] - 3s 3ms/step\n",
            "110/110 [==============================] - 7s 65ms/step - loss: 0.3429 - val_loss: 0.5789\n",
            "Epoch 1285/1500\n",
            "876/876 [==============================] - 3s 4ms/step\n",
            "110/110 [==============================] - 9s 81ms/step - loss: 0.3330 - val_loss: 0.5374\n",
            "Epoch 1286/1500\n",
            "876/876 [==============================] - 3s 3ms/step\n",
            "110/110 [==============================] - 7s 67ms/step - loss: 0.4253 - val_loss: 0.9191\n",
            "Epoch 1287/1500\n",
            "876/876 [==============================] - 4s 4ms/step\n",
            "110/110 [==============================] - 8s 72ms/step - loss: 0.6157 - val_loss: 0.6419\n",
            "Epoch 1288/1500\n",
            "876/876 [==============================] - 4s 4ms/step\n",
            "110/110 [==============================] - 10s 90ms/step - loss: 0.4478 - val_loss: 0.6064\n",
            "Epoch 1289/1500\n",
            "876/876 [==============================] - 3s 4ms/step\n",
            "110/110 [==============================] - 10s 93ms/step - loss: 0.5041 - val_loss: 1.0603\n",
            "Epoch 1290/1500\n",
            "876/876 [==============================] - 3s 4ms/step\n",
            "110/110 [==============================] - 8s 74ms/step - loss: 0.7901 - val_loss: 1.2996\n",
            "Epoch 1291/1500\n",
            "876/876 [==============================] - 4s 4ms/step\n",
            "110/110 [==============================] - 9s 81ms/step - loss: 0.6135 - val_loss: 0.6780\n",
            "Epoch 1292/1500\n",
            "876/876 [==============================] - 3s 3ms/step\n",
            "110/110 [==============================] - 10s 87ms/step - loss: 0.3553 - val_loss: 0.6842\n",
            "Epoch 1293/1500\n",
            "876/876 [==============================] - 4s 4ms/step\n",
            "110/110 [==============================] - 8s 75ms/step - loss: 0.4266 - val_loss: 0.7161\n",
            "Epoch 1294/1500\n",
            "876/876 [==============================] - 3s 3ms/step\n",
            "110/110 [==============================] - 10s 89ms/step - loss: 0.4305 - val_loss: 1.2844\n",
            "Epoch 1295/1500\n",
            "876/876 [==============================] - 3s 4ms/step\n",
            "110/110 [==============================] - 8s 72ms/step - loss: 0.4026 - val_loss: 0.9008\n",
            "Epoch 1296/1500\n",
            "876/876 [==============================] - 3s 3ms/step\n",
            "110/110 [==============================] - 8s 76ms/step - loss: 0.3699 - val_loss: 0.6244\n",
            "Epoch 1297/1500\n",
            "876/876 [==============================] - 3s 3ms/step\n",
            "110/110 [==============================] - 7s 64ms/step - loss: 0.8614 - val_loss: 0.6842\n",
            "Epoch 1298/1500\n",
            "876/876 [==============================] - 3s 4ms/step\n",
            "110/110 [==============================] - 9s 78ms/step - loss: 0.5386 - val_loss: 0.7064\n",
            "Epoch 1299/1500\n",
            "876/876 [==============================] - 3s 3ms/step\n",
            "110/110 [==============================] - 9s 80ms/step - loss: 0.3664 - val_loss: 0.7819\n",
            "Epoch 1300/1500\n",
            "876/876 [==============================] - 3s 3ms/step\n",
            "110/110 [==============================] - 8s 73ms/step - loss: 0.3843 - val_loss: 1.0728\n",
            "Epoch 1301/1500\n",
            "876/876 [==============================] - 3s 3ms/step\n",
            "110/110 [==============================] - 9s 80ms/step - loss: 0.8037 - val_loss: 0.6294\n",
            "Epoch 1302/1500\n",
            "876/876 [==============================] - 3s 4ms/step\n",
            "110/110 [==============================] - 10s 90ms/step - loss: 0.6644 - val_loss: 0.7457\n",
            "Epoch 1303/1500\n",
            "876/876 [==============================] - 3s 4ms/step\n",
            "110/110 [==============================] - 8s 77ms/step - loss: 0.5296 - val_loss: 0.6217\n",
            "Epoch 1304/1500\n",
            "876/876 [==============================] - 3s 3ms/step\n",
            "110/110 [==============================] - 7s 67ms/step - loss: 0.4402 - val_loss: 0.5885\n",
            "Epoch 1305/1500\n",
            "876/876 [==============================] - 3s 4ms/step\n",
            "110/110 [==============================] - 9s 79ms/step - loss: 0.5498 - val_loss: 2.0788\n",
            "Epoch 1306/1500\n",
            "876/876 [==============================] - 3s 3ms/step\n",
            "110/110 [==============================] - 7s 65ms/step - loss: 0.5751 - val_loss: 0.6421\n",
            "Epoch 1307/1500\n",
            "876/876 [==============================] - 3s 4ms/step\n",
            "110/110 [==============================] - 9s 80ms/step - loss: 0.5875 - val_loss: 1.0981\n",
            "Epoch 1308/1500\n",
            "876/876 [==============================] - 3s 3ms/step\n",
            "110/110 [==============================] - 9s 82ms/step - loss: 0.4533 - val_loss: 1.1042\n",
            "Epoch 1309/1500\n",
            "876/876 [==============================] - 3s 4ms/step\n",
            "110/110 [==============================] - 9s 84ms/step - loss: 0.4505 - val_loss: 0.6744\n",
            "Epoch 1310/1500\n",
            "876/876 [==============================] - 3s 3ms/step\n",
            "110/110 [==============================] - 7s 62ms/step - loss: 0.4688 - val_loss: 0.5682\n",
            "Epoch 1311/1500\n",
            "876/876 [==============================] - 3s 4ms/step\n",
            "110/110 [==============================] - 9s 82ms/step - loss: 0.6166 - val_loss: 0.9620\n",
            "Epoch 1312/1500\n",
            "876/876 [==============================] - 3s 3ms/step\n",
            "110/110 [==============================] - 7s 60ms/step - loss: 0.5460 - val_loss: 0.8077\n",
            "Epoch 1313/1500\n",
            "876/876 [==============================] - 3s 4ms/step\n",
            "110/110 [==============================] - 7s 68ms/step - loss: 0.5047 - val_loss: 0.6622\n",
            "Epoch 1314/1500\n",
            "876/876 [==============================] - 3s 3ms/step\n",
            "110/110 [==============================] - 10s 89ms/step - loss: 0.3564 - val_loss: 0.7179\n",
            "Epoch 1315/1500\n",
            "876/876 [==============================] - 3s 4ms/step\n",
            "110/110 [==============================] - 7s 65ms/step - loss: 0.6177 - val_loss: 3.0852\n",
            "Epoch 1316/1500\n",
            "876/876 [==============================] - 3s 3ms/step\n",
            "110/110 [==============================] - 8s 74ms/step - loss: 1.1294 - val_loss: 0.6720\n",
            "Epoch 1317/1500\n",
            "876/876 [==============================] - 3s 3ms/step\n",
            "110/110 [==============================] - 7s 60ms/step - loss: 0.3042 - val_loss: 0.6753\n",
            "Epoch 1318/1500\n",
            "876/876 [==============================] - 3s 4ms/step\n",
            "110/110 [==============================] - 9s 78ms/step - loss: 0.4299 - val_loss: 0.7081\n",
            "Epoch 1319/1500\n",
            "876/876 [==============================] - 3s 3ms/step\n",
            "110/110 [==============================] - 10s 95ms/step - loss: 0.5735 - val_loss: 0.7018\n",
            "Epoch 1320/1500\n",
            "876/876 [==============================] - 3s 4ms/step\n",
            "110/110 [==============================] - 8s 69ms/step - loss: 0.4585 - val_loss: 1.3232\n",
            "Epoch 1321/1500\n",
            "876/876 [==============================] - 3s 3ms/step\n",
            "110/110 [==============================] - 8s 73ms/step - loss: 0.4482 - val_loss: 1.0160\n",
            "Epoch 1322/1500\n",
            "876/876 [==============================] - 3s 3ms/step\n",
            "110/110 [==============================] - 7s 61ms/step - loss: 0.6369 - val_loss: 5.1791\n",
            "Epoch 1323/1500\n",
            "876/876 [==============================] - 3s 4ms/step\n",
            "110/110 [==============================] - 10s 91ms/step - loss: 0.6717 - val_loss: 0.6721\n",
            "Epoch 1324/1500\n",
            "876/876 [==============================] - 3s 3ms/step\n",
            "110/110 [==============================] - 7s 61ms/step - loss: 0.3361 - val_loss: 1.9928\n",
            "Epoch 1325/1500\n",
            "876/876 [==============================] - 3s 4ms/step\n",
            "110/110 [==============================] - 10s 87ms/step - loss: 0.4162 - val_loss: 0.6011\n",
            "Epoch 1326/1500\n",
            "876/876 [==============================] - 3s 3ms/step\n",
            "110/110 [==============================] - 9s 78ms/step - loss: 0.5803 - val_loss: 0.7166\n",
            "Epoch 1327/1500\n",
            "876/876 [==============================] - 3s 4ms/step\n",
            "110/110 [==============================] - 8s 77ms/step - loss: 0.4877 - val_loss: 0.5826\n",
            "Epoch 1328/1500\n",
            "876/876 [==============================] - 3s 3ms/step\n",
            "110/110 [==============================] - 7s 62ms/step - loss: 0.4270 - val_loss: 0.8951\n",
            "Epoch 1329/1500\n",
            "876/876 [==============================] - 3s 4ms/step\n",
            "110/110 [==============================] - 8s 70ms/step - loss: 0.3616 - val_loss: 1.1148\n",
            "Epoch 1330/1500\n",
            "876/876 [==============================] - 3s 3ms/step\n",
            "110/110 [==============================] - 10s 91ms/step - loss: 0.3240 - val_loss: 0.7543\n",
            "Epoch 1331/1500\n",
            "876/876 [==============================] - 3s 4ms/step\n",
            "110/110 [==============================] - 9s 80ms/step - loss: 0.5648 - val_loss: 0.6287\n",
            "Epoch 1332/1500\n",
            "876/876 [==============================] - 3s 3ms/step\n",
            "110/110 [==============================] - 7s 61ms/step - loss: 0.3326 - val_loss: 0.5708\n",
            "Epoch 1333/1500\n",
            "876/876 [==============================] - 3s 4ms/step\n",
            "110/110 [==============================] - 7s 66ms/step - loss: 0.2869 - val_loss: 1.7241\n",
            "Epoch 1334/1500\n",
            "876/876 [==============================] - 3s 3ms/step\n",
            "110/110 [==============================] - 8s 73ms/step - loss: 0.6918 - val_loss: 0.8206\n",
            "Epoch 1335/1500\n",
            "876/876 [==============================] - 3s 4ms/step\n",
            "110/110 [==============================] - 9s 79ms/step - loss: 0.6657 - val_loss: 0.7997\n",
            "Epoch 1336/1500\n",
            "876/876 [==============================] - 3s 4ms/step\n",
            "110/110 [==============================] - 10s 92ms/step - loss: 0.7143 - val_loss: 0.7514\n",
            "Epoch 1337/1500\n",
            "876/876 [==============================] - 3s 3ms/step\n",
            "110/110 [==============================] - 9s 80ms/step - loss: 0.3497 - val_loss: 1.3213\n",
            "Epoch 1338/1500\n",
            "876/876 [==============================] - 3s 3ms/step\n",
            "110/110 [==============================] - 9s 82ms/step - loss: 0.5074 - val_loss: 0.8506\n",
            "Epoch 1339/1500\n",
            "876/876 [==============================] - 3s 4ms/step\n",
            "110/110 [==============================] - 10s 87ms/step - loss: 0.4800 - val_loss: 0.6323\n",
            "Epoch 1340/1500\n",
            "876/876 [==============================] - 3s 3ms/step\n",
            "110/110 [==============================] - 7s 61ms/step - loss: 0.5524 - val_loss: 1.8222\n",
            "Epoch 1341/1500\n",
            "876/876 [==============================] - 3s 4ms/step\n",
            "110/110 [==============================] - 9s 83ms/step - loss: 0.5360 - val_loss: 0.9246\n",
            "Epoch 1342/1500\n",
            "876/876 [==============================] - 3s 3ms/step\n",
            "110/110 [==============================] - 9s 79ms/step - loss: 0.4991 - val_loss: 0.6083\n",
            "Epoch 1343/1500\n",
            "876/876 [==============================] - 3s 4ms/step\n",
            "110/110 [==============================] - 10s 89ms/step - loss: 0.3851 - val_loss: 0.6863\n",
            "Epoch 1344/1500\n",
            "876/876 [==============================] - 3s 3ms/step\n",
            "110/110 [==============================] - 7s 60ms/step - loss: 0.5196 - val_loss: 0.8536\n",
            "Epoch 1345/1500\n",
            "876/876 [==============================] - 3s 4ms/step\n",
            "110/110 [==============================] - 8s 72ms/step - loss: 0.6040 - val_loss: 0.7222\n",
            "Epoch 1346/1500\n",
            "876/876 [==============================] - 3s 3ms/step\n",
            "110/110 [==============================] - 8s 69ms/step - loss: 0.3589 - val_loss: 0.8115\n",
            "Epoch 1347/1500\n",
            "876/876 [==============================] - 3s 3ms/step\n",
            "110/110 [==============================] - 9s 80ms/step - loss: 0.4858 - val_loss: 0.9012\n",
            "Epoch 1348/1500\n",
            "876/876 [==============================] - 3s 3ms/step\n",
            "110/110 [==============================] - 7s 63ms/step - loss: 0.6423 - val_loss: 1.0432\n",
            "Epoch 1349/1500\n",
            "876/876 [==============================] - 3s 4ms/step\n",
            "110/110 [==============================] - 9s 78ms/step - loss: 0.3626 - val_loss: 0.5602\n",
            "Epoch 1350/1500\n",
            "876/876 [==============================] - 3s 3ms/step\n",
            "110/110 [==============================] - 7s 62ms/step - loss: 0.5576 - val_loss: 0.6053\n",
            "Epoch 1351/1500\n",
            "876/876 [==============================] - 3s 4ms/step\n",
            "110/110 [==============================] - 7s 66ms/step - loss: 0.3346 - val_loss: 1.4987\n",
            "Epoch 1352/1500\n",
            "876/876 [==============================] - 3s 4ms/step\n",
            "110/110 [==============================] - 10s 92ms/step - loss: 0.4574 - val_loss: 1.4906\n",
            "Epoch 1353/1500\n",
            "876/876 [==============================] - 3s 3ms/step\n",
            "110/110 [==============================] - 9s 82ms/step - loss: 0.6209 - val_loss: 1.2488\n",
            "Epoch 1354/1500\n",
            "876/876 [==============================] - 3s 3ms/step\n",
            "110/110 [==============================] - 9s 83ms/step - loss: 0.4940 - val_loss: 0.6511\n",
            "Epoch 1355/1500\n",
            "876/876 [==============================] - 3s 4ms/step\n",
            "110/110 [==============================] - 8s 72ms/step - loss: 0.4484 - val_loss: 0.7430\n",
            "Epoch 1356/1500\n",
            "876/876 [==============================] - 3s 3ms/step\n",
            "110/110 [==============================] - 8s 71ms/step - loss: 0.7990 - val_loss: 0.6953\n",
            "Epoch 1357/1500\n",
            "876/876 [==============================] - 3s 3ms/step\n",
            "110/110 [==============================] - 7s 64ms/step - loss: 0.3078 - val_loss: 0.7770\n",
            "Epoch 1358/1500\n",
            "876/876 [==============================] - 3s 4ms/step\n",
            "110/110 [==============================] - 9s 78ms/step - loss: 0.3330 - val_loss: 0.7675\n",
            "Epoch 1359/1500\n",
            "876/876 [==============================] - 3s 3ms/step\n",
            "110/110 [==============================] - 7s 62ms/step - loss: 0.7077 - val_loss: 1.8710\n",
            "Epoch 1360/1500\n",
            "876/876 [==============================] - 3s 4ms/step\n",
            "110/110 [==============================] - 9s 78ms/step - loss: 0.5139 - val_loss: 0.6031\n",
            "Epoch 1361/1500\n",
            "876/876 [==============================] - 3s 3ms/step\n",
            "110/110 [==============================] - 7s 67ms/step - loss: 0.3358 - val_loss: 0.6433\n",
            "Epoch 1362/1500\n",
            "876/876 [==============================] - 3s 4ms/step\n",
            "110/110 [==============================] - 9s 84ms/step - loss: 0.4062 - val_loss: 0.6079\n",
            "Epoch 1363/1500\n",
            "876/876 [==============================] - 3s 3ms/step\n",
            "110/110 [==============================] - 7s 62ms/step - loss: 0.3843 - val_loss: 0.8478\n",
            "Epoch 1364/1500\n",
            "876/876 [==============================] - 3s 4ms/step\n",
            "110/110 [==============================] - 9s 85ms/step - loss: 0.6420 - val_loss: 0.6983\n",
            "Epoch 1365/1500\n",
            "876/876 [==============================] - 3s 3ms/step\n",
            "110/110 [==============================] - 9s 79ms/step - loss: 0.4466 - val_loss: 1.3065\n",
            "Epoch 1366/1500\n",
            "876/876 [==============================] - 3s 4ms/step\n",
            "110/110 [==============================] - 10s 89ms/step - loss: 0.7994 - val_loss: 1.0179\n",
            "Epoch 1367/1500\n",
            "876/876 [==============================] - 3s 3ms/step\n",
            "110/110 [==============================] - 7s 62ms/step - loss: 0.7895 - val_loss: 0.6924\n",
            "Epoch 1368/1500\n",
            "876/876 [==============================] - 3s 4ms/step\n",
            "110/110 [==============================] - 9s 86ms/step - loss: 0.3182 - val_loss: 0.5716\n",
            "Epoch 1369/1500\n",
            "876/876 [==============================] - 3s 3ms/step\n",
            "110/110 [==============================] - 7s 63ms/step - loss: 0.6431 - val_loss: 0.7661\n",
            "Epoch 1370/1500\n",
            "876/876 [==============================] - 4s 4ms/step\n",
            "110/110 [==============================] - 10s 93ms/step - loss: 0.4250 - val_loss: 0.8171\n",
            "Epoch 1371/1500\n",
            "876/876 [==============================] - 3s 3ms/step\n",
            "110/110 [==============================] - 10s 89ms/step - loss: 0.3991 - val_loss: 1.7856\n",
            "Epoch 1372/1500\n",
            "876/876 [==============================] - 3s 4ms/step\n",
            "110/110 [==============================] - 9s 85ms/step - loss: 0.3732 - val_loss: 0.6972\n",
            "Epoch 1373/1500\n",
            "876/876 [==============================] - 3s 3ms/step\n",
            "110/110 [==============================] - 7s 62ms/step - loss: 0.3686 - val_loss: 0.5986\n",
            "Epoch 1374/1500\n",
            "876/876 [==============================] - 3s 4ms/step\n",
            "110/110 [==============================] - 9s 83ms/step - loss: 0.5232 - val_loss: 0.8708\n",
            "Epoch 1375/1500\n",
            "876/876 [==============================] - 3s 3ms/step\n",
            "110/110 [==============================] - 9s 80ms/step - loss: 0.4913 - val_loss: 1.4720\n",
            "Epoch 1376/1500\n",
            "876/876 [==============================] - 3s 4ms/step\n",
            "110/110 [==============================] - 9s 78ms/step - loss: 0.5515 - val_loss: 0.8840\n",
            "Epoch 1377/1500\n",
            "876/876 [==============================] - 3s 3ms/step\n",
            "110/110 [==============================] - 9s 86ms/step - loss: 0.4974 - val_loss: 1.0096\n",
            "Epoch 1378/1500\n",
            "876/876 [==============================] - 3s 4ms/step\n",
            "110/110 [==============================] - 10s 90ms/step - loss: 0.4515 - val_loss: 0.9290\n",
            "Epoch 1379/1500\n",
            "876/876 [==============================] - 3s 3ms/step\n",
            "110/110 [==============================] - 7s 64ms/step - loss: 0.3352 - val_loss: 0.5808\n",
            "Epoch 1380/1500\n",
            "876/876 [==============================] - 3s 4ms/step\n",
            "110/110 [==============================] - 9s 86ms/step - loss: 0.2973 - val_loss: 0.5449\n",
            "Epoch 1381/1500\n",
            "876/876 [==============================] - 3s 3ms/step\n",
            "110/110 [==============================] - 7s 61ms/step - loss: 0.5087 - val_loss: 0.6190\n",
            "Epoch 1382/1500\n",
            "876/876 [==============================] - 3s 4ms/step\n",
            "110/110 [==============================] - 9s 83ms/step - loss: 0.3683 - val_loss: 0.6838\n",
            "Epoch 1383/1500\n",
            "876/876 [==============================] - 3s 3ms/step\n",
            "110/110 [==============================] - 9s 79ms/step - loss: 0.5546 - val_loss: 1.4979\n",
            "Epoch 1384/1500\n",
            "876/876 [==============================] - 3s 4ms/step\n",
            "110/110 [==============================] - 8s 77ms/step - loss: 0.4256 - val_loss: 1.7631\n",
            "Epoch 1385/1500\n",
            "876/876 [==============================] - 3s 3ms/step\n",
            "110/110 [==============================] - 7s 68ms/step - loss: 0.4733 - val_loss: 0.8137\n",
            "Epoch 1386/1500\n",
            "876/876 [==============================] - 3s 4ms/step\n",
            "110/110 [==============================] - 9s 81ms/step - loss: 0.3771 - val_loss: 0.6134\n",
            "Epoch 1387/1500\n",
            "876/876 [==============================] - 3s 4ms/step\n",
            "110/110 [==============================] - 8s 69ms/step - loss: 0.3931 - val_loss: 0.7882\n",
            "Epoch 1388/1500\n",
            "876/876 [==============================] - 4s 4ms/step\n",
            "110/110 [==============================] - 10s 88ms/step - loss: 0.3709 - val_loss: 1.3079\n",
            "Epoch 1389/1500\n",
            "876/876 [==============================] - 3s 3ms/step\n",
            "110/110 [==============================] - 10s 90ms/step - loss: 0.3924 - val_loss: 0.7009\n",
            "Epoch 1390/1500\n",
            "876/876 [==============================] - 3s 4ms/step\n",
            "110/110 [==============================] - 8s 69ms/step - loss: 0.5704 - val_loss: 0.6239\n",
            "Epoch 1391/1500\n",
            "876/876 [==============================] - 3s 3ms/step\n",
            "110/110 [==============================] - 8s 74ms/step - loss: 0.3252 - val_loss: 0.8206\n",
            "Epoch 1392/1500\n",
            "876/876 [==============================] - 3s 4ms/step\n",
            "110/110 [==============================] - 7s 65ms/step - loss: 0.4704 - val_loss: 0.7575\n",
            "Epoch 1393/1500\n",
            "876/876 [==============================] - 3s 4ms/step\n",
            "110/110 [==============================] - 9s 78ms/step - loss: 0.3746 - val_loss: 0.8599\n",
            "Epoch 1394/1500\n",
            "876/876 [==============================] - 3s 3ms/step\n",
            "110/110 [==============================] - 7s 62ms/step - loss: 0.4472 - val_loss: 1.0034\n",
            "Epoch 1395/1500\n",
            "876/876 [==============================] - 3s 4ms/step\n",
            "110/110 [==============================] - 10s 91ms/step - loss: 0.5361 - val_loss: 0.6985\n",
            "Epoch 1396/1500\n",
            "876/876 [==============================] - 3s 3ms/step\n",
            "110/110 [==============================] - 7s 61ms/step - loss: 0.3476 - val_loss: 0.5571\n",
            "Epoch 1397/1500\n",
            "876/876 [==============================] - 3s 4ms/step\n",
            "110/110 [==============================] - 10s 88ms/step - loss: 0.4712 - val_loss: 0.6459\n",
            "Epoch 1398/1500\n",
            "876/876 [==============================] - 3s 3ms/step\n",
            "110/110 [==============================] - 7s 61ms/step - loss: 0.3732 - val_loss: 0.6843\n",
            "Epoch 1399/1500\n",
            "876/876 [==============================] - 3s 4ms/step\n",
            "110/110 [==============================] - 8s 72ms/step - loss: 0.4690 - val_loss: 0.5900\n",
            "Epoch 1400/1500\n",
            "876/876 [==============================] - 3s 3ms/step\n",
            "110/110 [==============================] - 8s 71ms/step - loss: 0.4487 - val_loss: 0.8025\n",
            "Epoch 1401/1500\n",
            "876/876 [==============================] - 3s 3ms/step\n",
            "110/110 [==============================] - 9s 80ms/step - loss: 0.3917 - val_loss: 0.5881\n",
            "Epoch 1402/1500\n",
            "876/876 [==============================] - 3s 3ms/step\n",
            "110/110 [==============================] - 7s 66ms/step - loss: 0.4640 - val_loss: 0.5985\n",
            "Epoch 1403/1500\n",
            "876/876 [==============================] - 3s 4ms/step\n",
            "110/110 [==============================] - 7s 66ms/step - loss: 0.4790 - val_loss: 0.5956\n",
            "Epoch 1404/1500\n",
            "876/876 [==============================] - 3s 3ms/step\n",
            "110/110 [==============================] - 10s 91ms/step - loss: 0.6823 - val_loss: 0.8027\n",
            "Epoch 1405/1500\n",
            "876/876 [==============================] - 3s 3ms/step\n",
            "110/110 [==============================] - 7s 64ms/step - loss: 0.3501 - val_loss: 0.5602\n",
            "Epoch 1406/1500\n",
            "876/876 [==============================] - 3s 4ms/step\n",
            "110/110 [==============================] - 10s 95ms/step - loss: 0.3558 - val_loss: 1.4067\n",
            "Epoch 1407/1500\n",
            "876/876 [==============================] - 3s 3ms/step\n",
            "110/110 [==============================] - 9s 85ms/step - loss: 0.4551 - val_loss: 0.7665\n",
            "Epoch 1408/1500\n",
            "876/876 [==============================] - 3s 4ms/step\n",
            "110/110 [==============================] - 8s 76ms/step - loss: 0.4587 - val_loss: 0.6697\n",
            "Epoch 1409/1500\n",
            "876/876 [==============================] - 3s 3ms/step\n",
            "110/110 [==============================] - 7s 62ms/step - loss: 0.5439 - val_loss: 1.7565\n",
            "Epoch 1410/1500\n",
            "876/876 [==============================] - 3s 4ms/step\n",
            "110/110 [==============================] - 9s 78ms/step - loss: 0.6294 - val_loss: 0.6933\n",
            "Epoch 1411/1500\n",
            "876/876 [==============================] - 3s 3ms/step\n",
            "110/110 [==============================] - 9s 84ms/step - loss: 0.3426 - val_loss: 0.6642\n",
            "Epoch 1412/1500\n",
            "876/876 [==============================] - 3s 3ms/step\n",
            "110/110 [==============================] - 10s 88ms/step - loss: 0.5652 - val_loss: 1.4376\n",
            "Epoch 1413/1500\n",
            "876/876 [==============================] - 3s 3ms/step\n",
            "110/110 [==============================] - 7s 61ms/step - loss: 0.4549 - val_loss: 1.4974\n",
            "Epoch 1414/1500\n",
            "876/876 [==============================] - 3s 4ms/step\n",
            "110/110 [==============================] - 9s 86ms/step - loss: 0.4091 - val_loss: 0.7427\n",
            "Epoch 1415/1500\n",
            "876/876 [==============================] - 3s 3ms/step\n",
            "110/110 [==============================] - 7s 62ms/step - loss: 0.3913 - val_loss: 0.8490\n",
            "Epoch 1416/1500\n",
            "876/876 [==============================] - 3s 4ms/step\n",
            "110/110 [==============================] - 9s 84ms/step - loss: 0.4366 - val_loss: 1.1540\n",
            "Epoch 1417/1500\n",
            "876/876 [==============================] - 3s 3ms/step\n",
            "110/110 [==============================] - 7s 61ms/step - loss: 0.3833 - val_loss: 0.7677\n",
            "Epoch 1418/1500\n",
            "876/876 [==============================] - 3s 4ms/step\n",
            "110/110 [==============================] - 8s 70ms/step - loss: 0.3866 - val_loss: 0.7573\n",
            "Epoch 1419/1500\n",
            "876/876 [==============================] - 3s 3ms/step\n",
            "110/110 [==============================] - 8s 73ms/step - loss: 0.6257 - val_loss: 0.6283\n",
            "Epoch 1420/1500\n",
            "876/876 [==============================] - 3s 3ms/step\n",
            "110/110 [==============================] - 9s 79ms/step - loss: 0.2850 - val_loss: 0.6752\n",
            "Epoch 1421/1500\n",
            "876/876 [==============================] - 3s 3ms/step\n",
            "110/110 [==============================] - 9s 83ms/step - loss: 0.3407 - val_loss: 0.5308\n",
            "Epoch 1422/1500\n",
            "876/876 [==============================] - 3s 4ms/step\n",
            "110/110 [==============================] - 8s 74ms/step - loss: 0.3161 - val_loss: 0.8172\n",
            "Epoch 1423/1500\n",
            "876/876 [==============================] - 3s 3ms/step\n",
            "110/110 [==============================] - 8s 69ms/step - loss: 0.7285 - val_loss: 0.7935\n",
            "Epoch 1424/1500\n",
            "876/876 [==============================] - 3s 3ms/step\n",
            "110/110 [==============================] - 9s 79ms/step - loss: 0.5458 - val_loss: 0.6041\n",
            "Epoch 1425/1500\n",
            "876/876 [==============================] - 3s 4ms/step\n",
            "110/110 [==============================] - 8s 77ms/step - loss: 0.4204 - val_loss: 0.8574\n",
            "Epoch 1426/1500\n",
            "876/876 [==============================] - 3s 4ms/step\n",
            "110/110 [==============================] - 10s 92ms/step - loss: 0.2833 - val_loss: 0.5648\n",
            "Epoch 1427/1500\n",
            "876/876 [==============================] - 3s 3ms/step\n",
            "110/110 [==============================] - 9s 80ms/step - loss: 0.3511 - val_loss: 1.6205\n",
            "Epoch 1428/1500\n",
            "876/876 [==============================] - 3s 4ms/step\n",
            "110/110 [==============================] - 10s 90ms/step - loss: 0.7610 - val_loss: 1.5279\n",
            "Epoch 1429/1500\n",
            "876/876 [==============================] - 3s 3ms/step\n",
            "110/110 [==============================] - 7s 61ms/step - loss: 0.6049 - val_loss: 0.6647\n",
            "Epoch 1430/1500\n",
            "876/876 [==============================] - 4s 5ms/step\n",
            "110/110 [==============================] - 9s 85ms/step - loss: 0.3400 - val_loss: 0.7774\n",
            "Epoch 1431/1500\n",
            "876/876 [==============================] - 3s 4ms/step\n",
            "110/110 [==============================] - 12s 109ms/step - loss: 0.4121 - val_loss: 0.6231\n",
            "Epoch 1432/1500\n",
            "876/876 [==============================] - 3s 4ms/step\n",
            "110/110 [==============================] - 9s 86ms/step - loss: 0.7474 - val_loss: 0.9845\n",
            "Epoch 1433/1500\n",
            "876/876 [==============================] - 3s 3ms/step\n",
            "110/110 [==============================] - 9s 81ms/step - loss: 0.5000 - val_loss: 1.3571\n",
            "Epoch 1434/1500\n",
            "876/876 [==============================] - 3s 4ms/step\n",
            "110/110 [==============================] - 10s 92ms/step - loss: 0.5314 - val_loss: 0.6919\n",
            "Epoch 1435/1500\n",
            "876/876 [==============================] - 3s 3ms/step\n",
            "110/110 [==============================] - 7s 64ms/step - loss: 0.3049 - val_loss: 0.7029\n",
            "Epoch 1436/1500\n",
            "876/876 [==============================] - 3s 4ms/step\n",
            "110/110 [==============================] - 10s 90ms/step - loss: 0.3755 - val_loss: 0.6040\n",
            "Epoch 1437/1500\n",
            "876/876 [==============================] - 3s 3ms/step\n",
            "110/110 [==============================] - 7s 64ms/step - loss: 0.2772 - val_loss: 0.6832\n",
            "Epoch 1438/1500\n",
            "876/876 [==============================] - 3s 3ms/step\n",
            "110/110 [==============================] - 8s 72ms/step - loss: 0.4917 - val_loss: 0.6216\n",
            "Epoch 1439/1500\n",
            "876/876 [==============================] - 3s 3ms/step\n",
            "110/110 [==============================] - 10s 91ms/step - loss: 0.3114 - val_loss: 0.6476\n",
            "Epoch 1440/1500\n",
            "876/876 [==============================] - 3s 4ms/step\n",
            "110/110 [==============================] - 8s 75ms/step - loss: 0.3255 - val_loss: 1.3784\n",
            "Epoch 1441/1500\n",
            "876/876 [==============================] - 3s 3ms/step\n",
            "110/110 [==============================] - 10s 88ms/step - loss: 0.4170 - val_loss: 0.6235\n",
            "Epoch 1442/1500\n",
            "876/876 [==============================] - 3s 4ms/step\n",
            "110/110 [==============================] - 8s 78ms/step - loss: 0.4163 - val_loss: 0.6333\n",
            "Epoch 1443/1500\n",
            "876/876 [==============================] - 3s 4ms/step\n",
            "110/110 [==============================] - 11s 98ms/step - loss: 0.2401 - val_loss: 0.7907\n",
            "Epoch 1444/1500\n",
            "876/876 [==============================] - 3s 4ms/step\n",
            "110/110 [==============================] - 9s 81ms/step - loss: 0.8981 - val_loss: 1.0542\n",
            "Epoch 1445/1500\n",
            "876/876 [==============================] - 3s 3ms/step\n",
            "110/110 [==============================] - 7s 67ms/step - loss: 0.4268 - val_loss: 0.6391\n",
            "Epoch 1446/1500\n",
            "876/876 [==============================] - 3s 4ms/step\n",
            "110/110 [==============================] - 10s 88ms/step - loss: 0.4793 - val_loss: 0.7603\n",
            "Epoch 1447/1500\n",
            "876/876 [==============================] - 3s 3ms/step\n",
            "110/110 [==============================] - 7s 64ms/step - loss: 0.3832 - val_loss: 0.7795\n",
            "Epoch 1448/1500\n",
            "876/876 [==============================] - 3s 4ms/step\n",
            "110/110 [==============================] - 8s 74ms/step - loss: 0.4199 - val_loss: 0.6901\n",
            "Epoch 1449/1500\n",
            "876/876 [==============================] - 3s 3ms/step\n",
            "110/110 [==============================] - 10s 93ms/step - loss: 0.3930 - val_loss: 0.6556\n",
            "Epoch 1450/1500\n",
            "876/876 [==============================] - 3s 4ms/step\n",
            "110/110 [==============================] - 8s 72ms/step - loss: 0.6653 - val_loss: 0.6567\n",
            "Epoch 1451/1500\n",
            "876/876 [==============================] - 3s 3ms/step\n",
            "110/110 [==============================] - 10s 94ms/step - loss: 0.3375 - val_loss: 1.1935\n",
            "Epoch 1452/1500\n",
            "876/876 [==============================] - 3s 4ms/step\n",
            "110/110 [==============================] - 10s 88ms/step - loss: 0.6627 - val_loss: 0.7722\n",
            "Epoch 1453/1500\n",
            "876/876 [==============================] - 3s 3ms/step\n",
            "110/110 [==============================] - 9s 82ms/step - loss: 0.3289 - val_loss: 0.9133\n",
            "Epoch 1454/1500\n",
            "876/876 [==============================] - 3s 4ms/step\n",
            "110/110 [==============================] - 9s 80ms/step - loss: 0.4766 - val_loss: 0.7841\n",
            "Epoch 1455/1500\n",
            "876/876 [==============================] - 3s 3ms/step\n",
            "110/110 [==============================] - 9s 84ms/step - loss: 0.4823 - val_loss: 1.0544\n",
            "Epoch 1456/1500\n",
            "876/876 [==============================] - 3s 4ms/step\n",
            "110/110 [==============================] - 10s 94ms/step - loss: 0.4258 - val_loss: 0.6530\n",
            "Epoch 1457/1500\n",
            "876/876 [==============================] - 3s 3ms/step\n",
            "110/110 [==============================] - 9s 81ms/step - loss: 0.4171 - val_loss: 0.5555\n",
            "Epoch 1458/1500\n",
            "876/876 [==============================] - 3s 3ms/step\n",
            "110/110 [==============================] - 10s 88ms/step - loss: 0.6684 - val_loss: 1.1342\n",
            "Epoch 1459/1500\n",
            "876/876 [==============================] - 3s 4ms/step\n",
            "110/110 [==============================] - 9s 83ms/step - loss: 0.3212 - val_loss: 0.5853\n",
            "Epoch 1460/1500\n",
            "876/876 [==============================] - 3s 3ms/step\n",
            "110/110 [==============================] - 9s 81ms/step - loss: 0.2892 - val_loss: 0.7876\n",
            "Epoch 1461/1500\n",
            "876/876 [==============================] - 3s 3ms/step\n",
            "110/110 [==============================] - 9s 78ms/step - loss: 0.3745 - val_loss: 1.2287\n",
            "Epoch 1462/1500\n",
            "876/876 [==============================] - 3s 3ms/step\n",
            "110/110 [==============================] - 9s 82ms/step - loss: 0.5570 - val_loss: 1.3997\n",
            "Epoch 1463/1500\n",
            "876/876 [==============================] - 3s 4ms/step\n",
            "110/110 [==============================] - 8s 75ms/step - loss: 0.6058 - val_loss: 0.6837\n",
            "Epoch 1464/1500\n",
            "876/876 [==============================] - 3s 3ms/step\n",
            "110/110 [==============================] - 8s 77ms/step - loss: 0.3875 - val_loss: 0.6937\n",
            "Epoch 1465/1500\n",
            "876/876 [==============================] - 3s 3ms/step\n",
            "110/110 [==============================] - 7s 66ms/step - loss: 0.6969 - val_loss: 0.8106\n",
            "Epoch 1466/1500\n",
            "876/876 [==============================] - 3s 4ms/step\n",
            "110/110 [==============================] - 9s 80ms/step - loss: 0.3049 - val_loss: 0.6458\n",
            "Epoch 1467/1500\n",
            "876/876 [==============================] - 3s 3ms/step\n",
            "110/110 [==============================] - 7s 64ms/step - loss: 0.4787 - val_loss: 0.6035\n",
            "Epoch 1468/1500\n",
            "876/876 [==============================] - 3s 4ms/step\n",
            "110/110 [==============================] - 10s 93ms/step - loss: 0.4665 - val_loss: 1.0272\n",
            "Epoch 1469/1500\n",
            "876/876 [==============================] - 3s 3ms/step\n",
            "110/110 [==============================] - 9s 81ms/step - loss: 0.5065 - val_loss: 0.7010\n",
            "Epoch 1470/1500\n",
            "876/876 [==============================] - 3s 3ms/step\n",
            "110/110 [==============================] - 10s 94ms/step - loss: 0.4531 - val_loss: 0.8315\n",
            "Epoch 1471/1500\n",
            "876/876 [==============================] - 3s 4ms/step\n",
            "110/110 [==============================] - 9s 81ms/step - loss: 0.4493 - val_loss: 1.2371\n",
            "Epoch 1472/1500\n",
            "876/876 [==============================] - 3s 3ms/step\n",
            "110/110 [==============================] - 7s 66ms/step - loss: 0.5350 - val_loss: 0.7136\n",
            "Epoch 1473/1500\n",
            "876/876 [==============================] - 3s 4ms/step\n",
            "110/110 [==============================] - 9s 81ms/step - loss: 0.3205 - val_loss: 1.2960\n",
            "Epoch 1474/1500\n",
            "876/876 [==============================] - 3s 3ms/step\n",
            "110/110 [==============================] - 9s 82ms/step - loss: 0.4831 - val_loss: 0.8767\n",
            "Epoch 1475/1500\n",
            "876/876 [==============================] - 3s 4ms/step\n",
            "110/110 [==============================] - 8s 76ms/step - loss: 0.5085 - val_loss: 0.8489\n",
            "Epoch 1476/1500\n",
            "876/876 [==============================] - 3s 3ms/step\n",
            "110/110 [==============================] - 8s 70ms/step - loss: 0.6124 - val_loss: 0.8371\n",
            "Epoch 1477/1500\n",
            "876/876 [==============================] - 3s 4ms/step\n",
            "110/110 [==============================] - 8s 72ms/step - loss: 0.3617 - val_loss: 0.8767\n",
            "Epoch 1478/1500\n",
            "876/876 [==============================] - 3s 4ms/step\n",
            "110/110 [==============================] - 8s 76ms/step - loss: 0.3751 - val_loss: 0.9888\n",
            "Epoch 1479/1500\n",
            "876/876 [==============================] - 3s 4ms/step\n",
            "110/110 [==============================] - 9s 81ms/step - loss: 0.3622 - val_loss: 0.6866\n",
            "Epoch 1480/1500\n",
            "876/876 [==============================] - 3s 3ms/step\n",
            "110/110 [==============================] - 7s 66ms/step - loss: 1.1504 - val_loss: 0.8610\n",
            "Epoch 1481/1500\n",
            "876/876 [==============================] - 3s 4ms/step\n",
            "110/110 [==============================] - 10s 90ms/step - loss: 0.3747 - val_loss: 0.6720\n",
            "Epoch 1482/1500\n",
            "876/876 [==============================] - 3s 4ms/step\n",
            "110/110 [==============================] - 10s 94ms/step - loss: 0.4790 - val_loss: 0.6168\n",
            "Epoch 1483/1500\n",
            "876/876 [==============================] - 3s 4ms/step\n",
            "110/110 [==============================] - 8s 70ms/step - loss: 0.2669 - val_loss: 1.3802\n",
            "Epoch 1484/1500\n",
            "876/876 [==============================] - 3s 3ms/step\n",
            "110/110 [==============================] - 8s 76ms/step - loss: 0.4969 - val_loss: 0.6082\n",
            "Epoch 1485/1500\n",
            "876/876 [==============================] - 3s 4ms/step\n",
            "110/110 [==============================] - 9s 81ms/step - loss: 0.3041 - val_loss: 1.3064\n",
            "Epoch 1486/1500\n",
            "876/876 [==============================] - 3s 3ms/step\n",
            "110/110 [==============================] - 9s 83ms/step - loss: 0.7171 - val_loss: 0.7437\n",
            "Epoch 1487/1500\n",
            "876/876 [==============================] - 3s 4ms/step\n",
            "110/110 [==============================] - 8s 77ms/step - loss: 0.2437 - val_loss: 0.7934\n",
            "Epoch 1488/1500\n",
            "876/876 [==============================] - 3s 3ms/step\n",
            "110/110 [==============================] - 8s 71ms/step - loss: 0.4101 - val_loss: 0.5977\n",
            "Epoch 1489/1500\n",
            "876/876 [==============================] - 3s 4ms/step\n",
            "110/110 [==============================] - 8s 72ms/step - loss: 0.3709 - val_loss: 0.6355\n",
            "Epoch 1490/1500\n",
            "876/876 [==============================] - 3s 3ms/step\n",
            "110/110 [==============================] - 10s 90ms/step - loss: 0.5034 - val_loss: 0.8219\n",
            "Epoch 1491/1500\n",
            "876/876 [==============================] - 3s 4ms/step\n",
            "110/110 [==============================] - 10s 88ms/step - loss: 0.3554 - val_loss: 0.8124\n",
            "Epoch 1492/1500\n",
            "876/876 [==============================] - 3s 3ms/step\n",
            "110/110 [==============================] - 7s 64ms/step - loss: 0.3813 - val_loss: 0.6187\n",
            "Epoch 1493/1500\n",
            "876/876 [==============================] - 3s 4ms/step\n",
            "110/110 [==============================] - 8s 74ms/step - loss: 0.7037 - val_loss: 0.6705\n",
            "Epoch 1494/1500\n",
            "876/876 [==============================] - 3s 3ms/step\n",
            "110/110 [==============================] - 10s 89ms/step - loss: 0.3816 - val_loss: 1.9996\n",
            "Epoch 1495/1500\n",
            "876/876 [==============================] - 3s 4ms/step\n",
            "110/110 [==============================] - 8s 75ms/step - loss: 0.4952 - val_loss: 0.6002\n",
            "Epoch 1496/1500\n",
            "876/876 [==============================] - 3s 3ms/step\n",
            "110/110 [==============================] - 8s 74ms/step - loss: 0.3123 - val_loss: 0.7089\n",
            "Epoch 1497/1500\n",
            "876/876 [==============================] - 3s 4ms/step\n",
            "110/110 [==============================] - 8s 69ms/step - loss: 0.2748 - val_loss: 0.6537\n",
            "Epoch 1498/1500\n",
            "876/876 [==============================] - 3s 4ms/step\n",
            "110/110 [==============================] - 10s 93ms/step - loss: 0.3898 - val_loss: 0.6932\n",
            "Epoch 1499/1500\n",
            "876/876 [==============================] - 3s 3ms/step\n",
            "110/110 [==============================] - 9s 82ms/step - loss: 0.4208 - val_loss: 0.9063\n",
            "Epoch 1500/1500\n",
            "876/876 [==============================] - 4s 5ms/step\n",
            "110/110 [==============================] - 11s 97ms/step - loss: 0.3840 - val_loss: 1.0058\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.src.callbacks.History at 0x7e62e5733eb0>"
            ]
          },
          "metadata": {},
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model_LSTM.save('/content/drive/MyDrive/Task2/model/LSTM_model.keras')"
      ],
      "metadata": {
        "id": "OHgA2tX5-nFz"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "Y_pred = model_LSTM.predict(X_test)\n",
        "mse, rmse, r_squared = calculate_metrics(Y_test, Y_pred)\n",
        "print(\"Metric for LSTM\")\n",
        "print(\"MSE = \"+str(mse))\n",
        "print(\"RMSE = \"+str(rmse))\n",
        "print(\"R^2 = \"+str(r_squared))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yFAIZvkBzwmo",
        "outputId": "1ed7e744-37d3-4ef6-8358-90f9957d77aa"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "219/219 [==============================] - 1s 3ms/step\n",
            "Metric for LSTM\n",
            "MSE = 1.0058167773033988\n",
            "RMSE = 1.0029041715455165\n",
            "R^2 = 0.9991051103356318\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model_GRU = keras.Sequential()\n",
        "model_GRU.add(keras.layers.GRU(units = 64, input_shape=(X_train.shape[1], X_train.shape[2])))\n",
        "model_GRU.add(keras.layers.Dense(units=1))\n",
        "model_GRU.compile(optimizer='adam', loss='mse')\n",
        "metrics_history_callback = MetricsHistory(X_train, Y_train,['Metrics over Epochs on GRU','Loss over Epochs on GRU'],['/content/drive/MyDrive/Task2/metricsGRU.png', '/content/drive/MyDrive/Task2/lossGRU.png'] )\n",
        "model_GRU.fit(X_train, Y_train,validation_data =(X_test, Y_test), epochs= 1500, batch_size= 256, callbacks=[metrics_history_callback])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "9KfXikXNTdsu",
        "outputId": "7ea54ae4-cb29-401f-eb29-517c98db0eb0"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/1500\n",
            "876/876 [==============================] - 3s 3ms/step\n",
            "110/110 [==============================] - 9s 65ms/step - loss: 1460.4922 - val_loss: 1254.8798\n",
            "Epoch 2/1500\n",
            "876/876 [==============================] - 2s 2ms/step\n",
            "110/110 [==============================] - 4s 41ms/step - loss: 1083.6011 - val_loss: 927.3832\n",
            "Epoch 3/1500\n",
            "876/876 [==============================] - 2s 2ms/step\n",
            "110/110 [==============================] - 4s 38ms/step - loss: 811.6473 - val_loss: 718.2593\n",
            "Epoch 4/1500\n",
            "876/876 [==============================] - 3s 3ms/step\n",
            "110/110 [==============================] - 6s 56ms/step - loss: 639.8430 - val_loss: 575.4385\n",
            "Epoch 5/1500\n",
            "876/876 [==============================] - 2s 2ms/step\n",
            "110/110 [==============================] - 4s 36ms/step - loss: 520.0354 - val_loss: 476.5615\n",
            "Epoch 6/1500\n",
            "876/876 [==============================] - 2s 2ms/step\n",
            "110/110 [==============================] - 4s 40ms/step - loss: 437.3253 - val_loss: 407.3375\n",
            "Epoch 7/1500\n",
            "876/876 [==============================] - 3s 3ms/step\n",
            "110/110 [==============================] - 8s 70ms/step - loss: 381.1639 - val_loss: 361.1662\n",
            "Epoch 8/1500\n",
            "876/876 [==============================] - 2s 2ms/step\n",
            "110/110 [==============================] - 4s 40ms/step - loss: 344.4539 - val_loss: 331.4517\n",
            "Epoch 9/1500\n",
            "876/876 [==============================] - 2s 2ms/step\n",
            "110/110 [==============================] - 4s 40ms/step - loss: 320.1382 - val_loss: 306.0440\n",
            "Epoch 10/1500\n",
            "876/876 [==============================] - 2s 2ms/step\n",
            "110/110 [==============================] - 6s 57ms/step - loss: 254.4499 - val_loss: 221.8984\n",
            "Epoch 11/1500\n",
            "876/876 [==============================] - 2s 2ms/step\n",
            "110/110 [==============================] - 4s 37ms/step - loss: 199.6184 - val_loss: 186.0854\n",
            "Epoch 12/1500\n",
            "876/876 [==============================] - 2s 2ms/step\n",
            "110/110 [==============================] - 4s 40ms/step - loss: 170.5162 - val_loss: 163.6764\n",
            "Epoch 13/1500\n",
            "876/876 [==============================] - 2s 2ms/step\n",
            "110/110 [==============================] - 6s 54ms/step - loss: 149.8266 - val_loss: 144.5725\n",
            "Epoch 14/1500\n",
            "876/876 [==============================] - 2s 2ms/step\n",
            "110/110 [==============================] - 4s 37ms/step - loss: 135.2220 - val_loss: 132.5299\n",
            "Epoch 15/1500\n",
            "876/876 [==============================] - 2s 2ms/step\n",
            "110/110 [==============================] - 4s 41ms/step - loss: 124.2423 - val_loss: 115.1584\n",
            "Epoch 16/1500\n",
            "876/876 [==============================] - 2s 2ms/step\n",
            "110/110 [==============================] - 6s 53ms/step - loss: 103.0478 - val_loss: 97.8787\n",
            "Epoch 17/1500\n",
            "876/876 [==============================] - 2s 2ms/step\n",
            "110/110 [==============================] - 4s 40ms/step - loss: 88.3908 - val_loss: 84.3951\n",
            "Epoch 18/1500\n",
            "876/876 [==============================] - 2s 2ms/step\n",
            "110/110 [==============================] - 4s 38ms/step - loss: 75.7747 - val_loss: 72.9300\n",
            "Epoch 19/1500\n",
            "876/876 [==============================] - 2s 2ms/step\n",
            "110/110 [==============================] - 6s 55ms/step - loss: 65.9946 - val_loss: 63.7271\n",
            "Epoch 20/1500\n",
            "876/876 [==============================] - 2s 2ms/step\n",
            "110/110 [==============================] - 4s 37ms/step - loss: 57.2481 - val_loss: 54.7901\n",
            "Epoch 21/1500\n",
            "876/876 [==============================] - 2s 2ms/step\n",
            "110/110 [==============================] - 4s 37ms/step - loss: 50.1236 - val_loss: 48.9723\n",
            "Epoch 22/1500\n",
            "876/876 [==============================] - 3s 3ms/step\n",
            "110/110 [==============================] - 6s 55ms/step - loss: 45.2499 - val_loss: 49.1121\n",
            "Epoch 23/1500\n",
            "876/876 [==============================] - 2s 2ms/step\n",
            "110/110 [==============================] - 4s 40ms/step - loss: 41.5210 - val_loss: 40.4708\n",
            "Epoch 24/1500\n",
            "876/876 [==============================] - 2s 2ms/step\n",
            "110/110 [==============================] - 4s 37ms/step - loss: 37.7826 - val_loss: 38.2357\n",
            "Epoch 25/1500\n",
            "876/876 [==============================] - 3s 3ms/step\n",
            "110/110 [==============================] - 6s 55ms/step - loss: 34.9518 - val_loss: 34.1691\n",
            "Epoch 26/1500\n",
            "876/876 [==============================] - 2s 2ms/step\n",
            "110/110 [==============================] - 4s 40ms/step - loss: 30.1415 - val_loss: 30.5624\n",
            "Epoch 27/1500\n",
            "876/876 [==============================] - 2s 2ms/step\n",
            "110/110 [==============================] - 4s 38ms/step - loss: 26.0797 - val_loss: 26.4707\n",
            "Epoch 28/1500\n",
            "876/876 [==============================] - 3s 3ms/step\n",
            "110/110 [==============================] - 8s 69ms/step - loss: 24.1696 - val_loss: 23.9367\n",
            "Epoch 29/1500\n",
            "876/876 [==============================] - 2s 2ms/step\n",
            "110/110 [==============================] - 4s 38ms/step - loss: 20.5178 - val_loss: 20.7598\n",
            "Epoch 30/1500\n",
            "876/876 [==============================] - 2s 2ms/step\n",
            "110/110 [==============================] - 4s 38ms/step - loss: 18.2980 - val_loss: 19.1179\n",
            "Epoch 31/1500\n",
            "876/876 [==============================] - 2s 3ms/step\n",
            "110/110 [==============================] - 9s 79ms/step - loss: 16.3811 - val_loss: 16.4871\n",
            "Epoch 32/1500\n",
            "876/876 [==============================] - 2s 2ms/step\n",
            "110/110 [==============================] - 4s 38ms/step - loss: 14.4338 - val_loss: 14.5067\n",
            "Epoch 33/1500\n",
            "876/876 [==============================] - 2s 3ms/step\n",
            "110/110 [==============================] - 7s 64ms/step - loss: 13.3365 - val_loss: 13.4179\n",
            "Epoch 34/1500\n",
            "876/876 [==============================] - 2s 2ms/step\n",
            "110/110 [==============================] - 4s 40ms/step - loss: 12.8853 - val_loss: 12.5446\n",
            "Epoch 35/1500\n",
            "876/876 [==============================] - 2s 2ms/step\n",
            "110/110 [==============================] - 4s 40ms/step - loss: 11.7623 - val_loss: 11.4485\n",
            "Epoch 36/1500\n",
            "876/876 [==============================] - 3s 3ms/step\n",
            "110/110 [==============================] - 8s 76ms/step - loss: 10.8116 - val_loss: 11.5636\n",
            "Epoch 37/1500\n",
            "876/876 [==============================] - 2s 2ms/step\n",
            "110/110 [==============================] - 4s 38ms/step - loss: 10.1302 - val_loss: 9.9446\n",
            "Epoch 38/1500\n",
            "876/876 [==============================] - 2s 2ms/step\n",
            "110/110 [==============================] - 7s 64ms/step - loss: 9.2150 - val_loss: 9.2716\n",
            "Epoch 39/1500\n",
            "876/876 [==============================] - 2s 2ms/step\n",
            "110/110 [==============================] - 4s 40ms/step - loss: 8.3752 - val_loss: 8.2486\n",
            "Epoch 40/1500\n",
            "876/876 [==============================] - 2s 2ms/step\n",
            "110/110 [==============================] - 4s 40ms/step - loss: 7.7931 - val_loss: 8.3866\n",
            "Epoch 41/1500\n",
            "876/876 [==============================] - 3s 3ms/step\n",
            "110/110 [==============================] - 8s 73ms/step - loss: 7.4135 - val_loss: 7.4693\n",
            "Epoch 42/1500\n",
            "876/876 [==============================] - 2s 2ms/step\n",
            "110/110 [==============================] - 4s 38ms/step - loss: 7.2339 - val_loss: 8.5144\n",
            "Epoch 43/1500\n",
            "876/876 [==============================] - 2s 2ms/step\n",
            "110/110 [==============================] - 4s 41ms/step - loss: 6.1052 - val_loss: 6.0833\n",
            "Epoch 44/1500\n",
            "876/876 [==============================] - 2s 2ms/step\n",
            "110/110 [==============================] - 6s 56ms/step - loss: 6.2728 - val_loss: 5.6960\n",
            "Epoch 45/1500\n",
            "876/876 [==============================] - 2s 2ms/step\n",
            "110/110 [==============================] - 4s 37ms/step - loss: 5.2370 - val_loss: 5.7101\n",
            "Epoch 46/1500\n",
            "876/876 [==============================] - 2s 2ms/step\n",
            "110/110 [==============================] - 4s 39ms/step - loss: 4.9261 - val_loss: 5.0139\n",
            "Epoch 47/1500\n",
            "876/876 [==============================] - 2s 2ms/step\n",
            "110/110 [==============================] - 6s 56ms/step - loss: 4.5636 - val_loss: 6.8198\n",
            "Epoch 48/1500\n",
            "876/876 [==============================] - 2s 2ms/step\n",
            "110/110 [==============================] - 4s 41ms/step - loss: 4.6349 - val_loss: 5.1516\n",
            "Epoch 49/1500\n",
            "876/876 [==============================] - 2s 2ms/step\n",
            "110/110 [==============================] - 4s 41ms/step - loss: 4.1966 - val_loss: 5.3650\n",
            "Epoch 50/1500\n",
            "876/876 [==============================] - 2s 2ms/step\n",
            "110/110 [==============================] - 6s 57ms/step - loss: 3.9953 - val_loss: 4.9151\n",
            "Epoch 51/1500\n",
            "876/876 [==============================] - 2s 2ms/step\n",
            "110/110 [==============================] - 4s 40ms/step - loss: 3.7345 - val_loss: 6.1272\n",
            "Epoch 52/1500\n",
            "876/876 [==============================] - 2s 2ms/step\n",
            "110/110 [==============================] - 4s 40ms/step - loss: 3.7263 - val_loss: 3.5056\n",
            "Epoch 53/1500\n",
            "876/876 [==============================] - 2s 2ms/step\n",
            "110/110 [==============================] - 6s 54ms/step - loss: 3.5174 - val_loss: 4.3045\n",
            "Epoch 54/1500\n",
            "876/876 [==============================] - 2s 2ms/step\n",
            "110/110 [==============================] - 4s 41ms/step - loss: 3.3394 - val_loss: 3.2274\n",
            "Epoch 55/1500\n",
            "876/876 [==============================] - 2s 2ms/step\n",
            "110/110 [==============================] - 4s 40ms/step - loss: 2.9998 - val_loss: 2.9429\n",
            "Epoch 56/1500\n",
            "876/876 [==============================] - 2s 2ms/step\n",
            "110/110 [==============================] - 6s 55ms/step - loss: 3.4292 - val_loss: 4.8491\n",
            "Epoch 57/1500\n",
            "876/876 [==============================] - 2s 2ms/step\n",
            "110/110 [==============================] - 4s 38ms/step - loss: 2.9520 - val_loss: 3.3304\n",
            "Epoch 58/1500\n",
            "876/876 [==============================] - 2s 2ms/step\n",
            "110/110 [==============================] - 4s 41ms/step - loss: 2.9655 - val_loss: 2.6436\n",
            "Epoch 59/1500\n",
            "876/876 [==============================] - 2s 2ms/step\n",
            "110/110 [==============================] - 6s 57ms/step - loss: 2.7542 - val_loss: 2.6049\n",
            "Epoch 60/1500\n",
            "876/876 [==============================] - 2s 2ms/step\n",
            "110/110 [==============================] - 4s 37ms/step - loss: 2.5620 - val_loss: 2.6118\n",
            "Epoch 61/1500\n",
            "876/876 [==============================] - 2s 2ms/step\n",
            "110/110 [==============================] - 4s 39ms/step - loss: 2.9873 - val_loss: 3.2874\n",
            "Epoch 62/1500\n",
            "876/876 [==============================] - 2s 2ms/step\n",
            "110/110 [==============================] - 6s 55ms/step - loss: 2.7402 - val_loss: 2.3302\n",
            "Epoch 63/1500\n",
            "876/876 [==============================] - 2s 2ms/step\n",
            "110/110 [==============================] - 4s 37ms/step - loss: 2.4089 - val_loss: 2.5122\n",
            "Epoch 64/1500\n",
            "876/876 [==============================] - 2s 2ms/step\n",
            "110/110 [==============================] - 4s 40ms/step - loss: 2.6817 - val_loss: 2.8016\n",
            "Epoch 65/1500\n",
            "876/876 [==============================] - 2s 3ms/step\n",
            "110/110 [==============================] - 9s 79ms/step - loss: 2.4748 - val_loss: 2.4254\n",
            "Epoch 66/1500\n",
            "876/876 [==============================] - 2s 2ms/step\n",
            "110/110 [==============================] - 4s 40ms/step - loss: 2.4628 - val_loss: 2.1780\n",
            "Epoch 67/1500\n",
            "876/876 [==============================] - 3s 3ms/step\n",
            "110/110 [==============================] - 7s 65ms/step - loss: 2.2595 - val_loss: 2.6380\n",
            "Epoch 68/1500\n",
            "876/876 [==============================] - 2s 2ms/step\n",
            "110/110 [==============================] - 4s 38ms/step - loss: 2.2354 - val_loss: 3.6214\n",
            "Epoch 69/1500\n",
            "876/876 [==============================] - 2s 2ms/step\n",
            "110/110 [==============================] - 4s 37ms/step - loss: 2.1969 - val_loss: 2.1164\n",
            "Epoch 70/1500\n",
            "876/876 [==============================] - 3s 3ms/step\n",
            "110/110 [==============================] - 6s 55ms/step - loss: 2.6639 - val_loss: 2.5218\n",
            "Epoch 71/1500\n",
            "876/876 [==============================] - 2s 2ms/step\n",
            "110/110 [==============================] - 4s 40ms/step - loss: 2.1214 - val_loss: 2.1420\n",
            "Epoch 72/1500\n",
            "876/876 [==============================] - 2s 2ms/step\n",
            "110/110 [==============================] - 4s 37ms/step - loss: 1.9487 - val_loss: 2.3676\n",
            "Epoch 73/1500\n",
            "876/876 [==============================] - 3s 3ms/step\n",
            "110/110 [==============================] - 6s 52ms/step - loss: 2.2652 - val_loss: 1.9719\n",
            "Epoch 74/1500\n",
            "876/876 [==============================] - 2s 2ms/step\n",
            "110/110 [==============================] - 5s 43ms/step - loss: 2.0721 - val_loss: 1.9580\n",
            "Epoch 75/1500\n",
            "876/876 [==============================] - 2s 2ms/step\n",
            "110/110 [==============================] - 4s 37ms/step - loss: 1.8983 - val_loss: 2.0922\n",
            "Epoch 76/1500\n",
            "876/876 [==============================] - 3s 3ms/step\n",
            "110/110 [==============================] - 7s 65ms/step - loss: 2.3120 - val_loss: 1.7468\n",
            "Epoch 77/1500\n",
            "876/876 [==============================] - 2s 2ms/step\n",
            "110/110 [==============================] - 4s 37ms/step - loss: 1.9952 - val_loss: 1.5824\n",
            "Epoch 78/1500\n",
            "876/876 [==============================] - 2s 2ms/step\n",
            "110/110 [==============================] - 4s 40ms/step - loss: 1.8300 - val_loss: 1.6238\n",
            "Epoch 79/1500\n",
            "876/876 [==============================] - 3s 3ms/step\n",
            "110/110 [==============================] - 6s 58ms/step - loss: 1.7809 - val_loss: 1.6567\n",
            "Epoch 80/1500\n",
            "876/876 [==============================] - 2s 2ms/step\n",
            "110/110 [==============================] - 4s 38ms/step - loss: 2.3430 - val_loss: 3.3964\n",
            "Epoch 81/1500\n",
            "876/876 [==============================] - 2s 2ms/step\n",
            "110/110 [==============================] - 4s 37ms/step - loss: 1.6603 - val_loss: 2.0695\n",
            "Epoch 82/1500\n",
            "876/876 [==============================] - 3s 3ms/step\n",
            "110/110 [==============================] - 6s 52ms/step - loss: 1.5957 - val_loss: 1.5714\n",
            "Epoch 83/1500\n",
            "876/876 [==============================] - 2s 2ms/step\n",
            "110/110 [==============================] - 4s 38ms/step - loss: 1.5214 - val_loss: 1.9814\n",
            "Epoch 84/1500\n",
            "876/876 [==============================] - 2s 2ms/step\n",
            "110/110 [==============================] - 4s 38ms/step - loss: 1.8035 - val_loss: 4.5876\n",
            "Epoch 85/1500\n",
            "876/876 [==============================] - 3s 3ms/step\n",
            "110/110 [==============================] - 5s 46ms/step - loss: 2.1494 - val_loss: 1.6753\n",
            "Epoch 86/1500\n",
            "876/876 [==============================] - 2s 2ms/step\n",
            "110/110 [==============================] - 5s 50ms/step - loss: 1.8335 - val_loss: 1.4787\n",
            "Epoch 87/1500\n",
            "876/876 [==============================] - 2s 2ms/step\n",
            "110/110 [==============================] - 4s 37ms/step - loss: 1.5788 - val_loss: 1.6082\n",
            "Epoch 88/1500\n",
            "876/876 [==============================] - 2s 3ms/step\n",
            "110/110 [==============================] - 5s 42ms/step - loss: 1.8847 - val_loss: 1.4567\n",
            "Epoch 89/1500\n",
            "876/876 [==============================] - 2s 2ms/step\n",
            "110/110 [==============================] - 6s 52ms/step - loss: 2.0255 - val_loss: 2.8791\n",
            "Epoch 90/1500\n",
            "876/876 [==============================] - 2s 2ms/step\n",
            "110/110 [==============================] - 4s 38ms/step - loss: 1.6986 - val_loss: 2.6895\n",
            "Epoch 91/1500\n",
            "876/876 [==============================] - 2s 2ms/step\n",
            "110/110 [==============================] - 4s 40ms/step - loss: 1.6952 - val_loss: 1.3833\n",
            "Epoch 92/1500\n",
            "876/876 [==============================] - 2s 3ms/step\n",
            "110/110 [==============================] - 6s 55ms/step - loss: 1.9275 - val_loss: 1.3017\n",
            "Epoch 93/1500\n",
            "876/876 [==============================] - 2s 2ms/step\n",
            "110/110 [==============================] - 4s 37ms/step - loss: 1.4025 - val_loss: 2.0181\n",
            "Epoch 94/1500\n",
            "876/876 [==============================] - 2s 2ms/step\n",
            "110/110 [==============================] - 4s 38ms/step - loss: 1.4270 - val_loss: 1.3407\n",
            "Epoch 95/1500\n",
            "876/876 [==============================] - 2s 3ms/step\n",
            "110/110 [==============================] - 9s 79ms/step - loss: 1.3159 - val_loss: 1.2371\n",
            "Epoch 96/1500\n",
            "876/876 [==============================] - 2s 2ms/step\n",
            "110/110 [==============================] - 4s 40ms/step - loss: 1.1536 - val_loss: 1.3529\n",
            "Epoch 97/1500\n",
            "876/876 [==============================] - 3s 3ms/step\n",
            "110/110 [==============================] - 7s 64ms/step - loss: 1.7121 - val_loss: 2.3023\n",
            "Epoch 98/1500\n",
            "876/876 [==============================] - 2s 2ms/step\n",
            "110/110 [==============================] - 4s 41ms/step - loss: 1.6878 - val_loss: 1.3597\n",
            "Epoch 99/1500\n",
            "876/876 [==============================] - 2s 2ms/step\n",
            "110/110 [==============================] - 4s 40ms/step - loss: 1.3151 - val_loss: 1.3402\n",
            "Epoch 100/1500\n",
            "876/876 [==============================] - 3s 3ms/step\n",
            "110/110 [==============================] - 8s 76ms/step - loss: 1.4183 - val_loss: 1.3390\n",
            "Epoch 101/1500\n",
            "876/876 [==============================] - 2s 2ms/step\n",
            "110/110 [==============================] - 4s 40ms/step - loss: 1.4699 - val_loss: 1.1417\n",
            "Epoch 102/1500\n",
            "876/876 [==============================] - 2s 3ms/step\n",
            "110/110 [==============================] - 5s 42ms/step - loss: 1.3031 - val_loss: 1.1977\n",
            "Epoch 103/1500\n",
            "876/876 [==============================] - 2s 2ms/step\n",
            "110/110 [==============================] - 6s 53ms/step - loss: 1.3834 - val_loss: 2.0149\n",
            "Epoch 104/1500\n",
            "876/876 [==============================] - 2s 2ms/step\n",
            "110/110 [==============================] - 4s 39ms/step - loss: 1.5005 - val_loss: 3.6901\n",
            "Epoch 105/1500\n",
            "876/876 [==============================] - 2s 2ms/step\n",
            "110/110 [==============================] - 4s 40ms/step - loss: 1.6392 - val_loss: 1.5444\n",
            "Epoch 106/1500\n",
            "876/876 [==============================] - 2s 2ms/step\n",
            "110/110 [==============================] - 6s 56ms/step - loss: 1.5341 - val_loss: 1.7084\n",
            "Epoch 107/1500\n",
            "876/876 [==============================] - 2s 2ms/step\n",
            "110/110 [==============================] - 4s 40ms/step - loss: 1.5337 - val_loss: 1.2727\n",
            "Epoch 108/1500\n",
            "876/876 [==============================] - 2s 2ms/step\n",
            "110/110 [==============================] - 4s 40ms/step - loss: 1.1351 - val_loss: 1.6833\n",
            "Epoch 109/1500\n",
            "876/876 [==============================] - 2s 2ms/step\n",
            "110/110 [==============================] - 6s 55ms/step - loss: 1.1855 - val_loss: 1.1073\n",
            "Epoch 110/1500\n",
            "876/876 [==============================] - 2s 2ms/step\n",
            "110/110 [==============================] - 4s 38ms/step - loss: 1.3621 - val_loss: 3.0247\n",
            "Epoch 111/1500\n",
            "876/876 [==============================] - 2s 2ms/step\n",
            "110/110 [==============================] - 4s 40ms/step - loss: 1.3666 - val_loss: 1.6761\n",
            "Epoch 112/1500\n",
            "876/876 [==============================] - 2s 3ms/step\n",
            "110/110 [==============================] - 6s 56ms/step - loss: 1.1038 - val_loss: 1.9197\n",
            "Epoch 113/1500\n",
            "876/876 [==============================] - 2s 2ms/step\n",
            "110/110 [==============================] - 4s 40ms/step - loss: 1.1840 - val_loss: 1.0058\n",
            "Epoch 114/1500\n",
            "876/876 [==============================] - 2s 2ms/step\n",
            "110/110 [==============================] - 4s 39ms/step - loss: 1.3406 - val_loss: 1.3760\n",
            "Epoch 115/1500\n",
            "876/876 [==============================] - 2s 3ms/step\n",
            "110/110 [==============================] - 9s 81ms/step - loss: 1.1725 - val_loss: 1.0916\n",
            "Epoch 116/1500\n",
            "876/876 [==============================] - 2s 2ms/step\n",
            "110/110 [==============================] - 4s 41ms/step - loss: 1.6880 - val_loss: 1.6424\n",
            "Epoch 117/1500\n",
            "876/876 [==============================] - 3s 3ms/step\n",
            "110/110 [==============================] - 7s 64ms/step - loss: 1.2066 - val_loss: 3.2710\n",
            "Epoch 118/1500\n",
            "876/876 [==============================] - 2s 2ms/step\n",
            "110/110 [==============================] - 4s 37ms/step - loss: 1.4687 - val_loss: 1.1942\n",
            "Epoch 119/1500\n",
            "876/876 [==============================] - 2s 2ms/step\n",
            "110/110 [==============================] - 4s 38ms/step - loss: 1.2464 - val_loss: 1.5997\n",
            "Epoch 120/1500\n",
            "876/876 [==============================] - 3s 3ms/step\n",
            "110/110 [==============================] - 8s 74ms/step - loss: 1.0863 - val_loss: 2.6925\n",
            "Epoch 121/1500\n",
            "876/876 [==============================] - 2s 2ms/step\n",
            "110/110 [==============================] - 4s 40ms/step - loss: 1.3875 - val_loss: 1.0773\n",
            "Epoch 122/1500\n",
            "876/876 [==============================] - 2s 2ms/step\n",
            "110/110 [==============================] - 4s 41ms/step - loss: 1.0829 - val_loss: 1.2650\n",
            "Epoch 123/1500\n",
            "876/876 [==============================] - 2s 2ms/step\n",
            "110/110 [==============================] - 6s 56ms/step - loss: 1.4008 - val_loss: 2.1069\n",
            "Epoch 124/1500\n",
            "876/876 [==============================] - 2s 2ms/step\n",
            "110/110 [==============================] - 4s 40ms/step - loss: 1.7498 - val_loss: 1.1534\n",
            "Epoch 125/1500\n",
            "876/876 [==============================] - 2s 2ms/step\n",
            "110/110 [==============================] - 4s 40ms/step - loss: 1.0969 - val_loss: 1.1669\n",
            "Epoch 126/1500\n",
            "876/876 [==============================] - 2s 2ms/step\n",
            "110/110 [==============================] - 6s 55ms/step - loss: 1.0275 - val_loss: 1.1392\n",
            "Epoch 127/1500\n",
            "876/876 [==============================] - 2s 2ms/step\n",
            "110/110 [==============================] - 4s 40ms/step - loss: 1.1028 - val_loss: 2.2084\n",
            "Epoch 128/1500\n",
            "876/876 [==============================] - 2s 2ms/step\n",
            "110/110 [==============================] - 4s 40ms/step - loss: 1.2563 - val_loss: 1.3729\n",
            "Epoch 129/1500\n",
            "876/876 [==============================] - 2s 2ms/step\n",
            "110/110 [==============================] - 6s 56ms/step - loss: 0.9591 - val_loss: 1.6958\n",
            "Epoch 130/1500\n",
            "876/876 [==============================] - 2s 2ms/step\n",
            "110/110 [==============================] - 4s 40ms/step - loss: 0.9886 - val_loss: 1.2789\n",
            "Epoch 131/1500\n",
            "876/876 [==============================] - 2s 2ms/step\n",
            "110/110 [==============================] - 4s 40ms/step - loss: 1.3505 - val_loss: 0.9257\n",
            "Epoch 132/1500\n",
            "876/876 [==============================] - 2s 2ms/step\n",
            "110/110 [==============================] - 6s 56ms/step - loss: 1.2713 - val_loss: 2.2608\n",
            "Epoch 133/1500\n",
            "876/876 [==============================] - 2s 2ms/step\n",
            "110/110 [==============================] - 4s 40ms/step - loss: 1.1322 - val_loss: 1.0467\n",
            "Epoch 134/1500\n",
            "876/876 [==============================] - 2s 2ms/step\n",
            "110/110 [==============================] - 4s 41ms/step - loss: 1.3537 - val_loss: 1.3322\n",
            "Epoch 135/1500\n",
            "876/876 [==============================] - 2s 2ms/step\n",
            "110/110 [==============================] - 6s 57ms/step - loss: 1.0757 - val_loss: 0.8562\n",
            "Epoch 136/1500\n",
            "876/876 [==============================] - 2s 2ms/step\n",
            "110/110 [==============================] - 4s 41ms/step - loss: 0.9267 - val_loss: 1.6382\n",
            "Epoch 137/1500\n",
            "876/876 [==============================] - 2s 3ms/step\n",
            "110/110 [==============================] - 4s 41ms/step - loss: 1.9739 - val_loss: 1.7327\n",
            "Epoch 138/1500\n",
            "876/876 [==============================] - 2s 2ms/step\n",
            "110/110 [==============================] - 6s 57ms/step - loss: 1.2756 - val_loss: 1.1330\n",
            "Epoch 139/1500\n",
            "876/876 [==============================] - 2s 2ms/step\n",
            "110/110 [==============================] - 5s 41ms/step - loss: 0.9757 - val_loss: 1.5837\n",
            "Epoch 140/1500\n",
            "876/876 [==============================] - 2s 3ms/step\n",
            "110/110 [==============================] - 5s 42ms/step - loss: 0.9595 - val_loss: 1.1764\n",
            "Epoch 141/1500\n",
            "876/876 [==============================] - 2s 2ms/step\n",
            "110/110 [==============================] - 6s 55ms/step - loss: 1.0400 - val_loss: 1.5894\n",
            "Epoch 142/1500\n",
            "876/876 [==============================] - 2s 2ms/step\n",
            "110/110 [==============================] - 4s 41ms/step - loss: 0.9067 - val_loss: 1.3419\n",
            "Epoch 143/1500\n",
            "876/876 [==============================] - 2s 3ms/step\n",
            "110/110 [==============================] - 7s 64ms/step - loss: 1.0034 - val_loss: 2.3689\n",
            "Epoch 144/1500\n",
            "876/876 [==============================] - 2s 2ms/step\n",
            "110/110 [==============================] - 4s 41ms/step - loss: 1.1930 - val_loss: 1.0555\n",
            "Epoch 145/1500\n",
            "876/876 [==============================] - 2s 2ms/step\n",
            "110/110 [==============================] - 4s 38ms/step - loss: 1.0122 - val_loss: 1.8193\n",
            "Epoch 146/1500\n",
            "876/876 [==============================] - 3s 3ms/step\n",
            "110/110 [==============================] - 8s 72ms/step - loss: 1.6052 - val_loss: 0.9567\n",
            "Epoch 147/1500\n",
            "876/876 [==============================] - 2s 2ms/step\n",
            "110/110 [==============================] - 4s 40ms/step - loss: 1.1069 - val_loss: 1.0559\n",
            "Epoch 148/1500\n",
            "876/876 [==============================] - 2s 2ms/step\n",
            "110/110 [==============================] - 4s 41ms/step - loss: 0.9474 - val_loss: 0.9312\n",
            "Epoch 149/1500\n",
            "876/876 [==============================] - 2s 2ms/step\n",
            "110/110 [==============================] - 6s 55ms/step - loss: 0.8356 - val_loss: 0.8177\n",
            "Epoch 150/1500\n",
            "876/876 [==============================] - 2s 2ms/step\n",
            "110/110 [==============================] - 4s 41ms/step - loss: 1.0560 - val_loss: 1.0998\n",
            "Epoch 151/1500\n",
            "876/876 [==============================] - 2s 2ms/step\n",
            "110/110 [==============================] - 4s 41ms/step - loss: 0.9169 - val_loss: 1.0137\n",
            "Epoch 152/1500\n",
            "876/876 [==============================] - 2s 2ms/step\n",
            "110/110 [==============================] - 6s 56ms/step - loss: 1.1512 - val_loss: 1.0431\n",
            "Epoch 153/1500\n",
            "876/876 [==============================] - 2s 2ms/step\n",
            "110/110 [==============================] - 4s 40ms/step - loss: 1.3700 - val_loss: 1.1930\n",
            "Epoch 154/1500\n",
            "876/876 [==============================] - 2s 2ms/step\n",
            "110/110 [==============================] - 4s 41ms/step - loss: 0.8949 - val_loss: 0.9382\n",
            "Epoch 155/1500\n",
            "876/876 [==============================] - 2s 2ms/step\n",
            "110/110 [==============================] - 6s 57ms/step - loss: 1.5477 - val_loss: 0.9097\n",
            "Epoch 156/1500\n",
            "876/876 [==============================] - 2s 2ms/step\n",
            "110/110 [==============================] - 4s 41ms/step - loss: 1.0363 - val_loss: 4.6514\n",
            "Epoch 157/1500\n",
            "876/876 [==============================] - 2s 3ms/step\n",
            "110/110 [==============================] - 5s 41ms/step - loss: 1.4843 - val_loss: 1.2811\n",
            "Epoch 158/1500\n",
            "876/876 [==============================] - 2s 2ms/step\n",
            "110/110 [==============================] - 6s 57ms/step - loss: 1.0205 - val_loss: 1.3493\n",
            "Epoch 159/1500\n",
            "876/876 [==============================] - 2s 2ms/step\n",
            "110/110 [==============================] - 5s 42ms/step - loss: 0.9166 - val_loss: 1.6720\n",
            "Epoch 160/1500\n",
            "876/876 [==============================] - 2s 3ms/step\n",
            "110/110 [==============================] - 5s 43ms/step - loss: 0.8495 - val_loss: 1.7340\n",
            "Epoch 161/1500\n",
            "876/876 [==============================] - 2s 2ms/step\n",
            "110/110 [==============================] - 6s 57ms/step - loss: 1.0877 - val_loss: 0.8458\n",
            "Epoch 162/1500\n",
            "876/876 [==============================] - 2s 2ms/step\n",
            "110/110 [==============================] - 5s 41ms/step - loss: 0.8961 - val_loss: 0.9923\n",
            "Epoch 163/1500\n",
            "876/876 [==============================] - 2s 3ms/step\n",
            "110/110 [==============================] - 7s 65ms/step - loss: 1.2664 - val_loss: 0.8532\n",
            "Epoch 164/1500\n",
            "876/876 [==============================] - 2s 2ms/step\n",
            "110/110 [==============================] - 4s 39ms/step - loss: 0.9830 - val_loss: 0.9500\n",
            "Epoch 165/1500\n",
            "876/876 [==============================] - 2s 2ms/step\n",
            "110/110 [==============================] - 4s 41ms/step - loss: 1.3509 - val_loss: 0.9074\n",
            "Epoch 166/1500\n",
            "876/876 [==============================] - 3s 3ms/step\n",
            "110/110 [==============================] - 8s 73ms/step - loss: 0.9718 - val_loss: 1.0753\n",
            "Epoch 167/1500\n",
            "876/876 [==============================] - 2s 2ms/step\n",
            "110/110 [==============================] - 4s 38ms/step - loss: 0.8808 - val_loss: 1.4622\n",
            "Epoch 168/1500\n",
            "876/876 [==============================] - 2s 2ms/step\n",
            "110/110 [==============================] - 4s 38ms/step - loss: 1.6545 - val_loss: 1.2808\n",
            "Epoch 169/1500\n",
            "876/876 [==============================] - 2s 3ms/step\n",
            "110/110 [==============================] - 9s 80ms/step - loss: 1.1367 - val_loss: 1.2797\n",
            "Epoch 170/1500\n",
            "876/876 [==============================] - 2s 2ms/step\n",
            "110/110 [==============================] - 4s 38ms/step - loss: 0.9525 - val_loss: 0.8668\n",
            "Epoch 171/1500\n",
            "876/876 [==============================] - 3s 3ms/step\n",
            "110/110 [==============================] - 5s 47ms/step - loss: 0.8284 - val_loss: 0.9424\n",
            "Epoch 172/1500\n",
            "876/876 [==============================] - 2s 2ms/step\n",
            "110/110 [==============================] - 6s 51ms/step - loss: 1.3222 - val_loss: 0.8633\n",
            "Epoch 173/1500\n",
            "876/876 [==============================] - 2s 2ms/step\n",
            "110/110 [==============================] - 4s 41ms/step - loss: 0.8413 - val_loss: 0.9112\n",
            "Epoch 174/1500\n",
            "876/876 [==============================] - 3s 3ms/step\n",
            "110/110 [==============================] - 5s 45ms/step - loss: 0.8582 - val_loss: 1.9212\n",
            "Epoch 175/1500\n",
            "876/876 [==============================] - 2s 2ms/step\n",
            "110/110 [==============================] - 6s 51ms/step - loss: 1.2769 - val_loss: 0.7789\n",
            "Epoch 176/1500\n",
            "876/876 [==============================] - 2s 2ms/step\n",
            "110/110 [==============================] - 4s 41ms/step - loss: 1.1279 - val_loss: 1.9653\n",
            "Epoch 177/1500\n",
            "876/876 [==============================] - 3s 3ms/step\n",
            "110/110 [==============================] - 5s 44ms/step - loss: 1.0556 - val_loss: 1.3601\n",
            "Epoch 178/1500\n",
            "876/876 [==============================] - 2s 2ms/step\n",
            "110/110 [==============================] - 6s 56ms/step - loss: 1.0718 - val_loss: 1.0921\n",
            "Epoch 179/1500\n",
            "876/876 [==============================] - 2s 2ms/step\n",
            "110/110 [==============================] - 4s 38ms/step - loss: 1.0177 - val_loss: 1.8702\n",
            "Epoch 180/1500\n",
            "876/876 [==============================] - 2s 3ms/step\n",
            "110/110 [==============================] - 7s 64ms/step - loss: 1.1323 - val_loss: 1.5142\n",
            "Epoch 181/1500\n",
            "876/876 [==============================] - 2s 2ms/step\n",
            "110/110 [==============================] - 4s 38ms/step - loss: 1.0967 - val_loss: 1.8308\n",
            "Epoch 182/1500\n",
            "876/876 [==============================] - 2s 2ms/step\n",
            "110/110 [==============================] - 4s 41ms/step - loss: 0.8855 - val_loss: 1.6551\n",
            "Epoch 183/1500\n",
            "876/876 [==============================] - 3s 3ms/step\n",
            "110/110 [==============================] - 6s 57ms/step - loss: 0.8735 - val_loss: 0.7440\n",
            "Epoch 184/1500\n",
            "876/876 [==============================] - 2s 2ms/step\n",
            "110/110 [==============================] - 4s 39ms/step - loss: 1.2207 - val_loss: 0.9440\n",
            "Epoch 185/1500\n",
            "876/876 [==============================] - 2s 2ms/step\n",
            "110/110 [==============================] - 4s 39ms/step - loss: 0.9737 - val_loss: 0.8871\n",
            "Epoch 186/1500\n",
            "876/876 [==============================] - 3s 3ms/step\n",
            "110/110 [==============================] - 7s 68ms/step - loss: 1.2414 - val_loss: 1.5674\n",
            "Epoch 187/1500\n",
            "876/876 [==============================] - 2s 2ms/step\n",
            "110/110 [==============================] - 4s 38ms/step - loss: 1.2443 - val_loss: 0.9010\n",
            "Epoch 188/1500\n",
            "876/876 [==============================] - 2s 2ms/step\n",
            "110/110 [==============================] - 4s 40ms/step - loss: 0.9179 - val_loss: 1.4834\n",
            "Epoch 189/1500\n",
            "876/876 [==============================] - 3s 3ms/step\n",
            "110/110 [==============================] - 7s 60ms/step - loss: 0.8275 - val_loss: 0.9223\n",
            "Epoch 190/1500\n",
            "876/876 [==============================] - 2s 2ms/step\n",
            "110/110 [==============================] - 4s 39ms/step - loss: 0.8564 - val_loss: 0.9131\n",
            "Epoch 191/1500\n",
            "876/876 [==============================] - 2s 2ms/step\n",
            "110/110 [==============================] - 4s 39ms/step - loss: 1.1018 - val_loss: 1.4910\n",
            "Epoch 192/1500\n",
            "876/876 [==============================] - 3s 3ms/step\n",
            "110/110 [==============================] - 8s 76ms/step - loss: 0.9692 - val_loss: 0.7960\n",
            "Epoch 193/1500\n",
            "876/876 [==============================] - 2s 2ms/step\n",
            "110/110 [==============================] - 4s 38ms/step - loss: 1.5715 - val_loss: 1.2517\n",
            "Epoch 194/1500\n",
            "876/876 [==============================] - 2s 2ms/step\n",
            "110/110 [==============================] - 5s 41ms/step - loss: 1.1481 - val_loss: 1.1247\n",
            "Epoch 195/1500\n",
            "876/876 [==============================] - 2s 2ms/step\n",
            "110/110 [==============================] - 6s 57ms/step - loss: 1.0243 - val_loss: 0.8669\n",
            "Epoch 196/1500\n",
            "876/876 [==============================] - 2s 2ms/step\n",
            "110/110 [==============================] - 4s 39ms/step - loss: 0.8350 - val_loss: 0.9150\n",
            "Epoch 197/1500\n",
            "876/876 [==============================] - 2s 2ms/step\n",
            "110/110 [==============================] - 5s 41ms/step - loss: 0.7254 - val_loss: 0.7175\n",
            "Epoch 198/1500\n",
            "876/876 [==============================] - 2s 2ms/step\n",
            "110/110 [==============================] - 6s 58ms/step - loss: 0.9949 - val_loss: 1.6547\n",
            "Epoch 199/1500\n",
            "876/876 [==============================] - 2s 2ms/step\n",
            "110/110 [==============================] - 4s 38ms/step - loss: 0.8601 - val_loss: 0.8579\n",
            "Epoch 200/1500\n",
            "876/876 [==============================] - 2s 2ms/step\n",
            "110/110 [==============================] - 7s 64ms/step - loss: 0.9394 - val_loss: 0.7519\n",
            "Epoch 201/1500\n",
            "876/876 [==============================] - 2s 2ms/step\n",
            "110/110 [==============================] - 5s 41ms/step - loss: 0.8351 - val_loss: 1.7406\n",
            "Epoch 202/1500\n",
            "876/876 [==============================] - 2s 2ms/step\n",
            "110/110 [==============================] - 4s 39ms/step - loss: 1.7671 - val_loss: 1.0684\n",
            "Epoch 203/1500\n",
            "876/876 [==============================] - 3s 3ms/step\n",
            "110/110 [==============================] - 8s 73ms/step - loss: 0.9520 - val_loss: 1.1416\n",
            "Epoch 204/1500\n",
            "876/876 [==============================] - 2s 2ms/step\n",
            "110/110 [==============================] - 4s 41ms/step - loss: 0.9665 - val_loss: 1.1513\n",
            "Epoch 205/1500\n",
            "876/876 [==============================] - 2s 2ms/step\n",
            "110/110 [==============================] - 4s 41ms/step - loss: 0.8300 - val_loss: 0.6854\n",
            "Epoch 206/1500\n",
            "876/876 [==============================] - 2s 2ms/step\n",
            "110/110 [==============================] - 6s 56ms/step - loss: 0.9268 - val_loss: 0.7256\n",
            "Epoch 207/1500\n",
            "876/876 [==============================] - 2s 2ms/step\n",
            "110/110 [==============================] - 5s 41ms/step - loss: 0.7924 - val_loss: 0.7390\n",
            "Epoch 208/1500\n",
            "876/876 [==============================] - 2s 3ms/step\n",
            "110/110 [==============================] - 7s 65ms/step - loss: 1.0808 - val_loss: 0.8375\n",
            "Epoch 209/1500\n",
            "876/876 [==============================] - 2s 2ms/step\n",
            "110/110 [==============================] - 5s 41ms/step - loss: 0.9634 - val_loss: 0.8747\n",
            "Epoch 210/1500\n",
            "876/876 [==============================] - 2s 2ms/step\n",
            "110/110 [==============================] - 4s 38ms/step - loss: 1.0501 - val_loss: 0.6909\n",
            "Epoch 211/1500\n",
            "876/876 [==============================] - 3s 3ms/step\n",
            "110/110 [==============================] - 8s 73ms/step - loss: 0.9285 - val_loss: 1.3810\n",
            "Epoch 212/1500\n",
            "876/876 [==============================] - 2s 2ms/step\n",
            "110/110 [==============================] - 4s 41ms/step - loss: 0.8235 - val_loss: 1.7009\n",
            "Epoch 213/1500\n",
            "876/876 [==============================] - 2s 2ms/step\n",
            "110/110 [==============================] - 4s 40ms/step - loss: 0.9366 - val_loss: 0.7543\n",
            "Epoch 214/1500\n",
            "876/876 [==============================] - 2s 3ms/step\n",
            "110/110 [==============================] - 9s 80ms/step - loss: 1.0104 - val_loss: 0.7192\n",
            "Epoch 215/1500\n",
            "876/876 [==============================] - 2s 2ms/step\n",
            "110/110 [==============================] - 4s 39ms/step - loss: 0.9548 - val_loss: 0.9402\n",
            "Epoch 216/1500\n",
            "876/876 [==============================] - 3s 3ms/step\n",
            "110/110 [==============================] - 5s 50ms/step - loss: 0.8790 - val_loss: 0.9728\n",
            "Epoch 217/1500\n",
            "876/876 [==============================] - 2s 2ms/step\n",
            "110/110 [==============================] - 5s 48ms/step - loss: 1.1844 - val_loss: 0.7598\n",
            "Epoch 218/1500\n",
            "876/876 [==============================] - 2s 2ms/step\n",
            "110/110 [==============================] - 4s 39ms/step - loss: 1.0113 - val_loss: 1.3935\n",
            "Epoch 219/1500\n",
            "876/876 [==============================] - 3s 3ms/step\n",
            "110/110 [==============================] - 5s 48ms/step - loss: 1.1508 - val_loss: 0.7654\n",
            "Epoch 220/1500\n",
            "876/876 [==============================] - 2s 2ms/step\n",
            "110/110 [==============================] - 5s 49ms/step - loss: 0.8980 - val_loss: 1.9785\n",
            "Epoch 221/1500\n",
            "876/876 [==============================] - 2s 2ms/step\n",
            "110/110 [==============================] - 4s 38ms/step - loss: 1.2043 - val_loss: 1.4809\n",
            "Epoch 222/1500\n",
            "876/876 [==============================] - 3s 3ms/step\n",
            "110/110 [==============================] - 5s 45ms/step - loss: 1.0294 - val_loss: 1.1045\n",
            "Epoch 223/1500\n",
            "876/876 [==============================] - 2s 2ms/step\n",
            "110/110 [==============================] - 6s 55ms/step - loss: 0.6900 - val_loss: 0.8549\n",
            "Epoch 224/1500\n",
            "876/876 [==============================] - 2s 2ms/step\n",
            "110/110 [==============================] - 5s 42ms/step - loss: 0.7636 - val_loss: 0.7021\n",
            "Epoch 225/1500\n",
            "876/876 [==============================] - 3s 3ms/step\n",
            "110/110 [==============================] - 7s 64ms/step - loss: 0.9078 - val_loss: 0.9711\n",
            "Epoch 226/1500\n",
            "876/876 [==============================] - 2s 2ms/step\n",
            "110/110 [==============================] - 4s 41ms/step - loss: 0.8223 - val_loss: 0.8115\n",
            "Epoch 227/1500\n",
            "876/876 [==============================] - 2s 2ms/step\n",
            "110/110 [==============================] - 4s 41ms/step - loss: 0.8029 - val_loss: 3.6670\n",
            "Epoch 228/1500\n",
            "876/876 [==============================] - 3s 3ms/step\n",
            "110/110 [==============================] - 8s 75ms/step - loss: 1.0633 - val_loss: 0.9759\n",
            "Epoch 229/1500\n",
            "876/876 [==============================] - 2s 2ms/step\n",
            "110/110 [==============================] - 4s 39ms/step - loss: 0.8820 - val_loss: 0.7296\n",
            "Epoch 230/1500\n",
            "876/876 [==============================] - 2s 3ms/step\n",
            "110/110 [==============================] - 7s 64ms/step - loss: 1.8104 - val_loss: 1.6267\n",
            "Epoch 231/1500\n",
            "876/876 [==============================] - 2s 2ms/step\n",
            "110/110 [==============================] - 4s 38ms/step - loss: 0.9823 - val_loss: 2.1589\n",
            "Epoch 232/1500\n",
            "876/876 [==============================] - 2s 2ms/step\n",
            "110/110 [==============================] - 4s 41ms/step - loss: 0.9233 - val_loss: 0.7867\n",
            "Epoch 233/1500\n",
            "876/876 [==============================] - 3s 3ms/step\n",
            "110/110 [==============================] - 6s 57ms/step - loss: 1.0150 - val_loss: 1.0550\n",
            "Epoch 234/1500\n",
            "876/876 [==============================] - 2s 2ms/step\n",
            "110/110 [==============================] - 4s 39ms/step - loss: 0.9156 - val_loss: 1.0323\n",
            "Epoch 235/1500\n",
            "876/876 [==============================] - 2s 2ms/step\n",
            "110/110 [==============================] - 5s 41ms/step - loss: 0.7866 - val_loss: 0.7480\n",
            "Epoch 236/1500\n",
            "876/876 [==============================] - 3s 3ms/step\n",
            "110/110 [==============================] - 8s 69ms/step - loss: 0.8116 - val_loss: 0.6994\n",
            "Epoch 237/1500\n",
            "876/876 [==============================] - 2s 2ms/step\n",
            "110/110 [==============================] - 4s 41ms/step - loss: 1.0256 - val_loss: 0.7966\n",
            "Epoch 238/1500\n",
            "876/876 [==============================] - 2s 2ms/step\n",
            "110/110 [==============================] - 4s 41ms/step - loss: 0.9358 - val_loss: 0.8166\n",
            "Epoch 239/1500\n",
            "876/876 [==============================] - 3s 3ms/step\n",
            "110/110 [==============================] - 7s 60ms/step - loss: 0.8017 - val_loss: 0.7735\n",
            "Epoch 240/1500\n",
            "876/876 [==============================] - 2s 2ms/step\n",
            "110/110 [==============================] - 4s 41ms/step - loss: 0.8817 - val_loss: 0.8010\n",
            "Epoch 241/1500\n",
            "876/876 [==============================] - 2s 2ms/step\n",
            "110/110 [==============================] - 4s 40ms/step - loss: 0.8368 - val_loss: 0.8906\n",
            "Epoch 242/1500\n",
            "876/876 [==============================] - 3s 3ms/step\n",
            "110/110 [==============================] - 9s 80ms/step - loss: 0.9432 - val_loss: 0.6534\n",
            "Epoch 243/1500\n",
            "876/876 [==============================] - 2s 2ms/step\n",
            "110/110 [==============================] - 4s 38ms/step - loss: 1.0470 - val_loss: 2.1910\n",
            "Epoch 244/1500\n",
            "876/876 [==============================] - 3s 3ms/step\n",
            "110/110 [==============================] - 5s 44ms/step - loss: 1.2013 - val_loss: 5.0319\n",
            "Epoch 245/1500\n",
            "876/876 [==============================] - 2s 2ms/step\n",
            "110/110 [==============================] - 6s 57ms/step - loss: 0.9088 - val_loss: 0.8874\n",
            "Epoch 246/1500\n",
            "876/876 [==============================] - 2s 2ms/step\n",
            "110/110 [==============================] - 5s 41ms/step - loss: 1.0221 - val_loss: 1.3498\n",
            "Epoch 247/1500\n",
            "876/876 [==============================] - 2s 3ms/step\n",
            "110/110 [==============================] - 7s 65ms/step - loss: 1.2196 - val_loss: 0.8926\n",
            "Epoch 248/1500\n",
            "876/876 [==============================] - 2s 2ms/step\n",
            "110/110 [==============================] - 5s 41ms/step - loss: 0.8491 - val_loss: 1.4119\n",
            "Epoch 249/1500\n",
            "876/876 [==============================] - 2s 2ms/step\n",
            "110/110 [==============================] - 4s 39ms/step - loss: 1.0292 - val_loss: 0.9534\n",
            "Epoch 250/1500\n",
            "876/876 [==============================] - 3s 3ms/step\n",
            "110/110 [==============================] - 6s 58ms/step - loss: 0.8130 - val_loss: 0.6813\n",
            "Epoch 251/1500\n",
            "876/876 [==============================] - 2s 2ms/step\n",
            "110/110 [==============================] - 4s 39ms/step - loss: 0.7475 - val_loss: 0.7346\n",
            "Epoch 252/1500\n",
            "876/876 [==============================] - 2s 2ms/step\n",
            "110/110 [==============================] - 4s 39ms/step - loss: 0.6876 - val_loss: 0.9934\n",
            "Epoch 253/1500\n",
            "876/876 [==============================] - 3s 3ms/step\n",
            "110/110 [==============================] - 6s 55ms/step - loss: 0.8364 - val_loss: 1.3283\n",
            "Epoch 254/1500\n",
            "876/876 [==============================] - 2s 2ms/step\n",
            "110/110 [==============================] - 5s 43ms/step - loss: 1.0749 - val_loss: 1.1058\n",
            "Epoch 255/1500\n",
            "876/876 [==============================] - 2s 2ms/step\n",
            "110/110 [==============================] - 4s 38ms/step - loss: 0.8454 - val_loss: 0.7408\n",
            "Epoch 256/1500\n",
            "876/876 [==============================] - 3s 3ms/step\n",
            "110/110 [==============================] - 7s 68ms/step - loss: 0.8027 - val_loss: 1.1611\n",
            "Epoch 257/1500\n",
            "876/876 [==============================] - 2s 2ms/step\n",
            "110/110 [==============================] - 5s 42ms/step - loss: 1.0544 - val_loss: 1.0125\n",
            "Epoch 258/1500\n",
            "876/876 [==============================] - 2s 2ms/step\n",
            "110/110 [==============================] - 4s 39ms/step - loss: 0.8550 - val_loss: 0.6427\n",
            "Epoch 259/1500\n",
            "876/876 [==============================] - 3s 3ms/step\n",
            "110/110 [==============================] - 9s 80ms/step - loss: 0.7873 - val_loss: 0.9063\n",
            "Epoch 260/1500\n",
            "876/876 [==============================] - 2s 2ms/step\n",
            "110/110 [==============================] - 5s 41ms/step - loss: 0.7757 - val_loss: 3.3519\n",
            "Epoch 261/1500\n",
            "876/876 [==============================] - 3s 3ms/step\n",
            "110/110 [==============================] - 5s 46ms/step - loss: 1.1341 - val_loss: 0.9409\n",
            "Epoch 262/1500\n",
            "876/876 [==============================] - 2s 2ms/step\n",
            "110/110 [==============================] - 6s 53ms/step - loss: 0.9559 - val_loss: 1.0574\n",
            "Epoch 263/1500\n",
            "876/876 [==============================] - 2s 2ms/step\n",
            "110/110 [==============================] - 5s 41ms/step - loss: 0.7451 - val_loss: 1.6731\n",
            "Epoch 264/1500\n",
            "876/876 [==============================] - 3s 3ms/step\n",
            "110/110 [==============================] - 7s 65ms/step - loss: 0.9407 - val_loss: 1.1156\n",
            "Epoch 265/1500\n",
            "876/876 [==============================] - 2s 2ms/step\n",
            "110/110 [==============================] - 4s 40ms/step - loss: 0.7125 - val_loss: 0.6096\n",
            "Epoch 266/1500\n",
            "876/876 [==============================] - 2s 2ms/step\n",
            "110/110 [==============================] - 4s 39ms/step - loss: 0.8074 - val_loss: 1.1405\n",
            "Epoch 267/1500\n",
            "876/876 [==============================] - 3s 3ms/step\n",
            "110/110 [==============================] - 6s 58ms/step - loss: 1.0978 - val_loss: 0.7513\n",
            "Epoch 268/1500\n",
            "876/876 [==============================] - 2s 2ms/step\n",
            "110/110 [==============================] - 5s 43ms/step - loss: 0.9624 - val_loss: 0.7450\n",
            "Epoch 269/1500\n",
            "876/876 [==============================] - 2s 2ms/step\n",
            "110/110 [==============================] - 4s 39ms/step - loss: 0.8759 - val_loss: 1.5086\n",
            "Epoch 270/1500\n",
            "876/876 [==============================] - 3s 3ms/step\n",
            "110/110 [==============================] - 7s 68ms/step - loss: 0.8914 - val_loss: 0.8443\n",
            "Epoch 271/1500\n",
            "876/876 [==============================] - 2s 2ms/step\n",
            "110/110 [==============================] - 5s 42ms/step - loss: 0.7090 - val_loss: 0.6179\n",
            "Epoch 272/1500\n",
            "876/876 [==============================] - 2s 2ms/step\n",
            "110/110 [==============================] - 5s 41ms/step - loss: 0.7212 - val_loss: 0.7118\n",
            "Epoch 273/1500\n",
            "876/876 [==============================] - 3s 3ms/step\n",
            "110/110 [==============================] - 9s 80ms/step - loss: 1.1494 - val_loss: 1.1446\n",
            "Epoch 274/1500\n",
            "876/876 [==============================] - 2s 2ms/step\n",
            "110/110 [==============================] - 5s 41ms/step - loss: 0.9370 - val_loss: 0.6520\n",
            "Epoch 275/1500\n",
            "876/876 [==============================] - 3s 3ms/step\n",
            "110/110 [==============================] - 7s 65ms/step - loss: 0.8101 - val_loss: 0.7909\n",
            "Epoch 276/1500\n",
            "876/876 [==============================] - 2s 2ms/step\n",
            "110/110 [==============================] - 5s 41ms/step - loss: 0.8258 - val_loss: 1.7036\n",
            "Epoch 277/1500\n",
            "876/876 [==============================] - 2s 2ms/step\n",
            "110/110 [==============================] - 4s 39ms/step - loss: 0.7097 - val_loss: 0.6960\n",
            "Epoch 278/1500\n",
            "876/876 [==============================] - 3s 3ms/step\n",
            "110/110 [==============================] - 9s 78ms/step - loss: 0.7636 - val_loss: 0.9919\n",
            "Epoch 279/1500\n",
            "876/876 [==============================] - 2s 2ms/step\n",
            "110/110 [==============================] - 4s 40ms/step - loss: 0.5674 - val_loss: 0.5437\n",
            "Epoch 280/1500\n",
            "876/876 [==============================] - 2s 3ms/step\n",
            "110/110 [==============================] - 7s 65ms/step - loss: 0.7514 - val_loss: 0.9913\n",
            "Epoch 281/1500\n",
            "876/876 [==============================] - 2s 2ms/step\n",
            "110/110 [==============================] - 4s 39ms/step - loss: 0.6522 - val_loss: 2.2081\n",
            "Epoch 282/1500\n",
            "876/876 [==============================] - 2s 2ms/step\n",
            "110/110 [==============================] - 5s 42ms/step - loss: 0.9510 - val_loss: 1.1877\n",
            "Epoch 283/1500\n",
            "876/876 [==============================] - 3s 3ms/step\n",
            "110/110 [==============================] - 6s 57ms/step - loss: 0.7599 - val_loss: 0.9437\n",
            "Epoch 284/1500\n",
            "876/876 [==============================] - 2s 2ms/step\n",
            "110/110 [==============================] - 4s 40ms/step - loss: 0.8099 - val_loss: 1.0688\n",
            "Epoch 285/1500\n",
            "876/876 [==============================] - 2s 2ms/step\n",
            "110/110 [==============================] - 5s 42ms/step - loss: 0.9624 - val_loss: 1.0737\n",
            "Epoch 286/1500\n",
            "876/876 [==============================] - 3s 3ms/step\n",
            "110/110 [==============================] - 8s 75ms/step - loss: 0.8411 - val_loss: 4.3514\n",
            "Epoch 287/1500\n",
            "876/876 [==============================] - 2s 2ms/step\n",
            "110/110 [==============================] - 5s 42ms/step - loss: 0.9396 - val_loss: 0.6441\n",
            "Epoch 288/1500\n",
            "876/876 [==============================] - 2s 3ms/step\n",
            "110/110 [==============================] - 5s 44ms/step - loss: 0.9056 - val_loss: 0.7581\n",
            "Epoch 289/1500\n",
            "876/876 [==============================] - 2s 3ms/step\n",
            "110/110 [==============================] - 6s 58ms/step - loss: 0.7332 - val_loss: 0.6173\n",
            "Epoch 290/1500\n",
            "876/876 [==============================] - 2s 2ms/step\n",
            "110/110 [==============================] - 4s 40ms/step - loss: 1.1001 - val_loss: 1.4006\n",
            "Epoch 291/1500\n",
            "876/876 [==============================] - 2s 3ms/step\n",
            "110/110 [==============================] - 7s 65ms/step - loss: 0.6698 - val_loss: 2.3419\n",
            "Epoch 292/1500\n",
            "876/876 [==============================] - 2s 2ms/step\n",
            "110/110 [==============================] - 5s 44ms/step - loss: 0.9510 - val_loss: 0.8337\n",
            "Epoch 293/1500\n",
            "876/876 [==============================] - 2s 2ms/step\n",
            "110/110 [==============================] - 4s 40ms/step - loss: 0.7261 - val_loss: 1.6167\n",
            "Epoch 294/1500\n",
            "876/876 [==============================] - 3s 3ms/step\n",
            "110/110 [==============================] - 7s 60ms/step - loss: 1.1681 - val_loss: 0.8206\n",
            "Epoch 295/1500\n",
            "876/876 [==============================] - 2s 2ms/step\n",
            "110/110 [==============================] - 5s 42ms/step - loss: 0.6444 - val_loss: 0.6096\n",
            "Epoch 296/1500\n",
            "876/876 [==============================] - 2s 2ms/step\n",
            "110/110 [==============================] - 4s 40ms/step - loss: 0.7994 - val_loss: 1.1548\n",
            "Epoch 297/1500\n",
            "876/876 [==============================] - 3s 3ms/step\n",
            "110/110 [==============================] - 7s 60ms/step - loss: 0.8001 - val_loss: 0.8648\n",
            "Epoch 298/1500\n",
            "876/876 [==============================] - 2s 2ms/step\n",
            "110/110 [==============================] - 5s 41ms/step - loss: 0.6549 - val_loss: 0.9420\n",
            "Epoch 299/1500\n",
            "876/876 [==============================] - 2s 2ms/step\n",
            "110/110 [==============================] - 5s 43ms/step - loss: 1.0099 - val_loss: 0.8033\n",
            "Epoch 300/1500\n",
            "876/876 [==============================] - 3s 3ms/step\n",
            "110/110 [==============================] - 8s 75ms/step - loss: 0.8578 - val_loss: 1.1540\n",
            "Epoch 301/1500\n",
            "876/876 [==============================] - 2s 2ms/step\n",
            "110/110 [==============================] - 5s 42ms/step - loss: 0.6802 - val_loss: 0.9926\n",
            "Epoch 302/1500\n",
            "876/876 [==============================] - 2s 3ms/step\n",
            "110/110 [==============================] - 5s 42ms/step - loss: 0.7613 - val_loss: 0.8932\n",
            "Epoch 303/1500\n",
            "876/876 [==============================] - 2s 3ms/step\n",
            "110/110 [==============================] - 6s 57ms/step - loss: 1.4773 - val_loss: 0.9753\n",
            "Epoch 304/1500\n",
            "876/876 [==============================] - 2s 2ms/step\n",
            "110/110 [==============================] - 4s 39ms/step - loss: 0.9652 - val_loss: 2.2154\n",
            "Epoch 305/1500\n",
            "876/876 [==============================] - 2s 2ms/step\n",
            "110/110 [==============================] - 5s 42ms/step - loss: 0.9456 - val_loss: 0.7971\n",
            "Epoch 306/1500\n",
            "876/876 [==============================] - 2s 3ms/step\n",
            "110/110 [==============================] - 6s 59ms/step - loss: 0.9093 - val_loss: 0.6265\n",
            "Epoch 307/1500\n",
            "876/876 [==============================] - 2s 2ms/step\n",
            "110/110 [==============================] - 5s 42ms/step - loss: 0.6621 - val_loss: 0.6338\n",
            "Epoch 308/1500\n",
            "876/876 [==============================] - 2s 2ms/step\n",
            "110/110 [==============================] - 5s 41ms/step - loss: 0.7526 - val_loss: 1.2195\n",
            "Epoch 309/1500\n",
            "876/876 [==============================] - 2s 3ms/step\n",
            "110/110 [==============================] - 6s 59ms/step - loss: 0.7768 - val_loss: 1.0715\n",
            "Epoch 310/1500\n",
            "876/876 [==============================] - 2s 2ms/step\n",
            "110/110 [==============================] - 5s 41ms/step - loss: 0.9462 - val_loss: 1.5329\n",
            "Epoch 311/1500\n",
            "876/876 [==============================] - 2s 3ms/step\n",
            "110/110 [==============================] - 7s 65ms/step - loss: 0.6076 - val_loss: 0.7966\n",
            "Epoch 312/1500\n",
            "876/876 [==============================] - 2s 2ms/step\n",
            "110/110 [==============================] - 4s 40ms/step - loss: 0.7680 - val_loss: 0.6629\n",
            "Epoch 313/1500\n",
            "876/876 [==============================] - 2s 2ms/step\n",
            "110/110 [==============================] - 5s 41ms/step - loss: 1.0092 - val_loss: 1.1245\n",
            "Epoch 314/1500\n",
            "876/876 [==============================] - 3s 3ms/step\n",
            "110/110 [==============================] - 6s 57ms/step - loss: 0.8578 - val_loss: 0.9355\n",
            "Epoch 315/1500\n",
            "876/876 [==============================] - 2s 2ms/step\n",
            "110/110 [==============================] - 4s 41ms/step - loss: 0.6991 - val_loss: 1.4193\n",
            "Epoch 316/1500\n",
            "876/876 [==============================] - 2s 2ms/step\n",
            "110/110 [==============================] - 5s 41ms/step - loss: 0.7757 - val_loss: 0.6941\n",
            "Epoch 317/1500\n",
            "876/876 [==============================] - 3s 3ms/step\n",
            "110/110 [==============================] - 6s 58ms/step - loss: 1.1902 - val_loss: 2.8515\n",
            "Epoch 318/1500\n",
            "876/876 [==============================] - 2s 2ms/step\n",
            "110/110 [==============================] - 5s 41ms/step - loss: 0.8290 - val_loss: 1.0942\n",
            "Epoch 319/1500\n",
            "876/876 [==============================] - 2s 2ms/step\n",
            "110/110 [==============================] - 4s 40ms/step - loss: 0.7207 - val_loss: 0.9957\n",
            "Epoch 320/1500\n",
            "876/876 [==============================] - 3s 3ms/step\n",
            "110/110 [==============================] - 8s 72ms/step - loss: 0.7347 - val_loss: 0.8653\n",
            "Epoch 321/1500\n",
            "876/876 [==============================] - 2s 2ms/step\n",
            "110/110 [==============================] - 4s 39ms/step - loss: 0.6907 - val_loss: 0.6938\n",
            "Epoch 322/1500\n",
            "876/876 [==============================] - 2s 2ms/step\n",
            "110/110 [==============================] - 4s 41ms/step - loss: 0.7316 - val_loss: 1.1072\n",
            "Epoch 323/1500\n",
            "876/876 [==============================] - 2s 3ms/step\n",
            "110/110 [==============================] - 7s 60ms/step - loss: 1.1263 - val_loss: 0.6759\n",
            "Epoch 324/1500\n",
            "876/876 [==============================] - 2s 2ms/step\n",
            "110/110 [==============================] - 4s 40ms/step - loss: 0.7437 - val_loss: 1.1515\n",
            "Epoch 325/1500\n",
            "876/876 [==============================] - 2s 2ms/step\n",
            "110/110 [==============================] - 5s 42ms/step - loss: 0.9237 - val_loss: 0.8869\n",
            "Epoch 326/1500\n",
            "876/876 [==============================] - 3s 3ms/step\n",
            "110/110 [==============================] - 9s 79ms/step - loss: 0.7803 - val_loss: 0.6620\n",
            "Epoch 327/1500\n",
            "876/876 [==============================] - 2s 2ms/step\n",
            "110/110 [==============================] - 4s 40ms/step - loss: 0.7808 - val_loss: 0.7556\n",
            "Epoch 328/1500\n",
            "876/876 [==============================] - 3s 3ms/step\n",
            "110/110 [==============================] - 7s 65ms/step - loss: 0.8634 - val_loss: 1.1377\n",
            "Epoch 329/1500\n",
            "876/876 [==============================] - 2s 2ms/step\n",
            "110/110 [==============================] - 5s 42ms/step - loss: 0.8643 - val_loss: 0.6585\n",
            "Epoch 330/1500\n",
            "876/876 [==============================] - 2s 2ms/step\n",
            "110/110 [==============================] - 4s 40ms/step - loss: 0.7229 - val_loss: 0.8750\n",
            "Epoch 331/1500\n",
            "876/876 [==============================] - 3s 3ms/step\n",
            "110/110 [==============================] - 9s 78ms/step - loss: 0.6416 - val_loss: 1.0579\n",
            "Epoch 332/1500\n",
            "876/876 [==============================] - 2s 2ms/step\n",
            "110/110 [==============================] - 5s 42ms/step - loss: 1.2982 - val_loss: 0.6965\n",
            "Epoch 333/1500\n",
            "876/876 [==============================] - 2s 3ms/step\n",
            "110/110 [==============================] - 7s 66ms/step - loss: 0.8583 - val_loss: 1.2175\n",
            "Epoch 334/1500\n",
            "876/876 [==============================] - 2s 2ms/step\n",
            "110/110 [==============================] - 4s 40ms/step - loss: 0.5919 - val_loss: 0.9801\n",
            "Epoch 335/1500\n",
            "876/876 [==============================] - 2s 2ms/step\n",
            "110/110 [==============================] - 5s 41ms/step - loss: 0.6516 - val_loss: 0.7334\n",
            "Epoch 336/1500\n",
            "876/876 [==============================] - 3s 3ms/step\n",
            "110/110 [==============================] - 8s 76ms/step - loss: 0.7127 - val_loss: 2.7665\n",
            "Epoch 337/1500\n",
            "876/876 [==============================] - 2s 2ms/step\n",
            "110/110 [==============================] - 5s 41ms/step - loss: 1.4829 - val_loss: 0.6604\n",
            "Epoch 338/1500\n",
            "876/876 [==============================] - 2s 3ms/step\n",
            "110/110 [==============================] - 7s 65ms/step - loss: 0.9149 - val_loss: 0.9478\n",
            "Epoch 339/1500\n",
            "876/876 [==============================] - 2s 2ms/step\n",
            "110/110 [==============================] - 4s 40ms/step - loss: 0.6698 - val_loss: 0.7561\n",
            "Epoch 340/1500\n",
            "876/876 [==============================] - 2s 2ms/step\n",
            "110/110 [==============================] - 5s 42ms/step - loss: 0.6725 - val_loss: 0.6958\n",
            "Epoch 341/1500\n",
            "876/876 [==============================] - 3s 3ms/step\n",
            "110/110 [==============================] - 8s 74ms/step - loss: 0.6681 - val_loss: 0.8142\n",
            "Epoch 342/1500\n",
            "876/876 [==============================] - 2s 2ms/step\n",
            "110/110 [==============================] - 5s 41ms/step - loss: 0.8578 - val_loss: 0.6468\n",
            "Epoch 343/1500\n",
            "876/876 [==============================] - 2s 2ms/step\n",
            "110/110 [==============================] - 7s 65ms/step - loss: 0.7962 - val_loss: 1.1471\n",
            "Epoch 344/1500\n",
            "876/876 [==============================] - 2s 2ms/step\n",
            "110/110 [==============================] - 4s 40ms/step - loss: 1.0792 - val_loss: 0.6899\n",
            "Epoch 345/1500\n",
            "876/876 [==============================] - 2s 2ms/step\n",
            "110/110 [==============================] - 4s 41ms/step - loss: 0.8792 - val_loss: 0.6962\n",
            "Epoch 346/1500\n",
            "876/876 [==============================] - 3s 3ms/step\n",
            "110/110 [==============================] - 6s 57ms/step - loss: 0.8003 - val_loss: 0.7888\n",
            "Epoch 347/1500\n",
            "876/876 [==============================] - 2s 2ms/step\n",
            "110/110 [==============================] - 5s 43ms/step - loss: 1.1061 - val_loss: 0.6805\n",
            "Epoch 348/1500\n",
            "876/876 [==============================] - 2s 2ms/step\n",
            "110/110 [==============================] - 4s 40ms/step - loss: 0.5859 - val_loss: 0.6082\n",
            "Epoch 349/1500\n",
            "876/876 [==============================] - 3s 3ms/step\n",
            "110/110 [==============================] - 8s 70ms/step - loss: 0.9047 - val_loss: 0.7701\n",
            "Epoch 350/1500\n",
            "876/876 [==============================] - 2s 2ms/step\n",
            "110/110 [==============================] - 5s 42ms/step - loss: 0.7604 - val_loss: 1.0276\n",
            "Epoch 351/1500\n",
            "876/876 [==============================] - 2s 2ms/step\n",
            "110/110 [==============================] - 5s 42ms/step - loss: 0.6680 - val_loss: 8.0275\n",
            "Epoch 352/1500\n",
            "876/876 [==============================] - 2s 3ms/step\n",
            "110/110 [==============================] - 6s 59ms/step - loss: 1.0546 - val_loss: 0.7073\n",
            "Epoch 353/1500\n",
            "876/876 [==============================] - 2s 2ms/step\n",
            "110/110 [==============================] - 5s 42ms/step - loss: 0.6047 - val_loss: 0.7202\n",
            "Epoch 354/1500\n",
            "876/876 [==============================] - 2s 2ms/step\n",
            "110/110 [==============================] - 7s 65ms/step - loss: 0.8767 - val_loss: 1.1260\n",
            "Epoch 355/1500\n",
            "876/876 [==============================] - 2s 2ms/step\n",
            "110/110 [==============================] - 4s 40ms/step - loss: 0.8642 - val_loss: 0.5793\n",
            "Epoch 356/1500\n",
            "876/876 [==============================] - 2s 2ms/step\n",
            "110/110 [==============================] - 5s 42ms/step - loss: 0.7652 - val_loss: 0.8700\n",
            "Epoch 357/1500\n",
            "876/876 [==============================] - 3s 3ms/step\n",
            "110/110 [==============================] - 6s 58ms/step - loss: 0.6431 - val_loss: 0.9525\n",
            "Epoch 358/1500\n",
            "876/876 [==============================] - 2s 2ms/step\n",
            "110/110 [==============================] - 5s 41ms/step - loss: 0.5983 - val_loss: 0.7636\n",
            "Epoch 359/1500\n",
            "876/876 [==============================] - 2s 2ms/step\n",
            "110/110 [==============================] - 4s 41ms/step - loss: 0.8682 - val_loss: 0.6943\n",
            "Epoch 360/1500\n",
            "876/876 [==============================] - 3s 3ms/step\n",
            "110/110 [==============================] - 8s 73ms/step - loss: 0.7155 - val_loss: 0.8608\n",
            "Epoch 361/1500\n",
            "876/876 [==============================] - 2s 2ms/step\n",
            "110/110 [==============================] - 5s 42ms/step - loss: 0.8195 - val_loss: 0.9288\n",
            "Epoch 362/1500\n",
            "876/876 [==============================] - 2s 3ms/step\n",
            "110/110 [==============================] - 7s 67ms/step - loss: 1.0052 - val_loss: 0.9526\n",
            "Epoch 363/1500\n",
            "876/876 [==============================] - 2s 2ms/step\n",
            "110/110 [==============================] - 5s 43ms/step - loss: 0.6885 - val_loss: 1.0170\n",
            "Epoch 364/1500\n",
            "876/876 [==============================] - 2s 2ms/step\n",
            "110/110 [==============================] - 5s 43ms/step - loss: 0.7919 - val_loss: 2.2677\n",
            "Epoch 365/1500\n",
            "876/876 [==============================] - 3s 3ms/step\n",
            "110/110 [==============================] - 9s 78ms/step - loss: 0.6369 - val_loss: 1.3015\n",
            "Epoch 366/1500\n",
            "876/876 [==============================] - 2s 2ms/step\n",
            "110/110 [==============================] - 5s 42ms/step - loss: 0.7236 - val_loss: 0.9742\n",
            "Epoch 367/1500\n",
            "876/876 [==============================] - 2s 3ms/step\n",
            "110/110 [==============================] - 7s 65ms/step - loss: 0.8193 - val_loss: 0.8214\n",
            "Epoch 368/1500\n",
            "876/876 [==============================] - 2s 2ms/step\n",
            "110/110 [==============================] - 4s 40ms/step - loss: 1.2350 - val_loss: 2.2559\n",
            "Epoch 369/1500\n",
            "876/876 [==============================] - 2s 2ms/step\n",
            "110/110 [==============================] - 5s 42ms/step - loss: 1.0107 - val_loss: 0.8457\n",
            "Epoch 370/1500\n",
            "876/876 [==============================] - 3s 3ms/step\n",
            "110/110 [==============================] - 6s 59ms/step - loss: 0.7177 - val_loss: 0.8098\n",
            "Epoch 371/1500\n",
            "876/876 [==============================] - 2s 2ms/step\n",
            "110/110 [==============================] - 4s 40ms/step - loss: 0.6153 - val_loss: 0.7165\n",
            "Epoch 372/1500\n",
            "876/876 [==============================] - 2s 2ms/step\n",
            "110/110 [==============================] - 4s 41ms/step - loss: 0.5626 - val_loss: 0.8737\n",
            "Epoch 373/1500\n",
            "876/876 [==============================] - 3s 3ms/step\n",
            "110/110 [==============================] - 8s 74ms/step - loss: 0.7355 - val_loss: 1.0466\n",
            "Epoch 374/1500\n",
            "876/876 [==============================] - 2s 2ms/step\n",
            "110/110 [==============================] - 4s 40ms/step - loss: 0.6792 - val_loss: 1.3021\n",
            "Epoch 375/1500\n",
            "876/876 [==============================] - 2s 2ms/step\n",
            "110/110 [==============================] - 7s 65ms/step - loss: 0.7437 - val_loss: 0.6517\n",
            "Epoch 376/1500\n",
            "876/876 [==============================] - 2s 2ms/step\n",
            "110/110 [==============================] - 5s 42ms/step - loss: 0.5962 - val_loss: 1.1538\n",
            "Epoch 377/1500\n",
            "876/876 [==============================] - 2s 2ms/step\n",
            "110/110 [==============================] - 5s 42ms/step - loss: 0.7597 - val_loss: 0.6751\n",
            "Epoch 378/1500\n",
            "876/876 [==============================] - 3s 3ms/step\n",
            "110/110 [==============================] - 8s 76ms/step - loss: 0.6056 - val_loss: 0.9896\n",
            "Epoch 379/1500\n",
            "876/876 [==============================] - 2s 2ms/step\n",
            "110/110 [==============================] - 5s 42ms/step - loss: 1.3562 - val_loss: 0.9958\n",
            "Epoch 380/1500\n",
            "876/876 [==============================] - 2s 3ms/step\n",
            "110/110 [==============================] - 5s 43ms/step - loss: 0.6870 - val_loss: 1.6204\n",
            "Epoch 381/1500\n",
            "876/876 [==============================] - 2s 3ms/step\n",
            "110/110 [==============================] - 6s 58ms/step - loss: 0.8034 - val_loss: 1.5369\n",
            "Epoch 382/1500\n",
            "876/876 [==============================] - 2s 2ms/step\n",
            "110/110 [==============================] - 5s 42ms/step - loss: 0.8590 - val_loss: 0.8125\n",
            "Epoch 383/1500\n",
            "876/876 [==============================] - 2s 3ms/step\n",
            "110/110 [==============================] - 7s 66ms/step - loss: 0.8440 - val_loss: 0.6739\n",
            "Epoch 384/1500\n",
            "876/876 [==============================] - 2s 2ms/step\n",
            "110/110 [==============================] - 5s 42ms/step - loss: 0.7344 - val_loss: 0.8230\n",
            "Epoch 385/1500\n",
            "876/876 [==============================] - 2s 2ms/step\n",
            "110/110 [==============================] - 5s 42ms/step - loss: 0.8989 - val_loss: 0.8824\n",
            "Epoch 386/1500\n",
            "876/876 [==============================] - 3s 3ms/step\n",
            "110/110 [==============================] - 8s 77ms/step - loss: 0.5872 - val_loss: 1.0621\n",
            "Epoch 387/1500\n",
            "876/876 [==============================] - 2s 2ms/step\n",
            "110/110 [==============================] - 5s 41ms/step - loss: 0.9027 - val_loss: 1.3204\n",
            "Epoch 388/1500\n",
            "876/876 [==============================] - 2s 3ms/step\n",
            "110/110 [==============================] - 7s 66ms/step - loss: 0.8057 - val_loss: 0.8034\n",
            "Epoch 389/1500\n",
            "876/876 [==============================] - 2s 2ms/step\n",
            "110/110 [==============================] - 5s 42ms/step - loss: 0.6756 - val_loss: 2.8102\n",
            "Epoch 390/1500\n",
            "876/876 [==============================] - 2s 2ms/step\n",
            "110/110 [==============================] - 5s 42ms/step - loss: 0.7294 - val_loss: 0.6565\n",
            "Epoch 391/1500\n",
            "876/876 [==============================] - 3s 3ms/step\n",
            "110/110 [==============================] - 7s 60ms/step - loss: 0.5915 - val_loss: 0.9548\n",
            "Epoch 392/1500\n",
            "876/876 [==============================] - 2s 2ms/step\n",
            "110/110 [==============================] - 5s 42ms/step - loss: 0.5988 - val_loss: 1.4015\n",
            "Epoch 393/1500\n",
            "876/876 [==============================] - 2s 2ms/step\n",
            "110/110 [==============================] - 5s 42ms/step - loss: 0.8451 - val_loss: 0.6043\n",
            "Epoch 394/1500\n",
            "876/876 [==============================] - 3s 3ms/step\n",
            "110/110 [==============================] - 6s 59ms/step - loss: 0.8366 - val_loss: 1.6078\n",
            "Epoch 395/1500\n",
            "876/876 [==============================] - 2s 2ms/step\n",
            "110/110 [==============================] - 5s 42ms/step - loss: 0.7975 - val_loss: 0.7582\n",
            "Epoch 396/1500\n",
            "876/876 [==============================] - 2s 2ms/step\n",
            "110/110 [==============================] - 5s 42ms/step - loss: 0.8873 - val_loss: 1.0161\n",
            "Epoch 397/1500\n",
            "876/876 [==============================] - 3s 3ms/step\n",
            "110/110 [==============================] - 8s 75ms/step - loss: 0.8849 - val_loss: 0.7793\n",
            "Epoch 398/1500\n",
            "876/876 [==============================] - 2s 2ms/step\n",
            "110/110 [==============================] - 4s 41ms/step - loss: 0.7385 - val_loss: 0.8534\n",
            "Epoch 399/1500\n",
            "876/876 [==============================] - 2s 2ms/step\n",
            "110/110 [==============================] - 5s 42ms/step - loss: 1.1783 - val_loss: 0.9477\n",
            "Epoch 400/1500\n",
            "876/876 [==============================] - 3s 3ms/step\n",
            "110/110 [==============================] - 6s 59ms/step - loss: 0.7654 - val_loss: 0.8027\n",
            "Epoch 401/1500\n",
            "876/876 [==============================] - 2s 2ms/step\n",
            "110/110 [==============================] - 5s 42ms/step - loss: 0.6807 - val_loss: 0.8602\n",
            "Epoch 402/1500\n",
            "876/876 [==============================] - 2s 2ms/step\n",
            "110/110 [==============================] - 5s 42ms/step - loss: 0.7377 - val_loss: 1.1865\n",
            "Epoch 403/1500\n",
            "876/876 [==============================] - 3s 3ms/step\n",
            "110/110 [==============================] - 7s 61ms/step - loss: 0.7478 - val_loss: 0.7194\n",
            "Epoch 404/1500\n",
            "876/876 [==============================] - 2s 2ms/step\n",
            "110/110 [==============================] - 4s 41ms/step - loss: 0.8089 - val_loss: 0.7810\n",
            "Epoch 405/1500\n",
            "876/876 [==============================] - 2s 2ms/step\n",
            "110/110 [==============================] - 5s 42ms/step - loss: 0.6939 - val_loss: 0.6182\n",
            "Epoch 406/1500\n",
            "876/876 [==============================] - 3s 3ms/step\n",
            "110/110 [==============================] - 7s 62ms/step - loss: 0.6373 - val_loss: 0.7885\n",
            "Epoch 407/1500\n",
            "876/876 [==============================] - 2s 2ms/step\n",
            "110/110 [==============================] - 5s 42ms/step - loss: 0.6565 - val_loss: 1.2089\n",
            "Epoch 408/1500\n",
            "876/876 [==============================] - 2s 2ms/step\n",
            "110/110 [==============================] - 4s 41ms/step - loss: 0.8450 - val_loss: 0.6944\n",
            "Epoch 409/1500\n",
            "876/876 [==============================] - 3s 3ms/step\n",
            "110/110 [==============================] - 7s 62ms/step - loss: 0.6299 - val_loss: 1.4074\n",
            "Epoch 410/1500\n",
            "876/876 [==============================] - 2s 2ms/step\n",
            "110/110 [==============================] - 4s 41ms/step - loss: 0.6865 - val_loss: 0.9162\n",
            "Epoch 411/1500\n",
            "876/876 [==============================] - 2s 2ms/step\n",
            "110/110 [==============================] - 5s 42ms/step - loss: 0.6283 - val_loss: 1.0573\n",
            "Epoch 412/1500\n",
            "876/876 [==============================] - 3s 3ms/step\n",
            "110/110 [==============================] - 6s 59ms/step - loss: 0.6436 - val_loss: 0.9070\n",
            "Epoch 413/1500\n",
            "876/876 [==============================] - 2s 2ms/step\n",
            "110/110 [==============================] - 5s 44ms/step - loss: 0.8914 - val_loss: 1.2299\n",
            "Epoch 414/1500\n",
            "876/876 [==============================] - 2s 2ms/step\n",
            "110/110 [==============================] - 5s 41ms/step - loss: 0.8477 - val_loss: 1.4962\n",
            "Epoch 415/1500\n",
            "876/876 [==============================] - 3s 3ms/step\n",
            "110/110 [==============================] - 6s 59ms/step - loss: 0.5679 - val_loss: 0.8714\n",
            "Epoch 416/1500\n",
            "876/876 [==============================] - 2s 2ms/step\n",
            "110/110 [==============================] - 5s 42ms/step - loss: 0.6218 - val_loss: 1.6855\n",
            "Epoch 417/1500\n",
            "876/876 [==============================] - 2s 2ms/step\n",
            "110/110 [==============================] - 4s 41ms/step - loss: 0.8480 - val_loss: 2.0002\n",
            "Epoch 418/1500\n",
            "876/876 [==============================] - 3s 3ms/step\n",
            "110/110 [==============================] - 6s 58ms/step - loss: 0.8328 - val_loss: 0.7437\n",
            "Epoch 419/1500\n",
            "876/876 [==============================] - 2s 2ms/step\n",
            "110/110 [==============================] - 5s 44ms/step - loss: 1.1849 - val_loss: 2.0008\n",
            "Epoch 420/1500\n",
            "876/876 [==============================] - 2s 2ms/step\n",
            "110/110 [==============================] - 4s 40ms/step - loss: 1.0608 - val_loss: 0.8137\n",
            "Epoch 421/1500\n",
            "876/876 [==============================] - 3s 3ms/step\n",
            "110/110 [==============================] - 6s 55ms/step - loss: 0.5758 - val_loss: 0.6986\n",
            "Epoch 422/1500\n",
            "876/876 [==============================] - 2s 2ms/step\n",
            "110/110 [==============================] - 5s 46ms/step - loss: 0.8312 - val_loss: 0.8645\n",
            "Epoch 423/1500\n",
            "876/876 [==============================] - 2s 2ms/step\n",
            "110/110 [==============================] - 5s 42ms/step - loss: 0.8235 - val_loss: 0.9604\n",
            "Epoch 424/1500\n",
            "876/876 [==============================] - 3s 3ms/step\n",
            "110/110 [==============================] - 6s 54ms/step - loss: 0.6811 - val_loss: 0.9804\n",
            "Epoch 425/1500\n",
            "876/876 [==============================] - 2s 2ms/step\n",
            "110/110 [==============================] - 5s 45ms/step - loss: 0.8086 - val_loss: 0.7613\n",
            "Epoch 426/1500\n",
            "876/876 [==============================] - 2s 2ms/step\n",
            "110/110 [==============================] - 5s 41ms/step - loss: 0.9044 - val_loss: 2.2332\n",
            "Epoch 427/1500\n",
            "876/876 [==============================] - 3s 3ms/step\n",
            "110/110 [==============================] - 6s 52ms/step - loss: 0.7360 - val_loss: 0.7866\n",
            "Epoch 428/1500\n",
            "876/876 [==============================] - 2s 2ms/step\n",
            "110/110 [==============================] - 6s 52ms/step - loss: 1.5190 - val_loss: 0.9572\n",
            "Epoch 429/1500\n",
            "876/876 [==============================] - 2s 2ms/step\n",
            "110/110 [==============================] - 5s 41ms/step - loss: 0.6223 - val_loss: 0.6521\n",
            "Epoch 430/1500\n",
            "876/876 [==============================] - 3s 3ms/step\n",
            "110/110 [==============================] - 7s 66ms/step - loss: 0.5794 - val_loss: 0.6670\n",
            "Epoch 431/1500\n",
            "876/876 [==============================] - 2s 2ms/step\n",
            "110/110 [==============================] - 4s 41ms/step - loss: 0.8848 - val_loss: 0.6504\n",
            "Epoch 432/1500\n",
            "876/876 [==============================] - 2s 2ms/step\n",
            "110/110 [==============================] - 5s 42ms/step - loss: 0.5550 - val_loss: 0.8110\n",
            "Epoch 433/1500\n",
            "876/876 [==============================] - 3s 3ms/step\n",
            "110/110 [==============================] - 9s 80ms/step - loss: 0.5621 - val_loss: 0.7565\n",
            "Epoch 434/1500\n",
            "876/876 [==============================] - 2s 2ms/step\n",
            "110/110 [==============================] - 5s 42ms/step - loss: 1.0009 - val_loss: 0.8311\n",
            "Epoch 435/1500\n",
            "876/876 [==============================] - 2s 3ms/step\n",
            "110/110 [==============================] - 5s 45ms/step - loss: 0.5357 - val_loss: 0.6953\n",
            "Epoch 436/1500\n",
            "876/876 [==============================] - 2s 2ms/step\n",
            "110/110 [==============================] - 6s 58ms/step - loss: 0.8244 - val_loss: 1.1953\n",
            "Epoch 437/1500\n",
            "876/876 [==============================] - 2s 2ms/step\n",
            "110/110 [==============================] - 5s 42ms/step - loss: 0.6341 - val_loss: 0.7311\n",
            "Epoch 438/1500\n",
            "876/876 [==============================] - 3s 3ms/step\n",
            "110/110 [==============================] - 7s 66ms/step - loss: 0.6863 - val_loss: 0.7449\n",
            "Epoch 439/1500\n",
            "876/876 [==============================] - 2s 2ms/step\n",
            "110/110 [==============================] - 4s 41ms/step - loss: 0.6453 - val_loss: 1.7742\n",
            "Epoch 440/1500\n",
            "876/876 [==============================] - 2s 2ms/step\n",
            "110/110 [==============================] - 5s 41ms/step - loss: 0.8170 - val_loss: 5.1571\n",
            "Epoch 441/1500\n",
            "876/876 [==============================] - 3s 3ms/step\n",
            "110/110 [==============================] - 8s 75ms/step - loss: 1.0760 - val_loss: 0.8342\n",
            "Epoch 442/1500\n",
            "876/876 [==============================] - 2s 2ms/step\n",
            "110/110 [==============================] - 5s 42ms/step - loss: 0.5955 - val_loss: 1.7454\n",
            "Epoch 443/1500\n",
            "876/876 [==============================] - 2s 3ms/step\n",
            "110/110 [==============================] - 5s 43ms/step - loss: 0.6315 - val_loss: 1.0070\n",
            "Epoch 444/1500\n",
            "876/876 [==============================] - 3s 3ms/step\n",
            "110/110 [==============================] - 9s 80ms/step - loss: 0.7512 - val_loss: 0.9245\n",
            "Epoch 445/1500\n",
            "876/876 [==============================] - 2s 2ms/step\n",
            "110/110 [==============================] - 4s 41ms/step - loss: 0.6514 - val_loss: 0.7014\n",
            "Epoch 446/1500\n",
            "876/876 [==============================] - 3s 3ms/step\n",
            "110/110 [==============================] - 7s 66ms/step - loss: 0.8608 - val_loss: 1.4960\n",
            "Epoch 447/1500\n",
            "876/876 [==============================] - 2s 2ms/step\n",
            "110/110 [==============================] - 5s 42ms/step - loss: 0.6185 - val_loss: 0.8690\n",
            "Epoch 448/1500\n",
            "876/876 [==============================] - 2s 2ms/step\n",
            "110/110 [==============================] - 4s 40ms/step - loss: 0.7380 - val_loss: 1.0778\n",
            "Epoch 449/1500\n",
            "876/876 [==============================] - 3s 3ms/step\n",
            "110/110 [==============================] - 7s 61ms/step - loss: 0.9286 - val_loss: 2.1329\n",
            "Epoch 450/1500\n",
            "876/876 [==============================] - 2s 2ms/step\n",
            "110/110 [==============================] - 5s 42ms/step - loss: 0.6452 - val_loss: 0.8757\n",
            "Epoch 451/1500\n",
            "876/876 [==============================] - 2s 2ms/step\n",
            "110/110 [==============================] - 4s 41ms/step - loss: 0.6491 - val_loss: 2.3945\n",
            "Epoch 452/1500\n",
            "876/876 [==============================] - 3s 3ms/step\n",
            "110/110 [==============================] - 9s 79ms/step - loss: 0.8238 - val_loss: 0.7911\n",
            "Epoch 453/1500\n",
            "876/876 [==============================] - 2s 2ms/step\n",
            "110/110 [==============================] - 4s 41ms/step - loss: 0.8548 - val_loss: 0.7008\n",
            "Epoch 454/1500\n",
            "876/876 [==============================] - 2s 3ms/step\n",
            "110/110 [==============================] - 7s 65ms/step - loss: 0.6113 - val_loss: 1.1724\n",
            "Epoch 455/1500\n",
            "876/876 [==============================] - 2s 2ms/step\n",
            "110/110 [==============================] - 5s 42ms/step - loss: 0.8846 - val_loss: 2.3801\n",
            "Epoch 456/1500\n",
            "876/876 [==============================] - 2s 2ms/step\n",
            "110/110 [==============================] - 4s 40ms/step - loss: 0.8612 - val_loss: 0.7574\n",
            "Epoch 457/1500\n",
            "876/876 [==============================] - 3s 3ms/step\n",
            "110/110 [==============================] - 8s 76ms/step - loss: 0.5860 - val_loss: 0.9320\n",
            "Epoch 458/1500\n",
            "876/876 [==============================] - 2s 2ms/step\n",
            "110/110 [==============================] - 4s 41ms/step - loss: 0.9821 - val_loss: 5.3858\n",
            "Epoch 459/1500\n",
            "876/876 [==============================] - 2s 3ms/step\n",
            "110/110 [==============================] - 7s 66ms/step - loss: 0.8133 - val_loss: 0.7092\n",
            "Epoch 460/1500\n",
            "876/876 [==============================] - 2s 2ms/step\n",
            "110/110 [==============================] - 5s 42ms/step - loss: 0.4541 - val_loss: 0.6430\n",
            "Epoch 461/1500\n",
            "876/876 [==============================] - 2s 2ms/step\n",
            "110/110 [==============================] - 5s 42ms/step - loss: 0.6911 - val_loss: 1.0997\n",
            "Epoch 462/1500\n",
            "876/876 [==============================] - 3s 3ms/step\n",
            "110/110 [==============================] - 9s 78ms/step - loss: 0.9258 - val_loss: 1.4768\n",
            "Epoch 463/1500\n",
            "876/876 [==============================] - 2s 2ms/step\n",
            "110/110 [==============================] - 5s 41ms/step - loss: 0.6343 - val_loss: 0.8165\n",
            "Epoch 464/1500\n",
            "876/876 [==============================] - 2s 3ms/step\n",
            "110/110 [==============================] - 5s 44ms/step - loss: 0.7931 - val_loss: 0.7784\n",
            "Epoch 465/1500\n",
            "876/876 [==============================] - 3s 3ms/step\n",
            "110/110 [==============================] - 6s 59ms/step - loss: 0.5175 - val_loss: 0.7220\n",
            "Epoch 466/1500\n",
            "876/876 [==============================] - 2s 2ms/step\n",
            "110/110 [==============================] - 4s 41ms/step - loss: 0.7534 - val_loss: 0.7618\n",
            "Epoch 467/1500\n",
            "876/876 [==============================] - 2s 2ms/step\n",
            "110/110 [==============================] - 5s 42ms/step - loss: 0.5389 - val_loss: 0.7053\n",
            "Epoch 468/1500\n",
            "876/876 [==============================] - 3s 3ms/step\n",
            "110/110 [==============================] - 9s 80ms/step - loss: 0.7105 - val_loss: 0.8644\n",
            "Epoch 469/1500\n",
            "876/876 [==============================] - 2s 2ms/step\n",
            "110/110 [==============================] - 5s 42ms/step - loss: 0.6161 - val_loss: 0.6773\n",
            "Epoch 470/1500\n",
            "876/876 [==============================] - 3s 3ms/step\n",
            "110/110 [==============================] - 7s 66ms/step - loss: 0.7173 - val_loss: 1.0362\n",
            "Epoch 471/1500\n",
            "876/876 [==============================] - 2s 2ms/step\n",
            "110/110 [==============================] - 5s 42ms/step - loss: 0.6542 - val_loss: 0.6579\n",
            "Epoch 472/1500\n",
            "876/876 [==============================] - 2s 2ms/step\n",
            "110/110 [==============================] - 5s 42ms/step - loss: 0.5481 - val_loss: 0.7763\n",
            "Epoch 473/1500\n",
            "876/876 [==============================] - 3s 3ms/step\n",
            "110/110 [==============================] - 9s 81ms/step - loss: 0.7942 - val_loss: 0.7922\n",
            "Epoch 474/1500\n",
            "876/876 [==============================] - 2s 2ms/step\n",
            "110/110 [==============================] - 5s 42ms/step - loss: 0.7663 - val_loss: 1.6198\n",
            "Epoch 475/1500\n",
            "876/876 [==============================] - 3s 3ms/step\n",
            "110/110 [==============================] - 7s 66ms/step - loss: 0.8777 - val_loss: 0.7395\n",
            "Epoch 476/1500\n",
            "876/876 [==============================] - 2s 2ms/step\n",
            "110/110 [==============================] - 5s 42ms/step - loss: 0.6895 - val_loss: 1.2323\n",
            "Epoch 477/1500\n",
            "876/876 [==============================] - 2s 2ms/step\n",
            "110/110 [==============================] - 5s 42ms/step - loss: 0.6377 - val_loss: 1.0067\n",
            "Epoch 478/1500\n",
            "876/876 [==============================] - 3s 3ms/step\n",
            "110/110 [==============================] - 9s 78ms/step - loss: 0.4971 - val_loss: 0.6465\n",
            "Epoch 479/1500\n",
            "876/876 [==============================] - 2s 2ms/step\n",
            "110/110 [==============================] - 5s 42ms/step - loss: 0.6249 - val_loss: 0.7325\n",
            "Epoch 480/1500\n",
            "876/876 [==============================] - 2s 3ms/step\n",
            "110/110 [==============================] - 5s 44ms/step - loss: 0.8276 - val_loss: 0.9804\n",
            "Epoch 481/1500\n",
            "876/876 [==============================] - 2s 3ms/step\n",
            "110/110 [==============================] - 7s 60ms/step - loss: 0.4984 - val_loss: 0.8339\n",
            "Epoch 482/1500\n",
            "876/876 [==============================] - 2s 2ms/step\n",
            "110/110 [==============================] - 5s 42ms/step - loss: 0.6739 - val_loss: 1.3603\n",
            "Epoch 483/1500\n",
            "876/876 [==============================] - 2s 3ms/step\n",
            "110/110 [==============================] - 7s 66ms/step - loss: 0.7524 - val_loss: 1.7734\n",
            "Epoch 484/1500\n",
            "876/876 [==============================] - 2s 2ms/step\n",
            "110/110 [==============================] - 5s 42ms/step - loss: 1.1364 - val_loss: 3.6219\n",
            "Epoch 485/1500\n",
            "876/876 [==============================] - 2s 2ms/step\n",
            "110/110 [==============================] - 5s 43ms/step - loss: 0.9035 - val_loss: 0.9451\n",
            "Epoch 486/1500\n",
            "876/876 [==============================] - 3s 3ms/step\n",
            "110/110 [==============================] - 8s 77ms/step - loss: 0.6244 - val_loss: 0.7202\n",
            "Epoch 487/1500\n",
            "876/876 [==============================] - 2s 2ms/step\n",
            "110/110 [==============================] - 5s 44ms/step - loss: 0.4782 - val_loss: 0.6108\n",
            "Epoch 488/1500\n",
            "876/876 [==============================] - 3s 3ms/step\n",
            "110/110 [==============================] - 5s 46ms/step - loss: 0.7145 - val_loss: 0.9999\n",
            "Epoch 489/1500\n",
            "876/876 [==============================] - 2s 3ms/step\n",
            "110/110 [==============================] - 9s 82ms/step - loss: 0.4788 - val_loss: 0.7054\n",
            "Epoch 490/1500\n",
            "876/876 [==============================] - 2s 2ms/step\n",
            "110/110 [==============================] - 5s 42ms/step - loss: 0.6808 - val_loss: 0.8419\n",
            "Epoch 491/1500\n",
            "876/876 [==============================] - 3s 3ms/step\n",
            "110/110 [==============================] - 7s 60ms/step - loss: 0.5866 - val_loss: 0.9387\n",
            "Epoch 492/1500\n",
            "876/876 [==============================] - 2s 2ms/step\n",
            "110/110 [==============================] - 5s 42ms/step - loss: 0.8855 - val_loss: 0.7778\n",
            "Epoch 493/1500\n",
            "876/876 [==============================] - 2s 2ms/step\n",
            "110/110 [==============================] - 5s 42ms/step - loss: 0.5592 - val_loss: 0.8339\n",
            "Epoch 494/1500\n",
            "876/876 [==============================] - 3s 3ms/step\n",
            "110/110 [==============================] - 6s 57ms/step - loss: 0.9801 - val_loss: 0.9767\n",
            "Epoch 495/1500\n",
            "876/876 [==============================] - 2s 2ms/step\n",
            "110/110 [==============================] - 5s 45ms/step - loss: 0.5947 - val_loss: 0.8644\n",
            "Epoch 496/1500\n",
            "876/876 [==============================] - 2s 2ms/step\n",
            "110/110 [==============================] - 5s 42ms/step - loss: 1.0803 - val_loss: 1.1674\n",
            "Epoch 497/1500\n",
            "876/876 [==============================] - 3s 3ms/step\n",
            "110/110 [==============================] - 6s 55ms/step - loss: 1.2647 - val_loss: 0.9223\n",
            "Epoch 498/1500\n",
            "876/876 [==============================] - 2s 2ms/step\n",
            "110/110 [==============================] - 5s 46ms/step - loss: 0.5252 - val_loss: 1.2485\n",
            "Epoch 499/1500\n",
            "876/876 [==============================] - 2s 2ms/step\n",
            "110/110 [==============================] - 5s 44ms/step - loss: 0.6280 - val_loss: 0.7883\n",
            "Epoch 500/1500\n",
            "876/876 [==============================] - 3s 3ms/step\n",
            "110/110 [==============================] - 6s 59ms/step - loss: 0.5334 - val_loss: 1.8357\n",
            "Epoch 501/1500\n",
            "876/876 [==============================] - 2s 2ms/step\n",
            "110/110 [==============================] - 5s 45ms/step - loss: 0.7507 - val_loss: 0.9353\n",
            "Epoch 502/1500\n",
            "876/876 [==============================] - 2s 2ms/step\n",
            "110/110 [==============================] - 5s 42ms/step - loss: 0.7278 - val_loss: 0.6420\n",
            "Epoch 503/1500\n",
            "876/876 [==============================] - 3s 3ms/step\n",
            "110/110 [==============================] - 8s 74ms/step - loss: 0.5517 - val_loss: 1.1818\n",
            "Epoch 504/1500\n",
            "876/876 [==============================] - 2s 2ms/step\n",
            "110/110 [==============================] - 5s 42ms/step - loss: 0.6415 - val_loss: 1.2279\n",
            "Epoch 505/1500\n",
            "876/876 [==============================] - 2s 3ms/step\n",
            "110/110 [==============================] - 7s 67ms/step - loss: 0.6222 - val_loss: 0.8568\n",
            "Epoch 506/1500\n",
            "876/876 [==============================] - 2s 2ms/step\n",
            "110/110 [==============================] - 5s 42ms/step - loss: 0.9190 - val_loss: 0.6920\n",
            "Epoch 507/1500\n",
            "876/876 [==============================] - 2s 2ms/step\n",
            "110/110 [==============================] - 5s 42ms/step - loss: 0.5328 - val_loss: 1.0176\n",
            "Epoch 508/1500\n",
            "876/876 [==============================] - 3s 3ms/step\n",
            "110/110 [==============================] - 7s 61ms/step - loss: 0.6930 - val_loss: 1.0002\n",
            "Epoch 509/1500\n",
            "876/876 [==============================] - 2s 2ms/step\n",
            "110/110 [==============================] - 5s 42ms/step - loss: 0.6287 - val_loss: 0.7602\n",
            "Epoch 510/1500\n",
            "876/876 [==============================] - 2s 2ms/step\n",
            "110/110 [==============================] - 5s 42ms/step - loss: 0.5742 - val_loss: 0.6181\n",
            "Epoch 511/1500\n",
            "876/876 [==============================] - 3s 3ms/step\n",
            "110/110 [==============================] - 6s 59ms/step - loss: 0.7469 - val_loss: 0.8414\n",
            "Epoch 512/1500\n",
            "876/876 [==============================] - 2s 2ms/step\n",
            "110/110 [==============================] - 5s 46ms/step - loss: 0.6499 - val_loss: 2.1822\n",
            "Epoch 513/1500\n",
            "876/876 [==============================] - 2s 2ms/step\n",
            "110/110 [==============================] - 5s 42ms/step - loss: 0.5950 - val_loss: 0.8680\n",
            "Epoch 514/1500\n",
            "876/876 [==============================] - 3s 3ms/step\n",
            "110/110 [==============================] - 6s 58ms/step - loss: 0.6112 - val_loss: 0.8791\n",
            "Epoch 515/1500\n",
            "876/876 [==============================] - 2s 2ms/step\n",
            "110/110 [==============================] - 5s 45ms/step - loss: 0.7003 - val_loss: 3.0432\n",
            "Epoch 516/1500\n",
            "876/876 [==============================] - 2s 2ms/step\n",
            "110/110 [==============================] - 5s 42ms/step - loss: 0.6400 - val_loss: 0.7744\n",
            "Epoch 517/1500\n",
            "876/876 [==============================] - 3s 3ms/step\n",
            "110/110 [==============================] - 8s 75ms/step - loss: 0.6258 - val_loss: 0.6122\n",
            "Epoch 518/1500\n",
            "876/876 [==============================] - 2s 2ms/step\n",
            "110/110 [==============================] - 5s 43ms/step - loss: 0.5476 - val_loss: 0.9907\n",
            "Epoch 519/1500\n",
            "876/876 [==============================] - 2s 3ms/step\n",
            "110/110 [==============================] - 5s 45ms/step - loss: 0.6994 - val_loss: 0.8073\n",
            "Epoch 520/1500\n",
            "876/876 [==============================] - 3s 3ms/step\n",
            "110/110 [==============================] - 9s 82ms/step - loss: 0.4999 - val_loss: 0.8415\n",
            "Epoch 521/1500\n",
            "876/876 [==============================] - 2s 2ms/step\n",
            "110/110 [==============================] - 5s 43ms/step - loss: 0.5311 - val_loss: 0.8763\n",
            "Epoch 522/1500\n",
            "876/876 [==============================] - 3s 3ms/step\n",
            "110/110 [==============================] - 6s 55ms/step - loss: 0.8603 - val_loss: 0.8071\n",
            "Epoch 523/1500\n",
            "876/876 [==============================] - 2s 2ms/step\n",
            "110/110 [==============================] - 6s 52ms/step - loss: 0.6267 - val_loss: 1.2285\n",
            "Epoch 524/1500\n",
            "876/876 [==============================] - 2s 2ms/step\n",
            "110/110 [==============================] - 5s 41ms/step - loss: 1.0056 - val_loss: 2.0640\n",
            "Epoch 525/1500\n",
            "876/876 [==============================] - 3s 3ms/step\n",
            "110/110 [==============================] - 7s 68ms/step - loss: 0.6648 - val_loss: 0.8879\n",
            "Epoch 526/1500\n",
            "876/876 [==============================] - 2s 2ms/step\n",
            "110/110 [==============================] - 5s 42ms/step - loss: 0.5073 - val_loss: 0.7554\n",
            "Epoch 527/1500\n",
            "876/876 [==============================] - 2s 2ms/step\n",
            "110/110 [==============================] - 5s 43ms/step - loss: 0.5170 - val_loss: 0.6209\n",
            "Epoch 528/1500\n",
            "876/876 [==============================] - 3s 3ms/step\n",
            "110/110 [==============================] - 9s 81ms/step - loss: 1.4766 - val_loss: 1.1209\n",
            "Epoch 529/1500\n",
            "876/876 [==============================] - 2s 2ms/step\n",
            "110/110 [==============================] - 5s 41ms/step - loss: 0.6815 - val_loss: 0.8421\n",
            "Epoch 530/1500\n",
            "876/876 [==============================] - 3s 3ms/step\n",
            "110/110 [==============================] - 7s 66ms/step - loss: 0.6183 - val_loss: 0.9137\n",
            "Epoch 531/1500\n",
            "876/876 [==============================] - 2s 2ms/step\n",
            "110/110 [==============================] - 5s 42ms/step - loss: 0.8100 - val_loss: 1.0958\n",
            "Epoch 532/1500\n",
            "876/876 [==============================] - 2s 2ms/step\n",
            "110/110 [==============================] - 5s 43ms/step - loss: 0.6075 - val_loss: 0.8462\n",
            "Epoch 533/1500\n",
            "876/876 [==============================] - 3s 3ms/step\n",
            "110/110 [==============================] - 9s 80ms/step - loss: 0.5475 - val_loss: 0.8317\n",
            "Epoch 534/1500\n",
            "876/876 [==============================] - 2s 2ms/step\n",
            "110/110 [==============================] - 5s 42ms/step - loss: 0.5395 - val_loss: 0.7673\n",
            "Epoch 535/1500\n",
            "876/876 [==============================] - 2s 3ms/step\n",
            "110/110 [==============================] - 7s 66ms/step - loss: 0.4989 - val_loss: 0.6663\n",
            "Epoch 536/1500\n",
            "876/876 [==============================] - 2s 2ms/step\n",
            "110/110 [==============================] - 5s 43ms/step - loss: 0.6065 - val_loss: 1.7797\n",
            "Epoch 537/1500\n",
            "876/876 [==============================] - 2s 2ms/step\n",
            "110/110 [==============================] - 5s 43ms/step - loss: 0.5754 - val_loss: 0.7668\n",
            "Epoch 538/1500\n",
            "876/876 [==============================] - 3s 3ms/step\n",
            "110/110 [==============================] - 7s 64ms/step - loss: 0.6325 - val_loss: 0.8142\n",
            "Epoch 539/1500\n",
            "876/876 [==============================] - 2s 2ms/step\n",
            "110/110 [==============================] - 5s 43ms/step - loss: 0.6519 - val_loss: 0.6435\n",
            "Epoch 540/1500\n",
            "876/876 [==============================] - 2s 2ms/step\n",
            "110/110 [==============================] - 5s 43ms/step - loss: 0.6652 - val_loss: 2.9073\n",
            "Epoch 541/1500\n",
            "876/876 [==============================] - 3s 3ms/step\n",
            "110/110 [==============================] - 9s 78ms/step - loss: 1.1563 - val_loss: 1.2271\n",
            "Epoch 542/1500\n",
            "876/876 [==============================] - 2s 2ms/step\n",
            "110/110 [==============================] - 5s 43ms/step - loss: 0.4869 - val_loss: 0.7806\n",
            "Epoch 543/1500\n",
            "876/876 [==============================] - 2s 3ms/step\n",
            "110/110 [==============================] - 7s 67ms/step - loss: 1.0351 - val_loss: 0.9917\n",
            "Epoch 544/1500\n",
            "876/876 [==============================] - 2s 2ms/step\n",
            "110/110 [==============================] - 5s 43ms/step - loss: 0.5680 - val_loss: 0.6844\n",
            "Epoch 545/1500\n",
            "876/876 [==============================] - 2s 2ms/step\n",
            "110/110 [==============================] - 5s 42ms/step - loss: 0.6083 - val_loss: 0.6715\n",
            "Epoch 546/1500\n",
            "876/876 [==============================] - 3s 3ms/step\n",
            "110/110 [==============================] - 7s 61ms/step - loss: 1.0642 - val_loss: 0.9921\n",
            "Epoch 547/1500\n",
            "876/876 [==============================] - 2s 2ms/step\n",
            "110/110 [==============================] - 5s 44ms/step - loss: 0.5503 - val_loss: 0.9308\n",
            "Epoch 548/1500\n",
            "876/876 [==============================] - 2s 2ms/step\n",
            "110/110 [==============================] - 5s 43ms/step - loss: 0.5085 - val_loss: 0.7209\n",
            "Epoch 549/1500\n",
            "876/876 [==============================] - 3s 3ms/step\n",
            "110/110 [==============================] - 7s 60ms/step - loss: 0.4882 - val_loss: 1.0453\n",
            "Epoch 550/1500\n",
            "876/876 [==============================] - 2s 2ms/step\n",
            "110/110 [==============================] - 5s 45ms/step - loss: 0.5136 - val_loss: 0.5838\n",
            "Epoch 551/1500\n",
            "876/876 [==============================] - 2s 2ms/step\n",
            "110/110 [==============================] - 5s 43ms/step - loss: 0.6447 - val_loss: 0.9060\n",
            "Epoch 552/1500\n",
            "876/876 [==============================] - 3s 3ms/step\n",
            "110/110 [==============================] - 8s 76ms/step - loss: 0.6368 - val_loss: 0.7344\n",
            "Epoch 553/1500\n",
            "876/876 [==============================] - 2s 3ms/step\n",
            "110/110 [==============================] - 5s 43ms/step - loss: 0.6156 - val_loss: 0.9740\n",
            "Epoch 554/1500\n",
            "876/876 [==============================] - 2s 3ms/step\n",
            "110/110 [==============================] - 7s 66ms/step - loss: 0.8909 - val_loss: 0.8932\n",
            "Epoch 555/1500\n",
            "876/876 [==============================] - 2s 2ms/step\n",
            "110/110 [==============================] - 5s 43ms/step - loss: 0.8172 - val_loss: 0.7905\n",
            "Epoch 556/1500\n",
            "876/876 [==============================] - 2s 2ms/step\n",
            "110/110 [==============================] - 5s 42ms/step - loss: 0.6205 - val_loss: 0.7245\n",
            "Epoch 557/1500\n",
            "876/876 [==============================] - 3s 3ms/step\n",
            "110/110 [==============================] - 7s 60ms/step - loss: 0.4690 - val_loss: 0.5795\n",
            "Epoch 558/1500\n",
            "876/876 [==============================] - 2s 2ms/step\n",
            "110/110 [==============================] - 5s 44ms/step - loss: 0.6473 - val_loss: 2.8506\n",
            "Epoch 559/1500\n",
            "876/876 [==============================] - 2s 2ms/step\n",
            "110/110 [==============================] - 5s 43ms/step - loss: 1.4706 - val_loss: 0.8335\n",
            "Epoch 560/1500\n",
            "876/876 [==============================] - 3s 3ms/step\n",
            "110/110 [==============================] - 6s 59ms/step - loss: 0.4820 - val_loss: 1.0136\n",
            "Epoch 561/1500\n",
            "876/876 [==============================] - 2s 2ms/step\n",
            "110/110 [==============================] - 5s 45ms/step - loss: 0.6442 - val_loss: 2.9925\n",
            "Epoch 562/1500\n",
            "876/876 [==============================] - 2s 2ms/step\n",
            "110/110 [==============================] - 5s 44ms/step - loss: 0.7826 - val_loss: 0.6807\n",
            "Epoch 563/1500\n",
            "876/876 [==============================] - 3s 3ms/step\n",
            "110/110 [==============================] - 6s 58ms/step - loss: 0.5587 - val_loss: 0.7450\n",
            "Epoch 564/1500\n",
            "876/876 [==============================] - 2s 2ms/step\n",
            "110/110 [==============================] - 5s 46ms/step - loss: 0.6810 - val_loss: 0.9014\n",
            "Epoch 565/1500\n",
            "876/876 [==============================] - 2s 2ms/step\n",
            "110/110 [==============================] - 5s 42ms/step - loss: 0.4708 - val_loss: 1.1093\n",
            "Epoch 566/1500\n",
            "876/876 [==============================] - 3s 3ms/step\n",
            "110/110 [==============================] - 8s 75ms/step - loss: 0.4943 - val_loss: 1.5601\n",
            "Epoch 567/1500\n",
            "876/876 [==============================] - 2s 2ms/step\n",
            "110/110 [==============================] - 5s 42ms/step - loss: 0.7234 - val_loss: 0.9451\n",
            "Epoch 568/1500\n",
            "876/876 [==============================] - 2s 3ms/step\n",
            "110/110 [==============================] - 5s 44ms/step - loss: 0.5671 - val_loss: 1.0693\n",
            "Epoch 569/1500\n",
            "876/876 [==============================] - 3s 3ms/step\n",
            "110/110 [==============================] - 9s 82ms/step - loss: 0.5541 - val_loss: 0.7159\n",
            "Epoch 570/1500\n",
            "876/876 [==============================] - 2s 2ms/step\n",
            "110/110 [==============================] - 5s 43ms/step - loss: 0.5142 - val_loss: 0.9277\n",
            "Epoch 571/1500\n",
            "876/876 [==============================] - 3s 3ms/step\n",
            "110/110 [==============================] - 8s 71ms/step - loss: 0.8751 - val_loss: 1.4560\n",
            "Epoch 572/1500\n",
            "876/876 [==============================] - 2s 2ms/step\n",
            "110/110 [==============================] - 5s 42ms/step - loss: 0.6906 - val_loss: 0.7027\n",
            "Epoch 573/1500\n",
            "876/876 [==============================] - 2s 2ms/step\n",
            "110/110 [==============================] - 7s 67ms/step - loss: 0.6521 - val_loss: 0.9323\n",
            "Epoch 574/1500\n",
            "876/876 [==============================] - 2s 2ms/step\n",
            "110/110 [==============================] - 5s 43ms/step - loss: 0.6595 - val_loss: 0.7949\n",
            "Epoch 575/1500\n",
            "876/876 [==============================] - 2s 2ms/step\n",
            "110/110 [==============================] - 5s 43ms/step - loss: 0.5883 - val_loss: 0.8463\n",
            "Epoch 576/1500\n",
            "876/876 [==============================] - 3s 3ms/step\n",
            "110/110 [==============================] - 6s 58ms/step - loss: 0.4650 - val_loss: 0.6480\n",
            "Epoch 577/1500\n",
            "876/876 [==============================] - 2s 2ms/step\n",
            "110/110 [==============================] - 5s 45ms/step - loss: 0.4796 - val_loss: 1.5286\n",
            "Epoch 578/1500\n",
            "876/876 [==============================] - 2s 2ms/step\n",
            "110/110 [==============================] - 5s 43ms/step - loss: 0.6922 - val_loss: 0.7666\n",
            "Epoch 579/1500\n",
            "876/876 [==============================] - 3s 3ms/step\n",
            "110/110 [==============================] - 8s 75ms/step - loss: 0.5539 - val_loss: 0.7789\n",
            "Epoch 580/1500\n",
            "876/876 [==============================] - 2s 2ms/step\n",
            "110/110 [==============================] - 5s 43ms/step - loss: 0.7437 - val_loss: 0.6776\n",
            "Epoch 581/1500\n",
            "876/876 [==============================] - 2s 3ms/step\n",
            "110/110 [==============================] - 7s 67ms/step - loss: 0.4679 - val_loss: 0.6692\n",
            "Epoch 582/1500\n",
            "876/876 [==============================] - 2s 2ms/step\n",
            "110/110 [==============================] - 5s 42ms/step - loss: 0.5614 - val_loss: 0.7206\n",
            "Epoch 583/1500\n",
            "876/876 [==============================] - 2s 2ms/step\n",
            "110/110 [==============================] - 5s 42ms/step - loss: 0.8891 - val_loss: 1.1077\n",
            "Epoch 584/1500\n",
            "876/876 [==============================] - 3s 3ms/step\n",
            "110/110 [==============================] - 7s 60ms/step - loss: 0.5279 - val_loss: 1.0170\n",
            "Epoch 585/1500\n",
            "876/876 [==============================] - 2s 2ms/step\n",
            "110/110 [==============================] - 5s 42ms/step - loss: 0.5628 - val_loss: 0.6991\n",
            "Epoch 586/1500\n",
            "876/876 [==============================] - 2s 2ms/step\n",
            "110/110 [==============================] - 5s 42ms/step - loss: 0.6664 - val_loss: 1.3598\n",
            "Epoch 587/1500\n",
            "876/876 [==============================] - 3s 3ms/step\n",
            "110/110 [==============================] - 7s 60ms/step - loss: 0.5140 - val_loss: 0.7166\n",
            "Epoch 588/1500\n",
            "876/876 [==============================] - 2s 2ms/step\n",
            "110/110 [==============================] - 5s 45ms/step - loss: 0.5284 - val_loss: 0.8764\n",
            "Epoch 589/1500\n",
            "876/876 [==============================] - 2s 2ms/step\n",
            "110/110 [==============================] - 5s 43ms/step - loss: 0.6923 - val_loss: 0.7301\n",
            "Epoch 590/1500\n",
            "876/876 [==============================] - 3s 3ms/step\n",
            "110/110 [==============================] - 7s 63ms/step - loss: 0.8024 - val_loss: 0.8106\n",
            "Epoch 591/1500\n",
            "876/876 [==============================] - 2s 2ms/step\n",
            "110/110 [==============================] - 5s 42ms/step - loss: 0.5646 - val_loss: 0.9411\n",
            "Epoch 592/1500\n",
            "876/876 [==============================] - 2s 2ms/step\n",
            "110/110 [==============================] - 5s 41ms/step - loss: 0.8338 - val_loss: 0.7630\n",
            "Epoch 593/1500\n",
            "876/876 [==============================] - 3s 3ms/step\n",
            "110/110 [==============================] - 6s 59ms/step - loss: 0.5412 - val_loss: 0.6801\n",
            "Epoch 594/1500\n",
            "876/876 [==============================] - 2s 2ms/step\n",
            "110/110 [==============================] - 5s 45ms/step - loss: 0.7093 - val_loss: 1.0349\n",
            "Epoch 595/1500\n",
            "876/876 [==============================] - 2s 2ms/step\n",
            "110/110 [==============================] - 5s 43ms/step - loss: 0.7458 - val_loss: 1.5796\n",
            "Epoch 596/1500\n",
            "876/876 [==============================] - 3s 3ms/step\n",
            "110/110 [==============================] - 8s 73ms/step - loss: 1.1425 - val_loss: 0.8108\n",
            "Epoch 597/1500\n",
            "876/876 [==============================] - 2s 2ms/step\n",
            "110/110 [==============================] - 5s 44ms/step - loss: 0.4785 - val_loss: 0.6604\n",
            "Epoch 598/1500\n",
            "876/876 [==============================] - 2s 3ms/step\n",
            "110/110 [==============================] - 5s 44ms/step - loss: 0.4508 - val_loss: 0.8513\n",
            "Epoch 599/1500\n",
            "876/876 [==============================] - 3s 3ms/step\n",
            "110/110 [==============================] - 7s 61ms/step - loss: 0.6157 - val_loss: 0.6541\n",
            "Epoch 600/1500\n",
            "876/876 [==============================] - 2s 2ms/step\n",
            "110/110 [==============================] - 5s 44ms/step - loss: 0.4738 - val_loss: 0.6895\n",
            "Epoch 601/1500\n",
            "876/876 [==============================] - 2s 2ms/step\n",
            "110/110 [==============================] - 5s 44ms/step - loss: 0.5687 - val_loss: 0.7552\n",
            "Epoch 602/1500\n",
            "876/876 [==============================] - 3s 3ms/step\n",
            "110/110 [==============================] - 7s 63ms/step - loss: 0.7370 - val_loss: 0.6728\n",
            "Epoch 603/1500\n",
            "876/876 [==============================] - 2s 2ms/step\n",
            "110/110 [==============================] - 5s 42ms/step - loss: 0.8003 - val_loss: 1.8547\n",
            "Epoch 604/1500\n",
            "876/876 [==============================] - 2s 2ms/step\n",
            "110/110 [==============================] - 5s 43ms/step - loss: 0.6197 - val_loss: 0.7706\n",
            "Epoch 605/1500\n",
            "876/876 [==============================] - 3s 3ms/step\n",
            "110/110 [==============================] - 9s 79ms/step - loss: 0.5208 - val_loss: 0.6275\n",
            "Epoch 606/1500\n",
            "876/876 [==============================] - 2s 2ms/step\n",
            "110/110 [==============================] - 5s 42ms/step - loss: 0.5399 - val_loss: 0.6795\n",
            "Epoch 607/1500\n",
            "876/876 [==============================] - 3s 3ms/step\n",
            "110/110 [==============================] - 5s 46ms/step - loss: 0.5683 - val_loss: 0.7624\n",
            "Epoch 608/1500\n",
            "876/876 [==============================] - 2s 3ms/step\n",
            "110/110 [==============================] - 6s 59ms/step - loss: 0.6534 - val_loss: 0.7315\n",
            "Epoch 609/1500\n",
            "876/876 [==============================] - 2s 2ms/step\n",
            "110/110 [==============================] - 5s 42ms/step - loss: 0.6306 - val_loss: 0.8126\n",
            "Epoch 610/1500\n",
            "876/876 [==============================] - 2s 3ms/step\n",
            "110/110 [==============================] - 5s 46ms/step - loss: 0.8700 - val_loss: 0.7005\n",
            "Epoch 611/1500\n",
            "876/876 [==============================] - 3s 3ms/step\n",
            "110/110 [==============================] - 7s 60ms/step - loss: 0.5836 - val_loss: 0.7097\n",
            "Epoch 612/1500\n",
            "876/876 [==============================] - 2s 2ms/step\n",
            "110/110 [==============================] - 5s 42ms/step - loss: 0.6124 - val_loss: 0.9643\n",
            "Epoch 613/1500\n",
            "876/876 [==============================] - 2s 3ms/step\n",
            "110/110 [==============================] - 5s 44ms/step - loss: 0.8228 - val_loss: 1.0437\n",
            "Epoch 614/1500\n",
            "876/876 [==============================] - 3s 3ms/step\n",
            "110/110 [==============================] - 7s 62ms/step - loss: 0.4781 - val_loss: 0.8670\n",
            "Epoch 615/1500\n",
            "876/876 [==============================] - 2s 2ms/step\n",
            "110/110 [==============================] - 5s 42ms/step - loss: 0.4238 - val_loss: 0.6524\n",
            "Epoch 616/1500\n",
            "876/876 [==============================] - 2s 2ms/step\n",
            "110/110 [==============================] - 5s 44ms/step - loss: 0.4751 - val_loss: 0.7798\n",
            "Epoch 617/1500\n",
            "876/876 [==============================] - 3s 3ms/step\n",
            "110/110 [==============================] - 9s 80ms/step - loss: 0.6967 - val_loss: 1.1537\n",
            "Epoch 618/1500\n",
            "876/876 [==============================] - 2s 2ms/step\n",
            "110/110 [==============================] - 5s 44ms/step - loss: 0.5570 - val_loss: 0.7259\n",
            "Epoch 619/1500\n",
            "876/876 [==============================] - 2s 3ms/step\n",
            "110/110 [==============================] - 5s 46ms/step - loss: 0.5251 - val_loss: 1.2799\n",
            "Epoch 620/1500\n",
            "876/876 [==============================] - 2s 3ms/step\n",
            "110/110 [==============================] - 9s 82ms/step - loss: 0.5791 - val_loss: 1.9395\n",
            "Epoch 621/1500\n",
            "876/876 [==============================] - 2s 3ms/step\n",
            "110/110 [==============================] - 5s 44ms/step - loss: 0.8848 - val_loss: 1.8463\n",
            "Epoch 622/1500\n",
            "876/876 [==============================] - 3s 3ms/step\n",
            "110/110 [==============================] - 8s 77ms/step - loss: 0.5864 - val_loss: 0.7424\n",
            "Epoch 623/1500\n",
            "876/876 [==============================] - 2s 2ms/step\n",
            "110/110 [==============================] - 5s 44ms/step - loss: 0.6738 - val_loss: 1.4290\n",
            "Epoch 624/1500\n",
            "876/876 [==============================] - 2s 3ms/step\n",
            "110/110 [==============================] - 7s 67ms/step - loss: 0.5130 - val_loss: 0.8888\n",
            "Epoch 625/1500\n",
            "876/876 [==============================] - 2s 2ms/step\n",
            "110/110 [==============================] - 5s 42ms/step - loss: 0.4568 - val_loss: 1.9930\n",
            "Epoch 626/1500\n",
            "876/876 [==============================] - 2s 2ms/step\n",
            "110/110 [==============================] - 5s 43ms/step - loss: 0.6922 - val_loss: 1.0590\n",
            "Epoch 627/1500\n",
            "876/876 [==============================] - 3s 3ms/step\n",
            "110/110 [==============================] - 9s 78ms/step - loss: 0.5707 - val_loss: 0.7724\n",
            "Epoch 628/1500\n",
            "876/876 [==============================] - 2s 2ms/step\n",
            "110/110 [==============================] - 5s 44ms/step - loss: 0.4595 - val_loss: 0.6658\n",
            "Epoch 629/1500\n",
            "876/876 [==============================] - 2s 3ms/step\n",
            "110/110 [==============================] - 5s 46ms/step - loss: 0.7883 - val_loss: 0.7481\n",
            "Epoch 630/1500\n",
            "876/876 [==============================] - 2s 3ms/step\n",
            "110/110 [==============================] - 6s 58ms/step - loss: 0.6843 - val_loss: 1.0601\n",
            "Epoch 631/1500\n",
            "876/876 [==============================] - 2s 2ms/step\n",
            "110/110 [==============================] - 5s 44ms/step - loss: 0.5920 - val_loss: 0.6622\n",
            "Epoch 632/1500\n",
            "876/876 [==============================] - 2s 3ms/step\n",
            "110/110 [==============================] - 7s 67ms/step - loss: 0.4101 - val_loss: 0.7667\n",
            "Epoch 633/1500\n",
            "876/876 [==============================] - 2s 2ms/step\n",
            "110/110 [==============================] - 5s 43ms/step - loss: 0.4597 - val_loss: 0.7472\n",
            "Epoch 634/1500\n",
            "876/876 [==============================] - 2s 2ms/step\n",
            "110/110 [==============================] - 5s 42ms/step - loss: 0.6787 - val_loss: 0.9603\n",
            "Epoch 635/1500\n",
            "876/876 [==============================] - 3s 3ms/step\n",
            "110/110 [==============================] - 7s 63ms/step - loss: 0.4496 - val_loss: 0.9578\n",
            "Epoch 636/1500\n",
            "876/876 [==============================] - 2s 2ms/step\n",
            "110/110 [==============================] - 5s 46ms/step - loss: 0.5541 - val_loss: 1.0114\n",
            "Epoch 637/1500\n",
            "876/876 [==============================] - 2s 2ms/step\n",
            "110/110 [==============================] - 5s 43ms/step - loss: 0.6115 - val_loss: 0.8218\n",
            "Epoch 638/1500\n",
            "876/876 [==============================] - 3s 3ms/step\n",
            "110/110 [==============================] - 8s 76ms/step - loss: 0.6260 - val_loss: 1.4180\n",
            "Epoch 639/1500\n",
            "876/876 [==============================] - 2s 2ms/step\n",
            "110/110 [==============================] - 5s 44ms/step - loss: 0.5847 - val_loss: 1.3862\n",
            "Epoch 640/1500\n",
            "876/876 [==============================] - 2s 3ms/step\n",
            "110/110 [==============================] - 7s 67ms/step - loss: 1.1306 - val_loss: 1.3626\n",
            "Epoch 641/1500\n",
            "876/876 [==============================] - 2s 2ms/step\n",
            "110/110 [==============================] - 5s 43ms/step - loss: 0.5259 - val_loss: 1.2026\n",
            "Epoch 642/1500\n",
            "876/876 [==============================] - 2s 2ms/step\n",
            "110/110 [==============================] - 5s 44ms/step - loss: 0.7109 - val_loss: 0.9193\n",
            "Epoch 643/1500\n",
            "876/876 [==============================] - 3s 3ms/step\n",
            "110/110 [==============================] - 7s 64ms/step - loss: 0.7769 - val_loss: 0.9193\n",
            "Epoch 644/1500\n",
            "876/876 [==============================] - 2s 2ms/step\n",
            "110/110 [==============================] - 5s 43ms/step - loss: 0.4922 - val_loss: 0.7299\n",
            "Epoch 645/1500\n",
            "876/876 [==============================] - 2s 2ms/step\n",
            "110/110 [==============================] - 5s 43ms/step - loss: 0.5304 - val_loss: 0.9455\n",
            "Epoch 646/1500\n",
            "876/876 [==============================] - 3s 3ms/step\n",
            "110/110 [==============================] - 9s 78ms/step - loss: 0.7493 - val_loss: 0.9604\n",
            "Epoch 647/1500\n",
            "876/876 [==============================] - 2s 3ms/step\n",
            "110/110 [==============================] - 5s 43ms/step - loss: 0.4495 - val_loss: 0.8019\n",
            "Epoch 648/1500\n",
            "876/876 [==============================] - 2s 3ms/step\n",
            "110/110 [==============================] - 5s 46ms/step - loss: 0.5484 - val_loss: 0.8796\n",
            "Epoch 649/1500\n",
            "876/876 [==============================] - 3s 3ms/step\n",
            "110/110 [==============================] - 9s 82ms/step - loss: 0.4578 - val_loss: 0.8358\n",
            "Epoch 650/1500\n",
            "876/876 [==============================] - 2s 2ms/step\n",
            "110/110 [==============================] - 5s 43ms/step - loss: 0.5595 - val_loss: 0.6976\n",
            "Epoch 651/1500\n",
            "876/876 [==============================] - 3s 3ms/step\n",
            "110/110 [==============================] - 6s 56ms/step - loss: 0.5274 - val_loss: 0.9226\n",
            "Epoch 652/1500\n",
            "876/876 [==============================] - 2s 2ms/step\n",
            "110/110 [==============================] - 6s 52ms/step - loss: 0.8064 - val_loss: 0.8220\n",
            "Epoch 653/1500\n",
            "876/876 [==============================] - 2s 2ms/step\n",
            "110/110 [==============================] - 5s 43ms/step - loss: 0.6251 - val_loss: 1.7016\n",
            "Epoch 654/1500\n",
            "876/876 [==============================] - 3s 3ms/step\n",
            "110/110 [==============================] - 6s 52ms/step - loss: 0.7062 - val_loss: 0.7797\n",
            "Epoch 655/1500\n",
            "876/876 [==============================] - 2s 2ms/step\n",
            "110/110 [==============================] - 6s 53ms/step - loss: 0.5468 - val_loss: 0.7330\n",
            "Epoch 656/1500\n",
            "876/876 [==============================] - 2s 2ms/step\n",
            "110/110 [==============================] - 5s 43ms/step - loss: 0.9503 - val_loss: 0.7987\n",
            "Epoch 657/1500\n",
            "876/876 [==============================] - 3s 3ms/step\n",
            "110/110 [==============================] - 8s 69ms/step - loss: 0.4578 - val_loss: 0.6899\n",
            "Epoch 658/1500\n",
            "876/876 [==============================] - 2s 2ms/step\n",
            "110/110 [==============================] - 5s 44ms/step - loss: 0.5948 - val_loss: 1.5776\n",
            "Epoch 659/1500\n",
            "876/876 [==============================] - 2s 2ms/step\n",
            "110/110 [==============================] - 7s 67ms/step - loss: 0.4844 - val_loss: 0.7990\n",
            "Epoch 660/1500\n",
            "876/876 [==============================] - 2s 2ms/step\n",
            "110/110 [==============================] - 5s 44ms/step - loss: 0.5642 - val_loss: 0.8486\n",
            "Epoch 661/1500\n",
            "876/876 [==============================] - 2s 2ms/step\n",
            "110/110 [==============================] - 5s 44ms/step - loss: 0.5959 - val_loss: 1.3550\n",
            "Epoch 662/1500\n",
            "876/876 [==============================] - 3s 3ms/step\n",
            "110/110 [==============================] - 7s 63ms/step - loss: 0.6517 - val_loss: 0.8758\n",
            "Epoch 663/1500\n",
            "876/876 [==============================] - 2s 2ms/step\n",
            "110/110 [==============================] - 5s 44ms/step - loss: 0.5058 - val_loss: 0.7540\n",
            "Epoch 664/1500\n",
            "876/876 [==============================] - 2s 2ms/step\n",
            "110/110 [==============================] - 5s 43ms/step - loss: 0.5283 - val_loss: 0.6520\n",
            "Epoch 665/1500\n",
            "876/876 [==============================] - 3s 3ms/step\n",
            "110/110 [==============================] - 7s 60ms/step - loss: 0.5347 - val_loss: 0.6747\n",
            "Epoch 666/1500\n",
            "876/876 [==============================] - 2s 2ms/step\n",
            "110/110 [==============================] - 5s 48ms/step - loss: 0.5952 - val_loss: 0.8298\n",
            "Epoch 667/1500\n",
            "876/876 [==============================] - 2s 3ms/step\n",
            "110/110 [==============================] - 5s 43ms/step - loss: 0.3930 - val_loss: 0.8079\n",
            "Epoch 668/1500\n",
            "876/876 [==============================] - 3s 3ms/step\n",
            "110/110 [==============================] - 6s 58ms/step - loss: 0.4456 - val_loss: 0.7240\n",
            "Epoch 669/1500\n",
            "876/876 [==============================] - 2s 2ms/step\n",
            "110/110 [==============================] - 6s 51ms/step - loss: 0.6015 - val_loss: 1.4959\n",
            "Epoch 670/1500\n",
            "876/876 [==============================] - 2s 2ms/step\n",
            "110/110 [==============================] - 5s 43ms/step - loss: 0.6416 - val_loss: 0.8488\n",
            "Epoch 671/1500\n",
            "876/876 [==============================] - 3s 3ms/step\n",
            "110/110 [==============================] - 8s 71ms/step - loss: 0.4549 - val_loss: 0.7118\n",
            "Epoch 672/1500\n",
            "876/876 [==============================] - 2s 3ms/step\n",
            "110/110 [==============================] - 5s 43ms/step - loss: 0.4550 - val_loss: 0.7517\n",
            "Epoch 673/1500\n",
            "876/876 [==============================] - 2s 3ms/step\n",
            "110/110 [==============================] - 7s 67ms/step - loss: 0.4426 - val_loss: 0.7863\n",
            "Epoch 674/1500\n",
            "876/876 [==============================] - 2s 2ms/step\n",
            "110/110 [==============================] - 5s 44ms/step - loss: 0.4781 - val_loss: 1.4941\n",
            "Epoch 675/1500\n",
            "876/876 [==============================] - 2s 2ms/step\n",
            "110/110 [==============================] - 5s 43ms/step - loss: 1.0020 - val_loss: 0.7494\n",
            "Epoch 676/1500\n",
            "876/876 [==============================] - 3s 3ms/step\n",
            "110/110 [==============================] - 7s 65ms/step - loss: 0.6946 - val_loss: 1.7893\n",
            "Epoch 677/1500\n",
            "876/876 [==============================] - 2s 2ms/step\n",
            "110/110 [==============================] - 5s 44ms/step - loss: 0.6670 - val_loss: 1.1656\n",
            "Epoch 678/1500\n",
            "876/876 [==============================] - 2s 2ms/step\n",
            "110/110 [==============================] - 5s 43ms/step - loss: 0.6963 - val_loss: 1.5292\n",
            "Epoch 679/1500\n",
            "876/876 [==============================] - 3s 3ms/step\n",
            "110/110 [==============================] - 8s 76ms/step - loss: 0.5873 - val_loss: 0.9698\n",
            "Epoch 680/1500\n",
            "876/876 [==============================] - 2s 2ms/step\n",
            "110/110 [==============================] - 5s 44ms/step - loss: 0.5667 - val_loss: 0.7389\n",
            "Epoch 681/1500\n",
            "876/876 [==============================] - 2s 3ms/step\n",
            "110/110 [==============================] - 5s 46ms/step - loss: 0.4994 - val_loss: 0.9395\n",
            "Epoch 682/1500\n",
            "876/876 [==============================] - 3s 3ms/step\n",
            "110/110 [==============================] - 7s 61ms/step - loss: 0.5016 - val_loss: 0.8921\n",
            "Epoch 683/1500\n",
            "876/876 [==============================] - 2s 2ms/step\n",
            "110/110 [==============================] - 5s 42ms/step - loss: 0.7644 - val_loss: 0.7179\n",
            "Epoch 684/1500\n",
            "876/876 [==============================] - 2s 3ms/step\n",
            "110/110 [==============================] - 7s 67ms/step - loss: 0.5042 - val_loss: 1.8909\n",
            "Epoch 685/1500\n",
            "876/876 [==============================] - 2s 2ms/step\n",
            "110/110 [==============================] - 5s 43ms/step - loss: 0.6001 - val_loss: 0.7933\n",
            "Epoch 686/1500\n",
            "876/876 [==============================] - 2s 3ms/step\n",
            "110/110 [==============================] - 5s 44ms/step - loss: 0.5326 - val_loss: 0.7471\n",
            "Epoch 687/1500\n",
            "876/876 [==============================] - 3s 3ms/step\n",
            "110/110 [==============================] - 9s 81ms/step - loss: 0.5888 - val_loss: 1.1403\n",
            "Epoch 688/1500\n",
            "876/876 [==============================] - 2s 2ms/step\n",
            "110/110 [==============================] - 5s 44ms/step - loss: 0.4199 - val_loss: 0.7881\n",
            "Epoch 689/1500\n",
            "876/876 [==============================] - 2s 3ms/step\n",
            "110/110 [==============================] - 5s 46ms/step - loss: 0.4359 - val_loss: 1.4938\n",
            "Epoch 690/1500\n",
            "876/876 [==============================] - 3s 3ms/step\n",
            "110/110 [==============================] - 7s 62ms/step - loss: 1.1574 - val_loss: 1.8418\n",
            "Epoch 691/1500\n",
            "876/876 [==============================] - 2s 3ms/step\n",
            "110/110 [==============================] - 5s 44ms/step - loss: 0.6062 - val_loss: 0.9166\n",
            "Epoch 692/1500\n",
            "876/876 [==============================] - 2s 3ms/step\n",
            "110/110 [==============================] - 5s 47ms/step - loss: 0.4981 - val_loss: 0.7074\n",
            "Epoch 693/1500\n",
            "876/876 [==============================] - 3s 3ms/step\n",
            "110/110 [==============================] - 7s 62ms/step - loss: 0.3851 - val_loss: 0.8068\n",
            "Epoch 694/1500\n",
            "876/876 [==============================] - 2s 2ms/step\n",
            "110/110 [==============================] - 5s 43ms/step - loss: 0.6733 - val_loss: 1.1043\n",
            "Epoch 695/1500\n",
            "876/876 [==============================] - 2s 3ms/step\n",
            "110/110 [==============================] - 5s 45ms/step - loss: 0.5332 - val_loss: 1.3712\n",
            "Epoch 696/1500\n",
            "876/876 [==============================] - 3s 3ms/step\n",
            "110/110 [==============================] - 7s 61ms/step - loss: 0.5678 - val_loss: 1.3711\n",
            "Epoch 697/1500\n",
            "876/876 [==============================] - 2s 2ms/step\n",
            "110/110 [==============================] - 5s 44ms/step - loss: 0.5436 - val_loss: 0.6508\n",
            "Epoch 698/1500\n",
            "876/876 [==============================] - 2s 2ms/step\n",
            "110/110 [==============================] - 5s 43ms/step - loss: 0.3928 - val_loss: 0.7632\n",
            "Epoch 699/1500\n",
            "876/876 [==============================] - 3s 3ms/step\n",
            "110/110 [==============================] - 7s 64ms/step - loss: 0.5550 - val_loss: 0.9842\n",
            "Epoch 700/1500\n",
            "876/876 [==============================] - 2s 3ms/step\n",
            "110/110 [==============================] - 5s 44ms/step - loss: 0.5921 - val_loss: 0.8495\n",
            "Epoch 701/1500\n",
            "876/876 [==============================] - 2s 2ms/step\n",
            "110/110 [==============================] - 5s 43ms/step - loss: 0.5078 - val_loss: 0.8802\n",
            "Epoch 702/1500\n",
            "876/876 [==============================] - 3s 3ms/step\n",
            "110/110 [==============================] - 7s 60ms/step - loss: 0.5702 - val_loss: 0.7010\n",
            "Epoch 703/1500\n",
            "876/876 [==============================] - 2s 2ms/step\n",
            "110/110 [==============================] - 5s 47ms/step - loss: 0.4317 - val_loss: 1.1819\n",
            "Epoch 704/1500\n",
            "876/876 [==============================] - 2s 3ms/step\n",
            "110/110 [==============================] - 5s 44ms/step - loss: 0.4152 - val_loss: 0.7031\n",
            "Epoch 705/1500\n",
            "876/876 [==============================] - 3s 3ms/step\n",
            "110/110 [==============================] - 6s 58ms/step - loss: 0.6272 - val_loss: 0.7535\n",
            "Epoch 706/1500\n",
            "876/876 [==============================] - 2s 2ms/step\n",
            "110/110 [==============================] - 6s 52ms/step - loss: 1.2933 - val_loss: 1.1737\n",
            "Epoch 707/1500\n",
            "876/876 [==============================] - 2s 3ms/step\n",
            "110/110 [==============================] - 5s 43ms/step - loss: 0.4266 - val_loss: 0.6501\n",
            "Epoch 708/1500\n",
            "876/876 [==============================] - 3s 3ms/step\n",
            "110/110 [==============================] - 8s 72ms/step - loss: 0.5414 - val_loss: 0.6907\n",
            "Epoch 709/1500\n",
            "876/876 [==============================] - 2s 3ms/step\n",
            "110/110 [==============================] - 5s 44ms/step - loss: 0.4017 - val_loss: 1.7292\n",
            "Epoch 710/1500\n",
            "876/876 [==============================] - 2s 3ms/step\n",
            "110/110 [==============================] - 7s 67ms/step - loss: 0.7712 - val_loss: 0.8537\n",
            "Epoch 711/1500\n",
            "876/876 [==============================] - 2s 2ms/step\n",
            "110/110 [==============================] - 5s 43ms/step - loss: 0.5992 - val_loss: 1.1669\n",
            "Epoch 712/1500\n",
            "876/876 [==============================] - 2s 3ms/step\n",
            "110/110 [==============================] - 5s 44ms/step - loss: 0.5379 - val_loss: 1.0254\n",
            "Epoch 713/1500\n",
            "876/876 [==============================] - 3s 3ms/step\n",
            "110/110 [==============================] - 9s 80ms/step - loss: 0.7714 - val_loss: 0.9118\n",
            "Epoch 714/1500\n",
            "876/876 [==============================] - 2s 3ms/step\n",
            "110/110 [==============================] - 5s 44ms/step - loss: 0.8408 - val_loss: 0.8053\n",
            "Epoch 715/1500\n",
            "876/876 [==============================] - 3s 3ms/step\n",
            "110/110 [==============================] - 6s 51ms/step - loss: 0.4035 - val_loss: 0.7317\n",
            "Epoch 716/1500\n",
            "876/876 [==============================] - 2s 3ms/step\n",
            "110/110 [==============================] - 7s 60ms/step - loss: 0.4680 - val_loss: 0.7441\n",
            "Epoch 717/1500\n",
            "876/876 [==============================] - 2s 3ms/step\n",
            "110/110 [==============================] - 5s 44ms/step - loss: 0.6372 - val_loss: 1.2937\n",
            "Epoch 718/1500\n",
            "876/876 [==============================] - 3s 3ms/step\n",
            "110/110 [==============================] - 7s 68ms/step - loss: 0.4290 - val_loss: 1.3948\n",
            "Epoch 719/1500\n",
            "876/876 [==============================] - 2s 3ms/step\n",
            "110/110 [==============================] - 5s 44ms/step - loss: 0.4375 - val_loss: 0.7339\n",
            "Epoch 720/1500\n",
            "876/876 [==============================] - 2s 3ms/step\n",
            "110/110 [==============================] - 5s 44ms/step - loss: 0.5691 - val_loss: 0.6175\n",
            "Epoch 721/1500\n",
            "876/876 [==============================] - 3s 3ms/step\n",
            "110/110 [==============================] - 9s 81ms/step - loss: 0.5777 - val_loss: 0.9758\n",
            "Epoch 722/1500\n",
            "876/876 [==============================] - 2s 3ms/step\n",
            "110/110 [==============================] - 5s 44ms/step - loss: 0.6192 - val_loss: 1.9693\n",
            "Epoch 723/1500\n",
            "876/876 [==============================] - 3s 3ms/step\n",
            "110/110 [==============================] - 5s 48ms/step - loss: 0.5618 - val_loss: 0.7361\n",
            "Epoch 724/1500\n",
            "876/876 [==============================] - 3s 3ms/step\n",
            "110/110 [==============================] - 9s 82ms/step - loss: 0.7670 - val_loss: 1.8486\n",
            "Epoch 725/1500\n",
            "876/876 [==============================] - 2s 3ms/step\n",
            "110/110 [==============================] - 5s 44ms/step - loss: 0.6656 - val_loss: 0.8734\n",
            "Epoch 726/1500\n",
            "876/876 [==============================] - 3s 3ms/step\n",
            "110/110 [==============================] - 6s 56ms/step - loss: 0.9979 - val_loss: 1.8174\n",
            "Epoch 727/1500\n",
            "876/876 [==============================] - 2s 3ms/step\n",
            "110/110 [==============================] - 6s 53ms/step - loss: 0.5643 - val_loss: 0.6857\n",
            "Epoch 728/1500\n",
            "876/876 [==============================] - 2s 3ms/step\n",
            "110/110 [==============================] - 5s 44ms/step - loss: 0.3538 - val_loss: 0.9132\n",
            "Epoch 729/1500\n",
            "876/876 [==============================] - 3s 3ms/step\n",
            "110/110 [==============================] - 6s 54ms/step - loss: 0.5670 - val_loss: 1.0454\n",
            "Epoch 730/1500\n",
            "876/876 [==============================] - 2s 3ms/step\n",
            "110/110 [==============================] - 6s 56ms/step - loss: 0.6154 - val_loss: 0.8403\n",
            "Epoch 731/1500\n",
            "876/876 [==============================] - 2s 3ms/step\n",
            "110/110 [==============================] - 5s 45ms/step - loss: 0.5842 - val_loss: 1.1121\n",
            "Epoch 732/1500\n",
            "876/876 [==============================] - 3s 3ms/step\n",
            "110/110 [==============================] - 7s 68ms/step - loss: 0.5936 - val_loss: 1.1177\n",
            "Epoch 733/1500\n",
            "876/876 [==============================] - 2s 3ms/step\n",
            "110/110 [==============================] - 5s 44ms/step - loss: 0.3301 - val_loss: 0.8005\n",
            "Epoch 734/1500\n",
            "876/876 [==============================] - 2s 3ms/step\n",
            "110/110 [==============================] - 5s 44ms/step - loss: 0.3855 - val_loss: 1.1772\n",
            "Epoch 735/1500\n",
            "876/876 [==============================] - 3s 3ms/step\n",
            "110/110 [==============================] - 9s 82ms/step - loss: 1.0899 - val_loss: 1.9152\n",
            "Epoch 736/1500\n",
            "876/876 [==============================] - 2s 3ms/step\n",
            "110/110 [==============================] - 5s 44ms/step - loss: 0.4496 - val_loss: 0.8194\n",
            "Epoch 737/1500\n",
            "876/876 [==============================] - 3s 3ms/step\n",
            "110/110 [==============================] - 7s 68ms/step - loss: 0.4667 - val_loss: 1.3052\n",
            "Epoch 738/1500\n",
            "876/876 [==============================] - 2s 3ms/step\n",
            "110/110 [==============================] - 5s 44ms/step - loss: 0.6946 - val_loss: 0.7425\n",
            "Epoch 739/1500\n",
            "876/876 [==============================] - 2s 3ms/step\n",
            "110/110 [==============================] - 5s 44ms/step - loss: 0.4847 - val_loss: 1.0278\n",
            "Epoch 740/1500\n",
            "876/876 [==============================] - 3s 3ms/step\n",
            "110/110 [==============================] - 9s 82ms/step - loss: 0.6468 - val_loss: 1.1193\n",
            "Epoch 741/1500\n",
            "876/876 [==============================] - 2s 3ms/step\n",
            "110/110 [==============================] - 5s 44ms/step - loss: 0.4030 - val_loss: 0.6961\n",
            "Epoch 742/1500\n",
            "876/876 [==============================] - 3s 3ms/step\n",
            "110/110 [==============================] - 5s 48ms/step - loss: 0.5050 - val_loss: 2.1596\n",
            "Epoch 743/1500\n",
            "876/876 [==============================] - 2s 3ms/step\n",
            "110/110 [==============================] - 9s 81ms/step - loss: 0.5443 - val_loss: 1.6401\n",
            "Epoch 744/1500\n",
            "876/876 [==============================] - 2s 3ms/step\n",
            "110/110 [==============================] - 5s 44ms/step - loss: 0.7450 - val_loss: 1.0373\n",
            "Epoch 745/1500\n",
            "876/876 [==============================] - 3s 3ms/step\n",
            "110/110 [==============================] - 6s 58ms/step - loss: 0.5060 - val_loss: 1.1134\n",
            "Epoch 746/1500\n",
            "876/876 [==============================] - 2s 3ms/step\n",
            "110/110 [==============================] - 6s 52ms/step - loss: 0.8939 - val_loss: 0.9878\n",
            "Epoch 747/1500\n",
            "876/876 [==============================] - 2s 3ms/step\n",
            "110/110 [==============================] - 7s 68ms/step - loss: 0.4571 - val_loss: 0.7873\n",
            "Epoch 748/1500\n",
            "876/876 [==============================] - 2s 3ms/step\n",
            "110/110 [==============================] - 9s 83ms/step - loss: 0.6771 - val_loss: 1.2074\n",
            "Epoch 749/1500\n",
            "876/876 [==============================] - 2s 3ms/step\n",
            "110/110 [==============================] - 5s 44ms/step - loss: 0.5286 - val_loss: 0.6858\n",
            "Epoch 750/1500\n",
            "876/876 [==============================] - 3s 3ms/step\n",
            "110/110 [==============================] - 7s 60ms/step - loss: 0.4491 - val_loss: 0.7457\n",
            "Epoch 751/1500\n",
            "876/876 [==============================] - 2s 3ms/step\n",
            "110/110 [==============================] - 6s 50ms/step - loss: 0.8297 - val_loss: 3.6245\n",
            "Epoch 752/1500\n",
            "876/876 [==============================] - 2s 3ms/step\n",
            "110/110 [==============================] - 5s 44ms/step - loss: 0.7038 - val_loss: 0.8026\n",
            "Epoch 753/1500\n",
            "876/876 [==============================] - 3s 3ms/step\n",
            "110/110 [==============================] - 8s 74ms/step - loss: 0.3637 - val_loss: 0.9078\n",
            "Epoch 754/1500\n",
            "876/876 [==============================] - 2s 3ms/step\n",
            "110/110 [==============================] - 5s 44ms/step - loss: 0.4327 - val_loss: 0.8232\n",
            "Epoch 755/1500\n",
            "876/876 [==============================] - 2s 3ms/step\n",
            "110/110 [==============================] - 5s 46ms/step - loss: 0.7002 - val_loss: 1.0624\n",
            "Epoch 756/1500\n",
            "876/876 [==============================] - 3s 3ms/step\n",
            "110/110 [==============================] - 7s 63ms/step - loss: 0.4925 - val_loss: 0.8706\n",
            "Epoch 757/1500\n",
            "876/876 [==============================] - 2s 3ms/step\n",
            "110/110 [==============================] - 7s 68ms/step - loss: 0.4416 - val_loss: 0.9783\n",
            "Epoch 758/1500\n",
            "876/876 [==============================] - 3s 3ms/step\n",
            "110/110 [==============================] - 8s 72ms/step - loss: 0.7659 - val_loss: 1.0028\n",
            "Epoch 759/1500\n",
            "876/876 [==============================] - 2s 3ms/step\n",
            "110/110 [==============================] - 5s 44ms/step - loss: 0.5239 - val_loss: 1.5759\n",
            "Epoch 760/1500\n",
            "876/876 [==============================] - 2s 3ms/step\n",
            "110/110 [==============================] - 7s 68ms/step - loss: 0.4728 - val_loss: 0.7834\n",
            "Epoch 761/1500\n",
            "876/876 [==============================] - 2s 3ms/step\n",
            "110/110 [==============================] - 5s 45ms/step - loss: 0.7248 - val_loss: 0.7509\n",
            "Epoch 762/1500\n",
            "876/876 [==============================] - 2s 3ms/step\n",
            "110/110 [==============================] - 5s 44ms/step - loss: 0.8253 - val_loss: 1.7909\n",
            "Epoch 763/1500\n",
            "876/876 [==============================] - 3s 4ms/step\n",
            "110/110 [==============================] - 9s 80ms/step - loss: 0.4801 - val_loss: 0.9300\n",
            "Epoch 764/1500\n",
            "876/876 [==============================] - 2s 3ms/step\n",
            "110/110 [==============================] - 5s 45ms/step - loss: 0.5082 - val_loss: 0.7331\n",
            "Epoch 765/1500\n",
            "876/876 [==============================] - 3s 3ms/step\n",
            "110/110 [==============================] - 5s 49ms/step - loss: 0.5009 - val_loss: 4.0238\n",
            "Epoch 766/1500\n",
            "876/876 [==============================] - 3s 3ms/step\n",
            "110/110 [==============================] - 9s 84ms/step - loss: 0.8883 - val_loss: 0.9745\n",
            "Epoch 767/1500\n",
            "876/876 [==============================] - 2s 3ms/step\n",
            "110/110 [==============================] - 8s 69ms/step - loss: 0.4290 - val_loss: 1.2098\n",
            "Epoch 768/1500\n",
            "876/876 [==============================] - 2s 3ms/step\n",
            "110/110 [==============================] - 6s 55ms/step - loss: 0.4049 - val_loss: 0.9267\n",
            "Epoch 769/1500\n",
            "876/876 [==============================] - 2s 3ms/step\n",
            "110/110 [==============================] - 8s 69ms/step - loss: 0.4314 - val_loss: 1.4492\n",
            "Epoch 770/1500\n",
            "876/876 [==============================] - 2s 3ms/step\n",
            "110/110 [==============================] - 7s 59ms/step - loss: 0.5607 - val_loss: 1.5584\n",
            "Epoch 771/1500\n",
            "876/876 [==============================] - 2s 3ms/step\n",
            "110/110 [==============================] - 5s 45ms/step - loss: 0.7759 - val_loss: 1.3280\n",
            "Epoch 772/1500\n",
            "876/876 [==============================] - 3s 3ms/step\n",
            "110/110 [==============================] - 6s 51ms/step - loss: 0.6667 - val_loss: 0.8542\n",
            "Epoch 773/1500\n",
            "876/876 [==============================] - 2s 3ms/step\n",
            "110/110 [==============================] - 6s 58ms/step - loss: 0.6620 - val_loss: 1.0853\n",
            "Epoch 774/1500\n",
            "876/876 [==============================] - 2s 3ms/step\n",
            "110/110 [==============================] - 5s 44ms/step - loss: 0.4970 - val_loss: 0.9147\n",
            "Epoch 775/1500\n",
            "876/876 [==============================] - 3s 3ms/step\n",
            "110/110 [==============================] - 5s 50ms/step - loss: 0.4915 - val_loss: 2.5845\n",
            "Epoch 776/1500\n",
            "876/876 [==============================] - 2s 3ms/step\n",
            "110/110 [==============================] - 6s 59ms/step - loss: 0.6947 - val_loss: 0.8079\n",
            "Epoch 777/1500\n",
            "876/876 [==============================] - 2s 3ms/step\n",
            "110/110 [==============================] - 7s 68ms/step - loss: 0.5368 - val_loss: 0.8663\n",
            "Epoch 778/1500\n",
            "876/876 [==============================] - 3s 3ms/step\n",
            "110/110 [==============================] - 7s 65ms/step - loss: 0.4666 - val_loss: 2.2489\n",
            "Epoch 779/1500\n",
            "876/876 [==============================] - 2s 3ms/step\n",
            "110/110 [==============================] - 5s 45ms/step - loss: 0.9379 - val_loss: 0.8336\n",
            "Epoch 780/1500\n",
            "876/876 [==============================] - 2s 3ms/step\n",
            "110/110 [==============================] - 5s 45ms/step - loss: 0.3915 - val_loss: 1.1143\n",
            "Epoch 781/1500\n",
            "876/876 [==============================] - 3s 3ms/step\n",
            "110/110 [==============================] - 9s 81ms/step - loss: 0.4563 - val_loss: 0.7376\n",
            "Epoch 782/1500\n",
            "876/876 [==============================] - 2s 3ms/step\n",
            "110/110 [==============================] - 5s 46ms/step - loss: 0.4060 - val_loss: 0.7224\n",
            "Epoch 783/1500\n",
            "876/876 [==============================] - 3s 3ms/step\n",
            "110/110 [==============================] - 5s 49ms/step - loss: 0.3690 - val_loss: 0.6426\n",
            "Epoch 784/1500\n",
            "876/876 [==============================] - 3s 3ms/step\n",
            "110/110 [==============================] - 9s 82ms/step - loss: 0.4678 - val_loss: 2.1285\n",
            "Epoch 785/1500\n",
            "876/876 [==============================] - 2s 3ms/step\n",
            "110/110 [==============================] - 7s 68ms/step - loss: 0.6493 - val_loss: 0.9789\n",
            "Epoch 786/1500\n",
            "876/876 [==============================] - 2s 3ms/step\n",
            "110/110 [==============================] - 7s 60ms/step - loss: 0.9761 - val_loss: 0.8077\n",
            "Epoch 787/1500\n",
            "876/876 [==============================] - 2s 3ms/step\n",
            "110/110 [==============================] - 5s 45ms/step - loss: 0.4863 - val_loss: 0.6803\n",
            "Epoch 788/1500\n",
            "876/876 [==============================] - 3s 3ms/step\n",
            "110/110 [==============================] - 7s 68ms/step - loss: 0.2917 - val_loss: 0.6410\n",
            "Epoch 789/1500\n",
            "876/876 [==============================] - 2s 3ms/step\n",
            "110/110 [==============================] - 7s 68ms/step - loss: 0.6283 - val_loss: 0.9500\n",
            "Epoch 790/1500\n",
            "876/876 [==============================] - 3s 3ms/step\n",
            "110/110 [==============================] - 8s 69ms/step - loss: 0.4130 - val_loss: 1.0509\n",
            "Epoch 791/1500\n",
            "876/876 [==============================] - 2s 3ms/step\n",
            "110/110 [==============================] - 7s 68ms/step - loss: 0.5915 - val_loss: 1.1341\n",
            "Epoch 792/1500\n",
            "876/876 [==============================] - 3s 3ms/step\n",
            "110/110 [==============================] - 6s 53ms/step - loss: 0.4325 - val_loss: 1.9381\n",
            "Epoch 793/1500\n",
            "876/876 [==============================] - 2s 3ms/step\n",
            "110/110 [==============================] - 6s 56ms/step - loss: 0.5721 - val_loss: 0.9565\n",
            "Epoch 794/1500\n",
            "876/876 [==============================] - 2s 3ms/step\n",
            "110/110 [==============================] - 5s 45ms/step - loss: 0.4256 - val_loss: 0.7227\n",
            "Epoch 795/1500\n",
            "876/876 [==============================] - 3s 3ms/step\n",
            "110/110 [==============================] - 6s 54ms/step - loss: 0.5549 - val_loss: 2.0801\n",
            "Epoch 796/1500\n",
            "876/876 [==============================] - 2s 3ms/step\n",
            "110/110 [==============================] - 6s 56ms/step - loss: 0.6516 - val_loss: 2.2863\n",
            "Epoch 797/1500\n",
            "876/876 [==============================] - 2s 3ms/step\n",
            "110/110 [==============================] - 5s 45ms/step - loss: 0.9206 - val_loss: 1.2375\n",
            "Epoch 798/1500\n",
            "876/876 [==============================] - 3s 3ms/step\n",
            "110/110 [==============================] - 8s 70ms/step - loss: 0.4001 - val_loss: 0.6895\n",
            "Epoch 799/1500\n",
            "876/876 [==============================] - 2s 3ms/step\n",
            "110/110 [==============================] - 5s 45ms/step - loss: 0.3828 - val_loss: 1.1274\n",
            "Epoch 800/1500\n",
            "876/876 [==============================] - 2s 3ms/step\n",
            "110/110 [==============================] - 8s 69ms/step - loss: 0.3982 - val_loss: 0.9070\n",
            "Epoch 801/1500\n",
            "876/876 [==============================] - 2s 3ms/step\n",
            "110/110 [==============================] - 5s 47ms/step - loss: 0.6710 - val_loss: 1.9373\n",
            "Epoch 802/1500\n",
            "876/876 [==============================] - 2s 3ms/step\n",
            "110/110 [==============================] - 7s 68ms/step - loss: 0.7332 - val_loss: 0.8204\n",
            "Epoch 803/1500\n",
            "876/876 [==============================] - 2s 3ms/step\n",
            "110/110 [==============================] - 6s 51ms/step - loss: 0.7149 - val_loss: 0.7969\n",
            "Epoch 804/1500\n",
            "876/876 [==============================] - 2s 3ms/step\n",
            "110/110 [==============================] - 5s 46ms/step - loss: 0.3540 - val_loss: 0.7415\n",
            "Epoch 805/1500\n",
            "876/876 [==============================] - 3s 3ms/step\n",
            "110/110 [==============================] - 7s 61ms/step - loss: 0.9846 - val_loss: 1.0337\n",
            "Epoch 806/1500\n",
            "876/876 [==============================] - 2s 3ms/step\n",
            "110/110 [==============================] - 5s 49ms/step - loss: 0.3968 - val_loss: 0.6729\n",
            "Epoch 807/1500\n",
            "876/876 [==============================] - 2s 3ms/step\n",
            "110/110 [==============================] - 5s 46ms/step - loss: 0.3465 - val_loss: 0.9861\n",
            "Epoch 808/1500\n",
            "876/876 [==============================] - 3s 3ms/step\n",
            "110/110 [==============================] - 9s 78ms/step - loss: 0.4546 - val_loss: 0.7355\n",
            "Epoch 809/1500\n",
            "876/876 [==============================] - 2s 3ms/step\n",
            "110/110 [==============================] - 5s 46ms/step - loss: 1.2150 - val_loss: 0.9500\n",
            "Epoch 810/1500\n",
            "876/876 [==============================] - 3s 3ms/step\n",
            "110/110 [==============================] - 7s 68ms/step - loss: 0.4068 - val_loss: 0.8985\n",
            "Epoch 811/1500\n",
            "876/876 [==============================] - 2s 3ms/step\n",
            "110/110 [==============================] - 5s 45ms/step - loss: 0.4625 - val_loss: 0.8673\n",
            "Epoch 812/1500\n",
            "876/876 [==============================] - 2s 3ms/step\n",
            "110/110 [==============================] - 7s 68ms/step - loss: 0.3787 - val_loss: 0.8905\n",
            "Epoch 813/1500\n",
            "876/876 [==============================] - 2s 3ms/step\n",
            "110/110 [==============================] - 5s 47ms/step - loss: 0.6370 - val_loss: 0.6981\n",
            "Epoch 814/1500\n",
            "876/876 [==============================] - 2s 3ms/step\n",
            "110/110 [==============================] - 5s 45ms/step - loss: 0.7248 - val_loss: 2.5157\n",
            "Epoch 815/1500\n",
            "876/876 [==============================] - 3s 3ms/step\n",
            "110/110 [==============================] - 7s 64ms/step - loss: 0.8207 - val_loss: 0.7512\n",
            "Epoch 816/1500\n",
            "876/876 [==============================] - 2s 3ms/step\n",
            "110/110 [==============================] - 5s 48ms/step - loss: 0.4863 - val_loss: 0.7397\n",
            "Epoch 817/1500\n",
            "876/876 [==============================] - 2s 3ms/step\n",
            "110/110 [==============================] - 5s 46ms/step - loss: 0.4161 - val_loss: 1.1610\n",
            "Epoch 818/1500\n",
            "876/876 [==============================] - 3s 3ms/step\n",
            "110/110 [==============================] - 7s 64ms/step - loss: 0.4257 - val_loss: 0.7645\n",
            "Epoch 819/1500\n",
            "876/876 [==============================] - 2s 3ms/step\n",
            "110/110 [==============================] - 5s 47ms/step - loss: 0.4048 - val_loss: 0.7237\n",
            "Epoch 820/1500\n",
            "876/876 [==============================] - 2s 3ms/step\n",
            "110/110 [==============================] - 7s 68ms/step - loss: 0.4076 - val_loss: 0.7686\n",
            "Epoch 821/1500\n",
            "876/876 [==============================] - 2s 3ms/step\n",
            "110/110 [==============================] - 6s 51ms/step - loss: 0.5490 - val_loss: 2.0833\n",
            "Epoch 822/1500\n",
            "876/876 [==============================] - 2s 3ms/step\n",
            "110/110 [==============================] - 5s 45ms/step - loss: 0.5557 - val_loss: 0.6704\n",
            "Epoch 823/1500\n",
            "876/876 [==============================] - 3s 3ms/step\n",
            "110/110 [==============================] - 8s 75ms/step - loss: 0.4841 - val_loss: 0.9301\n",
            "Epoch 824/1500\n",
            "876/876 [==============================] - 2s 3ms/step\n",
            "110/110 [==============================] - 5s 46ms/step - loss: 0.5888 - val_loss: 0.9289\n",
            "Epoch 825/1500\n",
            "876/876 [==============================] - 3s 3ms/step\n",
            "110/110 [==============================] - 7s 68ms/step - loss: 0.4759 - val_loss: 0.9064\n",
            "Epoch 826/1500\n",
            "876/876 [==============================] - 2s 3ms/step\n",
            "110/110 [==============================] - 7s 68ms/step - loss: 0.8162 - val_loss: 0.7567\n",
            "Epoch 827/1500\n",
            "876/876 [==============================] - 3s 3ms/step\n",
            "110/110 [==============================] - 8s 70ms/step - loss: 0.3881 - val_loss: 0.7533\n",
            "Epoch 828/1500\n",
            "876/876 [==============================] - 2s 3ms/step\n",
            "110/110 [==============================] - 5s 44ms/step - loss: 0.5368 - val_loss: 0.8440\n",
            "Epoch 829/1500\n",
            "876/876 [==============================] - 2s 3ms/step\n",
            "110/110 [==============================] - 5s 46ms/step - loss: 0.4141 - val_loss: 0.9460\n",
            "Epoch 830/1500\n",
            "876/876 [==============================] - 3s 3ms/step\n",
            "110/110 [==============================] - 7s 66ms/step - loss: 0.4073 - val_loss: 0.6843\n",
            "Epoch 831/1500\n",
            "876/876 [==============================] - 2s 3ms/step\n",
            "110/110 [==============================] - 5s 45ms/step - loss: 0.5553 - val_loss: 3.4356\n",
            "Epoch 832/1500\n",
            "876/876 [==============================] - 2s 3ms/step\n",
            "110/110 [==============================] - 5s 46ms/step - loss: 0.8142 - val_loss: 0.6652\n",
            "Epoch 833/1500\n",
            "876/876 [==============================] - 3s 3ms/step\n",
            "110/110 [==============================] - 9s 81ms/step - loss: 0.5323 - val_loss: 1.7079\n",
            "Epoch 834/1500\n",
            "876/876 [==============================] - 2s 3ms/step\n",
            "110/110 [==============================] - 7s 68ms/step - loss: 0.4549 - val_loss: 1.1189\n",
            "Epoch 835/1500\n",
            "876/876 [==============================] - 3s 3ms/step\n",
            "110/110 [==============================] - 7s 65ms/step - loss: 0.5074 - val_loss: 0.7604\n",
            "Epoch 836/1500\n",
            "876/876 [==============================] - 2s 3ms/step\n",
            "110/110 [==============================] - 8s 70ms/step - loss: 0.5238 - val_loss: 2.3030\n",
            "Epoch 837/1500\n",
            "876/876 [==============================] - 3s 3ms/step\n",
            "110/110 [==============================] - 8s 69ms/step - loss: 0.5110 - val_loss: 0.7572\n",
            "Epoch 838/1500\n",
            "876/876 [==============================] - 2s 3ms/step\n",
            "110/110 [==============================] - 8s 69ms/step - loss: 0.3606 - val_loss: 0.6428\n",
            "Epoch 839/1500\n",
            "876/876 [==============================] - 3s 3ms/step\n",
            "110/110 [==============================] - 7s 68ms/step - loss: 0.4110 - val_loss: 1.7036\n",
            "Epoch 840/1500\n",
            "876/876 [==============================] - 2s 3ms/step\n",
            "110/110 [==============================] - 7s 68ms/step - loss: 0.6178 - val_loss: 0.9605\n",
            "Epoch 841/1500\n",
            "876/876 [==============================] - 3s 3ms/step\n",
            "110/110 [==============================] - 7s 68ms/step - loss: 0.3883 - val_loss: 2.2756\n",
            "Epoch 842/1500\n",
            "876/876 [==============================] - 2s 3ms/step\n",
            "110/110 [==============================] - 5s 46ms/step - loss: 0.8323 - val_loss: 1.1213\n",
            "Epoch 843/1500\n",
            "876/876 [==============================] - 2s 3ms/step\n",
            "110/110 [==============================] - 8s 69ms/step - loss: 0.6009 - val_loss: 0.7805\n",
            "Epoch 844/1500\n",
            "876/876 [==============================] - 2s 3ms/step\n",
            "110/110 [==============================] - 8s 70ms/step - loss: 0.6118 - val_loss: 1.0548\n",
            "Epoch 845/1500\n",
            "876/876 [==============================] - 3s 3ms/step\n",
            "110/110 [==============================] - 8s 69ms/step - loss: 0.6012 - val_loss: 0.9899\n",
            "Epoch 846/1500\n",
            "876/876 [==============================] - 2s 3ms/step\n",
            "110/110 [==============================] - 8s 69ms/step - loss: 0.4575 - val_loss: 0.6958\n",
            "Epoch 847/1500\n",
            "876/876 [==============================] - 3s 3ms/step\n",
            "110/110 [==============================] - 6s 52ms/step - loss: 0.3583 - val_loss: 0.7001\n",
            "Epoch 848/1500\n",
            "876/876 [==============================] - 2s 3ms/step\n",
            "110/110 [==============================] - 9s 82ms/step - loss: 0.3451 - val_loss: 0.9541\n",
            "Epoch 849/1500\n",
            "876/876 [==============================] - 2s 3ms/step\n",
            "110/110 [==============================] - 5s 45ms/step - loss: 0.4029 - val_loss: 0.8118\n",
            "Epoch 850/1500\n",
            "876/876 [==============================] - 3s 3ms/step\n",
            "110/110 [==============================] - 7s 60ms/step - loss: 0.5260 - val_loss: 0.7337\n",
            "Epoch 851/1500\n",
            "876/876 [==============================] - 2s 3ms/step\n",
            "110/110 [==============================] - 8s 77ms/step - loss: 0.4630 - val_loss: 0.9587\n",
            "Epoch 852/1500\n",
            "876/876 [==============================] - 3s 3ms/step\n",
            "110/110 [==============================] - 5s 49ms/step - loss: 0.3901 - val_loss: 0.9197\n",
            "Epoch 853/1500\n",
            "876/876 [==============================] - 3s 3ms/step\n",
            "110/110 [==============================] - 7s 65ms/step - loss: 0.5884 - val_loss: 0.8076\n",
            "Epoch 854/1500\n",
            "876/876 [==============================] - 2s 3ms/step\n",
            "110/110 [==============================] - 5s 46ms/step - loss: 0.3626 - val_loss: 1.1244\n",
            "Epoch 855/1500\n",
            "876/876 [==============================] - 2s 3ms/step\n",
            "110/110 [==============================] - 5s 47ms/step - loss: 0.4817 - val_loss: 0.7014\n",
            "Epoch 856/1500\n",
            "876/876 [==============================] - 3s 3ms/step\n",
            "110/110 [==============================] - 9s 81ms/step - loss: 0.4865 - val_loss: 1.0708\n",
            "Epoch 857/1500\n",
            "876/876 [==============================] - 2s 3ms/step\n",
            "110/110 [==============================] - 8s 69ms/step - loss: 0.6920 - val_loss: 0.7807\n",
            "Epoch 858/1500\n",
            "876/876 [==============================] - 3s 3ms/step\n",
            "110/110 [==============================] - 9s 80ms/step - loss: 0.4524 - val_loss: 1.3053\n",
            "Epoch 859/1500\n",
            "876/876 [==============================] - 2s 3ms/step\n",
            "110/110 [==============================] - 5s 46ms/step - loss: 0.5125 - val_loss: 0.7788\n",
            "Epoch 860/1500\n",
            "876/876 [==============================] - 3s 3ms/step\n",
            "110/110 [==============================] - 6s 51ms/step - loss: 0.3827 - val_loss: 1.5830\n",
            "Epoch 861/1500\n",
            "876/876 [==============================] - 3s 3ms/step\n",
            "110/110 [==============================] - 7s 61ms/step - loss: 0.3798 - val_loss: 0.7174\n",
            "Epoch 862/1500\n",
            "876/876 [==============================] - 2s 3ms/step\n",
            "110/110 [==============================] - 5s 46ms/step - loss: 0.3354 - val_loss: 0.6446\n",
            "Epoch 863/1500\n",
            "876/876 [==============================] - 3s 3ms/step\n",
            "110/110 [==============================] - 8s 69ms/step - loss: 0.8083 - val_loss: 1.4228\n",
            "Epoch 864/1500\n",
            "876/876 [==============================] - 2s 3ms/step\n",
            "110/110 [==============================] - 5s 46ms/step - loss: 0.3610 - val_loss: 1.0774\n",
            "Epoch 865/1500\n",
            "876/876 [==============================] - 2s 3ms/step\n",
            "110/110 [==============================] - 5s 47ms/step - loss: 0.6832 - val_loss: 0.9161\n",
            "Epoch 866/1500\n",
            "876/876 [==============================] - 3s 3ms/step\n",
            "110/110 [==============================] - 9s 83ms/step - loss: 0.5586 - val_loss: 1.1337\n",
            "Epoch 867/1500\n",
            "876/876 [==============================] - 2s 3ms/step\n",
            "110/110 [==============================] - 7s 68ms/step - loss: 0.4483 - val_loss: 1.0904\n",
            "Epoch 868/1500\n",
            "876/876 [==============================] - 3s 3ms/step\n",
            "110/110 [==============================] - 7s 64ms/step - loss: 0.5348 - val_loss: 0.7101\n",
            "Epoch 869/1500\n",
            "876/876 [==============================] - 2s 3ms/step\n",
            "110/110 [==============================] - 5s 47ms/step - loss: 0.5064 - val_loss: 0.7937\n",
            "Epoch 870/1500\n",
            "876/876 [==============================] - 2s 3ms/step\n",
            "110/110 [==============================] - 5s 45ms/step - loss: 0.7185 - val_loss: 3.0216\n",
            "Epoch 871/1500\n",
            "876/876 [==============================] - 3s 3ms/step\n",
            "110/110 [==============================] - 9s 79ms/step - loss: 0.5777 - val_loss: 0.8729\n",
            "Epoch 872/1500\n",
            "876/876 [==============================] - 2s 3ms/step\n",
            "110/110 [==============================] - 5s 46ms/step - loss: 0.4539 - val_loss: 0.7712\n",
            "Epoch 873/1500\n",
            "876/876 [==============================] - 3s 3ms/step\n",
            "110/110 [==============================] - 7s 68ms/step - loss: 0.5777 - val_loss: 0.7565\n",
            "Epoch 874/1500\n",
            "876/876 [==============================] - 2s 3ms/step\n",
            "110/110 [==============================] - 5s 47ms/step - loss: 0.4089 - val_loss: 0.8663\n",
            "Epoch 875/1500\n",
            "876/876 [==============================] - 2s 3ms/step\n",
            "110/110 [==============================] - 5s 46ms/step - loss: 0.3997 - val_loss: 0.6269\n",
            "Epoch 876/1500\n",
            "876/876 [==============================] - 3s 3ms/step\n",
            "110/110 [==============================] - 9s 82ms/step - loss: 0.4637 - val_loss: 0.8405\n",
            "Epoch 877/1500\n",
            "876/876 [==============================] - 2s 3ms/step\n",
            "110/110 [==============================] - 8s 69ms/step - loss: 0.4464 - val_loss: 0.7837\n",
            "Epoch 878/1500\n",
            "876/876 [==============================] - 3s 3ms/step\n",
            "110/110 [==============================] - 7s 61ms/step - loss: 0.8932 - val_loss: 2.2936\n",
            "Epoch 879/1500\n",
            "876/876 [==============================] - 2s 3ms/step\n",
            "110/110 [==============================] - 6s 55ms/step - loss: 0.5223 - val_loss: 0.7910\n",
            "Epoch 880/1500\n",
            "876/876 [==============================] - 2s 3ms/step\n",
            "110/110 [==============================] - 5s 46ms/step - loss: 0.3242 - val_loss: 0.6628\n",
            "Epoch 881/1500\n",
            "876/876 [==============================] - 3s 3ms/step\n",
            "110/110 [==============================] - 6s 57ms/step - loss: 0.4349 - val_loss: 2.3621\n",
            "Epoch 882/1500\n",
            "876/876 [==============================] - 2s 3ms/step\n",
            "110/110 [==============================] - 6s 57ms/step - loss: 0.4292 - val_loss: 0.7465\n",
            "Epoch 883/1500\n",
            "876/876 [==============================] - 2s 3ms/step\n",
            "110/110 [==============================] - 8s 69ms/step - loss: 0.2986 - val_loss: 0.6677\n",
            "Epoch 884/1500\n",
            "876/876 [==============================] - 2s 3ms/step\n",
            "110/110 [==============================] - 7s 63ms/step - loss: 0.4492 - val_loss: 0.8350\n",
            "Epoch 885/1500\n",
            "876/876 [==============================] - 2s 3ms/step\n",
            "110/110 [==============================] - 8s 69ms/step - loss: 0.3489 - val_loss: 0.7379\n",
            "Epoch 886/1500\n",
            "876/876 [==============================] - 3s 3ms/step\n",
            "110/110 [==============================] - 9s 82ms/step - loss: 0.4709 - val_loss: 1.4612\n",
            "Epoch 887/1500\n",
            "876/876 [==============================] - 2s 3ms/step\n",
            "110/110 [==============================] - 8s 69ms/step - loss: 0.6181 - val_loss: 0.7051\n",
            "Epoch 888/1500\n",
            "876/876 [==============================] - 3s 3ms/step\n",
            "110/110 [==============================] - 8s 77ms/step - loss: 0.5967 - val_loss: 0.6516\n",
            "Epoch 889/1500\n",
            "876/876 [==============================] - 2s 3ms/step\n",
            "110/110 [==============================] - 8s 69ms/step - loss: 0.5027 - val_loss: 1.0067\n",
            "Epoch 890/1500\n",
            "876/876 [==============================] - 3s 3ms/step\n",
            "110/110 [==============================] - 6s 59ms/step - loss: 0.4932 - val_loss: 0.7771\n",
            "Epoch 891/1500\n",
            "876/876 [==============================] - 2s 3ms/step\n",
            "110/110 [==============================] - 8s 77ms/step - loss: 0.4316 - val_loss: 0.7674\n",
            "Epoch 892/1500\n",
            "876/876 [==============================] - 2s 3ms/step\n",
            "110/110 [==============================] - 5s 48ms/step - loss: 0.3863 - val_loss: 0.6989\n",
            "Epoch 893/1500\n",
            "876/876 [==============================] - 3s 3ms/step\n",
            "110/110 [==============================] - 7s 63ms/step - loss: 0.3643 - val_loss: 0.8783\n",
            "Epoch 894/1500\n",
            "876/876 [==============================] - 2s 3ms/step\n",
            "110/110 [==============================] - 5s 46ms/step - loss: 1.0188 - val_loss: 0.8949\n",
            "Epoch 895/1500\n",
            "876/876 [==============================] - 3s 3ms/step\n",
            "110/110 [==============================] - 5s 49ms/step - loss: 0.6064 - val_loss: 0.9296\n",
            "Epoch 896/1500\n",
            "876/876 [==============================] - 3s 3ms/step\n",
            "110/110 [==============================] - 7s 64ms/step - loss: 0.4385 - val_loss: 0.7256\n",
            "Epoch 897/1500\n",
            "876/876 [==============================] - 2s 3ms/step\n",
            "110/110 [==============================] - 5s 46ms/step - loss: 0.2699 - val_loss: 2.7939\n",
            "Epoch 898/1500\n",
            "876/876 [==============================] - 3s 3ms/step\n",
            "110/110 [==============================] - 6s 51ms/step - loss: 0.6536 - val_loss: 0.9499\n",
            "Epoch 899/1500\n",
            "876/876 [==============================] - 3s 3ms/step\n",
            "110/110 [==============================] - 9s 81ms/step - loss: 0.5867 - val_loss: 0.8484\n",
            "Epoch 900/1500\n",
            "876/876 [==============================] - 2s 3ms/step\n",
            "110/110 [==============================] - 8s 69ms/step - loss: 0.8091 - val_loss: 0.7905\n",
            "Epoch 901/1500\n",
            "876/876 [==============================] - 3s 3ms/step\n",
            "110/110 [==============================] - 7s 64ms/step - loss: 0.7807 - val_loss: 0.9014\n",
            "Epoch 902/1500\n",
            "876/876 [==============================] - 2s 3ms/step\n",
            "110/110 [==============================] - 5s 46ms/step - loss: 0.3979 - val_loss: 0.6956\n",
            "Epoch 903/1500\n",
            "876/876 [==============================] - 2s 3ms/step\n",
            "110/110 [==============================] - 7s 69ms/step - loss: 0.3686 - val_loss: 0.7726\n",
            "Epoch 904/1500\n",
            "876/876 [==============================] - 2s 3ms/step\n",
            "110/110 [==============================] - 8s 69ms/step - loss: 0.4317 - val_loss: 0.8406\n",
            "Epoch 905/1500\n",
            "876/876 [==============================] - 3s 3ms/step\n",
            "110/110 [==============================] - 5s 50ms/step - loss: 0.5095 - val_loss: 0.7027\n",
            "Epoch 906/1500\n",
            "876/876 [==============================] - 3s 3ms/step\n",
            "110/110 [==============================] - 9s 82ms/step - loss: 0.4372 - val_loss: 1.2860\n",
            "Epoch 907/1500\n",
            "876/876 [==============================] - 2s 3ms/step\n",
            "110/110 [==============================] - 5s 46ms/step - loss: 0.3842 - val_loss: 0.8726\n",
            "Epoch 908/1500\n",
            "876/876 [==============================] - 3s 3ms/step\n",
            "110/110 [==============================] - 8s 77ms/step - loss: 0.5873 - val_loss: 0.8138\n",
            "Epoch 909/1500\n",
            "876/876 [==============================] - 2s 3ms/step\n",
            "110/110 [==============================] - 8s 69ms/step - loss: 0.3774 - val_loss: 0.9958\n",
            "Epoch 910/1500\n",
            "876/876 [==============================] - 3s 3ms/step\n",
            "110/110 [==============================] - 8s 75ms/step - loss: 0.9901 - val_loss: 2.3658\n",
            "Epoch 911/1500\n",
            "876/876 [==============================] - 2s 3ms/step\n",
            "110/110 [==============================] - 5s 46ms/step - loss: 0.5466 - val_loss: 1.6981\n",
            "Epoch 912/1500\n",
            "876/876 [==============================] - 3s 3ms/step\n",
            "110/110 [==============================] - 8s 69ms/step - loss: 0.7482 - val_loss: 0.8122\n",
            "Epoch 913/1500\n",
            "876/876 [==============================] - 2s 3ms/step\n",
            "110/110 [==============================] - 5s 48ms/step - loss: 0.3907 - val_loss: 1.0033\n",
            "Epoch 914/1500\n",
            "876/876 [==============================] - 2s 3ms/step\n",
            "110/110 [==============================] - 5s 47ms/step - loss: 0.4421 - val_loss: 1.1558\n",
            "Epoch 915/1500\n",
            "876/876 [==============================] - 3s 4ms/step\n",
            "110/110 [==============================] - 9s 83ms/step - loss: 0.3824 - val_loss: 1.2218\n",
            "Epoch 916/1500\n",
            "876/876 [==============================] - 2s 3ms/step\n",
            "110/110 [==============================] - 8s 69ms/step - loss: 0.5971 - val_loss: 0.8599\n",
            "Epoch 917/1500\n",
            "876/876 [==============================] - 3s 3ms/step\n",
            "110/110 [==============================] - 7s 62ms/step - loss: 0.4493 - val_loss: 0.7823\n",
            "Epoch 918/1500\n",
            "876/876 [==============================] - 2s 3ms/step\n",
            "110/110 [==============================] - 8s 74ms/step - loss: 0.3537 - val_loss: 0.9314\n",
            "Epoch 919/1500\n",
            "876/876 [==============================] - 3s 3ms/step\n",
            "110/110 [==============================] - 5s 49ms/step - loss: 0.4341 - val_loss: 0.6830\n",
            "Epoch 920/1500\n",
            "876/876 [==============================] - 3s 3ms/step\n",
            "110/110 [==============================] - 7s 64ms/step - loss: 0.5551 - val_loss: 2.1488\n",
            "Epoch 921/1500\n",
            "876/876 [==============================] - 2s 3ms/step\n",
            "110/110 [==============================] - 7s 68ms/step - loss: 0.7593 - val_loss: 0.8056\n",
            "Epoch 922/1500\n",
            "876/876 [==============================] - 3s 3ms/step\n",
            "110/110 [==============================] - 8s 74ms/step - loss: 0.4799 - val_loss: 0.9112\n",
            "Epoch 923/1500\n",
            "876/876 [==============================] - 2s 3ms/step\n",
            "110/110 [==============================] - 8s 69ms/step - loss: 0.4298 - val_loss: 1.3009\n",
            "Epoch 924/1500\n",
            "876/876 [==============================] - 3s 3ms/step\n",
            "110/110 [==============================] - 8s 74ms/step - loss: 0.4913 - val_loss: 0.9804\n",
            "Epoch 925/1500\n",
            "876/876 [==============================] - 2s 3ms/step\n",
            "110/110 [==============================] - 5s 46ms/step - loss: 0.6085 - val_loss: 0.7187\n",
            "Epoch 926/1500\n",
            "876/876 [==============================] - 3s 3ms/step\n",
            "110/110 [==============================] - 5s 50ms/step - loss: 0.3425 - val_loss: 0.9178\n",
            "Epoch 927/1500\n",
            "876/876 [==============================] - 3s 3ms/step\n",
            "110/110 [==============================] - 7s 67ms/step - loss: 0.3687 - val_loss: 0.6970\n",
            "Epoch 928/1500\n",
            "876/876 [==============================] - 2s 3ms/step\n",
            "110/110 [==============================] - 5s 47ms/step - loss: 0.4308 - val_loss: 1.1238\n",
            "Epoch 929/1500\n",
            "876/876 [==============================] - 2s 3ms/step\n",
            "110/110 [==============================] - 5s 50ms/step - loss: 0.7467 - val_loss: 2.7384\n",
            "Epoch 930/1500\n",
            "876/876 [==============================] - 3s 3ms/step\n",
            "110/110 [==============================] - 7s 65ms/step - loss: 0.5563 - val_loss: 0.7885\n",
            "Epoch 931/1500\n",
            "876/876 [==============================] - 2s 3ms/step\n",
            "110/110 [==============================] - 8s 70ms/step - loss: 0.6262 - val_loss: 0.8150\n",
            "Epoch 932/1500\n",
            "876/876 [==============================] - 3s 3ms/step\n",
            "110/110 [==============================] - 8s 71ms/step - loss: 0.4052 - val_loss: 0.9141\n",
            "Epoch 933/1500\n",
            "876/876 [==============================] - 2s 3ms/step\n",
            "110/110 [==============================] - 8s 69ms/step - loss: 0.2837 - val_loss: 1.9227\n",
            "Epoch 934/1500\n",
            "876/876 [==============================] - 3s 3ms/step\n",
            "110/110 [==============================] - 6s 54ms/step - loss: 0.8554 - val_loss: 0.9084\n",
            "Epoch 935/1500\n",
            "876/876 [==============================] - 2s 3ms/step\n",
            "110/110 [==============================] - 7s 63ms/step - loss: 0.4609 - val_loss: 0.8376\n",
            "Epoch 936/1500\n",
            "876/876 [==============================] - 2s 3ms/step\n",
            "110/110 [==============================] - 5s 46ms/step - loss: 0.3913 - val_loss: 1.4844\n",
            "Epoch 937/1500\n",
            "876/876 [==============================] - 3s 3ms/step\n",
            "110/110 [==============================] - 6s 55ms/step - loss: 0.6536 - val_loss: 0.7992\n",
            "Epoch 938/1500\n",
            "876/876 [==============================] - 2s 3ms/step\n",
            "110/110 [==============================] - 9s 80ms/step - loss: 0.4517 - val_loss: 0.7179\n",
            "Epoch 939/1500\n",
            "876/876 [==============================] - 2s 3ms/step\n",
            "110/110 [==============================] - 8s 69ms/step - loss: 0.3947 - val_loss: 1.8763\n",
            "Epoch 940/1500\n",
            "876/876 [==============================] - 2s 3ms/step\n",
            "110/110 [==============================] - 5s 47ms/step - loss: 0.4448 - val_loss: 0.7502\n",
            "Epoch 941/1500\n",
            "876/876 [==============================] - 2s 3ms/step\n",
            "110/110 [==============================] - 8s 70ms/step - loss: 0.4651 - val_loss: 0.8496\n",
            "Epoch 942/1500\n",
            "876/876 [==============================] - 2s 3ms/step\n",
            "110/110 [==============================] - 5s 47ms/step - loss: 0.5651 - val_loss: 0.8580\n",
            "Epoch 943/1500\n",
            "876/876 [==============================] - 2s 3ms/step\n",
            "110/110 [==============================] - 7s 68ms/step - loss: 0.4146 - val_loss: 0.7545\n",
            "Epoch 944/1500\n",
            "876/876 [==============================] - 2s 3ms/step\n",
            "110/110 [==============================] - 8s 73ms/step - loss: 0.3398 - val_loss: 0.8955\n",
            "Epoch 945/1500\n",
            "876/876 [==============================] - 3s 3ms/step\n",
            "110/110 [==============================] - 6s 50ms/step - loss: 0.5389 - val_loss: 0.8157\n",
            "Epoch 946/1500\n",
            "876/876 [==============================] - 3s 3ms/step\n",
            "110/110 [==============================] - 9s 82ms/step - loss: 0.5258 - val_loss: 0.7582\n",
            "Epoch 947/1500\n",
            "876/876 [==============================] - 2s 3ms/step\n",
            "110/110 [==============================] - 5s 45ms/step - loss: 0.7574 - val_loss: 0.9839\n",
            "Epoch 948/1500\n",
            "876/876 [==============================] - 3s 3ms/step\n",
            "110/110 [==============================] - 6s 56ms/step - loss: 0.3834 - val_loss: 0.6814\n",
            "Epoch 949/1500\n",
            "876/876 [==============================] - 2s 3ms/step\n",
            "110/110 [==============================] - 9s 79ms/step - loss: 0.2983 - val_loss: 0.7843\n",
            "Epoch 950/1500\n",
            "876/876 [==============================] - 2s 3ms/step\n",
            "110/110 [==============================] - 5s 47ms/step - loss: 0.4279 - val_loss: 0.6901\n",
            "Epoch 951/1500\n",
            "876/876 [==============================] - 3s 3ms/step\n",
            "110/110 [==============================] - 9s 80ms/step - loss: 0.3708 - val_loss: 0.6610\n",
            "Epoch 952/1500\n",
            "876/876 [==============================] - 2s 3ms/step\n",
            "110/110 [==============================] - 5s 45ms/step - loss: 0.4317 - val_loss: 0.8542\n",
            "Epoch 953/1500\n",
            "876/876 [==============================] - 3s 3ms/step\n",
            "110/110 [==============================] - 8s 69ms/step - loss: 0.3939 - val_loss: 0.7122\n",
            "Epoch 954/1500\n",
            "876/876 [==============================] - 2s 3ms/step\n",
            "110/110 [==============================] - 5s 46ms/step - loss: 0.7754 - val_loss: 1.1049\n",
            "Epoch 955/1500\n",
            "876/876 [==============================] - 2s 3ms/step\n",
            "110/110 [==============================] - 5s 46ms/step - loss: 0.5400 - val_loss: 0.8499\n",
            "Epoch 956/1500\n",
            "876/876 [==============================] - 3s 3ms/step\n",
            "110/110 [==============================] - 7s 65ms/step - loss: 0.5441 - val_loss: 0.7348\n",
            "Epoch 957/1500\n",
            "876/876 [==============================] - 2s 3ms/step\n",
            "110/110 [==============================] - 5s 48ms/step - loss: 0.3723 - val_loss: 1.6650\n",
            "Epoch 958/1500\n",
            "876/876 [==============================] - 2s 3ms/step\n",
            "110/110 [==============================] - 5s 46ms/step - loss: 0.4822 - val_loss: 0.8186\n",
            "Epoch 959/1500\n",
            "876/876 [==============================] - 3s 3ms/step\n",
            "110/110 [==============================] - 9s 79ms/step - loss: 0.3877 - val_loss: 0.8053\n",
            "Epoch 960/1500\n",
            "876/876 [==============================] - 2s 3ms/step\n",
            "110/110 [==============================] - 5s 46ms/step - loss: 0.4994 - val_loss: 0.6925\n",
            "Epoch 961/1500\n",
            "876/876 [==============================] - 3s 3ms/step\n",
            "110/110 [==============================] - 5s 49ms/step - loss: 0.3934 - val_loss: 0.9889\n",
            "Epoch 962/1500\n",
            "876/876 [==============================] - 3s 3ms/step\n",
            "110/110 [==============================] - 7s 63ms/step - loss: 0.3401 - val_loss: 0.7340\n",
            "Epoch 963/1500\n",
            "876/876 [==============================] - 2s 3ms/step\n",
            "110/110 [==============================] - 5s 46ms/step - loss: 0.3721 - val_loss: 1.0152\n",
            "Epoch 964/1500\n",
            "876/876 [==============================] - 3s 3ms/step\n",
            "110/110 [==============================] - 8s 69ms/step - loss: 0.7501 - val_loss: 0.7505\n",
            "Epoch 965/1500\n",
            "876/876 [==============================] - 2s 3ms/step\n",
            "110/110 [==============================] - 5s 46ms/step - loss: 0.2952 - val_loss: 0.8986\n",
            "Epoch 966/1500\n",
            "876/876 [==============================] - 2s 3ms/step\n",
            "110/110 [==============================] - 8s 69ms/step - loss: 0.5547 - val_loss: 0.6912\n",
            "Epoch 967/1500\n",
            "876/876 [==============================] - 2s 3ms/step\n",
            "110/110 [==============================] - 8s 72ms/step - loss: 0.4294 - val_loss: 1.0072\n",
            "Epoch 968/1500\n",
            "876/876 [==============================] - 3s 3ms/step\n",
            "110/110 [==============================] - 6s 52ms/step - loss: 0.3890 - val_loss: 0.8717\n",
            "Epoch 969/1500\n",
            "876/876 [==============================] - 3s 3ms/step\n",
            "110/110 [==============================] - 9s 82ms/step - loss: 0.4116 - val_loss: 1.1980\n",
            "Epoch 970/1500\n",
            "876/876 [==============================] - 2s 3ms/step\n",
            "110/110 [==============================] - 8s 69ms/step - loss: 1.1836 - val_loss: 1.3465\n",
            "Epoch 971/1500\n",
            "876/876 [==============================] - 2s 3ms/step\n",
            "110/110 [==============================] - 6s 58ms/step - loss: 0.4891 - val_loss: 0.7401\n",
            "Epoch 972/1500\n",
            "876/876 [==============================] - 2s 3ms/step\n",
            "110/110 [==============================] - 8s 69ms/step - loss: 0.3388 - val_loss: 0.9096\n",
            "Epoch 973/1500\n",
            "876/876 [==============================] - 2s 3ms/step\n",
            "110/110 [==============================] - 9s 84ms/step - loss: 0.5864 - val_loss: 0.8687\n",
            "Epoch 974/1500\n",
            "876/876 [==============================] - 2s 3ms/step\n",
            "110/110 [==============================] - 5s 45ms/step - loss: 0.3256 - val_loss: 0.7121\n",
            "Epoch 975/1500\n",
            "876/876 [==============================] - 3s 3ms/step\n",
            "110/110 [==============================] - 7s 63ms/step - loss: 0.3698 - val_loss: 0.7360\n",
            "Epoch 976/1500\n",
            "876/876 [==============================] - 2s 3ms/step\n",
            "110/110 [==============================] - 8s 76ms/step - loss: 0.3523 - val_loss: 0.6708\n",
            "Epoch 977/1500\n",
            "876/876 [==============================] - 3s 3ms/step\n",
            "110/110 [==============================] - 5s 48ms/step - loss: 0.4151 - val_loss: 0.8888\n",
            "Epoch 978/1500\n",
            "876/876 [==============================] - 3s 3ms/step\n",
            "110/110 [==============================] - 9s 82ms/step - loss: 0.4117 - val_loss: 0.6743\n",
            "Epoch 979/1500\n",
            "876/876 [==============================] - 2s 3ms/step\n",
            "110/110 [==============================] - 5s 46ms/step - loss: 0.4214 - val_loss: 0.9784\n",
            "Epoch 980/1500\n",
            "876/876 [==============================] - 3s 3ms/step\n",
            "110/110 [==============================] - 6s 55ms/step - loss: 0.5761 - val_loss: 0.7240\n",
            "Epoch 981/1500\n",
            "876/876 [==============================] - 2s 3ms/step\n",
            "110/110 [==============================] - 6s 56ms/step - loss: 0.5929 - val_loss: 0.7809\n",
            "Epoch 982/1500\n",
            "876/876 [==============================] - 2s 3ms/step\n",
            "110/110 [==============================] - 8s 69ms/step - loss: 0.3531 - val_loss: 1.5115\n",
            "Epoch 983/1500\n",
            "876/876 [==============================] - 3s 3ms/step\n",
            "110/110 [==============================] - 9s 82ms/step - loss: 0.6583 - val_loss: 1.0199\n",
            "Epoch 984/1500\n",
            "876/876 [==============================] - 2s 3ms/step\n",
            "110/110 [==============================] - 8s 69ms/step - loss: 0.4152 - val_loss: 0.8041\n",
            "Epoch 985/1500\n",
            "876/876 [==============================] - 2s 3ms/step\n",
            "110/110 [==============================] - 9s 82ms/step - loss: 0.3069 - val_loss: 0.7273\n",
            "Epoch 986/1500\n",
            "876/876 [==============================] - 2s 3ms/step\n",
            "110/110 [==============================] - 8s 69ms/step - loss: 0.3498 - val_loss: 1.9370\n",
            "Epoch 987/1500\n",
            "876/876 [==============================] - 2s 3ms/step\n",
            "110/110 [==============================] - 5s 46ms/step - loss: 0.5626 - val_loss: 1.1061\n",
            "Epoch 988/1500\n",
            "876/876 [==============================] - 2s 3ms/step\n",
            "110/110 [==============================] - 5s 46ms/step - loss: 0.5074 - val_loss: 0.8429\n",
            "Epoch 989/1500\n",
            "876/876 [==============================] - 3s 3ms/step\n",
            "110/110 [==============================] - 9s 83ms/step - loss: 0.4528 - val_loss: 1.8304\n",
            "Epoch 990/1500\n",
            "876/876 [==============================] - 2s 3ms/step\n",
            "110/110 [==============================] - 5s 46ms/step - loss: 0.5635 - val_loss: 1.2284\n",
            "Epoch 991/1500\n",
            "876/876 [==============================] - 3s 3ms/step\n",
            "110/110 [==============================] - 6s 51ms/step - loss: 0.5084 - val_loss: 1.0622\n",
            "Epoch 992/1500\n",
            "876/876 [==============================] - 3s 3ms/step\n",
            "110/110 [==============================] - 7s 62ms/step - loss: 0.4230 - val_loss: 0.7320\n",
            "Epoch 993/1500\n",
            "876/876 [==============================] - 2s 3ms/step\n",
            "110/110 [==============================] - 8s 69ms/step - loss: 0.3487 - val_loss: 0.6988\n",
            "Epoch 994/1500\n",
            "876/876 [==============================] - 3s 3ms/step\n",
            "110/110 [==============================] - 8s 77ms/step - loss: 0.3912 - val_loss: 0.9291\n",
            "Epoch 995/1500\n",
            "876/876 [==============================] - 2s 3ms/step\n",
            "110/110 [==============================] - 7s 69ms/step - loss: 0.5432 - val_loss: 1.1045\n",
            "Epoch 996/1500\n",
            "876/876 [==============================] - 3s 3ms/step\n",
            "110/110 [==============================] - 6s 59ms/step - loss: 0.4279 - val_loss: 0.7984\n",
            "Epoch 997/1500\n",
            "876/876 [==============================] - 2s 3ms/step\n",
            "110/110 [==============================] - 6s 56ms/step - loss: 0.3927 - val_loss: 0.7335\n",
            "Epoch 998/1500\n",
            "876/876 [==============================] - 2s 3ms/step\n",
            "110/110 [==============================] - 8s 69ms/step - loss: 0.4579 - val_loss: 1.2715\n",
            "Epoch 999/1500\n",
            "876/876 [==============================] - 3s 3ms/step\n",
            "110/110 [==============================] - 7s 63ms/step - loss: 0.5187 - val_loss: 1.8922\n",
            "Epoch 1000/1500\n",
            "876/876 [==============================] - 2s 3ms/step\n",
            "110/110 [==============================] - 8s 69ms/step - loss: 0.4844 - val_loss: 0.7798\n",
            "Epoch 1001/1500\n",
            "876/876 [==============================] - 3s 3ms/step\n",
            "110/110 [==============================] - 8s 75ms/step - loss: 0.4718 - val_loss: 3.2860\n",
            "Epoch 1002/1500\n",
            "876/876 [==============================] - 2s 3ms/step\n",
            "110/110 [==============================] - 8s 69ms/step - loss: 0.5138 - val_loss: 0.7092\n",
            "Epoch 1003/1500\n",
            "876/876 [==============================] - 3s 3ms/step\n",
            "110/110 [==============================] - 6s 56ms/step - loss: 0.3084 - val_loss: 0.7004\n",
            "Epoch 1004/1500\n",
            "876/876 [==============================] - 2s 3ms/step\n",
            "110/110 [==============================] - 9s 82ms/step - loss: 0.2682 - val_loss: 0.8029\n",
            "Epoch 1005/1500\n",
            "876/876 [==============================] - 2s 3ms/step\n",
            "110/110 [==============================] - 7s 68ms/step - loss: 0.6701 - val_loss: 0.9343\n",
            "Epoch 1006/1500\n",
            "876/876 [==============================] - 2s 3ms/step\n",
            "110/110 [==============================] - 5s 49ms/step - loss: 0.7744 - val_loss: 1.1474\n",
            "Epoch 1007/1500\n",
            "876/876 [==============================] - 2s 3ms/step\n",
            "110/110 [==============================] - 8s 69ms/step - loss: 0.4044 - val_loss: 0.8448\n",
            "Epoch 1008/1500\n",
            "876/876 [==============================] - 2s 3ms/step\n",
            "110/110 [==============================] - 5s 49ms/step - loss: 0.3657 - val_loss: 0.9087\n",
            "Epoch 1009/1500\n",
            "876/876 [==============================] - 2s 3ms/step\n",
            "110/110 [==============================] - 7s 68ms/step - loss: 0.2838 - val_loss: 0.7235\n",
            "Epoch 1010/1500\n",
            "876/876 [==============================] - 2s 3ms/step\n",
            "110/110 [==============================] - 8s 75ms/step - loss: 0.2772 - val_loss: 0.7268\n",
            "Epoch 1011/1500\n",
            "876/876 [==============================] - 2s 3ms/step\n",
            "110/110 [==============================] - 5s 49ms/step - loss: 0.4879 - val_loss: 1.2439\n",
            "Epoch 1012/1500\n",
            "876/876 [==============================] - 3s 3ms/step\n",
            "110/110 [==============================] - 7s 63ms/step - loss: 0.6039 - val_loss: 0.9768\n",
            "Epoch 1013/1500\n",
            "876/876 [==============================] - 2s 3ms/step\n",
            "110/110 [==============================] - 5s 46ms/step - loss: 0.3351 - val_loss: 0.8701\n",
            "Epoch 1014/1500\n",
            "876/876 [==============================] - 3s 3ms/step\n",
            "110/110 [==============================] - 8s 69ms/step - loss: 0.4052 - val_loss: 1.3374\n",
            "Epoch 1015/1500\n",
            "876/876 [==============================] - 2s 3ms/step\n",
            "110/110 [==============================] - 5s 47ms/step - loss: 0.5292 - val_loss: 0.9526\n",
            "Epoch 1016/1500\n",
            "876/876 [==============================] - 2s 3ms/step\n",
            "110/110 [==============================] - 8s 69ms/step - loss: 0.5403 - val_loss: 0.8049\n",
            "Epoch 1017/1500\n",
            "876/876 [==============================] - 2s 3ms/step\n",
            "110/110 [==============================] - 8s 70ms/step - loss: 0.4141 - val_loss: 0.8383\n",
            "Epoch 1018/1500\n",
            "876/876 [==============================] - 3s 3ms/step\n",
            "110/110 [==============================] - 8s 69ms/step - loss: 0.4743 - val_loss: 3.1633\n",
            "Epoch 1019/1500\n",
            "876/876 [==============================] - 2s 3ms/step\n",
            "110/110 [==============================] - 8s 69ms/step - loss: 0.5156 - val_loss: 1.1822\n",
            "Epoch 1020/1500\n",
            "876/876 [==============================] - 3s 3ms/step\n",
            "110/110 [==============================] - 8s 70ms/step - loss: 0.4488 - val_loss: 0.7308\n",
            "Epoch 1021/1500\n",
            "876/876 [==============================] - 2s 3ms/step\n",
            "110/110 [==============================] - 8s 69ms/step - loss: 0.4852 - val_loss: 0.8637\n",
            "Epoch 1022/1500\n",
            "876/876 [==============================] - 3s 3ms/step\n",
            "110/110 [==============================] - 6s 55ms/step - loss: 0.4404 - val_loss: 0.9672\n",
            "Epoch 1023/1500\n",
            "876/876 [==============================] - 2s 3ms/step\n",
            "110/110 [==============================] - 9s 80ms/step - loss: 0.3866 - val_loss: 0.9594\n",
            "Epoch 1024/1500\n",
            "876/876 [==============================] - 2s 3ms/step\n",
            "110/110 [==============================] - 8s 69ms/step - loss: 0.3187 - val_loss: 0.6824\n",
            "Epoch 1025/1500\n",
            "876/876 [==============================] - 2s 3ms/step\n",
            "110/110 [==============================] - 7s 68ms/step - loss: 1.1170 - val_loss: 1.4998\n",
            "Epoch 1026/1500\n",
            "876/876 [==============================] - 3s 3ms/step\n",
            "110/110 [==============================] - 8s 69ms/step - loss: 0.9247 - val_loss: 0.8520\n",
            "Epoch 1027/1500\n",
            "876/876 [==============================] - 2s 3ms/step\n",
            "110/110 [==============================] - 8s 69ms/step - loss: 0.3913 - val_loss: 0.7188\n",
            "Epoch 1028/1500\n",
            "876/876 [==============================] - 3s 3ms/step\n",
            "110/110 [==============================] - 6s 54ms/step - loss: 0.3075 - val_loss: 0.7773\n",
            "Epoch 1029/1500\n",
            "876/876 [==============================] - 2s 3ms/step\n",
            "110/110 [==============================] - 6s 59ms/step - loss: 0.2795 - val_loss: 0.7378\n",
            "Epoch 1030/1500\n",
            "876/876 [==============================] - 2s 3ms/step\n",
            "110/110 [==============================] - 5s 46ms/step - loss: 0.3414 - val_loss: 1.1458\n",
            "Epoch 1031/1500\n",
            "876/876 [==============================] - 3s 3ms/step\n",
            "110/110 [==============================] - 8s 71ms/step - loss: 0.4973 - val_loss: 1.1851\n",
            "Epoch 1032/1500\n",
            "876/876 [==============================] - 2s 3ms/step\n",
            "110/110 [==============================] - 5s 47ms/step - loss: 0.4723 - val_loss: 1.0590\n",
            "Epoch 1033/1500\n",
            "876/876 [==============================] - 2s 3ms/step\n",
            "110/110 [==============================] - 5s 49ms/step - loss: 0.4725 - val_loss: 0.7275\n",
            "Epoch 1034/1500\n",
            "876/876 [==============================] - 3s 3ms/step\n",
            "110/110 [==============================] - 9s 83ms/step - loss: 0.3783 - val_loss: 0.7787\n",
            "Epoch 1035/1500\n",
            "876/876 [==============================] - 2s 3ms/step\n",
            "110/110 [==============================] - 8s 70ms/step - loss: 0.2785 - val_loss: 0.8642\n",
            "Epoch 1036/1500\n",
            "876/876 [==============================] - 3s 3ms/step\n",
            "110/110 [==============================] - 9s 84ms/step - loss: 1.1132 - val_loss: 1.8377\n",
            "Epoch 1037/1500\n",
            "876/876 [==============================] - 2s 3ms/step\n",
            "110/110 [==============================] - 5s 47ms/step - loss: 0.4161 - val_loss: 0.8523\n",
            "Epoch 1038/1500\n",
            "876/876 [==============================] - 3s 3ms/step\n",
            "110/110 [==============================] - 8s 74ms/step - loss: 0.7854 - val_loss: 0.8334\n",
            "Epoch 1039/1500\n",
            "876/876 [==============================] - 2s 3ms/step\n",
            "110/110 [==============================] - 8s 70ms/step - loss: 0.4219 - val_loss: 0.6694\n",
            "Epoch 1040/1500\n",
            "876/876 [==============================] - 3s 3ms/step\n",
            "110/110 [==============================] - 6s 59ms/step - loss: 0.3157 - val_loss: 0.6865\n",
            "Epoch 1041/1500\n",
            "876/876 [==============================] - 2s 3ms/step\n",
            "110/110 [==============================] - 9s 79ms/step - loss: 0.2754 - val_loss: 0.6850\n",
            "Epoch 1042/1500\n",
            "876/876 [==============================] - 3s 3ms/step\n",
            "110/110 [==============================] - 6s 50ms/step - loss: 0.3504 - val_loss: 0.7250\n",
            "Epoch 1043/1500\n",
            "876/876 [==============================] - 3s 3ms/step\n",
            "110/110 [==============================] - 9s 82ms/step - loss: 0.7984 - val_loss: 0.7956\n",
            "Epoch 1044/1500\n",
            "876/876 [==============================] - 2s 3ms/step\n",
            "110/110 [==============================] - 5s 47ms/step - loss: 0.4785 - val_loss: 0.6786\n",
            "Epoch 1045/1500\n",
            "876/876 [==============================] - 3s 3ms/step\n",
            "110/110 [==============================] - 8s 73ms/step - loss: 0.3476 - val_loss: 0.8195\n",
            "Epoch 1046/1500\n",
            "876/876 [==============================] - 2s 3ms/step\n",
            "110/110 [==============================] - 5s 46ms/step - loss: 0.8165 - val_loss: 0.8894\n",
            "Epoch 1047/1500\n",
            "876/876 [==============================] - 3s 3ms/step\n",
            "110/110 [==============================] - 6s 50ms/step - loss: 0.4146 - val_loss: 0.7122\n",
            "Epoch 1048/1500\n",
            "876/876 [==============================] - 3s 3ms/step\n",
            "110/110 [==============================] - 9s 82ms/step - loss: 0.3674 - val_loss: 0.8408\n",
            "Epoch 1049/1500\n",
            "876/876 [==============================] - 2s 3ms/step\n",
            "110/110 [==============================] - 8s 70ms/step - loss: 0.2526 - val_loss: 0.6731\n",
            "Epoch 1050/1500\n",
            "876/876 [==============================] - 3s 3ms/step\n",
            "110/110 [==============================] - 9s 84ms/step - loss: 0.4471 - val_loss: 1.0307\n",
            "Epoch 1051/1500\n",
            "876/876 [==============================] - 2s 3ms/step\n",
            "110/110 [==============================] - 8s 70ms/step - loss: 0.2968 - val_loss: 0.6949\n",
            "Epoch 1052/1500\n",
            "876/876 [==============================] - 3s 3ms/step\n",
            "110/110 [==============================] - 9s 82ms/step - loss: 0.2807 - val_loss: 0.6604\n",
            "Epoch 1053/1500\n",
            "876/876 [==============================] - 2s 3ms/step\n",
            "110/110 [==============================] - 8s 69ms/step - loss: 0.6669 - val_loss: 0.9674\n",
            "Epoch 1054/1500\n",
            "876/876 [==============================] - 2s 3ms/step\n",
            "110/110 [==============================] - 9s 86ms/step - loss: 0.4983 - val_loss: 1.1700\n",
            "Epoch 1055/1500\n",
            "876/876 [==============================] - 2s 3ms/step\n",
            "110/110 [==============================] - 5s 48ms/step - loss: 0.3294 - val_loss: 0.6669\n",
            "Epoch 1056/1500\n",
            "876/876 [==============================] - 3s 3ms/step\n",
            "110/110 [==============================] - 7s 67ms/step - loss: 0.3652 - val_loss: 0.7804\n",
            "Epoch 1057/1500\n",
            "876/876 [==============================] - 2s 3ms/step\n",
            "110/110 [==============================] - 8s 69ms/step - loss: 0.6329 - val_loss: 0.7107\n",
            "Epoch 1058/1500\n",
            "876/876 [==============================] - 3s 3ms/step\n",
            "110/110 [==============================] - 8s 76ms/step - loss: 0.4951 - val_loss: 0.7563\n",
            "Epoch 1059/1500\n",
            "876/876 [==============================] - 2s 3ms/step\n",
            "110/110 [==============================] - 5s 47ms/step - loss: 0.3308 - val_loss: 0.7121\n",
            "Epoch 1060/1500\n",
            "876/876 [==============================] - 3s 3ms/step\n",
            "110/110 [==============================] - 8s 69ms/step - loss: 0.3371 - val_loss: 0.8837\n",
            "Epoch 1061/1500\n",
            "876/876 [==============================] - 2s 3ms/step\n",
            "110/110 [==============================] - 5s 46ms/step - loss: 0.6915 - val_loss: 1.1226\n",
            "Epoch 1062/1500\n",
            "876/876 [==============================] - 2s 3ms/step\n",
            "110/110 [==============================] - 5s 49ms/step - loss: 0.6570 - val_loss: 1.0579\n",
            "Epoch 1063/1500\n",
            "876/876 [==============================] - 3s 3ms/step\n",
            "110/110 [==============================] - 7s 66ms/step - loss: 0.4268 - val_loss: 0.8120\n",
            "Epoch 1064/1500\n",
            "876/876 [==============================] - 2s 3ms/step\n",
            "110/110 [==============================] - 5s 47ms/step - loss: 0.2513 - val_loss: 0.8161\n",
            "Epoch 1065/1500\n",
            "876/876 [==============================] - 3s 3ms/step\n",
            "110/110 [==============================] - 8s 69ms/step - loss: 0.4794 - val_loss: 1.3955\n",
            "Epoch 1066/1500\n",
            "876/876 [==============================] - 2s 3ms/step\n",
            "110/110 [==============================] - 8s 70ms/step - loss: 0.3238 - val_loss: 0.7189\n",
            "Epoch 1067/1500\n",
            "876/876 [==============================] - 3s 3ms/step\n",
            "110/110 [==============================] - 8s 71ms/step - loss: 0.5802 - val_loss: 0.7831\n",
            "Epoch 1068/1500\n",
            "876/876 [==============================] - 2s 3ms/step\n",
            "110/110 [==============================] - 5s 47ms/step - loss: 0.3166 - val_loss: 1.0716\n",
            "Epoch 1069/1500\n",
            "876/876 [==============================] - 3s 3ms/step\n",
            "110/110 [==============================] - 8s 69ms/step - loss: 0.6119 - val_loss: 0.7933\n",
            "Epoch 1070/1500\n",
            "876/876 [==============================] - 2s 3ms/step\n",
            "110/110 [==============================] - 5s 49ms/step - loss: 0.4440 - val_loss: 0.8106\n",
            "Epoch 1071/1500\n",
            "876/876 [==============================] - 2s 3ms/step\n",
            "110/110 [==============================] - 5s 49ms/step - loss: 0.4709 - val_loss: 0.6896\n",
            "Epoch 1072/1500\n",
            "876/876 [==============================] - 3s 3ms/step\n",
            "110/110 [==============================] - 7s 67ms/step - loss: 0.6818 - val_loss: 0.8218\n",
            "Epoch 1073/1500\n",
            "876/876 [==============================] - 2s 3ms/step\n",
            "110/110 [==============================] - 5s 48ms/step - loss: 0.3713 - val_loss: 0.7986\n",
            "Epoch 1074/1500\n",
            "876/876 [==============================] - 2s 3ms/step\n",
            "110/110 [==============================] - 5s 49ms/step - loss: 0.3206 - val_loss: 0.6590\n",
            "Epoch 1075/1500\n",
            "876/876 [==============================] - 3s 3ms/step\n",
            "110/110 [==============================] - 7s 66ms/step - loss: 0.3250 - val_loss: 0.7700\n",
            "Epoch 1076/1500\n",
            "876/876 [==============================] - 2s 3ms/step\n",
            "110/110 [==============================] - 5s 48ms/step - loss: 0.3414 - val_loss: 0.8147\n",
            "Epoch 1077/1500\n",
            "876/876 [==============================] - 3s 3ms/step\n",
            "110/110 [==============================] - 8s 70ms/step - loss: 0.8605 - val_loss: 0.7593\n",
            "Epoch 1078/1500\n",
            "876/876 [==============================] - 2s 3ms/step\n",
            "110/110 [==============================] - 5s 48ms/step - loss: 0.2759 - val_loss: 0.7218\n",
            "Epoch 1079/1500\n",
            "876/876 [==============================] - 2s 3ms/step\n",
            "110/110 [==============================] - 5s 48ms/step - loss: 0.3622 - val_loss: 2.9478\n",
            "Epoch 1080/1500\n",
            "876/876 [==============================] - 3s 3ms/step\n",
            "110/110 [==============================] - 8s 68ms/step - loss: 0.5400 - val_loss: 1.4793\n",
            "Epoch 1081/1500\n",
            "876/876 [==============================] - 2s 3ms/step\n",
            "110/110 [==============================] - 8s 72ms/step - loss: 0.6560 - val_loss: 3.9166\n",
            "Epoch 1082/1500\n",
            "876/876 [==============================] - 3s 3ms/step\n",
            "110/110 [==============================] - 7s 61ms/step - loss: 0.5393 - val_loss: 1.2677\n",
            "Epoch 1083/1500\n",
            "876/876 [==============================] - 2s 3ms/step\n",
            "110/110 [==============================] - 6s 55ms/step - loss: 0.2871 - val_loss: 0.6657\n",
            "Epoch 1084/1500\n",
            "876/876 [==============================] - 2s 3ms/step\n",
            "110/110 [==============================] - 8s 71ms/step - loss: 0.3645 - val_loss: 0.7656\n",
            "Epoch 1085/1500\n",
            "876/876 [==============================] - 2s 3ms/step\n",
            "110/110 [==============================] - 6s 57ms/step - loss: 0.4889 - val_loss: 0.8468\n",
            "Epoch 1086/1500\n",
            "876/876 [==============================] - 2s 3ms/step\n",
            "110/110 [==============================] - 8s 69ms/step - loss: 0.3409 - val_loss: 0.7623\n",
            "Epoch 1087/1500\n",
            "876/876 [==============================] - 2s 3ms/step\n",
            "110/110 [==============================] - 9s 83ms/step - loss: 0.4880 - val_loss: 0.7202\n",
            "Epoch 1088/1500\n",
            "876/876 [==============================] - 2s 3ms/step\n",
            "110/110 [==============================] - 5s 49ms/step - loss: 0.3125 - val_loss: 1.5563\n",
            "Epoch 1089/1500\n",
            "876/876 [==============================] - 3s 3ms/step\n",
            "110/110 [==============================] - 9s 82ms/step - loss: 0.5848 - val_loss: 0.7713\n",
            "Epoch 1090/1500\n",
            "876/876 [==============================] - 2s 3ms/step\n",
            "110/110 [==============================] - 5s 47ms/step - loss: 0.3793 - val_loss: 0.8563\n",
            "Epoch 1091/1500\n",
            "876/876 [==============================] - 3s 3ms/step\n",
            "110/110 [==============================] - 8s 71ms/step - loss: 0.4162 - val_loss: 0.6801\n",
            "Epoch 1092/1500\n",
            "876/876 [==============================] - 2s 3ms/step\n",
            "110/110 [==============================] - 8s 70ms/step - loss: 0.2692 - val_loss: 0.6747\n",
            "Epoch 1093/1500\n",
            "876/876 [==============================] - 3s 3ms/step\n",
            "110/110 [==============================] - 8s 71ms/step - loss: 0.4187 - val_loss: 0.9239\n",
            "Epoch 1094/1500\n",
            "876/876 [==============================] - 2s 3ms/step\n",
            "110/110 [==============================] - 5s 48ms/step - loss: 0.5039 - val_loss: 1.1374\n",
            "Epoch 1095/1500\n",
            "876/876 [==============================] - 2s 3ms/step\n",
            "110/110 [==============================] - 8s 70ms/step - loss: 0.6859 - val_loss: 1.0187\n",
            "Epoch 1096/1500\n",
            "876/876 [==============================] - 2s 3ms/step\n",
            "110/110 [==============================] - 8s 71ms/step - loss: 0.3612 - val_loss: 2.5284\n",
            "Epoch 1097/1500\n",
            "876/876 [==============================] - 3s 3ms/step\n",
            "110/110 [==============================] - 6s 54ms/step - loss: 0.6100 - val_loss: 0.7107\n",
            "Epoch 1098/1500\n",
            "876/876 [==============================] - 3s 3ms/step\n",
            "110/110 [==============================] - 7s 64ms/step - loss: 0.3210 - val_loss: 0.7506\n",
            "Epoch 1099/1500\n",
            "876/876 [==============================] - 2s 3ms/step\n",
            "110/110 [==============================] - 8s 70ms/step - loss: 0.3090 - val_loss: 1.2377\n",
            "Epoch 1100/1500\n",
            "876/876 [==============================] - 3s 3ms/step\n",
            "110/110 [==============================] - 7s 66ms/step - loss: 0.5288 - val_loss: 0.7327\n",
            "Epoch 1101/1500\n",
            "876/876 [==============================] - 2s 3ms/step\n",
            "110/110 [==============================] - 6s 54ms/step - loss: 0.3739 - val_loss: 0.6999\n",
            "Epoch 1102/1500\n",
            "876/876 [==============================] - 2s 3ms/step\n",
            "110/110 [==============================] - 8s 70ms/step - loss: 0.4676 - val_loss: 0.9278\n",
            "Epoch 1103/1500\n",
            "876/876 [==============================] - 2s 3ms/step\n",
            "110/110 [==============================] - 6s 54ms/step - loss: 0.5085 - val_loss: 0.9903\n",
            "Epoch 1104/1500\n",
            "876/876 [==============================] - 2s 3ms/step\n",
            "110/110 [==============================] - 5s 47ms/step - loss: 0.3300 - val_loss: 0.7480\n",
            "Epoch 1105/1500\n",
            "876/876 [==============================] - 3s 3ms/step\n",
            "110/110 [==============================] - 7s 65ms/step - loss: 0.5746 - val_loss: 1.1247\n",
            "Epoch 1106/1500\n",
            "876/876 [==============================] - 2s 3ms/step\n",
            "110/110 [==============================] - 6s 53ms/step - loss: 0.9209 - val_loss: 0.7515\n",
            "Epoch 1107/1500\n",
            "876/876 [==============================] - 2s 3ms/step\n",
            "110/110 [==============================] - 8s 70ms/step - loss: 0.4439 - val_loss: 1.1088\n",
            "Epoch 1108/1500\n",
            "876/876 [==============================] - 2s 3ms/step\n",
            "110/110 [==============================] - 6s 51ms/step - loss: 0.2727 - val_loss: 0.7834\n",
            "Epoch 1109/1500\n",
            "876/876 [==============================] - 2s 3ms/step\n",
            "110/110 [==============================] - 5s 48ms/step - loss: 0.2692 - val_loss: 0.7227\n",
            "Epoch 1110/1500\n",
            "876/876 [==============================] - 3s 4ms/step\n",
            "110/110 [==============================] - 8s 71ms/step - loss: 0.3159 - val_loss: 1.2442\n",
            "Epoch 1111/1500\n",
            "876/876 [==============================] - 2s 3ms/step\n",
            "110/110 [==============================] - 8s 70ms/step - loss: 0.4516 - val_loss: 0.6721\n",
            "Epoch 1112/1500\n",
            "876/876 [==============================] - 3s 3ms/step\n",
            "110/110 [==============================] - 7s 61ms/step - loss: 0.3004 - val_loss: 0.8460\n",
            "Epoch 1113/1500\n",
            "876/876 [==============================] - 2s 3ms/step\n",
            "110/110 [==============================] - 9s 78ms/step - loss: 0.2625 - val_loss: 1.0409\n",
            "Epoch 1114/1500\n",
            "876/876 [==============================] - 3s 3ms/step\n",
            "110/110 [==============================] - 8s 70ms/step - loss: 0.6973 - val_loss: 3.2262\n",
            "Epoch 1115/1500\n",
            "876/876 [==============================] - 3s 3ms/step\n",
            "110/110 [==============================] - 8s 70ms/step - loss: 0.4030 - val_loss: 0.7733\n",
            "Epoch 1116/1500\n",
            "876/876 [==============================] - 3s 3ms/step\n",
            "110/110 [==============================] - 8s 70ms/step - loss: 0.6757 - val_loss: 1.3429\n",
            "Epoch 1117/1500\n",
            "876/876 [==============================] - 2s 3ms/step\n",
            "110/110 [==============================] - 8s 70ms/step - loss: 0.5100 - val_loss: 0.7395\n",
            "Epoch 1118/1500\n",
            "876/876 [==============================] - 3s 3ms/step\n",
            "110/110 [==============================] - 6s 55ms/step - loss: 0.2646 - val_loss: 0.7148\n",
            "Epoch 1119/1500\n",
            "876/876 [==============================] - 3s 3ms/step\n",
            "110/110 [==============================] - 7s 61ms/step - loss: 0.5515 - val_loss: 0.9390\n",
            "Epoch 1120/1500\n",
            "876/876 [==============================] - 2s 3ms/step\n",
            "110/110 [==============================] - 8s 69ms/step - loss: 0.4575 - val_loss: 0.7506\n",
            "Epoch 1121/1500\n",
            "876/876 [==============================] - 3s 3ms/step\n",
            "110/110 [==============================] - 7s 64ms/step - loss: 0.4883 - val_loss: 0.8042\n",
            "Epoch 1122/1500\n",
            "876/876 [==============================] - 3s 3ms/step\n",
            "110/110 [==============================] - 8s 70ms/step - loss: 0.2831 - val_loss: 0.7105\n",
            "Epoch 1123/1500\n",
            "876/876 [==============================] - 3s 3ms/step\n",
            "110/110 [==============================] - 8s 77ms/step - loss: 0.3446 - val_loss: 0.8018\n",
            "Epoch 1124/1500\n",
            "876/876 [==============================] - 3s 3ms/step\n",
            "110/110 [==============================] - 8s 70ms/step - loss: 0.3261 - val_loss: 0.9511\n",
            "Epoch 1125/1500\n",
            "876/876 [==============================] - 3s 3ms/step\n",
            "110/110 [==============================] - 8s 75ms/step - loss: 0.6533 - val_loss: 0.8030\n",
            "Epoch 1126/1500\n",
            "876/876 [==============================] - 2s 3ms/step\n",
            "110/110 [==============================] - 8s 70ms/step - loss: 0.2900 - val_loss: 0.6995\n",
            "Epoch 1127/1500\n",
            "876/876 [==============================] - 3s 3ms/step\n",
            "110/110 [==============================] - 8s 74ms/step - loss: 0.3254 - val_loss: 0.9274\n",
            "Epoch 1128/1500\n",
            "876/876 [==============================] - 2s 3ms/step\n",
            "110/110 [==============================] - 8s 70ms/step - loss: 0.3010 - val_loss: 0.6990\n",
            "Epoch 1129/1500\n",
            "876/876 [==============================] - 3s 3ms/step\n",
            "110/110 [==============================] - 6s 57ms/step - loss: 0.8074 - val_loss: 0.7147\n",
            "Epoch 1130/1500\n",
            "876/876 [==============================] - 2s 3ms/step\n",
            "110/110 [==============================] - 9s 86ms/step - loss: 0.3649 - val_loss: 0.6937\n",
            "Epoch 1131/1500\n",
            "876/876 [==============================] - 3s 3ms/step\n",
            "110/110 [==============================] - 6s 50ms/step - loss: 0.4303 - val_loss: 0.8827\n",
            "Epoch 1132/1500\n",
            "876/876 [==============================] - 3s 3ms/step\n",
            "110/110 [==============================] - 9s 83ms/step - loss: 0.3512 - val_loss: 0.7248\n",
            "Epoch 1133/1500\n",
            "876/876 [==============================] - 2s 3ms/step\n",
            "110/110 [==============================] - 5s 48ms/step - loss: 0.2814 - val_loss: 1.2382\n",
            "Epoch 1134/1500\n",
            "876/876 [==============================] - 3s 3ms/step\n",
            "110/110 [==============================] - 6s 55ms/step - loss: 0.2742 - val_loss: 0.9961\n",
            "Epoch 1135/1500\n",
            "876/876 [==============================] - 3s 3ms/step\n",
            "110/110 [==============================] - 9s 84ms/step - loss: 0.4165 - val_loss: 1.6075\n",
            "Epoch 1136/1500\n",
            "876/876 [==============================] - 2s 3ms/step\n",
            "110/110 [==============================] - 8s 70ms/step - loss: 0.5641 - val_loss: 1.4694\n",
            "Epoch 1137/1500\n",
            "876/876 [==============================] - 2s 3ms/step\n",
            "110/110 [==============================] - 8s 73ms/step - loss: 0.5343 - val_loss: 0.8220\n",
            "Epoch 1138/1500\n",
            "876/876 [==============================] - 3s 3ms/step\n",
            "110/110 [==============================] - 8s 70ms/step - loss: 0.3524 - val_loss: 1.6186\n",
            "Epoch 1139/1500\n",
            "876/876 [==============================] - 2s 3ms/step\n",
            "110/110 [==============================] - 5s 47ms/step - loss: 0.4379 - val_loss: 0.8019\n",
            "Epoch 1140/1500\n",
            "876/876 [==============================] - 3s 3ms/step\n",
            "110/110 [==============================] - 8s 71ms/step - loss: 0.2441 - val_loss: 0.8112\n",
            "Epoch 1141/1500\n",
            "876/876 [==============================] - 2s 3ms/step\n",
            "110/110 [==============================] - 6s 50ms/step - loss: 0.3738 - val_loss: 0.8864\n",
            "Epoch 1142/1500\n",
            "876/876 [==============================] - 2s 3ms/step\n",
            "110/110 [==============================] - 5s 49ms/step - loss: 0.6190 - val_loss: 1.7000\n",
            "Epoch 1143/1500\n",
            "876/876 [==============================] - 3s 3ms/step\n",
            "110/110 [==============================] - 9s 81ms/step - loss: 0.3888 - val_loss: 1.0407\n",
            "Epoch 1144/1500\n",
            "876/876 [==============================] - 2s 3ms/step\n",
            "110/110 [==============================] - 5s 49ms/step - loss: 0.3553 - val_loss: 0.7843\n",
            "Epoch 1145/1500\n",
            "876/876 [==============================] - 3s 3ms/step\n",
            "110/110 [==============================] - 6s 53ms/step - loss: 0.3947 - val_loss: 0.9723\n",
            "Epoch 1146/1500\n",
            "876/876 [==============================] - 3s 3ms/step\n",
            "110/110 [==============================] - 9s 80ms/step - loss: 0.5377 - val_loss: 0.9237\n",
            "Epoch 1147/1500\n",
            "876/876 [==============================] - 2s 3ms/step\n",
            "110/110 [==============================] - 8s 70ms/step - loss: 0.4650 - val_loss: 1.3587\n",
            "Epoch 1148/1500\n",
            "876/876 [==============================] - 3s 3ms/step\n",
            "110/110 [==============================] - 7s 63ms/step - loss: 0.4610 - val_loss: 0.7837\n",
            "Epoch 1149/1500\n",
            "876/876 [==============================] - 2s 3ms/step\n",
            "110/110 [==============================] - 8s 70ms/step - loss: 0.8063 - val_loss: 1.1479\n",
            "Epoch 1150/1500\n",
            "876/876 [==============================] - 3s 3ms/step\n",
            "110/110 [==============================] - 7s 65ms/step - loss: 0.3122 - val_loss: 0.7895\n",
            "Epoch 1151/1500\n",
            "876/876 [==============================] - 2s 3ms/step\n",
            "110/110 [==============================] - 8s 74ms/step - loss: 0.2573 - val_loss: 0.7668\n",
            "Epoch 1152/1500\n",
            "876/876 [==============================] - 3s 3ms/step\n",
            "110/110 [==============================] - 6s 53ms/step - loss: 0.3782 - val_loss: 1.5123\n",
            "Epoch 1153/1500\n",
            "876/876 [==============================] - 3s 3ms/step\n",
            "110/110 [==============================] - 7s 66ms/step - loss: 0.3153 - val_loss: 0.7161\n",
            "Epoch 1154/1500\n",
            "876/876 [==============================] - 2s 3ms/step\n",
            "110/110 [==============================] - 8s 70ms/step - loss: 0.4920 - val_loss: 2.9949\n",
            "Epoch 1155/1500\n",
            "876/876 [==============================] - 3s 3ms/step\n",
            "110/110 [==============================] - 9s 79ms/step - loss: 0.5827 - val_loss: 0.7603\n",
            "Epoch 1156/1500\n",
            "876/876 [==============================] - 2s 3ms/step\n",
            "110/110 [==============================] - 5s 49ms/step - loss: 0.2921 - val_loss: 0.8249\n",
            "Epoch 1157/1500\n",
            "876/876 [==============================] - 3s 3ms/step\n",
            "110/110 [==============================] - 6s 52ms/step - loss: 0.5135 - val_loss: 0.9523\n",
            "Epoch 1158/1500\n",
            "876/876 [==============================] - 3s 3ms/step\n",
            "110/110 [==============================] - 7s 66ms/step - loss: 0.3480 - val_loss: 0.7866\n",
            "Epoch 1159/1500\n",
            "876/876 [==============================] - 2s 3ms/step\n",
            "110/110 [==============================] - 5s 48ms/step - loss: 0.2597 - val_loss: 0.7717\n",
            "Epoch 1160/1500\n",
            "876/876 [==============================] - 3s 3ms/step\n",
            "110/110 [==============================] - 6s 52ms/step - loss: 0.6334 - val_loss: 0.7554\n",
            "Epoch 1161/1500\n",
            "876/876 [==============================] - 3s 3ms/step\n",
            "110/110 [==============================] - 9s 85ms/step - loss: 0.4211 - val_loss: 0.8086\n",
            "Epoch 1162/1500\n",
            "876/876 [==============================] - 2s 3ms/step\n",
            "110/110 [==============================] - 8s 70ms/step - loss: 0.5473 - val_loss: 1.5028\n",
            "Epoch 1163/1500\n",
            "876/876 [==============================] - 3s 3ms/step\n",
            "110/110 [==============================] - 7s 64ms/step - loss: 0.3609 - val_loss: 0.7652\n",
            "Epoch 1164/1500\n",
            "876/876 [==============================] - 2s 3ms/step\n",
            "110/110 [==============================] - 5s 48ms/step - loss: 0.3735 - val_loss: 1.1023\n",
            "Epoch 1165/1500\n",
            "876/876 [==============================] - 3s 3ms/step\n",
            "110/110 [==============================] - 6s 56ms/step - loss: 0.4672 - val_loss: 1.0340\n",
            "Epoch 1166/1500\n",
            "876/876 [==============================] - 2s 3ms/step\n",
            "110/110 [==============================] - 7s 63ms/step - loss: 0.3140 - val_loss: 0.7920\n",
            "Epoch 1167/1500\n",
            "876/876 [==============================] - 2s 3ms/step\n",
            "110/110 [==============================] - 8s 70ms/step - loss: 0.5029 - val_loss: 0.7461\n",
            "Epoch 1168/1500\n",
            "876/876 [==============================] - 3s 3ms/step\n",
            "110/110 [==============================] - 7s 66ms/step - loss: 0.3093 - val_loss: 0.8307\n",
            "Epoch 1169/1500\n",
            "876/876 [==============================] - 2s 3ms/step\n",
            "110/110 [==============================] - 5s 48ms/step - loss: 0.5503 - val_loss: 0.8482\n",
            "Epoch 1170/1500\n",
            "876/876 [==============================] - 3s 3ms/step\n",
            "110/110 [==============================] - 8s 70ms/step - loss: 0.3797 - val_loss: 0.8523\n",
            "Epoch 1171/1500\n",
            "876/876 [==============================] - 2s 3ms/step\n",
            "110/110 [==============================] - 5s 50ms/step - loss: 0.4148 - val_loss: 0.8408\n",
            "Epoch 1172/1500\n",
            "876/876 [==============================] - 3s 3ms/step\n",
            "110/110 [==============================] - 6s 51ms/step - loss: 0.3881 - val_loss: 1.2461\n",
            "Epoch 1173/1500\n",
            "876/876 [==============================] - 3s 3ms/step\n",
            "110/110 [==============================] - 8s 69ms/step - loss: 0.4528 - val_loss: 0.8922\n",
            "Epoch 1174/1500\n",
            "876/876 [==============================] - 2s 3ms/step\n",
            "110/110 [==============================] - 8s 71ms/step - loss: 0.2408 - val_loss: 0.7537\n",
            "Epoch 1175/1500\n",
            "876/876 [==============================] - 3s 3ms/step\n",
            "110/110 [==============================] - 8s 73ms/step - loss: 0.7075 - val_loss: 0.9827\n",
            "Epoch 1176/1500\n",
            "876/876 [==============================] - 2s 3ms/step\n",
            "110/110 [==============================] - 5s 49ms/step - loss: 0.3055 - val_loss: 0.8542\n",
            "Epoch 1177/1500\n",
            "876/876 [==============================] - 3s 3ms/step\n",
            "110/110 [==============================] - 8s 70ms/step - loss: 0.8752 - val_loss: 2.2998\n",
            "Epoch 1178/1500\n",
            "876/876 [==============================] - 2s 3ms/step\n",
            "110/110 [==============================] - 8s 71ms/step - loss: 0.4042 - val_loss: 0.8635\n",
            "Epoch 1179/1500\n",
            "876/876 [==============================] - 3s 3ms/step\n",
            "110/110 [==============================] - 8s 72ms/step - loss: 0.3035 - val_loss: 0.6922\n",
            "Epoch 1180/1500\n",
            "876/876 [==============================] - 2s 3ms/step\n",
            "110/110 [==============================] - 8s 70ms/step - loss: 0.3024 - val_loss: 0.9483\n",
            "Epoch 1181/1500\n",
            "876/876 [==============================] - 3s 3ms/step\n",
            "110/110 [==============================] - 6s 56ms/step - loss: 0.4557 - val_loss: 0.7757\n",
            "Epoch 1182/1500\n",
            "876/876 [==============================] - 2s 3ms/step\n",
            "110/110 [==============================] - 7s 61ms/step - loss: 0.9640 - val_loss: 0.8326\n",
            "Epoch 1183/1500\n",
            "876/876 [==============================] - 2s 3ms/step\n",
            "110/110 [==============================] - 5s 48ms/step - loss: 0.2949 - val_loss: 0.7663\n",
            "Epoch 1184/1500\n",
            "876/876 [==============================] - 3s 3ms/step\n",
            "110/110 [==============================] - 7s 62ms/step - loss: 0.2676 - val_loss: 0.7191\n",
            "Epoch 1185/1500\n",
            "876/876 [==============================] - 2s 3ms/step\n",
            "110/110 [==============================] - 6s 57ms/step - loss: 0.5537 - val_loss: 1.1319\n",
            "Epoch 1186/1500\n",
            "876/876 [==============================] - 2s 3ms/step\n",
            "110/110 [==============================] - 8s 70ms/step - loss: 0.5425 - val_loss: 0.7686\n",
            "Epoch 1187/1500\n",
            "876/876 [==============================] - 2s 3ms/step\n",
            "110/110 [==============================] - 9s 83ms/step - loss: 0.2804 - val_loss: 0.9873\n",
            "Epoch 1188/1500\n",
            "876/876 [==============================] - 3s 3ms/step\n",
            "110/110 [==============================] - 6s 51ms/step - loss: 0.3176 - val_loss: 0.9039\n",
            "Epoch 1189/1500\n",
            "876/876 [==============================] - 3s 3ms/step\n",
            "110/110 [==============================] - 9s 82ms/step - loss: 0.3730 - val_loss: 0.7908\n",
            "Epoch 1190/1500\n",
            "876/876 [==============================] - 2s 3ms/step\n",
            "110/110 [==============================] - 5s 48ms/step - loss: 0.3628 - val_loss: 0.7536\n",
            "Epoch 1191/1500\n",
            "876/876 [==============================] - 3s 3ms/step\n",
            "110/110 [==============================] - 8s 70ms/step - loss: 0.2955 - val_loss: 0.7476\n",
            "Epoch 1192/1500\n",
            "876/876 [==============================] - 2s 3ms/step\n",
            "110/110 [==============================] - 8s 70ms/step - loss: 0.2947 - val_loss: 0.7672\n",
            "Epoch 1193/1500\n",
            "876/876 [==============================] - 3s 3ms/step\n",
            "110/110 [==============================] - 6s 57ms/step - loss: 0.2569 - val_loss: 0.8763\n",
            "Epoch 1194/1500\n",
            "876/876 [==============================] - 2s 3ms/step\n",
            "110/110 [==============================] - 7s 61ms/step - loss: 0.4110 - val_loss: 0.7175\n",
            "Epoch 1195/1500\n",
            "876/876 [==============================] - 2s 3ms/step\n",
            "110/110 [==============================] - 8s 70ms/step - loss: 0.4282 - val_loss: 0.8647\n",
            "Epoch 1196/1500\n",
            "876/876 [==============================] - 3s 3ms/step\n",
            "110/110 [==============================] - 9s 86ms/step - loss: 0.3669 - val_loss: 0.8359\n",
            "Epoch 1197/1500\n",
            "876/876 [==============================] - 2s 3ms/step\n",
            "110/110 [==============================] - 5s 48ms/step - loss: 0.2985 - val_loss: 0.7751\n",
            "Epoch 1198/1500\n",
            "876/876 [==============================] - 3s 3ms/step\n",
            "110/110 [==============================] - 7s 66ms/step - loss: 0.3695 - val_loss: 0.7039\n",
            "Epoch 1199/1500\n",
            "876/876 [==============================] - 2s 3ms/step\n",
            "110/110 [==============================] - 6s 55ms/step - loss: 0.4244 - val_loss: 0.7997\n",
            "Epoch 1200/1500\n",
            "876/876 [==============================] - 2s 3ms/step\n",
            "110/110 [==============================] - 8s 70ms/step - loss: 0.5929 - val_loss: 0.9146\n",
            "Epoch 1201/1500\n",
            "876/876 [==============================] - 2s 3ms/step\n",
            "110/110 [==============================] - 8s 74ms/step - loss: 0.2830 - val_loss: 0.7045\n",
            "Epoch 1202/1500\n",
            "876/876 [==============================] - 3s 3ms/step\n",
            "110/110 [==============================] - 8s 70ms/step - loss: 0.6229 - val_loss: 0.7973\n",
            "Epoch 1203/1500\n",
            "876/876 [==============================] - 2s 3ms/step\n",
            "110/110 [==============================] - 8s 71ms/step - loss: 0.2986 - val_loss: 0.7410\n",
            "Epoch 1204/1500\n",
            "876/876 [==============================] - 3s 3ms/step\n",
            "110/110 [==============================] - 8s 72ms/step - loss: 0.4845 - val_loss: 1.3530\n",
            "Epoch 1205/1500\n",
            "876/876 [==============================] - 2s 3ms/step\n",
            "110/110 [==============================] - 8s 70ms/step - loss: 0.3533 - val_loss: 0.8429\n",
            "Epoch 1206/1500\n",
            "876/876 [==============================] - 3s 3ms/step\n",
            "110/110 [==============================] - 8s 73ms/step - loss: 0.4827 - val_loss: 0.8917\n",
            "Epoch 1207/1500\n",
            "876/876 [==============================] - 2s 3ms/step\n",
            "110/110 [==============================] - 8s 71ms/step - loss: 0.4521 - val_loss: 2.2662\n",
            "Epoch 1208/1500\n",
            "876/876 [==============================] - 3s 3ms/step\n",
            "110/110 [==============================] - 8s 74ms/step - loss: 0.4072 - val_loss: 0.7180\n",
            "Epoch 1209/1500\n",
            "876/876 [==============================] - 2s 3ms/step\n",
            "110/110 [==============================] - 8s 70ms/step - loss: 0.4159 - val_loss: 0.7379\n",
            "Epoch 1210/1500\n",
            "876/876 [==============================] - 3s 3ms/step\n",
            "110/110 [==============================] - 8s 74ms/step - loss: 0.2730 - val_loss: 0.8125\n",
            "Epoch 1211/1500\n",
            "876/876 [==============================] - 2s 3ms/step\n",
            "110/110 [==============================] - 8s 71ms/step - loss: 0.3064 - val_loss: 0.7558\n",
            "Epoch 1212/1500\n",
            "876/876 [==============================] - 3s 3ms/step\n",
            "110/110 [==============================] - 6s 58ms/step - loss: 0.3442 - val_loss: 0.8696\n",
            "Epoch 1213/1500\n",
            "876/876 [==============================] - 2s 3ms/step\n",
            "110/110 [==============================] - 7s 64ms/step - loss: 0.4530 - val_loss: 1.3910\n",
            "Epoch 1214/1500\n",
            "876/876 [==============================] - 2s 3ms/step\n",
            "110/110 [==============================] - 5s 48ms/step - loss: 0.3472 - val_loss: 0.7570\n",
            "Epoch 1215/1500\n",
            "876/876 [==============================] - 3s 3ms/step\n",
            "110/110 [==============================] - 6s 57ms/step - loss: 0.2851 - val_loss: 0.9722\n",
            "Epoch 1216/1500\n",
            "876/876 [==============================] - 2s 3ms/step\n",
            "110/110 [==============================] - 7s 60ms/step - loss: 0.4260 - val_loss: 2.1853\n",
            "Epoch 1217/1500\n",
            "876/876 [==============================] - 3s 3ms/step\n",
            "110/110 [==============================] - 5s 49ms/step - loss: 0.5864 - val_loss: 1.5044\n",
            "Epoch 1218/1500\n",
            "876/876 [==============================] - 3s 3ms/step\n",
            "110/110 [==============================] - 7s 68ms/step - loss: 0.6025 - val_loss: 0.9244\n",
            "Epoch 1219/1500\n",
            "876/876 [==============================] - 3s 3ms/step\n",
            "110/110 [==============================] - 6s 56ms/step - loss: 0.2877 - val_loss: 0.7204\n",
            "Epoch 1220/1500\n",
            "876/876 [==============================] - 3s 3ms/step\n",
            "110/110 [==============================] - 8s 70ms/step - loss: 0.2415 - val_loss: 0.9996\n",
            "Epoch 1221/1500\n",
            "876/876 [==============================] - 2s 3ms/step\n",
            "110/110 [==============================] - 8s 73ms/step - loss: 0.3170 - val_loss: 0.7647\n",
            "Epoch 1222/1500\n",
            "876/876 [==============================] - 3s 3ms/step\n",
            "110/110 [==============================] - 8s 70ms/step - loss: 0.2424 - val_loss: 0.7121\n",
            "Epoch 1223/1500\n",
            "876/876 [==============================] - 2s 3ms/step\n",
            "110/110 [==============================] - 5s 49ms/step - loss: 0.2943 - val_loss: 1.0382\n",
            "Epoch 1224/1500\n",
            "876/876 [==============================] - 3s 3ms/step\n",
            "110/110 [==============================] - 8s 70ms/step - loss: 0.5170 - val_loss: 0.9357\n",
            "Epoch 1225/1500\n",
            "876/876 [==============================] - 3s 3ms/step\n",
            "110/110 [==============================] - 5s 50ms/step - loss: 0.3323 - val_loss: 0.7652\n",
            "Epoch 1226/1500\n",
            "876/876 [==============================] - 3s 3ms/step\n",
            "110/110 [==============================] - 8s 73ms/step - loss: 0.2922 - val_loss: 0.7408\n",
            "Epoch 1227/1500\n",
            "876/876 [==============================] - 2s 3ms/step\n",
            "110/110 [==============================] - 8s 72ms/step - loss: 0.3908 - val_loss: 1.1003\n",
            "Epoch 1228/1500\n",
            "876/876 [==============================] - 3s 3ms/step\n",
            "110/110 [==============================] - 8s 70ms/step - loss: 0.4069 - val_loss: 1.1031\n",
            "Epoch 1229/1500\n",
            "876/876 [==============================] - 2s 3ms/step\n",
            "110/110 [==============================] - 8s 71ms/step - loss: 0.3850 - val_loss: 1.0464\n",
            "Epoch 1230/1500\n",
            "876/876 [==============================] - 3s 3ms/step\n",
            "110/110 [==============================] - 8s 72ms/step - loss: 0.6459 - val_loss: 1.7009\n",
            "Epoch 1231/1500\n",
            "876/876 [==============================] - 2s 3ms/step\n",
            "110/110 [==============================] - 5s 49ms/step - loss: 0.3953 - val_loss: 0.7736\n",
            "Epoch 1232/1500\n",
            "876/876 [==============================] - 3s 3ms/step\n",
            "110/110 [==============================] - 8s 70ms/step - loss: 0.5182 - val_loss: 0.8188\n",
            "Epoch 1233/1500\n",
            "876/876 [==============================] - 2s 3ms/step\n",
            "110/110 [==============================] - 8s 72ms/step - loss: 0.2568 - val_loss: 0.7197\n",
            "Epoch 1234/1500\n",
            "876/876 [==============================] - 3s 4ms/step\n",
            "110/110 [==============================] - 6s 59ms/step - loss: 0.2688 - val_loss: 1.2034\n",
            "Epoch 1235/1500\n",
            "876/876 [==============================] - 3s 3ms/step\n",
            "110/110 [==============================] - 9s 84ms/step - loss: 0.3755 - val_loss: 2.0873\n",
            "Epoch 1236/1500\n",
            "876/876 [==============================] - 3s 3ms/step\n",
            "110/110 [==============================] - 6s 52ms/step - loss: 0.4610 - val_loss: 0.7749\n",
            "Epoch 1237/1500\n",
            "876/876 [==============================] - 3s 3ms/step\n",
            "110/110 [==============================] - 7s 67ms/step - loss: 0.5999 - val_loss: 1.0548\n",
            "Epoch 1238/1500\n",
            "876/876 [==============================] - 3s 3ms/step\n",
            "110/110 [==============================] - 6s 50ms/step - loss: 0.2500 - val_loss: 0.8917\n",
            "Epoch 1239/1500\n",
            "876/876 [==============================] - 3s 3ms/step\n",
            "110/110 [==============================] - 6s 52ms/step - loss: 0.2243 - val_loss: 0.7173\n",
            "Epoch 1240/1500\n",
            "876/876 [==============================] - 3s 3ms/step\n",
            "110/110 [==============================] - 8s 69ms/step - loss: 0.3978 - val_loss: 1.7587\n",
            "Epoch 1241/1500\n",
            "876/876 [==============================] - 3s 3ms/step\n",
            "110/110 [==============================] - 8s 71ms/step - loss: 0.9117 - val_loss: 0.9488\n",
            "Epoch 1242/1500\n",
            "876/876 [==============================] - 3s 3ms/step\n",
            "110/110 [==============================] - 9s 78ms/step - loss: 0.4135 - val_loss: 0.9146\n",
            "Epoch 1243/1500\n",
            "876/876 [==============================] - 3s 3ms/step\n",
            "110/110 [==============================] - 5s 49ms/step - loss: 0.3167 - val_loss: 0.8443\n",
            "Epoch 1244/1500\n",
            "876/876 [==============================] - 3s 3ms/step\n",
            "110/110 [==============================] - 8s 70ms/step - loss: 0.3938 - val_loss: 0.7262\n",
            "Epoch 1245/1500\n",
            "876/876 [==============================] - 3s 3ms/step\n",
            "110/110 [==============================] - 8s 71ms/step - loss: 0.2832 - val_loss: 0.8001\n",
            "Epoch 1246/1500\n",
            "876/876 [==============================] - 3s 3ms/step\n",
            "110/110 [==============================] - 8s 72ms/step - loss: 0.4421 - val_loss: 1.0093\n",
            "Epoch 1247/1500\n",
            "876/876 [==============================] - 2s 3ms/step\n",
            "110/110 [==============================] - 8s 71ms/step - loss: 0.3780 - val_loss: 0.9555\n",
            "Epoch 1248/1500\n",
            "876/876 [==============================] - 3s 3ms/step\n",
            "110/110 [==============================] - 6s 57ms/step - loss: 0.2963 - val_loss: 1.3095\n",
            "Epoch 1249/1500\n",
            "876/876 [==============================] - 3s 3ms/step\n",
            "110/110 [==============================] - 9s 82ms/step - loss: 0.3505 - val_loss: 0.7265\n",
            "Epoch 1250/1500\n",
            "876/876 [==============================] - 3s 3ms/step\n",
            "110/110 [==============================] - 6s 50ms/step - loss: 0.2375 - val_loss: 1.1679\n",
            "Epoch 1251/1500\n",
            "876/876 [==============================] - 3s 3ms/step\n",
            "110/110 [==============================] - 7s 64ms/step - loss: 0.6753 - val_loss: 0.8565\n",
            "Epoch 1252/1500\n",
            "876/876 [==============================] - 3s 3ms/step\n",
            "110/110 [==============================] - 6s 51ms/step - loss: 0.2569 - val_loss: 0.8013\n",
            "Epoch 1253/1500\n",
            "876/876 [==============================] - 3s 3ms/step\n",
            "110/110 [==============================] - 6s 52ms/step - loss: 0.3411 - val_loss: 0.9639\n",
            "Epoch 1254/1500\n",
            "876/876 [==============================] - 3s 3ms/step\n",
            "110/110 [==============================] - 7s 68ms/step - loss: 0.3154 - val_loss: 0.8316\n",
            "Epoch 1255/1500\n",
            "876/876 [==============================] - 2s 3ms/step\n",
            "110/110 [==============================] - 5s 49ms/step - loss: 0.2523 - val_loss: 1.0838\n",
            "Epoch 1256/1500\n",
            "876/876 [==============================] - 3s 3ms/step\n",
            "110/110 [==============================] - 6s 55ms/step - loss: 0.4187 - val_loss: 5.6482\n",
            "Epoch 1257/1500\n",
            "876/876 [==============================] - 3s 3ms/step\n",
            "110/110 [==============================] - 7s 62ms/step - loss: 0.5505 - val_loss: 0.8819\n",
            "Epoch 1258/1500\n",
            "876/876 [==============================] - 2s 3ms/step\n",
            "110/110 [==============================] - 8s 71ms/step - loss: 0.5082 - val_loss: 1.1960\n",
            "Epoch 1259/1500\n",
            "876/876 [==============================] - 3s 3ms/step\n",
            "110/110 [==============================] - 9s 82ms/step - loss: 0.3704 - val_loss: 0.9248\n",
            "Epoch 1260/1500\n",
            "876/876 [==============================] - 3s 3ms/step\n",
            "110/110 [==============================] - 6s 50ms/step - loss: 0.4257 - val_loss: 0.9001\n",
            "Epoch 1261/1500\n",
            "876/876 [==============================] - 3s 3ms/step\n",
            "110/110 [==============================] - 8s 75ms/step - loss: 0.3453 - val_loss: 1.1357\n",
            "Epoch 1262/1500\n",
            "876/876 [==============================] - 3s 3ms/step\n",
            "110/110 [==============================] - 5s 50ms/step - loss: 0.5695 - val_loss: 0.8114\n",
            "Epoch 1263/1500\n",
            "876/876 [==============================] - 3s 3ms/step\n",
            "110/110 [==============================] - 8s 71ms/step - loss: 0.5271 - val_loss: 0.7480\n",
            "Epoch 1264/1500\n",
            "876/876 [==============================] - 3s 3ms/step\n",
            "110/110 [==============================] - 6s 52ms/step - loss: 0.2463 - val_loss: 0.7606\n",
            "Epoch 1265/1500\n",
            "876/876 [==============================] - 3s 3ms/step\n",
            "110/110 [==============================] - 8s 71ms/step - loss: 0.4936 - val_loss: 0.7707\n",
            "Epoch 1266/1500\n",
            "876/876 [==============================] - 2s 3ms/step\n",
            "110/110 [==============================] - 5s 50ms/step - loss: 0.2818 - val_loss: 0.8330\n",
            "Epoch 1267/1500\n",
            "876/876 [==============================] - 3s 3ms/step\n",
            "110/110 [==============================] - 8s 70ms/step - loss: 0.3996 - val_loss: 0.8015\n",
            "Epoch 1268/1500\n",
            "876/876 [==============================] - 3s 3ms/step\n",
            "110/110 [==============================] - 6s 51ms/step - loss: 0.3570 - val_loss: 0.8846\n",
            "Epoch 1269/1500\n",
            "876/876 [==============================] - 3s 3ms/step\n",
            "110/110 [==============================] - 8s 71ms/step - loss: 0.3804 - val_loss: 1.5208\n",
            "Epoch 1270/1500\n",
            "876/876 [==============================] - 3s 3ms/step\n",
            "110/110 [==============================] - 8s 74ms/step - loss: 0.5937 - val_loss: 0.8666\n",
            "Epoch 1271/1500\n",
            "876/876 [==============================] - 3s 3ms/step\n",
            "110/110 [==============================] - 8s 70ms/step - loss: 0.2537 - val_loss: 0.7371\n",
            "Epoch 1272/1500\n",
            "876/876 [==============================] - 2s 3ms/step\n",
            "110/110 [==============================] - 5s 49ms/step - loss: 0.3317 - val_loss: 1.0330\n",
            "Epoch 1273/1500\n",
            "876/876 [==============================] - 3s 3ms/step\n",
            "110/110 [==============================] - 6s 51ms/step - loss: 0.2996 - val_loss: 0.8870\n",
            "Epoch 1274/1500\n",
            "876/876 [==============================] - 3s 3ms/step\n",
            "110/110 [==============================] - 9s 85ms/step - loss: 0.2781 - val_loss: 1.0129\n",
            "Epoch 1275/1500\n",
            "876/876 [==============================] - 2s 3ms/step\n",
            "110/110 [==============================] - 5s 48ms/step - loss: 0.8183 - val_loss: 0.8533\n",
            "Epoch 1276/1500\n",
            "876/876 [==============================] - 3s 3ms/step\n",
            "110/110 [==============================] - 8s 75ms/step - loss: 0.3561 - val_loss: 0.7469\n",
            "Epoch 1277/1500\n",
            "876/876 [==============================] - 2s 3ms/step\n",
            "110/110 [==============================] - 5s 50ms/step - loss: 0.2925 - val_loss: 0.7950\n",
            "Epoch 1278/1500\n",
            "876/876 [==============================] - 3s 3ms/step\n",
            "110/110 [==============================] - 6s 53ms/step - loss: 0.3814 - val_loss: 0.8524\n",
            "Epoch 1279/1500\n",
            "876/876 [==============================] - 3s 3ms/step\n",
            "110/110 [==============================] - 9s 82ms/step - loss: 0.3695 - val_loss: 1.2710\n",
            "Epoch 1280/1500\n",
            "876/876 [==============================] - 3s 3ms/step\n",
            "110/110 [==============================] - 8s 71ms/step - loss: 0.2614 - val_loss: 0.7728\n",
            "Epoch 1281/1500\n",
            "876/876 [==============================] - 3s 3ms/step\n",
            "110/110 [==============================] - 7s 68ms/step - loss: 0.3462 - val_loss: 0.9798\n",
            "Epoch 1282/1500\n",
            "876/876 [==============================] - 2s 3ms/step\n",
            "110/110 [==============================] - 8s 71ms/step - loss: 0.4860 - val_loss: 0.7600\n",
            "Epoch 1283/1500\n",
            "876/876 [==============================] - 3s 3ms/step\n",
            "110/110 [==============================] - 9s 84ms/step - loss: 0.2648 - val_loss: 0.9280\n",
            "Epoch 1284/1500\n",
            "876/876 [==============================] - 2s 3ms/step\n",
            "110/110 [==============================] - 5s 49ms/step - loss: 0.5173 - val_loss: 0.7903\n",
            "Epoch 1285/1500\n",
            "876/876 [==============================] - 3s 3ms/step\n",
            "110/110 [==============================] - 6s 55ms/step - loss: 0.5381 - val_loss: 1.1994\n",
            "Epoch 1286/1500\n",
            "876/876 [==============================] - 3s 3ms/step\n",
            "110/110 [==============================] - 9s 84ms/step - loss: 0.3017 - val_loss: 0.7824\n",
            "Epoch 1287/1500\n",
            "876/876 [==============================] - 3s 3ms/step\n",
            "110/110 [==============================] - 5s 49ms/step - loss: 0.4740 - val_loss: 0.7770\n",
            "Epoch 1288/1500\n",
            "876/876 [==============================] - 3s 3ms/step\n",
            "110/110 [==============================] - 9s 80ms/step - loss: 0.3361 - val_loss: 1.0035\n",
            "Epoch 1289/1500\n",
            "876/876 [==============================] - 3s 3ms/step\n",
            "110/110 [==============================] - 5s 49ms/step - loss: 0.3342 - val_loss: 0.8138\n",
            "Epoch 1290/1500\n",
            "876/876 [==============================] - 3s 3ms/step\n",
            "110/110 [==============================] - 6s 55ms/step - loss: 0.3304 - val_loss: 0.8854\n",
            "Epoch 1291/1500\n",
            "876/876 [==============================] - 3s 3ms/step\n",
            "110/110 [==============================] - 9s 83ms/step - loss: 0.3893 - val_loss: 0.8150\n",
            "Epoch 1292/1500\n",
            "876/876 [==============================] - 2s 3ms/step\n",
            "110/110 [==============================] - 8s 71ms/step - loss: 0.2489 - val_loss: 2.7199\n",
            "Epoch 1293/1500\n",
            "876/876 [==============================] - 3s 3ms/step\n",
            "110/110 [==============================] - 9s 83ms/step - loss: 0.7654 - val_loss: 0.8098\n",
            "Epoch 1294/1500\n",
            "876/876 [==============================] - 2s 3ms/step\n",
            "110/110 [==============================] - 6s 50ms/step - loss: 0.3334 - val_loss: 1.1356\n",
            "Epoch 1295/1500\n",
            "876/876 [==============================] - 3s 3ms/step\n",
            "110/110 [==============================] - 9s 78ms/step - loss: 0.2838 - val_loss: 1.5224\n",
            "Epoch 1296/1500\n",
            "876/876 [==============================] - 3s 3ms/step\n",
            "110/110 [==============================] - 5s 49ms/step - loss: 0.3363 - val_loss: 0.9215\n",
            "Epoch 1297/1500\n",
            "876/876 [==============================] - 3s 3ms/step\n",
            "110/110 [==============================] - 6s 52ms/step - loss: 0.3211 - val_loss: 0.7539\n",
            "Epoch 1298/1500\n",
            "876/876 [==============================] - 3s 3ms/step\n",
            "110/110 [==============================] - 9s 83ms/step - loss: 0.2875 - val_loss: 0.9504\n",
            "Epoch 1299/1500\n",
            "876/876 [==============================] - 2s 3ms/step\n",
            "110/110 [==============================] - 5s 49ms/step - loss: 0.3453 - val_loss: 0.7786\n",
            "Epoch 1300/1500\n",
            "876/876 [==============================] - 3s 3ms/step\n",
            "110/110 [==============================] - 8s 72ms/step - loss: 0.2991 - val_loss: 0.9330\n",
            "Epoch 1301/1500\n",
            "876/876 [==============================] - 3s 3ms/step\n",
            "110/110 [==============================] - 6s 51ms/step - loss: 0.7895 - val_loss: 0.9719\n",
            "Epoch 1302/1500\n",
            "876/876 [==============================] - 3s 3ms/step\n",
            "110/110 [==============================] - 6s 53ms/step - loss: 0.3153 - val_loss: 0.8543\n",
            "Epoch 1303/1500\n",
            "876/876 [==============================] - 3s 3ms/step\n",
            "110/110 [==============================] - 9s 85ms/step - loss: 0.6242 - val_loss: 0.9748\n",
            "Epoch 1304/1500\n",
            "876/876 [==============================] - 3s 3ms/step\n",
            "110/110 [==============================] - 8s 71ms/step - loss: 0.2567 - val_loss: 0.9699\n",
            "Epoch 1305/1500\n",
            "876/876 [==============================] - 3s 3ms/step\n",
            "110/110 [==============================] - 8s 69ms/step - loss: 0.3113 - val_loss: 1.0762\n",
            "Epoch 1306/1500\n",
            "876/876 [==============================] - 3s 3ms/step\n",
            "110/110 [==============================] - 6s 50ms/step - loss: 0.6504 - val_loss: 1.1368\n",
            "Epoch 1307/1500\n",
            "876/876 [==============================] - 3s 3ms/step\n",
            "110/110 [==============================] - 8s 72ms/step - loss: 0.3420 - val_loss: 0.7570\n",
            "Epoch 1308/1500\n",
            "876/876 [==============================] - 3s 3ms/step\n",
            "110/110 [==============================] - 6s 52ms/step - loss: 0.2037 - val_loss: 0.7952\n",
            "Epoch 1309/1500\n",
            "876/876 [==============================] - 3s 3ms/step\n",
            "110/110 [==============================] - 8s 71ms/step - loss: 0.2309 - val_loss: 0.7831\n",
            "Epoch 1310/1500\n",
            "876/876 [==============================] - 3s 3ms/step\n",
            "110/110 [==============================] - 8s 74ms/step - loss: 0.2749 - val_loss: 0.8652\n",
            "Epoch 1311/1500\n",
            "876/876 [==============================] - 3s 3ms/step\n",
            "110/110 [==============================] - 8s 71ms/step - loss: 0.3731 - val_loss: 1.0853\n",
            "Epoch 1312/1500\n",
            "876/876 [==============================] - 3s 3ms/step\n",
            "110/110 [==============================] - 6s 52ms/step - loss: 0.2456 - val_loss: 0.7854\n",
            "Epoch 1313/1500\n",
            "876/876 [==============================] - 3s 3ms/step\n",
            "110/110 [==============================] - 6s 51ms/step - loss: 0.3507 - val_loss: 1.0802\n",
            "Epoch 1314/1500\n",
            "876/876 [==============================] - 3s 3ms/step\n",
            "110/110 [==============================] - 9s 85ms/step - loss: 0.4622 - val_loss: 0.9670\n",
            "Epoch 1315/1500\n",
            "876/876 [==============================] - 2s 3ms/step\n",
            "110/110 [==============================] - 5s 50ms/step - loss: 0.3366 - val_loss: 1.1946\n",
            "Epoch 1316/1500\n",
            "876/876 [==============================] - 3s 3ms/step\n",
            "110/110 [==============================] - 8s 74ms/step - loss: 0.5475 - val_loss: 0.9683\n",
            "Epoch 1317/1500\n",
            "876/876 [==============================] - 3s 3ms/step\n",
            "110/110 [==============================] - 5s 49ms/step - loss: 0.4176 - val_loss: 0.9429\n",
            "Epoch 1318/1500\n",
            "876/876 [==============================] - 3s 3ms/step\n",
            "110/110 [==============================] - 8s 72ms/step - loss: 0.4020 - val_loss: 1.1137\n",
            "Epoch 1319/1500\n",
            "876/876 [==============================] - 3s 3ms/step\n",
            "110/110 [==============================] - 8s 72ms/step - loss: 0.3033 - val_loss: 0.8382\n",
            "Epoch 1320/1500\n",
            "876/876 [==============================] - 3s 3ms/step\n",
            "110/110 [==============================] - 6s 57ms/step - loss: 0.3783 - val_loss: 0.8972\n",
            "Epoch 1321/1500\n",
            "876/876 [==============================] - 3s 3ms/step\n",
            "110/110 [==============================] - 7s 62ms/step - loss: 0.5170 - val_loss: 0.7520\n",
            "Epoch 1322/1500\n",
            "876/876 [==============================] - 3s 3ms/step\n",
            "110/110 [==============================] - 8s 71ms/step - loss: 0.2525 - val_loss: 0.8456\n",
            "Epoch 1323/1500\n",
            "876/876 [==============================] - 3s 3ms/step\n",
            "110/110 [==============================] - 7s 65ms/step - loss: 0.9769 - val_loss: 0.8418\n",
            "Epoch 1324/1500\n",
            "876/876 [==============================] - 3s 3ms/step\n",
            "110/110 [==============================] - 8s 71ms/step - loss: 0.2837 - val_loss: 1.0442\n",
            "Epoch 1325/1500\n",
            "876/876 [==============================] - 3s 3ms/step\n",
            "110/110 [==============================] - 7s 66ms/step - loss: 0.3590 - val_loss: 1.0069\n",
            "Epoch 1326/1500\n",
            "876/876 [==============================] - 3s 3ms/step\n",
            "110/110 [==============================] - 8s 72ms/step - loss: 0.8527 - val_loss: 0.8573\n",
            "Epoch 1327/1500\n",
            "876/876 [==============================] - 3s 3ms/step\n",
            "110/110 [==============================] - 7s 65ms/step - loss: 0.2659 - val_loss: 0.9279\n",
            "Epoch 1328/1500\n",
            "876/876 [==============================] - 3s 3ms/step\n",
            "110/110 [==============================] - 6s 58ms/step - loss: 0.6642 - val_loss: 0.8567\n",
            "Epoch 1329/1500\n",
            "876/876 [==============================] - 3s 3ms/step\n",
            "110/110 [==============================] - 6s 52ms/step - loss: 0.2426 - val_loss: 1.1011\n",
            "Epoch 1330/1500\n",
            "876/876 [==============================] - 3s 3ms/step\n",
            "110/110 [==============================] - 8s 71ms/step - loss: 0.3984 - val_loss: 1.0621\n",
            "Epoch 1331/1500\n",
            "876/876 [==============================] - 3s 3ms/step\n",
            "110/110 [==============================] - 5s 50ms/step - loss: 0.2176 - val_loss: 0.8385\n",
            "Epoch 1332/1500\n",
            "876/876 [==============================] - 3s 3ms/step\n",
            "110/110 [==============================] - 6s 53ms/step - loss: 0.3207 - val_loss: 0.8228\n",
            "Epoch 1333/1500\n",
            "876/876 [==============================] - 3s 3ms/step\n",
            "110/110 [==============================] - 10s 87ms/step - loss: 0.3319 - val_loss: 1.0373\n",
            "Epoch 1334/1500\n",
            "876/876 [==============================] - 3s 3ms/step\n",
            "110/110 [==============================] - 6s 51ms/step - loss: 0.3299 - val_loss: 0.9397\n",
            "Epoch 1335/1500\n",
            "876/876 [==============================] - 3s 3ms/step\n",
            "110/110 [==============================] - 9s 84ms/step - loss: 0.6046 - val_loss: 1.3231\n",
            "Epoch 1336/1500\n",
            "876/876 [==============================] - 3s 3ms/step\n",
            "110/110 [==============================] - 8s 70ms/step - loss: 0.3269 - val_loss: 1.3085\n",
            "Epoch 1337/1500\n",
            "876/876 [==============================] - 3s 3ms/step\n",
            "110/110 [==============================] - 9s 84ms/step - loss: 0.4495 - val_loss: 0.8790\n",
            "Epoch 1338/1500\n",
            "876/876 [==============================] - 3s 3ms/step\n",
            "110/110 [==============================] - 8s 71ms/step - loss: 0.2834 - val_loss: 0.8235\n",
            "Epoch 1339/1500\n",
            "876/876 [==============================] - 2s 3ms/step\n",
            "110/110 [==============================] - 9s 82ms/step - loss: 0.3071 - val_loss: 0.8684\n",
            "Epoch 1340/1500\n",
            "876/876 [==============================] - 3s 3ms/step\n",
            "110/110 [==============================] - 6s 53ms/step - loss: 0.3001 - val_loss: 0.8623\n",
            "Epoch 1341/1500\n",
            "876/876 [==============================] - 3s 3ms/step\n",
            "110/110 [==============================] - 9s 82ms/step - loss: 0.5141 - val_loss: 1.3369\n",
            "Epoch 1342/1500\n",
            "876/876 [==============================] - 3s 3ms/step\n",
            "110/110 [==============================] - 5s 50ms/step - loss: 0.3119 - val_loss: 0.8378\n",
            "Epoch 1343/1500\n",
            "876/876 [==============================] - 3s 3ms/step\n",
            "110/110 [==============================] - 6s 59ms/step - loss: 0.3689 - val_loss: 0.8199\n",
            "Epoch 1344/1500\n",
            "876/876 [==============================] - 3s 3ms/step\n",
            "110/110 [==============================] - 9s 80ms/step - loss: 0.3156 - val_loss: 0.8716\n",
            "Epoch 1345/1500\n",
            "876/876 [==============================] - 3s 3ms/step\n",
            "110/110 [==============================] - 8s 71ms/step - loss: 0.4123 - val_loss: 0.8442\n",
            "Epoch 1346/1500\n",
            "876/876 [==============================] - 3s 3ms/step\n",
            "110/110 [==============================] - 8s 72ms/step - loss: 0.3294 - val_loss: 0.9349\n",
            "Epoch 1347/1500\n",
            "876/876 [==============================] - 3s 3ms/step\n",
            "110/110 [==============================] - 8s 74ms/step - loss: 0.3494 - val_loss: 1.1694\n",
            "Epoch 1348/1500\n",
            "876/876 [==============================] - 3s 3ms/step\n",
            "110/110 [==============================] - 5s 50ms/step - loss: 0.4897 - val_loss: 0.7680\n",
            "Epoch 1349/1500\n",
            "876/876 [==============================] - 3s 3ms/step\n",
            "110/110 [==============================] - 8s 71ms/step - loss: 0.2362 - val_loss: 0.7841\n",
            "Epoch 1350/1500\n",
            "876/876 [==============================] - 3s 3ms/step\n",
            "110/110 [==============================] - 6s 54ms/step - loss: 0.4170 - val_loss: 0.9782\n",
            "Epoch 1351/1500\n",
            "876/876 [==============================] - 3s 3ms/step\n",
            "110/110 [==============================] - 8s 71ms/step - loss: 0.4826 - val_loss: 0.9594\n",
            "Epoch 1352/1500\n",
            "876/876 [==============================] - 3s 3ms/step\n",
            "110/110 [==============================] - 6s 53ms/step - loss: 0.7324 - val_loss: 1.0217\n",
            "Epoch 1353/1500\n",
            "876/876 [==============================] - 3s 3ms/step\n",
            "110/110 [==============================] - 6s 53ms/step - loss: 0.2406 - val_loss: 0.8097\n",
            "Epoch 1354/1500\n",
            "876/876 [==============================] - 3s 3ms/step\n",
            "110/110 [==============================] - 8s 69ms/step - loss: 0.2767 - val_loss: 1.0374\n",
            "Epoch 1355/1500\n",
            "876/876 [==============================] - 3s 3ms/step\n",
            "110/110 [==============================] - 6s 54ms/step - loss: 0.2916 - val_loss: 0.9459\n",
            "Epoch 1356/1500\n",
            "876/876 [==============================] - 3s 3ms/step\n",
            "110/110 [==============================] - 8s 72ms/step - loss: 0.2768 - val_loss: 0.8851\n",
            "Epoch 1357/1500\n",
            "876/876 [==============================] - 3s 3ms/step\n",
            "110/110 [==============================] - 6s 52ms/step - loss: 0.2331 - val_loss: 0.9074\n",
            "Epoch 1358/1500\n",
            "876/876 [==============================] - 3s 3ms/step\n",
            "110/110 [==============================] - 6s 53ms/step - loss: 0.3719 - val_loss: 0.8079\n",
            "Epoch 1359/1500\n",
            "876/876 [==============================] - 3s 4ms/step\n",
            "110/110 [==============================] - 9s 82ms/step - loss: 0.3721 - val_loss: 1.3615\n",
            "Epoch 1360/1500\n",
            "876/876 [==============================] - 3s 3ms/step\n",
            "110/110 [==============================] - 6s 51ms/step - loss: 0.3473 - val_loss: 0.8268\n",
            "Epoch 1361/1500\n",
            "876/876 [==============================] - 3s 3ms/step\n",
            "110/110 [==============================] - 6s 54ms/step - loss: 0.3599 - val_loss: 1.2731\n",
            "Epoch 1362/1500\n",
            "876/876 [==============================] - 3s 3ms/step\n",
            "110/110 [==============================] - 7s 68ms/step - loss: 0.4738 - val_loss: 0.7975\n",
            "Epoch 1363/1500\n",
            "876/876 [==============================] - 3s 3ms/step\n",
            "110/110 [==============================] - 8s 71ms/step - loss: 0.2422 - val_loss: 0.7666\n",
            "Epoch 1364/1500\n",
            "876/876 [==============================] - 3s 3ms/step\n",
            "110/110 [==============================] - 9s 84ms/step - loss: 0.3412 - val_loss: 1.5017\n",
            "Epoch 1365/1500\n",
            "876/876 [==============================] - 3s 3ms/step\n",
            "110/110 [==============================] - 6s 51ms/step - loss: 0.2873 - val_loss: 1.1608\n",
            "Epoch 1366/1500\n",
            "876/876 [==============================] - 3s 3ms/step\n",
            "110/110 [==============================] - 6s 54ms/step - loss: 0.3594 - val_loss: 1.1650\n",
            "Epoch 1367/1500\n",
            "876/876 [==============================] - 3s 3ms/step\n",
            "110/110 [==============================] - 9s 82ms/step - loss: 0.3274 - val_loss: 0.8626\n",
            "Epoch 1368/1500\n",
            "876/876 [==============================] - 3s 3ms/step\n",
            "110/110 [==============================] - 6s 51ms/step - loss: 0.6324 - val_loss: 1.5023\n",
            "Epoch 1369/1500\n",
            "876/876 [==============================] - 3s 3ms/step\n",
            "110/110 [==============================] - 7s 65ms/step - loss: 0.3910 - val_loss: 0.9138\n",
            "Epoch 1370/1500\n",
            "876/876 [==============================] - 3s 3ms/step\n",
            "110/110 [==============================] - 7s 62ms/step - loss: 0.2868 - val_loss: 0.7668\n",
            "Epoch 1371/1500\n",
            "876/876 [==============================] - 3s 3ms/step\n",
            "110/110 [==============================] - 6s 52ms/step - loss: 0.5191 - val_loss: 0.8846\n",
            "Epoch 1372/1500\n",
            "876/876 [==============================] - 3s 3ms/step\n",
            "110/110 [==============================] - 7s 67ms/step - loss: 0.2098 - val_loss: 0.7792\n",
            "Epoch 1373/1500\n",
            "876/876 [==============================] - 3s 3ms/step\n",
            "110/110 [==============================] - 6s 59ms/step - loss: 0.4432 - val_loss: 0.8505\n",
            "Epoch 1374/1500\n",
            "876/876 [==============================] - 3s 3ms/step\n",
            "110/110 [==============================] - 8s 72ms/step - loss: 0.5893 - val_loss: 1.5502\n",
            "Epoch 1375/1500\n",
            "876/876 [==============================] - 3s 3ms/step\n",
            "110/110 [==============================] - 6s 53ms/step - loss: 0.6435 - val_loss: 0.7918\n",
            "Epoch 1376/1500\n",
            "876/876 [==============================] - 3s 3ms/step\n",
            "110/110 [==============================] - 8s 71ms/step - loss: 0.2453 - val_loss: 0.7993\n",
            "Epoch 1377/1500\n",
            "876/876 [==============================] - 3s 3ms/step\n",
            "110/110 [==============================] - 6s 53ms/step - loss: 0.2296 - val_loss: 0.8077\n",
            "Epoch 1378/1500\n",
            "876/876 [==============================] - 3s 3ms/step\n",
            "110/110 [==============================] - 6s 52ms/step - loss: 0.2283 - val_loss: 0.8032\n",
            "Epoch 1379/1500\n",
            "876/876 [==============================] - 3s 3ms/step\n",
            "110/110 [==============================] - 9s 83ms/step - loss: 0.7616 - val_loss: 0.8981\n",
            "Epoch 1380/1500\n",
            "876/876 [==============================] - 3s 3ms/step\n",
            "110/110 [==============================] - 8s 72ms/step - loss: 0.2764 - val_loss: 1.0115\n",
            "Epoch 1381/1500\n",
            "876/876 [==============================] - 3s 3ms/step\n",
            "110/110 [==============================] - 9s 79ms/step - loss: 0.2947 - val_loss: 0.7556\n",
            "Epoch 1382/1500\n",
            "876/876 [==============================] - 3s 3ms/step\n",
            "110/110 [==============================] - 6s 52ms/step - loss: 0.2456 - val_loss: 0.8080\n",
            "Epoch 1383/1500\n",
            "876/876 [==============================] - 3s 3ms/step\n",
            "110/110 [==============================] - 6s 54ms/step - loss: 0.2790 - val_loss: 1.7060\n",
            "Epoch 1384/1500\n",
            "876/876 [==============================] - 3s 3ms/step\n",
            "110/110 [==============================] - 7s 67ms/step - loss: 0.4373 - val_loss: 0.9682\n",
            "Epoch 1385/1500\n",
            "876/876 [==============================] - 3s 3ms/step\n",
            "110/110 [==============================] - 6s 53ms/step - loss: 0.3216 - val_loss: 0.9473\n",
            "Epoch 1386/1500\n",
            "876/876 [==============================] - 3s 3ms/step\n",
            "110/110 [==============================] - 8s 73ms/step - loss: 0.3215 - val_loss: 0.8679\n",
            "Epoch 1387/1500\n",
            "876/876 [==============================] - 3s 3ms/step\n",
            "110/110 [==============================] - 6s 52ms/step - loss: 0.6668 - val_loss: 0.8094\n",
            "Epoch 1388/1500\n",
            "876/876 [==============================] - 3s 3ms/step\n",
            "110/110 [==============================] - 8s 72ms/step - loss: 0.2547 - val_loss: 0.7845\n",
            "Epoch 1389/1500\n",
            "876/876 [==============================] - 3s 3ms/step\n",
            "110/110 [==============================] - 8s 74ms/step - loss: 0.2428 - val_loss: 0.9478\n",
            "Epoch 1390/1500\n",
            "876/876 [==============================] - 3s 3ms/step\n",
            "110/110 [==============================] - 6s 57ms/step - loss: 0.3057 - val_loss: 0.8109\n",
            "Epoch 1391/1500\n",
            "876/876 [==============================] - 3s 3ms/step\n",
            "110/110 [==============================] - 9s 83ms/step - loss: 0.5847 - val_loss: 1.1699\n",
            "Epoch 1392/1500\n",
            "876/876 [==============================] - 3s 3ms/step\n",
            "110/110 [==============================] - 6s 53ms/step - loss: 0.5052 - val_loss: 0.8716\n",
            "Epoch 1393/1500\n",
            "876/876 [==============================] - 3s 3ms/step\n",
            "110/110 [==============================] - 8s 69ms/step - loss: 0.2216 - val_loss: 0.8905\n",
            "Epoch 1394/1500\n",
            "876/876 [==============================] - 3s 3ms/step\n",
            "110/110 [==============================] - 8s 73ms/step - loss: 0.3008 - val_loss: 1.2790\n",
            "Epoch 1395/1500\n",
            "876/876 [==============================] - 3s 3ms/step\n",
            "110/110 [==============================] - 7s 62ms/step - loss: 0.2710 - val_loss: 0.7987\n",
            "Epoch 1396/1500\n",
            "876/876 [==============================] - 3s 3ms/step\n",
            "110/110 [==============================] - 7s 61ms/step - loss: 0.2532 - val_loss: 0.7821\n",
            "Epoch 1397/1500\n",
            "876/876 [==============================] - 2s 3ms/step\n",
            "110/110 [==============================] - 8s 72ms/step - loss: 0.1837 - val_loss: 0.9509\n",
            "Epoch 1398/1500\n",
            "876/876 [==============================] - 3s 3ms/step\n",
            "110/110 [==============================] - 6s 53ms/step - loss: 0.4574 - val_loss: 0.8732\n",
            "Epoch 1399/1500\n",
            "876/876 [==============================] - 3s 3ms/step\n",
            "110/110 [==============================] - 8s 71ms/step - loss: 0.3256 - val_loss: 0.8303\n",
            "Epoch 1400/1500\n",
            "876/876 [==============================] - 3s 3ms/step\n",
            "110/110 [==============================] - 6s 52ms/step - loss: 0.4560 - val_loss: 0.9795\n",
            "Epoch 1401/1500\n",
            "876/876 [==============================] - 3s 3ms/step\n",
            "110/110 [==============================] - 6s 54ms/step - loss: 0.3265 - val_loss: 0.8230\n",
            "Epoch 1402/1500\n",
            "876/876 [==============================] - 3s 3ms/step\n",
            "110/110 [==============================] - 7s 67ms/step - loss: 0.6248 - val_loss: 0.8536\n",
            "Epoch 1403/1500\n",
            "876/876 [==============================] - 3s 3ms/step\n",
            "110/110 [==============================] - 6s 55ms/step - loss: 0.2553 - val_loss: 0.8058\n",
            "Epoch 1404/1500\n",
            "876/876 [==============================] - 3s 3ms/step\n",
            "110/110 [==============================] - 6s 55ms/step - loss: 0.5077 - val_loss: 1.8913\n",
            "Epoch 1405/1500\n",
            "876/876 [==============================] - 3s 3ms/step\n",
            "110/110 [==============================] - 7s 66ms/step - loss: 0.4001 - val_loss: 0.9407\n",
            "Epoch 1406/1500\n",
            "876/876 [==============================] - 3s 3ms/step\n",
            "110/110 [==============================] - 8s 72ms/step - loss: 0.2374 - val_loss: 0.9953\n",
            "Epoch 1407/1500\n",
            "876/876 [==============================] - 3s 3ms/step\n",
            "110/110 [==============================] - 7s 66ms/step - loss: 0.2511 - val_loss: 0.9078\n",
            "Epoch 1408/1500\n",
            "876/876 [==============================] - 3s 3ms/step\n",
            "110/110 [==============================] - 7s 60ms/step - loss: 0.3292 - val_loss: 1.0209\n",
            "Epoch 1409/1500\n",
            "876/876 [==============================] - 3s 3ms/step\n",
            "110/110 [==============================] - 8s 72ms/step - loss: 0.3236 - val_loss: 0.8207\n",
            "Epoch 1410/1500\n",
            "876/876 [==============================] - 3s 3ms/step\n",
            "110/110 [==============================] - 6s 52ms/step - loss: 0.2529 - val_loss: 0.7952\n",
            "Epoch 1411/1500\n",
            "876/876 [==============================] - 3s 3ms/step\n",
            "110/110 [==============================] - 6s 52ms/step - loss: 0.3029 - val_loss: 1.3688\n",
            "Epoch 1412/1500\n",
            "876/876 [==============================] - 3s 3ms/step\n",
            "110/110 [==============================] - 7s 67ms/step - loss: 0.3233 - val_loss: 0.8309\n",
            "Epoch 1413/1500\n",
            "876/876 [==============================] - 3s 3ms/step\n",
            "110/110 [==============================] - 8s 73ms/step - loss: 0.3509 - val_loss: 1.0944\n",
            "Epoch 1414/1500\n",
            "876/876 [==============================] - 3s 3ms/step\n",
            "110/110 [==============================] - 7s 64ms/step - loss: 0.3435 - val_loss: 0.8416\n",
            "Epoch 1415/1500\n",
            "876/876 [==============================] - 3s 3ms/step\n",
            "110/110 [==============================] - 7s 62ms/step - loss: 0.2217 - val_loss: 0.7441\n",
            "Epoch 1416/1500\n",
            "876/876 [==============================] - 3s 3ms/step\n",
            "110/110 [==============================] - 6s 51ms/step - loss: 0.4833 - val_loss: 0.9146\n",
            "Epoch 1417/1500\n",
            "876/876 [==============================] - 3s 3ms/step\n",
            "110/110 [==============================] - 9s 82ms/step - loss: 0.2989 - val_loss: 0.9617\n",
            "Epoch 1418/1500\n",
            "876/876 [==============================] - 3s 3ms/step\n",
            "110/110 [==============================] - 8s 71ms/step - loss: 0.4029 - val_loss: 0.9020\n",
            "Epoch 1419/1500\n",
            "876/876 [==============================] - 3s 3ms/step\n",
            "110/110 [==============================] - 7s 63ms/step - loss: 0.2707 - val_loss: 0.7869\n",
            "Epoch 1420/1500\n",
            "876/876 [==============================] - 3s 3ms/step\n",
            "110/110 [==============================] - 9s 80ms/step - loss: 0.1856 - val_loss: 0.8315\n",
            "Epoch 1421/1500\n",
            "876/876 [==============================] - 3s 3ms/step\n",
            "110/110 [==============================] - 6s 54ms/step - loss: 0.4008 - val_loss: 1.0968\n",
            "Epoch 1422/1500\n",
            "876/876 [==============================] - 3s 3ms/step\n",
            "110/110 [==============================] - 9s 83ms/step - loss: 0.2449 - val_loss: 0.7641\n",
            "Epoch 1423/1500\n",
            "876/876 [==============================] - 3s 3ms/step\n",
            "110/110 [==============================] - 6s 51ms/step - loss: 0.4197 - val_loss: 0.9109\n",
            "Epoch 1424/1500\n",
            "876/876 [==============================] - 3s 3ms/step\n",
            "110/110 [==============================] - 9s 79ms/step - loss: 0.4084 - val_loss: 0.8663\n",
            "Epoch 1425/1500\n",
            "876/876 [==============================] - 3s 3ms/step\n",
            "110/110 [==============================] - 6s 51ms/step - loss: 0.2090 - val_loss: 0.8440\n",
            "Epoch 1426/1500\n",
            "876/876 [==============================] - 3s 3ms/step\n",
            "110/110 [==============================] - 8s 71ms/step - loss: 0.6357 - val_loss: 1.0611\n",
            "Epoch 1427/1500\n",
            "876/876 [==============================] - 3s 3ms/step\n",
            "110/110 [==============================] - 6s 53ms/step - loss: 0.5965 - val_loss: 1.1848\n",
            "Epoch 1428/1500\n",
            "876/876 [==============================] - 3s 3ms/step\n",
            "110/110 [==============================] - 8s 72ms/step - loss: 0.3526 - val_loss: 0.7893\n",
            "Epoch 1429/1500\n",
            "876/876 [==============================] - 3s 3ms/step\n",
            "110/110 [==============================] - 6s 54ms/step - loss: 0.2084 - val_loss: 1.0432\n",
            "Epoch 1430/1500\n",
            "876/876 [==============================] - 3s 3ms/step\n",
            "110/110 [==============================] - 6s 52ms/step - loss: 0.2363 - val_loss: 0.7926\n",
            "Epoch 1431/1500\n",
            "876/876 [==============================] - 3s 3ms/step\n",
            "110/110 [==============================] - 7s 66ms/step - loss: 0.4280 - val_loss: 0.8548\n",
            "Epoch 1432/1500\n",
            "876/876 [==============================] - 3s 3ms/step\n",
            "110/110 [==============================] - 6s 58ms/step - loss: 0.2937 - val_loss: 0.9467\n",
            "Epoch 1433/1500\n",
            "876/876 [==============================] - 3s 3ms/step\n",
            "110/110 [==============================] - 6s 55ms/step - loss: 0.8154 - val_loss: 0.8531\n",
            "Epoch 1434/1500\n",
            "876/876 [==============================] - 3s 3ms/step\n",
            "110/110 [==============================] - 8s 69ms/step - loss: 0.3300 - val_loss: 1.1429\n",
            "Epoch 1435/1500\n",
            "876/876 [==============================] - 3s 3ms/step\n",
            "110/110 [==============================] - 6s 52ms/step - loss: 0.5268 - val_loss: 0.9252\n",
            "Epoch 1436/1500\n",
            "876/876 [==============================] - 3s 3ms/step\n",
            "110/110 [==============================] - 8s 76ms/step - loss: 0.3505 - val_loss: 0.8550\n",
            "Epoch 1437/1500\n",
            "876/876 [==============================] - 3s 3ms/step\n",
            "110/110 [==============================] - 6s 50ms/step - loss: 0.2857 - val_loss: 0.7683\n",
            "Epoch 1438/1500\n",
            "876/876 [==============================] - 3s 3ms/step\n",
            "110/110 [==============================] - 8s 71ms/step - loss: 0.2318 - val_loss: 1.1467\n",
            "Epoch 1439/1500\n",
            "876/876 [==============================] - 3s 3ms/step\n",
            "110/110 [==============================] - 8s 76ms/step - loss: 0.4010 - val_loss: 1.0696\n",
            "Epoch 1440/1500\n",
            "876/876 [==============================] - 3s 3ms/step\n",
            "110/110 [==============================] - 6s 59ms/step - loss: 0.2861 - val_loss: 0.7682\n",
            "Epoch 1441/1500\n",
            "876/876 [==============================] - 3s 3ms/step\n",
            "110/110 [==============================] - 9s 84ms/step - loss: 0.5679 - val_loss: 2.5665\n",
            "Epoch 1442/1500\n",
            "876/876 [==============================] - 3s 3ms/step\n",
            "110/110 [==============================] - 6s 53ms/step - loss: 0.4857 - val_loss: 0.8656\n",
            "Epoch 1443/1500\n",
            "876/876 [==============================] - 3s 3ms/step\n",
            "110/110 [==============================] - 9s 85ms/step - loss: 0.1861 - val_loss: 0.7878\n",
            "Epoch 1444/1500\n",
            "876/876 [==============================] - 3s 3ms/step\n",
            "110/110 [==============================] - 8s 72ms/step - loss: 0.5989 - val_loss: 0.9740\n",
            "Epoch 1445/1500\n",
            "876/876 [==============================] - 3s 3ms/step\n",
            "110/110 [==============================] - 9s 84ms/step - loss: 0.6441 - val_loss: 0.8544\n",
            "Epoch 1446/1500\n",
            "876/876 [==============================] - 3s 3ms/step\n",
            "110/110 [==============================] - 6s 51ms/step - loss: 0.1942 - val_loss: 0.9052\n",
            "Epoch 1447/1500\n",
            "876/876 [==============================] - 3s 3ms/step\n",
            "110/110 [==============================] - 8s 73ms/step - loss: 0.2704 - val_loss: 1.5805\n",
            "Epoch 1448/1500\n",
            "876/876 [==============================] - 3s 3ms/step\n",
            "110/110 [==============================] - 6s 52ms/step - loss: 0.2282 - val_loss: 0.9332\n",
            "Epoch 1449/1500\n",
            "876/876 [==============================] - 3s 3ms/step\n",
            "110/110 [==============================] - 8s 72ms/step - loss: 0.2079 - val_loss: 0.8504\n",
            "Epoch 1450/1500\n",
            "876/876 [==============================] - 3s 3ms/step\n",
            "110/110 [==============================] - 6s 56ms/step - loss: 0.3548 - val_loss: 0.7183\n",
            "Epoch 1451/1500\n",
            "876/876 [==============================] - 3s 3ms/step\n",
            "110/110 [==============================] - 6s 53ms/step - loss: 0.2095 - val_loss: 0.9586\n",
            "Epoch 1452/1500\n",
            "876/876 [==============================] - 3s 3ms/step\n",
            "110/110 [==============================] - 8s 70ms/step - loss: 0.2213 - val_loss: 0.8099\n",
            "Epoch 1453/1500\n",
            "876/876 [==============================] - 3s 3ms/step\n",
            "110/110 [==============================] - 6s 51ms/step - loss: 0.2496 - val_loss: 0.8035\n",
            "Epoch 1454/1500\n",
            "876/876 [==============================] - 3s 3ms/step\n",
            "110/110 [==============================] - 8s 72ms/step - loss: 0.3334 - val_loss: 1.1166\n",
            "Epoch 1455/1500\n",
            "876/876 [==============================] - 3s 3ms/step\n",
            "110/110 [==============================] - 6s 53ms/step - loss: 0.4807 - val_loss: 1.1900\n",
            "Epoch 1456/1500\n",
            "876/876 [==============================] - 3s 3ms/step\n",
            "110/110 [==============================] - 8s 72ms/step - loss: 0.3058 - val_loss: 1.2297\n",
            "Epoch 1457/1500\n",
            "876/876 [==============================] - 3s 3ms/step\n",
            "110/110 [==============================] - 8s 75ms/step - loss: 0.3018 - val_loss: 1.6789\n",
            "Epoch 1458/1500\n",
            "876/876 [==============================] - 3s 3ms/step\n",
            "110/110 [==============================] - 8s 73ms/step - loss: 0.3054 - val_loss: 0.8842\n",
            "Epoch 1459/1500\n",
            "876/876 [==============================] - 3s 3ms/step\n",
            "110/110 [==============================] - 8s 73ms/step - loss: 0.2151 - val_loss: 0.8456\n",
            "Epoch 1460/1500\n",
            "876/876 [==============================] - 3s 3ms/step\n",
            "110/110 [==============================] - 6s 58ms/step - loss: 1.3899 - val_loss: 1.0724\n",
            "Epoch 1461/1500\n",
            "876/876 [==============================] - 3s 3ms/step\n",
            "110/110 [==============================] - 7s 64ms/step - loss: 0.3255 - val_loss: 0.8184\n",
            "Epoch 1462/1500\n",
            "876/876 [==============================] - 3s 3ms/step\n",
            "110/110 [==============================] - 6s 54ms/step - loss: 0.2147 - val_loss: 1.1937\n",
            "Epoch 1463/1500\n",
            "876/876 [==============================] - 3s 3ms/step\n",
            "110/110 [==============================] - 9s 79ms/step - loss: 0.2411 - val_loss: 0.8461\n",
            "Epoch 1464/1500\n",
            "876/876 [==============================] - 3s 3ms/step\n",
            "110/110 [==============================] - 8s 72ms/step - loss: 0.4071 - val_loss: 0.8267\n",
            "Epoch 1465/1500\n",
            "876/876 [==============================] - 3s 3ms/step\n",
            "110/110 [==============================] - 8s 77ms/step - loss: 0.3142 - val_loss: 1.0014\n",
            "Epoch 1466/1500\n",
            "876/876 [==============================] - 3s 3ms/step\n",
            "110/110 [==============================] - 6s 51ms/step - loss: 0.4599 - val_loss: 0.8890\n",
            "Epoch 1467/1500\n",
            "876/876 [==============================] - 3s 3ms/step\n",
            "110/110 [==============================] - 6s 55ms/step - loss: 0.2098 - val_loss: 0.8884\n",
            "Epoch 1468/1500\n",
            "876/876 [==============================] - 3s 3ms/step\n",
            "110/110 [==============================] - 9s 83ms/step - loss: 0.4707 - val_loss: 1.2140\n",
            "Epoch 1469/1500\n",
            "876/876 [==============================] - 3s 3ms/step\n",
            "110/110 [==============================] - 8s 74ms/step - loss: 0.3319 - val_loss: 0.9653\n",
            "Epoch 1470/1500\n",
            "876/876 [==============================] - 3s 3ms/step\n",
            "110/110 [==============================] - 7s 63ms/step - loss: 0.2293 - val_loss: 0.7979\n",
            "Epoch 1471/1500\n",
            "876/876 [==============================] - 3s 3ms/step\n",
            "110/110 [==============================] - 8s 71ms/step - loss: 0.2151 - val_loss: 1.1251\n",
            "Epoch 1472/1500\n",
            "876/876 [==============================] - 3s 3ms/step\n",
            "110/110 [==============================] - 9s 84ms/step - loss: 0.2818 - val_loss: 1.1040\n",
            "Epoch 1473/1500\n",
            "876/876 [==============================] - 3s 3ms/step\n",
            "110/110 [==============================] - 6s 51ms/step - loss: 0.3643 - val_loss: 0.9269\n",
            "Epoch 1474/1500\n",
            "876/876 [==============================] - 3s 3ms/step\n",
            "110/110 [==============================] - 7s 64ms/step - loss: 0.6163 - val_loss: 0.8213\n",
            "Epoch 1475/1500\n",
            "876/876 [==============================] - 3s 3ms/step\n",
            "110/110 [==============================] - 9s 81ms/step - loss: 0.1974 - val_loss: 0.8161\n",
            "Epoch 1476/1500\n",
            "876/876 [==============================] - 3s 3ms/step\n",
            "110/110 [==============================] - 6s 53ms/step - loss: 0.3736 - val_loss: 0.9355\n",
            "Epoch 1477/1500\n",
            "876/876 [==============================] - 3s 3ms/step\n",
            "110/110 [==============================] - 9s 84ms/step - loss: 0.4162 - val_loss: 0.8731\n",
            "Epoch 1478/1500\n",
            "876/876 [==============================] - 3s 3ms/step\n",
            "110/110 [==============================] - 8s 73ms/step - loss: 0.2578 - val_loss: 1.3027\n",
            "Epoch 1479/1500\n",
            "876/876 [==============================] - 3s 3ms/step\n",
            "110/110 [==============================] - 7s 63ms/step - loss: 0.3477 - val_loss: 1.1251\n",
            "Epoch 1480/1500\n",
            "876/876 [==============================] - 3s 3ms/step\n",
            "110/110 [==============================] - 6s 53ms/step - loss: 0.4048 - val_loss: 1.1907\n",
            "Epoch 1481/1500\n",
            "876/876 [==============================] - 3s 4ms/step\n",
            "110/110 [==============================] - 7s 67ms/step - loss: 0.2535 - val_loss: 0.9666\n",
            "Epoch 1482/1500\n",
            "876/876 [==============================] - 3s 3ms/step\n",
            "110/110 [==============================] - 9s 81ms/step - loss: 0.2151 - val_loss: 0.8481\n",
            "Epoch 1483/1500\n",
            "876/876 [==============================] - 3s 3ms/step\n",
            "110/110 [==============================] - 7s 60ms/step - loss: 0.4679 - val_loss: 1.2446\n",
            "Epoch 1484/1500\n",
            "876/876 [==============================] - 3s 3ms/step\n",
            "110/110 [==============================] - 9s 85ms/step - loss: 0.2618 - val_loss: 0.9041\n",
            "Epoch 1485/1500\n",
            "876/876 [==============================] - 3s 3ms/step\n",
            "110/110 [==============================] - 8s 73ms/step - loss: 0.2530 - val_loss: 0.8822\n",
            "Epoch 1486/1500\n",
            "876/876 [==============================] - 3s 3ms/step\n",
            "110/110 [==============================] - 6s 55ms/step - loss: 0.2791 - val_loss: 0.8459\n",
            "Epoch 1487/1500\n",
            "876/876 [==============================] - 3s 3ms/step\n",
            "110/110 [==============================] - 6s 53ms/step - loss: 0.4380 - val_loss: 2.2165\n",
            "Epoch 1488/1500\n",
            "876/876 [==============================] - 3s 3ms/step\n",
            "110/110 [==============================] - 7s 69ms/step - loss: 0.3518 - val_loss: 0.8929\n",
            "Epoch 1489/1500\n",
            "876/876 [==============================] - 3s 3ms/step\n",
            "110/110 [==============================] - 6s 58ms/step - loss: 0.2592 - val_loss: 0.8922\n",
            "Epoch 1490/1500\n",
            "876/876 [==============================] - 3s 3ms/step\n",
            "110/110 [==============================] - 8s 72ms/step - loss: 0.3738 - val_loss: 1.1499\n",
            "Epoch 1491/1500\n",
            "876/876 [==============================] - 3s 3ms/step\n",
            "110/110 [==============================] - 6s 56ms/step - loss: 0.1992 - val_loss: 0.7923\n",
            "Epoch 1492/1500\n",
            "876/876 [==============================] - 3s 3ms/step\n",
            "110/110 [==============================] - 6s 54ms/step - loss: 0.2050 - val_loss: 0.8593\n",
            "Epoch 1493/1500\n",
            "876/876 [==============================] - 3s 3ms/step\n",
            "110/110 [==============================] - 7s 67ms/step - loss: 0.3722 - val_loss: 1.5685\n",
            "Epoch 1494/1500\n",
            "876/876 [==============================] - 3s 3ms/step\n",
            "110/110 [==============================] - 6s 59ms/step - loss: 0.8194 - val_loss: 0.8891\n",
            "Epoch 1495/1500\n",
            "876/876 [==============================] - 3s 3ms/step\n",
            "110/110 [==============================] - 8s 72ms/step - loss: 0.3307 - val_loss: 0.8470\n",
            "Epoch 1496/1500\n",
            "876/876 [==============================] - 3s 3ms/step\n",
            "110/110 [==============================] - 6s 52ms/step - loss: 0.1905 - val_loss: 0.8499\n",
            "Epoch 1497/1500\n",
            "876/876 [==============================] - 3s 3ms/step\n",
            "110/110 [==============================] - 8s 73ms/step - loss: 0.4721 - val_loss: 1.1062\n",
            "Epoch 1498/1500\n",
            "876/876 [==============================] - 3s 3ms/step\n",
            "110/110 [==============================] - 6s 55ms/step - loss: 0.2294 - val_loss: 0.8294\n",
            "Epoch 1499/1500\n",
            "876/876 [==============================] - 3s 3ms/step\n",
            "110/110 [==============================] - 6s 55ms/step - loss: 0.4787 - val_loss: 2.1458\n",
            "Epoch 1500/1500\n",
            "876/876 [==============================] - 3s 3ms/step\n",
            "110/110 [==============================] - 9s 85ms/step - loss: 0.3266 - val_loss: 0.9293\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.src.callbacks.History at 0x7f6981637d00>"
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model_GRU.save('/content/drive/MyDrive/Task2/model/GRU_model.keras')"
      ],
      "metadata": {
        "id": "D3ya3OX8-s1J"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "Y_pred = model_GRU.predict(X_test)\n",
        "mse, rmse, r_squared = calculate_metrics(Y_test, Y_pred)\n",
        "print(\"Metric for LSTM\")\n",
        "print(\"MSE = \"+str(mse))\n",
        "print(\"RMSE = \"+str(rmse))\n",
        "print(\"R^2 = \"+str(r_squared))"
      ],
      "metadata": {
        "id": "wDwXz09U-C_o",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "64481903-23d8-40c5-c9f2-24bedf7b457c"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "219/219 [==============================] - 1s 2ms/step\n",
            "Metric for LSTM\n",
            "MSE = 0.9293396631862973\n",
            "RMSE = 0.9640226466148486\n",
            "R^2 = 0.9991731531248638\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model_GRU_multilayers = keras.Sequential()\n",
        "model_GRU_multilayers.add(keras.layers.GRU(units = 64,return_sequences=True, input_shape=(X_train.shape[1], X_train.shape[2])))\n",
        "model_GRU_multilayers.add( keras.layers.Dropout(0.2))\n",
        "model_GRU_multilayers.add(keras.layers.GRU(units = 64,return_sequences=True))\n",
        "model_GRU_multilayers.add( keras.layers.Dropout(0.2))\n",
        "model_GRU_multilayers.add(keras.layers.GRU(units = 64,return_sequences=True))\n",
        "model_GRU_multilayers.add( keras.layers.Dropout(0.2))\n",
        "model_GRU_multilayers.add(keras.layers.GRU(units = 64))\n",
        "model_GRU_multilayers.add( keras.layers.Dropout(0.2))\n",
        "model_GRU_multilayers.add(keras.layers.Dense(units=1))\n",
        "model_GRU_multilayers.compile(optimizer='adam', loss='mse')\n",
        "metrics_history_callback = MetricsHistory(X_train, Y_train,['Metrics over Epochs on GRU multilayers','Loss over Epochs on GRU multilayers'],['/content/drive/MyDrive/Task2/metricsGRU_multilayer.png', '/content/drive/MyDrive/Task2/lossGRU_multilayer.png'] )\n",
        "model_GRU_multilayers.fit(X_train, Y_train,validation_data =(X_test, Y_test), epochs= 1500, batch_size= 256, callbacks=[metrics_history_callback])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "QHP7jMiEzl_l",
        "outputId": "edacdc05-5093-4b92-cea3-409f708fa559"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/1500\n",
            "876/876 [==============================] - 6s 6ms/step\n",
            "110/110 [==============================] - 32s 224ms/step - loss: 1376.2560 - val_loss: 1245.5465\n",
            "Epoch 2/1500\n",
            "876/876 [==============================] - 5s 6ms/step\n",
            "110/110 [==============================] - 17s 154ms/step - loss: 1191.4701 - val_loss: 1159.9174\n",
            "Epoch 3/1500\n",
            "876/876 [==============================] - 5s 6ms/step\n",
            "110/110 [==============================] - 22s 204ms/step - loss: 1139.8580 - val_loss: 1132.3595\n",
            "Epoch 4/1500\n",
            "876/876 [==============================] - 7s 8ms/step\n",
            "110/110 [==============================] - 21s 192ms/step - loss: 1114.2310 - val_loss: 1045.2646\n",
            "Epoch 5/1500\n",
            "876/876 [==============================] - 5s 6ms/step\n",
            "110/110 [==============================] - 17s 153ms/step - loss: 756.1772 - val_loss: 622.3644\n",
            "Epoch 6/1500\n",
            "876/876 [==============================] - 5s 6ms/step\n",
            "110/110 [==============================] - 17s 153ms/step - loss: 513.1135 - val_loss: 435.3492\n",
            "Epoch 7/1500\n",
            "876/876 [==============================] - 5s 6ms/step\n",
            "110/110 [==============================] - 17s 157ms/step - loss: 388.6322 - val_loss: 341.2043\n",
            "Epoch 8/1500\n",
            "876/876 [==============================] - 6s 7ms/step\n",
            "110/110 [==============================] - 18s 162ms/step - loss: 311.3534 - val_loss: 272.9077\n",
            "Epoch 9/1500\n",
            "876/876 [==============================] - 7s 7ms/step\n",
            "110/110 [==============================] - 20s 186ms/step - loss: 251.3139 - val_loss: 221.1032\n",
            "Epoch 10/1500\n",
            "876/876 [==============================] - 5s 6ms/step\n",
            "110/110 [==============================] - 17s 154ms/step - loss: 207.4856 - val_loss: 185.0694\n",
            "Epoch 11/1500\n",
            "876/876 [==============================] - 5s 6ms/step\n",
            "110/110 [==============================] - 22s 201ms/step - loss: 175.8466 - val_loss: 159.6759\n",
            "Epoch 12/1500\n",
            "876/876 [==============================] - 7s 7ms/step\n",
            "110/110 [==============================] - 17s 151ms/step - loss: 155.3246 - val_loss: 142.6630\n",
            "Epoch 13/1500\n",
            "876/876 [==============================] - 6s 7ms/step\n",
            "110/110 [==============================] - 16s 149ms/step - loss: 140.0542 - val_loss: 131.7162\n",
            "Epoch 14/1500\n",
            "876/876 [==============================] - 6s 6ms/step\n",
            "110/110 [==============================] - 17s 153ms/step - loss: 125.1191 - val_loss: 107.5406\n",
            "Epoch 15/1500\n",
            "876/876 [==============================] - 5s 6ms/step\n",
            "110/110 [==============================] - 17s 155ms/step - loss: 105.3716 - val_loss: 91.5911\n",
            "Epoch 16/1500\n",
            "876/876 [==============================] - 5s 6ms/step\n",
            "110/110 [==============================] - 17s 155ms/step - loss: 91.5380 - val_loss: 79.6159\n",
            "Epoch 17/1500\n",
            "876/876 [==============================] - 5s 6ms/step\n",
            "110/110 [==============================] - 17s 156ms/step - loss: 80.8441 - val_loss: 68.3544\n",
            "Epoch 18/1500\n",
            "876/876 [==============================] - 6s 6ms/step\n",
            "110/110 [==============================] - 22s 201ms/step - loss: 70.9766 - val_loss: 59.8672\n",
            "Epoch 19/1500\n",
            "876/876 [==============================] - 5s 6ms/step\n",
            "110/110 [==============================] - 22s 197ms/step - loss: 63.1952 - val_loss: 52.3586\n",
            "Epoch 20/1500\n",
            "876/876 [==============================] - 6s 6ms/step\n",
            "110/110 [==============================] - 18s 162ms/step - loss: 58.3264 - val_loss: 48.3817\n",
            "Epoch 21/1500\n",
            "876/876 [==============================] - 6s 7ms/step\n",
            "110/110 [==============================] - 18s 161ms/step - loss: 53.1129 - val_loss: 44.6446\n",
            "Epoch 22/1500\n",
            "876/876 [==============================] - 7s 8ms/step\n",
            "110/110 [==============================] - 17s 156ms/step - loss: 48.0685 - val_loss: 38.0981\n",
            "Epoch 23/1500\n",
            "876/876 [==============================] - 6s 7ms/step\n",
            "110/110 [==============================] - 17s 153ms/step - loss: 45.5891 - val_loss: 34.8591\n",
            "Epoch 24/1500\n",
            "876/876 [==============================] - 5s 6ms/step\n",
            "110/110 [==============================] - 22s 201ms/step - loss: 42.1209 - val_loss: 35.1553\n",
            "Epoch 25/1500\n",
            "876/876 [==============================] - 6s 7ms/step\n",
            "110/110 [==============================] - 21s 195ms/step - loss: 38.5479 - val_loss: 27.9159\n",
            "Epoch 26/1500\n",
            "876/876 [==============================] - 5s 6ms/step\n",
            "110/110 [==============================] - 22s 199ms/step - loss: 35.7959 - val_loss: 25.1095\n",
            "Epoch 27/1500\n",
            "876/876 [==============================] - 6s 7ms/step\n",
            "110/110 [==============================] - 18s 165ms/step - loss: 32.3554 - val_loss: 22.0370\n",
            "Epoch 28/1500\n",
            "876/876 [==============================] - 6s 7ms/step\n",
            "110/110 [==============================] - 21s 189ms/step - loss: 29.1209 - val_loss: 20.3668\n",
            "Epoch 29/1500\n",
            "876/876 [==============================] - 5s 6ms/step\n",
            "110/110 [==============================] - 22s 201ms/step - loss: 28.1375 - val_loss: 19.5887\n",
            "Epoch 30/1500\n",
            "876/876 [==============================] - 6s 7ms/step\n",
            "110/110 [==============================] - 18s 161ms/step - loss: 25.4670 - val_loss: 15.5742\n",
            "Epoch 31/1500\n",
            "876/876 [==============================] - 7s 8ms/step\n",
            "110/110 [==============================] - 20s 184ms/step - loss: 24.0511 - val_loss: 13.8238\n",
            "Epoch 32/1500\n",
            "876/876 [==============================] - 5s 6ms/step\n",
            "110/110 [==============================] - 17s 154ms/step - loss: 23.6453 - val_loss: 14.9822\n",
            "Epoch 33/1500\n",
            "876/876 [==============================] - 5s 6ms/step\n",
            "110/110 [==============================] - 22s 200ms/step - loss: 22.6818 - val_loss: 12.8772\n",
            "Epoch 34/1500\n",
            "876/876 [==============================] - 7s 8ms/step\n",
            "110/110 [==============================] - 20s 180ms/step - loss: 20.8202 - val_loss: 12.4221\n",
            "Epoch 35/1500\n",
            "876/876 [==============================] - 5s 6ms/step\n",
            "110/110 [==============================] - 17s 155ms/step - loss: 20.6074 - val_loss: 14.4405\n",
            "Epoch 36/1500\n",
            "876/876 [==============================] - 5s 6ms/step\n",
            "110/110 [==============================] - 17s 155ms/step - loss: 19.4086 - val_loss: 10.4003\n",
            "Epoch 37/1500\n",
            "876/876 [==============================] - 5s 6ms/step\n",
            "110/110 [==============================] - 22s 201ms/step - loss: 19.0972 - val_loss: 11.1398\n",
            "Epoch 38/1500\n",
            "876/876 [==============================] - 5s 6ms/step\n",
            "110/110 [==============================] - 17s 153ms/step - loss: 19.0549 - val_loss: 8.6401\n",
            "Epoch 39/1500\n",
            "876/876 [==============================] - 5s 6ms/step\n",
            "110/110 [==============================] - 22s 200ms/step - loss: 17.8577 - val_loss: 8.0411\n",
            "Epoch 40/1500\n",
            "876/876 [==============================] - 7s 8ms/step\n",
            "110/110 [==============================] - 17s 158ms/step - loss: 17.1852 - val_loss: 7.6637\n",
            "Epoch 41/1500\n",
            "876/876 [==============================] - 7s 8ms/step\n",
            "110/110 [==============================] - 20s 180ms/step - loss: 16.9041 - val_loss: 8.9992\n",
            "Epoch 42/1500\n",
            "876/876 [==============================] - 5s 6ms/step\n",
            "110/110 [==============================] - 17s 157ms/step - loss: 17.0490 - val_loss: 7.4409\n",
            "Epoch 43/1500\n",
            "876/876 [==============================] - 5s 6ms/step\n",
            "110/110 [==============================] - 17s 156ms/step - loss: 16.8159 - val_loss: 6.2924\n",
            "Epoch 44/1500\n",
            "876/876 [==============================] - 5s 6ms/step\n",
            "110/110 [==============================] - 22s 201ms/step - loss: 15.7596 - val_loss: 6.7539\n",
            "Epoch 45/1500\n",
            "876/876 [==============================] - 5s 6ms/step\n",
            "110/110 [==============================] - 17s 152ms/step - loss: 15.0737 - val_loss: 5.5720\n",
            "Epoch 46/1500\n",
            "876/876 [==============================] - 5s 6ms/step\n",
            "110/110 [==============================] - 22s 200ms/step - loss: 15.1349 - val_loss: 6.0712\n",
            "Epoch 47/1500\n",
            "876/876 [==============================] - 6s 7ms/step\n",
            "110/110 [==============================] - 21s 193ms/step - loss: 14.7893 - val_loss: 5.2972\n",
            "Epoch 48/1500\n",
            "876/876 [==============================] - 5s 6ms/step\n",
            "110/110 [==============================] - 22s 200ms/step - loss: 13.4809 - val_loss: 4.7602\n",
            "Epoch 49/1500\n",
            "876/876 [==============================] - 6s 7ms/step\n",
            "110/110 [==============================] - 18s 162ms/step - loss: 14.1450 - val_loss: 4.9600\n",
            "Epoch 50/1500\n",
            "876/876 [==============================] - 6s 7ms/step\n",
            "110/110 [==============================] - 17s 153ms/step - loss: 13.9795 - val_loss: 7.7968\n",
            "Epoch 51/1500\n",
            "876/876 [==============================] - 7s 7ms/step\n",
            "110/110 [==============================] - 20s 179ms/step - loss: 14.3091 - val_loss: 4.8245\n",
            "Epoch 52/1500\n",
            "876/876 [==============================] - 5s 6ms/step\n",
            "110/110 [==============================] - 22s 202ms/step - loss: 14.2897 - val_loss: 4.5066\n",
            "Epoch 53/1500\n",
            "876/876 [==============================] - 7s 7ms/step\n",
            "110/110 [==============================] - 17s 154ms/step - loss: 12.9672 - val_loss: 4.0652\n",
            "Epoch 54/1500\n",
            "876/876 [==============================] - 7s 7ms/step\n",
            "110/110 [==============================] - 20s 179ms/step - loss: 12.9064 - val_loss: 4.1310\n",
            "Epoch 55/1500\n",
            "876/876 [==============================] - 5s 6ms/step\n",
            "110/110 [==============================] - 17s 154ms/step - loss: 12.8566 - val_loss: 3.8449\n",
            "Epoch 56/1500\n",
            "876/876 [==============================] - 5s 6ms/step\n",
            "110/110 [==============================] - 17s 153ms/step - loss: 12.5521 - val_loss: 4.7563\n",
            "Epoch 57/1500\n",
            "876/876 [==============================] - 5s 6ms/step\n",
            "110/110 [==============================] - 22s 200ms/step - loss: 13.3048 - val_loss: 5.0675\n",
            "Epoch 58/1500\n",
            "876/876 [==============================] - 6s 6ms/step\n",
            "110/110 [==============================] - 17s 151ms/step - loss: 13.3100 - val_loss: 3.3839\n",
            "Epoch 59/1500\n",
            "876/876 [==============================] - 5s 6ms/step\n",
            "110/110 [==============================] - 17s 154ms/step - loss: 12.4619 - val_loss: 13.7123\n",
            "Epoch 60/1500\n",
            "876/876 [==============================] - 5s 6ms/step\n",
            "110/110 [==============================] - 17s 156ms/step - loss: 13.5082 - val_loss: 6.6333\n",
            "Epoch 61/1500\n",
            "876/876 [==============================] - 5s 6ms/step\n",
            "110/110 [==============================] - 22s 201ms/step - loss: 12.2174 - val_loss: 5.0021\n",
            "Epoch 62/1500\n",
            "876/876 [==============================] - 5s 6ms/step\n",
            "110/110 [==============================] - 17s 151ms/step - loss: 12.8105 - val_loss: 5.4868\n",
            "Epoch 63/1500\n",
            "876/876 [==============================] - 5s 6ms/step\n",
            "110/110 [==============================] - 17s 155ms/step - loss: 12.1437 - val_loss: 3.5814\n",
            "Epoch 64/1500\n",
            "876/876 [==============================] - 5s 6ms/step\n",
            "110/110 [==============================] - 22s 200ms/step - loss: 12.1661 - val_loss: 12.2852\n",
            "Epoch 65/1500\n",
            "876/876 [==============================] - 7s 8ms/step\n",
            "110/110 [==============================] - 16s 150ms/step - loss: 12.1474 - val_loss: 2.9313\n",
            "Epoch 66/1500\n",
            "876/876 [==============================] - 6s 7ms/step\n",
            "110/110 [==============================] - 16s 149ms/step - loss: 11.9856 - val_loss: 3.3637\n",
            "Epoch 67/1500\n",
            "876/876 [==============================] - 6s 6ms/step\n",
            "110/110 [==============================] - 21s 192ms/step - loss: 12.9803 - val_loss: 8.4639\n",
            "Epoch 68/1500\n",
            "876/876 [==============================] - 5s 6ms/step\n",
            "110/110 [==============================] - 17s 156ms/step - loss: 12.8166 - val_loss: 12.3366\n",
            "Epoch 69/1500\n",
            "876/876 [==============================] - 6s 7ms/step\n",
            "110/110 [==============================] - 18s 161ms/step - loss: 13.1289 - val_loss: 3.8134\n",
            "Epoch 70/1500\n",
            "876/876 [==============================] - 7s 7ms/step\n",
            "110/110 [==============================] - 17s 158ms/step - loss: 12.3456 - val_loss: 6.6060\n",
            "Epoch 71/1500\n",
            "876/876 [==============================] - 7s 7ms/step\n",
            "110/110 [==============================] - 20s 182ms/step - loss: 12.0245 - val_loss: 4.5881\n",
            "Epoch 72/1500\n",
            "876/876 [==============================] - 5s 6ms/step\n",
            "110/110 [==============================] - 17s 156ms/step - loss: 12.1850 - val_loss: 5.7222\n",
            "Epoch 73/1500\n",
            "876/876 [==============================] - 5s 6ms/step\n",
            "110/110 [==============================] - 17s 156ms/step - loss: 12.7254 - val_loss: 6.0413\n",
            "Epoch 74/1500\n",
            "876/876 [==============================] - 5s 6ms/step\n",
            "110/110 [==============================] - 17s 158ms/step - loss: 11.6368 - val_loss: 2.9784\n",
            "Epoch 75/1500\n",
            "876/876 [==============================] - 6s 7ms/step\n",
            "110/110 [==============================] - 21s 194ms/step - loss: 12.0836 - val_loss: 5.0519\n",
            "Epoch 76/1500\n",
            "876/876 [==============================] - 5s 6ms/step\n",
            "110/110 [==============================] - 23s 211ms/step - loss: 11.7693 - val_loss: 6.9825\n",
            "Epoch 77/1500\n",
            "876/876 [==============================] - 6s 7ms/step\n",
            "110/110 [==============================] - 18s 159ms/step - loss: 11.5445 - val_loss: 3.4901\n",
            "Epoch 78/1500\n",
            "876/876 [==============================] - 7s 8ms/step\n",
            "110/110 [==============================] - 16s 149ms/step - loss: 11.7268 - val_loss: 3.7041\n",
            "Epoch 79/1500\n",
            "876/876 [==============================] - 6s 7ms/step\n",
            "110/110 [==============================] - 20s 182ms/step - loss: 11.7363 - val_loss: 5.0120\n",
            "Epoch 80/1500\n",
            "876/876 [==============================] - 5s 6ms/step\n",
            "110/110 [==============================] - 22s 199ms/step - loss: 13.4840 - val_loss: 5.9467\n",
            "Epoch 81/1500\n",
            "876/876 [==============================] - 7s 8ms/step\n",
            "110/110 [==============================] - 17s 151ms/step - loss: 11.9868 - val_loss: 2.9536\n",
            "Epoch 82/1500\n",
            "876/876 [==============================] - 6s 7ms/step\n",
            "110/110 [==============================] - 21s 188ms/step - loss: 12.1128 - val_loss: 5.4556\n",
            "Epoch 83/1500\n",
            "876/876 [==============================] - 5s 6ms/step\n",
            "110/110 [==============================] - 17s 155ms/step - loss: 11.4942 - val_loss: 4.1801\n",
            "Epoch 84/1500\n",
            "876/876 [==============================] - 5s 6ms/step\n",
            "110/110 [==============================] - 17s 158ms/step - loss: 11.2941 - val_loss: 4.7067\n",
            "Epoch 85/1500\n",
            "876/876 [==============================] - 6s 7ms/step\n",
            "110/110 [==============================] - 22s 196ms/step - loss: 11.6003 - val_loss: 2.5309\n",
            "Epoch 86/1500\n",
            "876/876 [==============================] - 5s 6ms/step\n",
            "110/110 [==============================] - 23s 211ms/step - loss: 11.4414 - val_loss: 3.1536\n",
            "Epoch 87/1500\n",
            "876/876 [==============================] - 7s 8ms/step\n",
            "110/110 [==============================] - 21s 189ms/step - loss: 11.0211 - val_loss: 3.1013\n",
            "Epoch 88/1500\n",
            "876/876 [==============================] - 5s 6ms/step\n",
            "110/110 [==============================] - 22s 200ms/step - loss: 11.3578 - val_loss: 3.5251\n",
            "Epoch 89/1500\n",
            "876/876 [==============================] - 6s 7ms/step\n",
            "110/110 [==============================] - 18s 161ms/step - loss: 11.3948 - val_loss: 3.9143\n",
            "Epoch 90/1500\n",
            "876/876 [==============================] - 7s 8ms/step\n",
            "110/110 [==============================] - 17s 152ms/step - loss: 11.3617 - val_loss: 3.9238\n",
            "Epoch 91/1500\n",
            "876/876 [==============================] - 6s 7ms/step\n",
            "110/110 [==============================] - 20s 186ms/step - loss: 11.7504 - val_loss: 4.0665\n",
            "Epoch 92/1500\n",
            "876/876 [==============================] - 5s 6ms/step\n",
            "110/110 [==============================] - 17s 157ms/step - loss: 11.6808 - val_loss: 2.4413\n",
            "Epoch 93/1500\n",
            "876/876 [==============================] - 5s 6ms/step\n",
            "110/110 [==============================] - 22s 202ms/step - loss: 11.3523 - val_loss: 6.0274\n",
            "Epoch 94/1500\n",
            "876/876 [==============================] - 6s 6ms/step\n",
            "110/110 [==============================] - 17s 157ms/step - loss: 11.4264 - val_loss: 2.7922\n",
            "Epoch 95/1500\n",
            "876/876 [==============================] - 5s 6ms/step\n",
            "110/110 [==============================] - 17s 157ms/step - loss: 10.7924 - val_loss: 3.2375\n",
            "Epoch 96/1500\n",
            "876/876 [==============================] - 5s 6ms/step\n",
            "110/110 [==============================] - 17s 154ms/step - loss: 12.0496 - val_loss: 2.9417\n",
            "Epoch 97/1500\n",
            "876/876 [==============================] - 5s 6ms/step\n",
            "110/110 [==============================] - 22s 200ms/step - loss: 10.7241 - val_loss: 2.5681\n",
            "Epoch 98/1500\n",
            "876/876 [==============================] - 6s 6ms/step\n",
            "110/110 [==============================] - 21s 194ms/step - loss: 10.8796 - val_loss: 5.0736\n",
            "Epoch 99/1500\n",
            "876/876 [==============================] - 5s 6ms/step\n",
            "110/110 [==============================] - 17s 155ms/step - loss: 11.2459 - val_loss: 2.8304\n",
            "Epoch 100/1500\n",
            "876/876 [==============================] - 6s 7ms/step\n",
            "110/110 [==============================] - 22s 197ms/step - loss: 11.5427 - val_loss: 2.4160\n",
            "Epoch 101/1500\n",
            "876/876 [==============================] - 5s 6ms/step\n",
            "110/110 [==============================] - 17s 153ms/step - loss: 10.7406 - val_loss: 2.9919\n",
            "Epoch 102/1500\n",
            "876/876 [==============================] - 5s 6ms/step\n",
            "110/110 [==============================] - 17s 155ms/step - loss: 11.1334 - val_loss: 2.5662\n",
            "Epoch 103/1500\n",
            "876/876 [==============================] - 5s 6ms/step\n",
            "110/110 [==============================] - 17s 155ms/step - loss: 11.0962 - val_loss: 5.8127\n",
            "Epoch 104/1500\n",
            "876/876 [==============================] - 5s 6ms/step\n",
            "110/110 [==============================] - 17s 157ms/step - loss: 10.6689 - val_loss: 2.5778\n",
            "Epoch 105/1500\n",
            "876/876 [==============================] - 6s 7ms/step\n",
            "110/110 [==============================] - 21s 195ms/step - loss: 11.0893 - val_loss: 5.2468\n",
            "Epoch 106/1500\n",
            "876/876 [==============================] - 5s 6ms/step\n",
            "110/110 [==============================] - 17s 153ms/step - loss: 10.7827 - val_loss: 2.3579\n",
            "Epoch 107/1500\n",
            "876/876 [==============================] - 5s 6ms/step\n",
            "110/110 [==============================] - 22s 203ms/step - loss: 11.6946 - val_loss: 18.8928\n",
            "Epoch 108/1500\n",
            "876/876 [==============================] - 7s 8ms/step\n",
            "110/110 [==============================] - 17s 158ms/step - loss: 12.3253 - val_loss: 4.6787\n",
            "Epoch 109/1500\n",
            "876/876 [==============================] - 7s 7ms/step\n",
            "110/110 [==============================] - 17s 153ms/step - loss: 10.7122 - val_loss: 2.8777\n",
            "Epoch 110/1500\n",
            "876/876 [==============================] - 5s 6ms/step\n",
            "110/110 [==============================] - 18s 163ms/step - loss: 10.6582 - val_loss: 3.1982\n",
            "Epoch 111/1500\n",
            "876/876 [==============================] - 5s 6ms/step\n",
            "110/110 [==============================] - 17s 158ms/step - loss: 10.6523 - val_loss: 3.0805\n",
            "Epoch 112/1500\n",
            "876/876 [==============================] - 5s 6ms/step\n",
            "110/110 [==============================] - 22s 203ms/step - loss: 10.5673 - val_loss: 3.1950\n",
            "Epoch 113/1500\n",
            "876/876 [==============================] - 6s 6ms/step\n",
            "110/110 [==============================] - 22s 198ms/step - loss: 10.6719 - val_loss: 2.9712\n",
            "Epoch 114/1500\n",
            "876/876 [==============================] - 6s 6ms/step\n",
            "110/110 [==============================] - 22s 202ms/step - loss: 10.5873 - val_loss: 2.7041\n",
            "Epoch 115/1500\n",
            "876/876 [==============================] - 5s 6ms/step\n",
            "110/110 [==============================] - 22s 198ms/step - loss: 10.2721 - val_loss: 3.0475\n",
            "Epoch 116/1500\n",
            "876/876 [==============================] - 6s 6ms/step\n",
            "110/110 [==============================] - 18s 164ms/step - loss: 11.6812 - val_loss: 2.4492\n",
            "Epoch 117/1500\n",
            "876/876 [==============================] - 6s 7ms/step\n",
            "110/110 [==============================] - 21s 192ms/step - loss: 11.0373 - val_loss: 2.2550\n",
            "Epoch 118/1500\n",
            "876/876 [==============================] - 5s 6ms/step\n",
            "110/110 [==============================] - 18s 169ms/step - loss: 10.3796 - val_loss: 4.5000\n",
            "Epoch 119/1500\n",
            "876/876 [==============================] - 5s 6ms/step\n",
            "110/110 [==============================] - 22s 202ms/step - loss: 10.5029 - val_loss: 6.9016\n",
            "Epoch 120/1500\n",
            "876/876 [==============================] - 6s 7ms/step\n",
            "110/110 [==============================] - 17s 154ms/step - loss: 10.8864 - val_loss: 4.8630\n",
            "Epoch 121/1500\n",
            "876/876 [==============================] - 5s 6ms/step\n",
            "110/110 [==============================] - 21s 195ms/step - loss: 10.9885 - val_loss: 4.5671\n",
            "Epoch 122/1500\n",
            "876/876 [==============================] - 6s 6ms/step\n",
            "110/110 [==============================] - 18s 162ms/step - loss: 11.0742 - val_loss: 2.9297\n",
            "Epoch 123/1500\n",
            "876/876 [==============================] - 7s 8ms/step\n",
            "110/110 [==============================] - 21s 193ms/step - loss: 10.6954 - val_loss: 2.2007\n",
            "Epoch 124/1500\n",
            "876/876 [==============================] - 5s 6ms/step\n",
            "110/110 [==============================] - 17s 158ms/step - loss: 10.5478 - val_loss: 2.6441\n",
            "Epoch 125/1500\n",
            "876/876 [==============================] - 5s 6ms/step\n",
            "110/110 [==============================] - 17s 158ms/step - loss: 11.0194 - val_loss: 3.9897\n",
            "Epoch 126/1500\n",
            "876/876 [==============================] - 5s 6ms/step\n",
            "110/110 [==============================] - 22s 202ms/step - loss: 10.8564 - val_loss: 2.3913\n",
            "Epoch 127/1500\n",
            "876/876 [==============================] - 6s 7ms/step\n",
            "110/110 [==============================] - 17s 154ms/step - loss: 10.5822 - val_loss: 7.5425\n",
            "Epoch 128/1500\n",
            "876/876 [==============================] - 5s 6ms/step\n",
            "110/110 [==============================] - 17s 157ms/step - loss: 10.4639 - val_loss: 2.3194\n",
            "Epoch 129/1500\n",
            "876/876 [==============================] - 5s 6ms/step\n",
            "110/110 [==============================] - 17s 156ms/step - loss: 9.9167 - val_loss: 3.4939\n",
            "Epoch 130/1500\n",
            "876/876 [==============================] - 5s 6ms/step\n",
            "110/110 [==============================] - 22s 201ms/step - loss: 10.1700 - val_loss: 2.1126\n",
            "Epoch 131/1500\n",
            "876/876 [==============================] - 6s 6ms/step\n",
            "110/110 [==============================] - 17s 155ms/step - loss: 11.5056 - val_loss: 5.1672\n",
            "Epoch 132/1500\n",
            "876/876 [==============================] - 5s 6ms/step\n",
            "110/110 [==============================] - 22s 202ms/step - loss: 10.6125 - val_loss: 2.4519\n",
            "Epoch 133/1500\n",
            "876/876 [==============================] - 7s 8ms/step\n",
            "110/110 [==============================] - 18s 160ms/step - loss: 10.4209 - val_loss: 5.1847\n",
            "Epoch 134/1500\n",
            "876/876 [==============================] - 7s 8ms/step\n",
            "110/110 [==============================] - 20s 181ms/step - loss: 10.6285 - val_loss: 2.2736\n",
            "Epoch 135/1500\n",
            "876/876 [==============================] - 5s 6ms/step\n",
            "110/110 [==============================] - 17s 156ms/step - loss: 9.6826 - val_loss: 1.8624\n",
            "Epoch 136/1500\n",
            "876/876 [==============================] - 5s 6ms/step\n",
            "110/110 [==============================] - 17s 158ms/step - loss: 10.8673 - val_loss: 4.7902\n",
            "Epoch 137/1500\n",
            "876/876 [==============================] - 5s 6ms/step\n",
            "110/110 [==============================] - 22s 202ms/step - loss: 10.7062 - val_loss: 2.6496\n",
            "Epoch 138/1500\n",
            "876/876 [==============================] - 6s 6ms/step\n",
            "110/110 [==============================] - 17s 155ms/step - loss: 10.2915 - val_loss: 3.4764\n",
            "Epoch 139/1500\n",
            "876/876 [==============================] - 5s 6ms/step\n",
            "110/110 [==============================] - 22s 201ms/step - loss: 10.1376 - val_loss: 2.1392\n",
            "Epoch 140/1500\n",
            "876/876 [==============================] - 7s 8ms/step\n",
            "110/110 [==============================] - 18s 162ms/step - loss: 10.5329 - val_loss: 2.1511\n",
            "Epoch 141/1500\n",
            "876/876 [==============================] - 7s 8ms/step\n",
            "110/110 [==============================] - 20s 181ms/step - loss: 9.6769 - val_loss: 2.0475\n",
            "Epoch 142/1500\n",
            "876/876 [==============================] - 5s 6ms/step\n",
            "110/110 [==============================] - 17s 157ms/step - loss: 9.9850 - val_loss: 3.5144\n",
            "Epoch 143/1500\n",
            "876/876 [==============================] - 5s 6ms/step\n",
            "110/110 [==============================] - 17s 155ms/step - loss: 10.8797 - val_loss: 4.0615\n",
            "Epoch 144/1500\n",
            "876/876 [==============================] - 5s 6ms/step\n",
            "110/110 [==============================] - 22s 199ms/step - loss: 10.1580 - val_loss: 3.3242\n",
            "Epoch 145/1500\n",
            "876/876 [==============================] - 6s 7ms/step\n",
            "110/110 [==============================] - 21s 194ms/step - loss: 10.5825 - val_loss: 3.0711\n",
            "Epoch 146/1500\n",
            "876/876 [==============================] - 5s 6ms/step\n",
            "110/110 [==============================] - 22s 203ms/step - loss: 10.9485 - val_loss: 3.0722\n",
            "Epoch 147/1500\n",
            "876/876 [==============================] - 6s 7ms/step\n",
            "110/110 [==============================] - 17s 154ms/step - loss: 9.7815 - val_loss: 2.7881\n",
            "Epoch 148/1500\n",
            "876/876 [==============================] - 5s 6ms/step\n",
            "110/110 [==============================] - 22s 200ms/step - loss: 9.8014 - val_loss: 1.9140\n",
            "Epoch 149/1500\n",
            "876/876 [==============================] - 6s 7ms/step\n",
            "110/110 [==============================] - 18s 162ms/step - loss: 10.6123 - val_loss: 2.7635\n",
            "Epoch 150/1500\n",
            "876/876 [==============================] - 7s 8ms/step\n",
            "110/110 [==============================] - 17s 155ms/step - loss: 10.5365 - val_loss: 8.4708\n",
            "Epoch 151/1500\n",
            "876/876 [==============================] - 7s 8ms/step\n",
            "110/110 [==============================] - 20s 179ms/step - loss: 10.1611 - val_loss: 1.7916\n",
            "Epoch 152/1500\n",
            "876/876 [==============================] - 5s 6ms/step\n",
            "110/110 [==============================] - 22s 202ms/step - loss: 10.0083 - val_loss: 3.2246\n",
            "Epoch 153/1500\n",
            "876/876 [==============================] - 6s 7ms/step\n",
            "110/110 [==============================] - 21s 192ms/step - loss: 10.0944 - val_loss: 2.6362\n",
            "Epoch 154/1500\n",
            "876/876 [==============================] - 5s 6ms/step\n",
            "110/110 [==============================] - 17s 155ms/step - loss: 9.9775 - val_loss: 4.4064\n",
            "Epoch 155/1500\n",
            "876/876 [==============================] - 5s 6ms/step\n",
            "110/110 [==============================] - 17s 157ms/step - loss: 10.1548 - val_loss: 1.7765\n",
            "Epoch 156/1500\n",
            "876/876 [==============================] - 5s 6ms/step\n",
            "110/110 [==============================] - 22s 200ms/step - loss: 10.0803 - val_loss: 3.4450\n",
            "Epoch 157/1500\n",
            "876/876 [==============================] - 6s 7ms/step\n",
            "110/110 [==============================] - 16s 150ms/step - loss: 9.6037 - val_loss: 1.7629\n",
            "Epoch 158/1500\n",
            "876/876 [==============================] - 6s 6ms/step\n",
            "110/110 [==============================] - 21s 194ms/step - loss: 11.5090 - val_loss: 2.8283\n",
            "Epoch 159/1500\n",
            "876/876 [==============================] - 5s 6ms/step\n",
            "110/110 [==============================] - 22s 200ms/step - loss: 9.6976 - val_loss: 2.1782\n",
            "Epoch 160/1500\n",
            "876/876 [==============================] - 6s 7ms/step\n",
            "110/110 [==============================] - 21s 192ms/step - loss: 10.0116 - val_loss: 1.7267\n",
            "Epoch 161/1500\n",
            "876/876 [==============================] - 5s 6ms/step\n",
            "110/110 [==============================] - 17s 158ms/step - loss: 10.0493 - val_loss: 1.9378\n",
            "Epoch 162/1500\n",
            "876/876 [==============================] - 6s 7ms/step\n",
            "110/110 [==============================] - 22s 200ms/step - loss: 9.8950 - val_loss: 5.0513\n",
            "Epoch 163/1500\n",
            "876/876 [==============================] - 5s 6ms/step\n",
            "110/110 [==============================] - 17s 156ms/step - loss: 9.4210 - val_loss: 3.4587\n",
            "Epoch 164/1500\n",
            "876/876 [==============================] - 5s 6ms/step\n",
            "110/110 [==============================] - 17s 156ms/step - loss: 9.5163 - val_loss: 4.4417\n",
            "Epoch 165/1500\n",
            "876/876 [==============================] - 5s 6ms/step\n",
            "110/110 [==============================] - 22s 199ms/step - loss: 9.6004 - val_loss: 1.8960\n",
            "Epoch 166/1500\n",
            "876/876 [==============================] - 6s 6ms/step\n",
            "110/110 [==============================] - 21s 195ms/step - loss: 9.8432 - val_loss: 3.4289\n",
            "Epoch 167/1500\n",
            "876/876 [==============================] - 5s 6ms/step\n",
            "110/110 [==============================] - 17s 155ms/step - loss: 9.3524 - val_loss: 1.8241\n",
            "Epoch 168/1500\n",
            "876/876 [==============================] - 6s 6ms/step\n",
            "110/110 [==============================] - 22s 200ms/step - loss: 10.0141 - val_loss: 4.1492\n",
            "Epoch 169/1500\n",
            "876/876 [==============================] - 5s 6ms/step\n",
            "110/110 [==============================] - 22s 198ms/step - loss: 9.5973 - val_loss: 1.9658\n",
            "Epoch 170/1500\n",
            "876/876 [==============================] - 5s 6ms/step\n",
            "110/110 [==============================] - 22s 200ms/step - loss: 9.7444 - val_loss: 2.4846\n",
            "Epoch 171/1500\n",
            "876/876 [==============================] - 6s 6ms/step\n",
            "110/110 [==============================] - 21s 193ms/step - loss: 10.0120 - val_loss: 2.2852\n",
            "Epoch 172/1500\n",
            "876/876 [==============================] - 5s 6ms/step\n",
            "110/110 [==============================] - 22s 201ms/step - loss: 10.4675 - val_loss: 2.9775\n",
            "Epoch 173/1500\n",
            "876/876 [==============================] - 6s 6ms/step\n",
            "110/110 [==============================] - 17s 154ms/step - loss: 9.3519 - val_loss: 2.9748\n",
            "Epoch 174/1500\n",
            "876/876 [==============================] - 5s 6ms/step\n",
            "110/110 [==============================] - 22s 201ms/step - loss: 9.2102 - val_loss: 5.5708\n",
            "Epoch 175/1500\n",
            "876/876 [==============================] - 6s 7ms/step\n",
            "110/110 [==============================] - 17s 159ms/step - loss: 9.5145 - val_loss: 3.0101\n",
            "Epoch 176/1500\n",
            "876/876 [==============================] - 7s 8ms/step\n",
            "110/110 [==============================] - 20s 184ms/step - loss: 9.5331 - val_loss: 4.9194\n",
            "Epoch 177/1500\n",
            "876/876 [==============================] - 5s 6ms/step\n",
            "110/110 [==============================] - 17s 158ms/step - loss: 9.6724 - val_loss: 3.0895\n",
            "Epoch 178/1500\n",
            "876/876 [==============================] - 5s 6ms/step\n",
            "110/110 [==============================] - 22s 202ms/step - loss: 9.8413 - val_loss: 2.1596\n",
            "Epoch 179/1500\n",
            "876/876 [==============================] - 7s 8ms/step\n",
            "110/110 [==============================] - 17s 154ms/step - loss: 9.8779 - val_loss: 1.3701\n",
            "Epoch 180/1500\n",
            "876/876 [==============================] - 6s 7ms/step\n",
            "110/110 [==============================] - 21s 196ms/step - loss: 9.6692 - val_loss: 4.0546\n",
            "Epoch 181/1500\n",
            "876/876 [==============================] - 5s 6ms/step\n",
            "110/110 [==============================] - 17s 159ms/step - loss: 9.9264 - val_loss: 2.0301\n",
            "Epoch 182/1500\n",
            "876/876 [==============================] - 6s 7ms/step\n",
            "110/110 [==============================] - 18s 165ms/step - loss: 9.8717 - val_loss: 3.0021\n",
            "Epoch 183/1500\n",
            "876/876 [==============================] - 7s 8ms/step\n",
            "110/110 [==============================] - 20s 184ms/step - loss: 9.1549 - val_loss: 1.9261\n",
            "Epoch 184/1500\n",
            "876/876 [==============================] - 5s 6ms/step\n",
            "110/110 [==============================] - 17s 157ms/step - loss: 9.0564 - val_loss: 3.1991\n",
            "Epoch 185/1500\n",
            "876/876 [==============================] - 5s 6ms/step\n",
            "110/110 [==============================] - 22s 202ms/step - loss: 10.3765 - val_loss: 3.6684\n",
            "Epoch 186/1500\n",
            "876/876 [==============================] - 7s 8ms/step\n",
            "110/110 [==============================] - 17s 151ms/step - loss: 9.7975 - val_loss: 1.5690\n",
            "Epoch 187/1500\n",
            "876/876 [==============================] - 6s 7ms/step\n",
            "110/110 [==============================] - 21s 188ms/step - loss: 9.5879 - val_loss: 2.6866\n",
            "Epoch 188/1500\n",
            "876/876 [==============================] - 5s 6ms/step\n",
            "110/110 [==============================] - 17s 157ms/step - loss: 10.1657 - val_loss: 1.8332\n",
            "Epoch 189/1500\n",
            "876/876 [==============================] - 6s 6ms/step\n",
            "110/110 [==============================] - 18s 165ms/step - loss: 9.9620 - val_loss: 1.8458\n",
            "Epoch 190/1500\n",
            "876/876 [==============================] - 6s 7ms/step\n",
            "110/110 [==============================] - 18s 164ms/step - loss: 9.6822 - val_loss: 3.0442\n",
            "Epoch 191/1500\n",
            "876/876 [==============================] - 7s 8ms/step\n",
            "110/110 [==============================] - 17s 154ms/step - loss: 9.4916 - val_loss: 2.5052\n",
            "Epoch 192/1500\n",
            "876/876 [==============================] - 7s 7ms/step\n",
            "110/110 [==============================] - 20s 187ms/step - loss: 9.4450 - val_loss: 3.4040\n",
            "Epoch 193/1500\n",
            "876/876 [==============================] - 5s 6ms/step\n",
            "110/110 [==============================] - 17s 160ms/step - loss: 9.5793 - val_loss: 4.8485\n",
            "Epoch 194/1500\n",
            "876/876 [==============================] - 5s 6ms/step\n",
            "110/110 [==============================] - 18s 160ms/step - loss: 10.0055 - val_loss: 3.0702\n",
            "Epoch 195/1500\n",
            "876/876 [==============================] - 6s 7ms/step\n",
            "110/110 [==============================] - 22s 198ms/step - loss: 9.6797 - val_loss: 2.4170\n",
            "Epoch 196/1500\n",
            "876/876 [==============================] - 5s 6ms/step\n",
            "110/110 [==============================] - 22s 200ms/step - loss: 10.0940 - val_loss: 2.8723\n",
            "Epoch 197/1500\n",
            "876/876 [==============================] - 6s 7ms/step\n",
            "110/110 [==============================] - 22s 202ms/step - loss: 10.2380 - val_loss: 6.1848\n",
            "Epoch 198/1500\n",
            "876/876 [==============================] - 5s 6ms/step\n",
            "110/110 [==============================] - 17s 156ms/step - loss: 9.5867 - val_loss: 1.7993\n",
            "Epoch 199/1500\n",
            "876/876 [==============================] - 5s 6ms/step\n",
            "110/110 [==============================] - 17s 159ms/step - loss: 9.4002 - val_loss: 1.9728\n",
            "Epoch 200/1500\n",
            "876/876 [==============================] - 5s 6ms/step\n",
            "110/110 [==============================] - 17s 157ms/step - loss: 9.4343 - val_loss: 2.5122\n",
            "Epoch 201/1500\n",
            "876/876 [==============================] - 6s 6ms/step\n",
            "110/110 [==============================] - 22s 202ms/step - loss: 9.3036 - val_loss: 1.4928\n",
            "Epoch 202/1500\n",
            "876/876 [==============================] - 6s 6ms/step\n",
            "110/110 [==============================] - 17s 156ms/step - loss: 10.0170 - val_loss: 2.3358\n",
            "Epoch 203/1500\n",
            "876/876 [==============================] - 5s 6ms/step\n",
            "110/110 [==============================] - 22s 203ms/step - loss: 9.1986 - val_loss: 1.5754\n",
            "Epoch 204/1500\n",
            "876/876 [==============================] - 7s 8ms/step\n",
            "110/110 [==============================] - 18s 164ms/step - loss: 9.0669 - val_loss: 2.2625\n",
            "Epoch 205/1500\n",
            "876/876 [==============================] - 7s 8ms/step\n",
            "110/110 [==============================] - 20s 183ms/step - loss: 9.3066 - val_loss: 1.9274\n",
            "Epoch 206/1500\n",
            "876/876 [==============================] - 5s 6ms/step\n",
            "110/110 [==============================] - 22s 204ms/step - loss: 9.6278 - val_loss: 1.6180\n",
            "Epoch 207/1500\n",
            "876/876 [==============================] - 7s 8ms/step\n",
            "110/110 [==============================] - 21s 192ms/step - loss: 8.8601 - val_loss: 4.6398\n",
            "Epoch 208/1500\n",
            "876/876 [==============================] - 5s 6ms/step\n",
            "110/110 [==============================] - 22s 203ms/step - loss: 9.6037 - val_loss: 1.8490\n",
            "Epoch 209/1500\n",
            "876/876 [==============================] - 6s 7ms/step\n",
            "110/110 [==============================] - 22s 199ms/step - loss: 9.0065 - val_loss: 2.8517\n",
            "Epoch 210/1500\n",
            "876/876 [==============================] - 5s 6ms/step\n",
            "110/110 [==============================] - 17s 159ms/step - loss: 9.5842 - val_loss: 4.2635\n",
            "Epoch 211/1500\n",
            "876/876 [==============================] - 5s 6ms/step\n",
            "110/110 [==============================] - 22s 204ms/step - loss: 9.4787 - val_loss: 1.9913\n",
            "Epoch 212/1500\n",
            "876/876 [==============================] - 7s 8ms/step\n",
            "110/110 [==============================] - 20s 186ms/step - loss: 9.3354 - val_loss: 2.3304\n",
            "Epoch 213/1500\n",
            "876/876 [==============================] - 5s 6ms/step\n",
            "110/110 [==============================] - 17s 159ms/step - loss: 9.1520 - val_loss: 2.5050\n",
            "Epoch 214/1500\n",
            "876/876 [==============================] - 5s 6ms/step\n",
            "110/110 [==============================] - 17s 158ms/step - loss: 9.2708 - val_loss: 5.7853\n",
            "Epoch 215/1500\n",
            "876/876 [==============================] - 6s 6ms/step\n",
            "110/110 [==============================] - 22s 203ms/step - loss: 9.3937 - val_loss: 2.5944\n",
            "Epoch 216/1500\n",
            "876/876 [==============================] - 6s 6ms/step\n",
            "110/110 [==============================] - 17s 157ms/step - loss: 9.6673 - val_loss: 5.4157\n",
            "Epoch 217/1500\n",
            "876/876 [==============================] - 5s 6ms/step\n",
            "110/110 [==============================] - 17s 159ms/step - loss: 9.4169 - val_loss: 4.7203\n",
            "Epoch 218/1500\n",
            "876/876 [==============================] - 5s 6ms/step\n",
            "110/110 [==============================] - 17s 158ms/step - loss: 9.3571 - val_loss: 2.1670\n",
            "Epoch 219/1500\n",
            "876/876 [==============================] - 6s 6ms/step\n",
            "110/110 [==============================] - 18s 164ms/step - loss: 9.6311 - val_loss: 2.4276\n",
            "Epoch 220/1500\n",
            "876/876 [==============================] - 6s 7ms/step\n",
            "110/110 [==============================] - 18s 165ms/step - loss: 9.3413 - val_loss: 2.7138\n",
            "Epoch 221/1500\n",
            "876/876 [==============================] - 7s 8ms/step\n",
            "110/110 [==============================] - 20s 185ms/step - loss: 9.8005 - val_loss: 2.2821\n",
            "Epoch 222/1500\n",
            "876/876 [==============================] - 5s 6ms/step\n",
            "110/110 [==============================] - 17s 160ms/step - loss: 9.3294 - val_loss: 1.7581\n",
            "Epoch 223/1500\n",
            "876/876 [==============================] - 5s 6ms/step\n",
            "110/110 [==============================] - 22s 204ms/step - loss: 9.2435 - val_loss: 1.6154\n",
            "Epoch 224/1500\n",
            "876/876 [==============================] - 7s 8ms/step\n",
            "110/110 [==============================] - 20s 184ms/step - loss: 8.9183 - val_loss: 1.5702\n",
            "Epoch 225/1500\n",
            "876/876 [==============================] - 5s 6ms/step\n",
            "110/110 [==============================] - 17s 159ms/step - loss: 8.8685 - val_loss: 1.3686\n",
            "Epoch 226/1500\n",
            "876/876 [==============================] - 5s 6ms/step\n",
            "110/110 [==============================] - 22s 202ms/step - loss: 8.6253 - val_loss: 1.7741\n",
            "Epoch 227/1500\n",
            "876/876 [==============================] - 6s 7ms/step\n",
            "110/110 [==============================] - 21s 191ms/step - loss: 8.9544 - val_loss: 2.7454\n",
            "Epoch 228/1500\n",
            "876/876 [==============================] - 5s 6ms/step\n",
            "110/110 [==============================] - 17s 158ms/step - loss: 9.2061 - val_loss: 1.8203\n",
            "Epoch 229/1500\n",
            "876/876 [==============================] - 6s 7ms/step\n",
            "110/110 [==============================] - 18s 167ms/step - loss: 9.3638 - val_loss: 2.0500\n",
            "Epoch 230/1500\n",
            "876/876 [==============================] - 7s 8ms/step\n",
            "110/110 [==============================] - 18s 164ms/step - loss: 8.9105 - val_loss: 1.4531\n",
            "Epoch 231/1500\n",
            "876/876 [==============================] - 7s 8ms/step\n",
            "110/110 [==============================] - 20s 183ms/step - loss: 9.2796 - val_loss: 2.2227\n",
            "Epoch 232/1500\n",
            "876/876 [==============================] - 5s 6ms/step\n",
            "110/110 [==============================] - 18s 161ms/step - loss: 9.6619 - val_loss: 2.5293\n",
            "Epoch 233/1500\n",
            "876/876 [==============================] - 5s 6ms/step\n",
            "110/110 [==============================] - 18s 161ms/step - loss: 8.9053 - val_loss: 1.8696\n",
            "Epoch 234/1500\n",
            "876/876 [==============================] - 6s 7ms/step\n",
            "110/110 [==============================] - 22s 204ms/step - loss: 9.3690 - val_loss: 1.5312\n",
            "Epoch 235/1500\n",
            "876/876 [==============================] - 6s 6ms/step\n",
            "110/110 [==============================] - 22s 199ms/step - loss: 8.5878 - val_loss: 2.3371\n",
            "Epoch 236/1500\n",
            "876/876 [==============================] - 6s 7ms/step\n",
            "110/110 [==============================] - 18s 167ms/step - loss: 9.5434 - val_loss: 3.8517\n",
            "Epoch 237/1500\n",
            "876/876 [==============================] - 7s 8ms/step\n",
            "110/110 [==============================] - 18s 164ms/step - loss: 9.8305 - val_loss: 3.1557\n",
            "Epoch 238/1500\n",
            "876/876 [==============================] - 7s 8ms/step\n",
            "110/110 [==============================] - 20s 185ms/step - loss: 9.0138 - val_loss: 1.9070\n",
            "Epoch 239/1500\n",
            "876/876 [==============================] - 5s 6ms/step\n",
            "110/110 [==============================] - 17s 159ms/step - loss: 9.3292 - val_loss: 1.4216\n",
            "Epoch 240/1500\n",
            "876/876 [==============================] - 5s 6ms/step\n",
            "110/110 [==============================] - 22s 202ms/step - loss: 8.8021 - val_loss: 3.2488\n",
            "Epoch 241/1500\n",
            "876/876 [==============================] - 7s 8ms/step\n",
            "110/110 [==============================] - 17s 155ms/step - loss: 8.6503 - val_loss: 2.7299\n",
            "Epoch 242/1500\n",
            "876/876 [==============================] - 6s 7ms/step\n",
            "110/110 [==============================] - 17s 159ms/step - loss: 9.0622 - val_loss: 3.8019\n",
            "Epoch 243/1500\n",
            "876/876 [==============================] - 5s 6ms/step\n",
            "110/110 [==============================] - 22s 203ms/step - loss: 8.9187 - val_loss: 1.4269\n",
            "Epoch 244/1500\n",
            "876/876 [==============================] - 6s 7ms/step\n",
            "110/110 [==============================] - 18s 167ms/step - loss: 9.2906 - val_loss: 2.1827\n",
            "Epoch 245/1500\n",
            "876/876 [==============================] - 7s 8ms/step\n",
            "110/110 [==============================] - 21s 188ms/step - loss: 8.7466 - val_loss: 1.5177\n",
            "Epoch 246/1500\n",
            "876/876 [==============================] - 5s 6ms/step\n",
            "110/110 [==============================] - 18s 162ms/step - loss: 9.0746 - val_loss: 1.4767\n",
            "Epoch 247/1500\n",
            "876/876 [==============================] - 5s 6ms/step\n",
            "110/110 [==============================] - 18s 160ms/step - loss: 8.9261 - val_loss: 2.5782\n",
            "Epoch 248/1500\n",
            "876/876 [==============================] - 6s 6ms/step\n",
            "110/110 [==============================] - 22s 203ms/step - loss: 8.7141 - val_loss: 1.9809\n",
            "Epoch 249/1500\n",
            "876/876 [==============================] - 6s 7ms/step\n",
            "110/110 [==============================] - 22s 197ms/step - loss: 9.0844 - val_loss: 2.4865\n",
            "Epoch 250/1500\n",
            "876/876 [==============================] - 6s 6ms/step\n",
            "110/110 [==============================] - 18s 165ms/step - loss: 8.8945 - val_loss: 1.3208\n",
            "Epoch 251/1500\n",
            "876/876 [==============================] - 6s 7ms/step\n",
            "110/110 [==============================] - 18s 168ms/step - loss: 8.5223 - val_loss: 2.2301\n",
            "Epoch 252/1500\n",
            "876/876 [==============================] - 7s 8ms/step\n",
            "110/110 [==============================] - 18s 161ms/step - loss: 8.8694 - val_loss: 2.9708\n",
            "Epoch 253/1500\n",
            "876/876 [==============================] - 7s 7ms/step\n",
            "110/110 [==============================] - 20s 187ms/step - loss: 9.2510 - val_loss: 3.2256\n",
            "Epoch 254/1500\n",
            "876/876 [==============================] - 5s 6ms/step\n",
            "110/110 [==============================] - 18s 162ms/step - loss: 8.6457 - val_loss: 3.4961\n",
            "Epoch 255/1500\n",
            "876/876 [==============================] - 5s 6ms/step\n",
            "110/110 [==============================] - 18s 165ms/step - loss: 9.0482 - val_loss: 1.7985\n",
            "Epoch 256/1500\n",
            "876/876 [==============================] - 6s 7ms/step\n",
            "110/110 [==============================] - 22s 201ms/step - loss: 9.7659 - val_loss: 2.8033\n",
            "Epoch 257/1500\n",
            "876/876 [==============================] - 5s 6ms/step\n",
            "110/110 [==============================] - 22s 204ms/step - loss: 8.5573 - val_loss: 2.1876\n",
            "Epoch 258/1500\n",
            "876/876 [==============================] - 6s 7ms/step\n",
            "110/110 [==============================] - 19s 171ms/step - loss: 8.7021 - val_loss: 1.5782\n",
            "Epoch 259/1500\n",
            "876/876 [==============================] - 7s 8ms/step\n",
            "110/110 [==============================] - 21s 188ms/step - loss: 8.6327 - val_loss: 3.8514\n",
            "Epoch 260/1500\n",
            "876/876 [==============================] - 5s 6ms/step\n",
            "110/110 [==============================] - 18s 160ms/step - loss: 9.5568 - val_loss: 1.6138\n",
            "Epoch 261/1500\n",
            "876/876 [==============================] - 5s 6ms/step\n",
            "110/110 [==============================] - 18s 164ms/step - loss: 9.1868 - val_loss: 1.7499\n",
            "Epoch 262/1500\n",
            "876/876 [==============================] - 6s 6ms/step\n",
            "110/110 [==============================] - 18s 166ms/step - loss: 8.5280 - val_loss: 2.5074\n",
            "Epoch 263/1500\n",
            "876/876 [==============================] - 6s 7ms/step\n",
            "110/110 [==============================] - 22s 198ms/step - loss: 9.0537 - val_loss: 4.9145\n",
            "Epoch 264/1500\n",
            "876/876 [==============================] - 5s 6ms/step\n",
            "110/110 [==============================] - 18s 161ms/step - loss: 8.7777 - val_loss: 2.2185\n",
            "Epoch 265/1500\n",
            "876/876 [==============================] - 5s 6ms/step\n",
            "110/110 [==============================] - 22s 205ms/step - loss: 9.1917 - val_loss: 2.4696\n",
            "Epoch 266/1500\n",
            "876/876 [==============================] - 7s 8ms/step\n",
            "110/110 [==============================] - 17s 156ms/step - loss: 9.3700 - val_loss: 2.1672\n",
            "Epoch 267/1500\n",
            "876/876 [==============================] - 6s 7ms/step\n",
            "110/110 [==============================] - 17s 154ms/step - loss: 8.4420 - val_loss: 1.8327\n",
            "Epoch 268/1500\n",
            "876/876 [==============================] - 5s 6ms/step\n",
            "110/110 [==============================] - 18s 160ms/step - loss: 9.2540 - val_loss: 1.6166\n",
            "Epoch 269/1500\n",
            "876/876 [==============================] - 5s 6ms/step\n",
            "110/110 [==============================] - 18s 161ms/step - loss: 8.7381 - val_loss: 1.1898\n",
            "Epoch 270/1500\n",
            "876/876 [==============================] - 5s 6ms/step\n",
            "110/110 [==============================] - 18s 164ms/step - loss: 8.4643 - val_loss: 2.5273\n",
            "Epoch 271/1500\n",
            "876/876 [==============================] - 6s 7ms/step\n",
            "110/110 [==============================] - 18s 168ms/step - loss: 8.7848 - val_loss: 1.4191\n",
            "Epoch 272/1500\n",
            "876/876 [==============================] - 7s 8ms/step\n",
            "110/110 [==============================] - 21s 188ms/step - loss: 9.0086 - val_loss: 2.0870\n",
            "Epoch 273/1500\n",
            "876/876 [==============================] - 5s 6ms/step\n",
            "110/110 [==============================] - 22s 201ms/step - loss: 8.9375 - val_loss: 3.3329\n",
            "Epoch 274/1500\n",
            "876/876 [==============================] - 6s 7ms/step\n",
            "110/110 [==============================] - 18s 166ms/step - loss: 8.8679 - val_loss: 1.3891\n",
            "Epoch 275/1500\n",
            "876/876 [==============================] - 7s 8ms/step\n",
            "110/110 [==============================] - 18s 159ms/step - loss: 8.6192 - val_loss: 1.2978\n",
            "Epoch 276/1500\n",
            "876/876 [==============================] - 7s 8ms/step\n",
            "110/110 [==============================] - 17s 155ms/step - loss: 9.3199 - val_loss: 3.0591\n",
            "Epoch 277/1500\n",
            "876/876 [==============================] - 7s 7ms/step\n",
            "110/110 [==============================] - 17s 157ms/step - loss: 8.6158 - val_loss: 1.4697\n",
            "Epoch 278/1500\n",
            "876/876 [==============================] - 6s 6ms/step\n",
            "110/110 [==============================] - 17s 159ms/step - loss: 8.6802 - val_loss: 1.5765\n",
            "Epoch 279/1500\n",
            "876/876 [==============================] - 5s 6ms/step\n",
            "110/110 [==============================] - 22s 205ms/step - loss: 8.0167 - val_loss: 1.9673\n",
            "Epoch 280/1500\n",
            "876/876 [==============================] - 7s 8ms/step\n",
            "110/110 [==============================] - 20s 185ms/step - loss: 8.2454 - val_loss: 2.1976\n",
            "Epoch 281/1500\n",
            "876/876 [==============================] - 5s 6ms/step\n",
            "110/110 [==============================] - 22s 202ms/step - loss: 8.1751 - val_loss: 1.2509\n",
            "Epoch 282/1500\n",
            "876/876 [==============================] - 7s 7ms/step\n",
            "110/110 [==============================] - 22s 200ms/step - loss: 8.4042 - val_loss: 1.3607\n",
            "Epoch 283/1500\n",
            "876/876 [==============================] - 5s 6ms/step\n",
            "110/110 [==============================] - 22s 202ms/step - loss: 8.8321 - val_loss: 4.1171\n",
            "Epoch 284/1500\n",
            "876/876 [==============================] - 6s 7ms/step\n",
            "110/110 [==============================] - 18s 168ms/step - loss: 8.9023 - val_loss: 2.0463\n",
            "Epoch 285/1500\n",
            "876/876 [==============================] - 7s 8ms/step\n",
            "110/110 [==============================] - 18s 167ms/step - loss: 8.8833 - val_loss: 1.5663\n",
            "Epoch 286/1500\n",
            "876/876 [==============================] - 7s 8ms/step\n",
            "110/110 [==============================] - 17s 156ms/step - loss: 8.7974 - val_loss: 1.9125\n",
            "Epoch 287/1500\n",
            "876/876 [==============================] - 7s 8ms/step\n",
            "110/110 [==============================] - 20s 187ms/step - loss: 8.3782 - val_loss: 6.4467\n",
            "Epoch 288/1500\n",
            "876/876 [==============================] - 5s 6ms/step\n",
            "110/110 [==============================] - 18s 161ms/step - loss: 8.8361 - val_loss: 2.1890\n",
            "Epoch 289/1500\n",
            "876/876 [==============================] - 6s 6ms/step\n",
            "110/110 [==============================] - 22s 202ms/step - loss: 8.4427 - val_loss: 1.8915\n",
            "Epoch 290/1500\n",
            "876/876 [==============================] - 6s 7ms/step\n",
            "110/110 [==============================] - 22s 197ms/step - loss: 9.1152 - val_loss: 1.4117\n",
            "Epoch 291/1500\n",
            "876/876 [==============================] - 6s 6ms/step\n",
            "110/110 [==============================] - 18s 164ms/step - loss: 8.5149 - val_loss: 1.7090\n",
            "Epoch 292/1500\n",
            "876/876 [==============================] - 6s 7ms/step\n",
            "110/110 [==============================] - 18s 168ms/step - loss: 8.0797 - val_loss: 1.9196\n",
            "Epoch 293/1500\n",
            "876/876 [==============================] - 7s 8ms/step\n",
            "110/110 [==============================] - 21s 190ms/step - loss: 8.8513 - val_loss: 5.2541\n",
            "Epoch 294/1500\n",
            "876/876 [==============================] - 5s 6ms/step\n",
            "110/110 [==============================] - 22s 202ms/step - loss: 9.0816 - val_loss: 3.7992\n",
            "Epoch 295/1500\n",
            "876/876 [==============================] - 6s 7ms/step\n",
            "110/110 [==============================] - 19s 169ms/step - loss: 8.4771 - val_loss: 1.5368\n",
            "Epoch 296/1500\n",
            "876/876 [==============================] - 7s 8ms/step\n",
            "110/110 [==============================] - 18s 163ms/step - loss: 8.6804 - val_loss: 2.1110\n",
            "Epoch 297/1500\n",
            "876/876 [==============================] - 7s 8ms/step\n",
            "110/110 [==============================] - 21s 188ms/step - loss: 8.5066 - val_loss: 3.5072\n",
            "Epoch 298/1500\n",
            "876/876 [==============================] - 5s 6ms/step\n",
            "110/110 [==============================] - 18s 164ms/step - loss: 8.3657 - val_loss: 2.2055\n",
            "Epoch 299/1500\n",
            "876/876 [==============================] - 5s 6ms/step\n",
            "110/110 [==============================] - 18s 162ms/step - loss: 8.8312 - val_loss: 3.0424\n",
            "Epoch 300/1500\n",
            "876/876 [==============================] - 6s 7ms/step\n",
            "110/110 [==============================] - 22s 205ms/step - loss: 8.4604 - val_loss: 3.5305\n",
            "Epoch 301/1500\n",
            "876/876 [==============================] - 6s 6ms/step\n",
            "110/110 [==============================] - 22s 202ms/step - loss: 8.0026 - val_loss: 1.4510\n",
            "Epoch 302/1500\n",
            "876/876 [==============================] - 6s 7ms/step\n",
            "110/110 [==============================] - 22s 204ms/step - loss: 8.6372 - val_loss: 2.2380\n",
            "Epoch 303/1500\n",
            "876/876 [==============================] - 6s 6ms/step\n",
            "110/110 [==============================] - 18s 161ms/step - loss: 8.3422 - val_loss: 2.5872\n",
            "Epoch 304/1500\n",
            "876/876 [==============================] - 5s 6ms/step\n",
            "110/110 [==============================] - 22s 205ms/step - loss: 8.7394 - val_loss: 1.5962\n",
            "Epoch 305/1500\n",
            "876/876 [==============================] - 7s 8ms/step\n",
            "110/110 [==============================] - 18s 162ms/step - loss: 8.3111 - val_loss: 1.5639\n",
            "Epoch 306/1500\n",
            "876/876 [==============================] - 7s 8ms/step\n",
            "110/110 [==============================] - 20s 184ms/step - loss: 8.7329 - val_loss: 3.5867\n",
            "Epoch 307/1500\n",
            "876/876 [==============================] - 5s 6ms/step\n",
            "110/110 [==============================] - 22s 203ms/step - loss: 9.1075 - val_loss: 1.7104\n",
            "Epoch 308/1500\n",
            "876/876 [==============================] - 7s 8ms/step\n",
            "110/110 [==============================] - 18s 163ms/step - loss: 8.6127 - val_loss: 1.7074\n",
            "Epoch 309/1500\n",
            "876/876 [==============================] - 7s 8ms/step\n",
            "110/110 [==============================] - 17s 158ms/step - loss: 8.6986 - val_loss: 1.8081\n",
            "Epoch 310/1500\n",
            "876/876 [==============================] - 6s 7ms/step\n",
            "110/110 [==============================] - 21s 194ms/step - loss: 8.1886 - val_loss: 1.9272\n",
            "Epoch 311/1500\n",
            "876/876 [==============================] - 5s 6ms/step\n",
            "110/110 [==============================] - 22s 204ms/step - loss: 8.8258 - val_loss: 1.8200\n",
            "Epoch 312/1500\n",
            "876/876 [==============================] - 6s 7ms/step\n",
            "110/110 [==============================] - 18s 160ms/step - loss: 8.4789 - val_loss: 1.4942\n",
            "Epoch 313/1500\n",
            "876/876 [==============================] - 5s 6ms/step\n",
            "110/110 [==============================] - 18s 163ms/step - loss: 8.3748 - val_loss: 2.6854\n",
            "Epoch 314/1500\n",
            "876/876 [==============================] - 5s 6ms/step\n",
            "110/110 [==============================] - 18s 162ms/step - loss: 7.9949 - val_loss: 1.5947\n",
            "Epoch 315/1500\n",
            "876/876 [==============================] - 6s 7ms/step\n",
            "110/110 [==============================] - 22s 205ms/step - loss: 8.2577 - val_loss: 3.5596\n",
            "Epoch 316/1500\n",
            "876/876 [==============================] - 6s 7ms/step\n",
            "110/110 [==============================] - 18s 161ms/step - loss: 8.4215 - val_loss: 1.6411\n",
            "Epoch 317/1500\n",
            "876/876 [==============================] - 5s 6ms/step\n",
            "110/110 [==============================] - 18s 163ms/step - loss: 8.4446 - val_loss: 1.8015\n",
            "Epoch 318/1500\n",
            "876/876 [==============================] - 6s 6ms/step\n",
            "110/110 [==============================] - 18s 166ms/step - loss: 8.5541 - val_loss: 1.3438\n",
            "Epoch 319/1500\n",
            "876/876 [==============================] - 7s 7ms/step\n",
            "110/110 [==============================] - 19s 171ms/step - loss: 8.5612 - val_loss: 2.2729\n",
            "Epoch 320/1500\n",
            "876/876 [==============================] - 7s 8ms/step\n",
            "110/110 [==============================] - 18s 163ms/step - loss: 8.1476 - val_loss: 2.0869\n",
            "Epoch 321/1500\n",
            "876/876 [==============================] - 7s 8ms/step\n",
            "110/110 [==============================] - 17s 156ms/step - loss: 8.5080 - val_loss: 1.9708\n",
            "Epoch 322/1500\n",
            "876/876 [==============================] - 6s 7ms/step\n",
            "110/110 [==============================] - 21s 196ms/step - loss: 8.2508 - val_loss: 1.7283\n",
            "Epoch 323/1500\n",
            "876/876 [==============================] - 6s 6ms/step\n",
            "110/110 [==============================] - 22s 205ms/step - loss: 9.1900 - val_loss: 2.0699\n",
            "Epoch 324/1500\n",
            "876/876 [==============================] - 6s 7ms/step\n",
            "110/110 [==============================] - 22s 198ms/step - loss: 7.8079 - val_loss: 3.1033\n",
            "Epoch 325/1500\n",
            "876/876 [==============================] - 6s 7ms/step\n",
            "110/110 [==============================] - 18s 169ms/step - loss: 8.8924 - val_loss: 1.5045\n",
            "Epoch 326/1500\n",
            "876/876 [==============================] - 7s 8ms/step\n",
            "110/110 [==============================] - 19s 173ms/step - loss: 8.5397 - val_loss: 2.8047\n",
            "Epoch 327/1500\n",
            "876/876 [==============================] - 7s 8ms/step\n",
            "110/110 [==============================] - 20s 186ms/step - loss: 8.5368 - val_loss: 1.7990\n",
            "Epoch 328/1500\n",
            "876/876 [==============================] - 6s 6ms/step\n",
            "110/110 [==============================] - 18s 165ms/step - loss: 8.2921 - val_loss: 1.3241\n",
            "Epoch 329/1500\n",
            "876/876 [==============================] - 5s 6ms/step\n",
            "110/110 [==============================] - 18s 166ms/step - loss: 8.3216 - val_loss: 1.5645\n",
            "Epoch 330/1500\n",
            "876/876 [==============================] - 6s 7ms/step\n",
            "110/110 [==============================] - 23s 206ms/step - loss: 8.6891 - val_loss: 2.6143\n",
            "Epoch 331/1500\n",
            "876/876 [==============================] - 6s 6ms/step\n",
            "110/110 [==============================] - 22s 201ms/step - loss: 8.5580 - val_loss: 1.4986\n",
            "Epoch 332/1500\n",
            "876/876 [==============================] - 6s 7ms/step\n",
            "110/110 [==============================] - 22s 203ms/step - loss: 8.0312 - val_loss: 1.5718\n",
            "Epoch 333/1500\n",
            "876/876 [==============================] - 6s 6ms/step\n",
            "110/110 [==============================] - 22s 204ms/step - loss: 8.2012 - val_loss: 2.0127\n",
            "Epoch 334/1500\n",
            "876/876 [==============================] - 6s 7ms/step\n",
            "110/110 [==============================] - 22s 202ms/step - loss: 8.3756 - val_loss: 1.5139\n",
            "Epoch 335/1500\n",
            "876/876 [==============================] - 5s 6ms/step\n",
            "110/110 [==============================] - 22s 203ms/step - loss: 8.2659 - val_loss: 2.9669\n",
            "Epoch 336/1500\n",
            "876/876 [==============================] - 6s 7ms/step\n",
            "110/110 [==============================] - 22s 204ms/step - loss: 8.4735 - val_loss: 1.5766\n",
            "Epoch 337/1500\n",
            "876/876 [==============================] - 6s 6ms/step\n",
            "110/110 [==============================] - 18s 164ms/step - loss: 8.0482 - val_loss: 2.8247\n",
            "Epoch 338/1500\n",
            "876/876 [==============================] - 5s 6ms/step\n",
            "110/110 [==============================] - 22s 205ms/step - loss: 8.3487 - val_loss: 2.6095\n",
            "Epoch 339/1500\n",
            "876/876 [==============================] - 7s 8ms/step\n",
            "110/110 [==============================] - 20s 185ms/step - loss: 8.5939 - val_loss: 1.6027\n",
            "Epoch 340/1500\n",
            "876/876 [==============================] - 5s 6ms/step\n",
            "110/110 [==============================] - 18s 163ms/step - loss: 8.5784 - val_loss: 1.4802\n",
            "Epoch 341/1500\n",
            "876/876 [==============================] - 5s 6ms/step\n",
            "110/110 [==============================] - 18s 165ms/step - loss: 8.9865 - val_loss: 1.7414\n",
            "Epoch 342/1500\n",
            "876/876 [==============================] - 6s 7ms/step\n",
            "110/110 [==============================] - 23s 206ms/step - loss: 8.5298 - val_loss: 1.7156\n",
            "Epoch 343/1500\n",
            "876/876 [==============================] - 6s 6ms/step\n",
            "110/110 [==============================] - 18s 163ms/step - loss: 8.1549 - val_loss: 1.3850\n",
            "Epoch 344/1500\n",
            "876/876 [==============================] - 5s 6ms/step\n",
            "110/110 [==============================] - 18s 163ms/step - loss: 8.4473 - val_loss: 2.9862\n",
            "Epoch 345/1500\n",
            "876/876 [==============================] - 6s 6ms/step\n",
            "110/110 [==============================] - 18s 167ms/step - loss: 8.5974 - val_loss: 2.2462\n",
            "Epoch 346/1500\n",
            "876/876 [==============================] - 7s 8ms/step\n",
            "110/110 [==============================] - 22s 198ms/step - loss: 7.6616 - val_loss: 1.0557\n",
            "Epoch 347/1500\n",
            "876/876 [==============================] - 6s 6ms/step\n",
            "110/110 [==============================] - 18s 161ms/step - loss: 8.0661 - val_loss: 1.5445\n",
            "Epoch 348/1500\n",
            "876/876 [==============================] - 5s 6ms/step\n",
            "110/110 [==============================] - 18s 164ms/step - loss: 8.7726 - val_loss: 1.6442\n",
            "Epoch 349/1500\n",
            "876/876 [==============================] - 6s 6ms/step\n",
            "110/110 [==============================] - 18s 168ms/step - loss: 8.0977 - val_loss: 1.3428\n",
            "Epoch 350/1500\n",
            "876/876 [==============================] - 7s 7ms/step\n",
            "110/110 [==============================] - 19s 172ms/step - loss: 8.1455 - val_loss: 4.2126\n",
            "Epoch 351/1500\n",
            "876/876 [==============================] - 7s 8ms/step\n",
            "110/110 [==============================] - 21s 188ms/step - loss: 8.1538 - val_loss: 1.7746\n",
            "Epoch 352/1500\n",
            "876/876 [==============================] - 5s 6ms/step\n",
            "110/110 [==============================] - 22s 205ms/step - loss: 8.2056 - val_loss: 2.3138\n",
            "Epoch 353/1500\n",
            "876/876 [==============================] - 7s 8ms/step\n",
            "110/110 [==============================] - 22s 200ms/step - loss: 8.2338 - val_loss: 1.3160\n",
            "Epoch 354/1500\n",
            "876/876 [==============================] - 6s 6ms/step\n",
            "110/110 [==============================] - 22s 205ms/step - loss: 8.1202 - val_loss: 1.8692\n",
            "Epoch 355/1500\n",
            "876/876 [==============================] - 6s 7ms/step\n",
            "110/110 [==============================] - 19s 174ms/step - loss: 8.1339 - val_loss: 1.8782\n",
            "Epoch 356/1500\n",
            "876/876 [==============================] - 7s 8ms/step\n",
            "110/110 [==============================] - 21s 191ms/step - loss: 8.4436 - val_loss: 1.8049\n",
            "Epoch 357/1500\n",
            "876/876 [==============================] - 5s 6ms/step\n",
            "110/110 [==============================] - 22s 204ms/step - loss: 8.0130 - val_loss: 1.5097\n",
            "Epoch 358/1500\n",
            "876/876 [==============================] - 6s 7ms/step\n",
            "110/110 [==============================] - 22s 203ms/step - loss: 8.3483 - val_loss: 1.1892\n",
            "Epoch 359/1500\n",
            "876/876 [==============================] - 6s 6ms/step\n",
            "110/110 [==============================] - 22s 200ms/step - loss: 8.0353 - val_loss: 1.2849\n",
            "Epoch 360/1500\n",
            "876/876 [==============================] - 6s 7ms/step\n",
            "110/110 [==============================] - 22s 205ms/step - loss: 7.9097 - val_loss: 1.1565\n",
            "Epoch 361/1500\n",
            "876/876 [==============================] - 6s 7ms/step\n",
            "110/110 [==============================] - 22s 203ms/step - loss: 8.1166 - val_loss: 3.6585\n",
            "Epoch 362/1500\n",
            "876/876 [==============================] - 6s 7ms/step\n",
            "110/110 [==============================] - 23s 206ms/step - loss: 7.8916 - val_loss: 2.8125\n",
            "Epoch 363/1500\n",
            "876/876 [==============================] - 6s 7ms/step\n",
            "110/110 [==============================] - 18s 161ms/step - loss: 8.0833 - val_loss: 1.3711\n",
            "Epoch 364/1500\n",
            "876/876 [==============================] - 5s 6ms/step\n",
            "110/110 [==============================] - 23s 206ms/step - loss: 8.0104 - val_loss: 2.0246\n",
            "Epoch 365/1500\n",
            "876/876 [==============================] - 7s 8ms/step\n",
            "110/110 [==============================] - 18s 160ms/step - loss: 7.9591 - val_loss: 2.1342\n",
            "Epoch 366/1500\n",
            "876/876 [==============================] - 7s 8ms/step\n",
            "110/110 [==============================] - 21s 189ms/step - loss: 7.9826 - val_loss: 2.3785\n",
            "Epoch 367/1500\n",
            "876/876 [==============================] - 5s 6ms/step\n",
            "110/110 [==============================] - 22s 203ms/step - loss: 8.2152 - val_loss: 1.8609\n",
            "Epoch 368/1500\n",
            "876/876 [==============================] - 7s 8ms/step\n",
            "110/110 [==============================] - 17s 159ms/step - loss: 8.3827 - val_loss: 1.3669\n",
            "Epoch 369/1500\n",
            "876/876 [==============================] - 6s 6ms/step\n",
            "110/110 [==============================] - 22s 203ms/step - loss: 7.9621 - val_loss: 1.9044\n",
            "Epoch 370/1500\n",
            "876/876 [==============================] - 6s 7ms/step\n",
            "110/110 [==============================] - 23s 207ms/step - loss: 8.3014 - val_loss: 1.9141\n",
            "Epoch 371/1500\n",
            "876/876 [==============================] - 6s 7ms/step\n",
            "110/110 [==============================] - 22s 201ms/step - loss: 8.2305 - val_loss: 1.4740\n",
            "Epoch 372/1500\n",
            "876/876 [==============================] - 6s 7ms/step\n",
            "110/110 [==============================] - 18s 168ms/step - loss: 8.2729 - val_loss: 2.1247\n",
            "Epoch 373/1500\n",
            "876/876 [==============================] - 7s 8ms/step\n",
            "110/110 [==============================] - 19s 169ms/step - loss: 7.6009 - val_loss: 1.5966\n",
            "Epoch 374/1500\n",
            "876/876 [==============================] - 7s 8ms/step\n",
            "110/110 [==============================] - 18s 160ms/step - loss: 8.6545 - val_loss: 1.4858\n",
            "Epoch 375/1500\n",
            "876/876 [==============================] - 7s 8ms/step\n",
            "110/110 [==============================] - 21s 189ms/step - loss: 8.0042 - val_loss: 1.6127\n",
            "Epoch 376/1500\n",
            "876/876 [==============================] - 6s 6ms/step\n",
            "110/110 [==============================] - 18s 164ms/step - loss: 7.4903 - val_loss: 1.1678\n",
            "Epoch 377/1500\n",
            "876/876 [==============================] - 6s 7ms/step\n",
            "110/110 [==============================] - 22s 204ms/step - loss: 8.5433 - val_loss: 1.6972\n",
            "Epoch 378/1500\n",
            "876/876 [==============================] - 6s 7ms/step\n",
            "110/110 [==============================] - 18s 161ms/step - loss: 7.9367 - val_loss: 1.8902\n",
            "Epoch 379/1500\n",
            "876/876 [==============================] - 6s 6ms/step\n",
            "110/110 [==============================] - 18s 165ms/step - loss: 8.5723 - val_loss: 3.0743\n",
            "Epoch 380/1500\n",
            "876/876 [==============================] - 5s 6ms/step\n",
            "110/110 [==============================] - 22s 204ms/step - loss: 8.0418 - val_loss: 1.6537\n",
            "Epoch 381/1500\n",
            "876/876 [==============================] - 6s 7ms/step\n",
            "110/110 [==============================] - 18s 162ms/step - loss: 7.9295 - val_loss: 1.3441\n",
            "Epoch 382/1500\n",
            "876/876 [==============================] - 6s 6ms/step\n",
            "110/110 [==============================] - 22s 205ms/step - loss: 7.8003 - val_loss: 1.5120\n",
            "Epoch 383/1500\n",
            "876/876 [==============================] - 7s 7ms/step\n",
            "110/110 [==============================] - 19s 171ms/step - loss: 7.8609 - val_loss: 1.4096\n",
            "Epoch 384/1500\n",
            "876/876 [==============================] - 7s 8ms/step\n",
            "110/110 [==============================] - 18s 163ms/step - loss: 8.5555 - val_loss: 2.9828\n",
            "Epoch 385/1500\n",
            "876/876 [==============================] - 7s 8ms/step\n",
            "110/110 [==============================] - 21s 189ms/step - loss: 7.8143 - val_loss: 1.7927\n",
            "Epoch 386/1500\n",
            "876/876 [==============================] - 5s 6ms/step\n",
            "110/110 [==============================] - 22s 204ms/step - loss: 7.7359 - val_loss: 1.4128\n",
            "Epoch 387/1500\n",
            "876/876 [==============================] - 7s 8ms/step\n",
            "110/110 [==============================] - 21s 188ms/step - loss: 8.0415 - val_loss: 1.8633\n",
            "Epoch 388/1500\n",
            "876/876 [==============================] - 5s 6ms/step\n",
            "110/110 [==============================] - 23s 207ms/step - loss: 8.2011 - val_loss: 1.6453\n",
            "Epoch 389/1500\n",
            "876/876 [==============================] - 7s 8ms/step\n",
            "110/110 [==============================] - 22s 200ms/step - loss: 8.2079 - val_loss: 1.9529\n",
            "Epoch 390/1500\n",
            "876/876 [==============================] - 6s 6ms/step\n",
            "110/110 [==============================] - 22s 203ms/step - loss: 7.7458 - val_loss: 2.6005\n",
            "Epoch 391/1500\n",
            "876/876 [==============================] - 6s 7ms/step\n",
            "110/110 [==============================] - 22s 204ms/step - loss: 8.2099 - val_loss: 1.2378\n",
            "Epoch 392/1500\n",
            "876/876 [==============================] - 6s 6ms/step\n",
            "110/110 [==============================] - 18s 164ms/step - loss: 8.2462 - val_loss: 6.1076\n",
            "Epoch 393/1500\n",
            "876/876 [==============================] - 5s 6ms/step\n",
            "110/110 [==============================] - 23s 206ms/step - loss: 8.0583 - val_loss: 4.0235\n",
            "Epoch 394/1500\n",
            "876/876 [==============================] - 7s 8ms/step\n",
            "110/110 [==============================] - 20s 187ms/step - loss: 8.0633 - val_loss: 4.0058\n",
            "Epoch 395/1500\n",
            "876/876 [==============================] - 6s 6ms/step\n",
            "110/110 [==============================] - 18s 165ms/step - loss: 7.9530 - val_loss: 3.1552\n",
            "Epoch 396/1500\n",
            "876/876 [==============================] - 5s 6ms/step\n",
            "110/110 [==============================] - 23s 207ms/step - loss: 8.1590 - val_loss: 1.8605\n",
            "Epoch 397/1500\n",
            "876/876 [==============================] - 6s 7ms/step\n",
            "110/110 [==============================] - 18s 163ms/step - loss: 7.9779 - val_loss: 4.3333\n",
            "Epoch 398/1500\n",
            "876/876 [==============================] - 5s 6ms/step\n",
            "110/110 [==============================] - 18s 165ms/step - loss: 7.5845 - val_loss: 1.2127\n",
            "Epoch 399/1500\n",
            "876/876 [==============================] - 5s 6ms/step\n",
            "110/110 [==============================] - 18s 163ms/step - loss: 8.2682 - val_loss: 2.0816\n",
            "Epoch 400/1500\n",
            "876/876 [==============================] - 6s 7ms/step\n",
            "110/110 [==============================] - 19s 172ms/step - loss: 7.4797 - val_loss: 3.1903\n",
            "Epoch 401/1500\n",
            "876/876 [==============================] - 7s 8ms/step\n",
            "110/110 [==============================] - 19s 169ms/step - loss: 8.2602 - val_loss: 4.0618\n",
            "Epoch 402/1500\n",
            "876/876 [==============================] - 7s 8ms/step\n",
            "110/110 [==============================] - 21s 187ms/step - loss: 8.2949 - val_loss: 3.3460\n",
            "Epoch 403/1500\n",
            "876/876 [==============================] - 5s 6ms/step\n",
            "110/110 [==============================] - 18s 164ms/step - loss: 8.1427 - val_loss: 3.3142\n",
            "Epoch 404/1500\n",
            "876/876 [==============================] - 6s 6ms/step\n",
            "110/110 [==============================] - 18s 165ms/step - loss: 8.0647 - val_loss: 2.0821\n",
            "Epoch 405/1500\n",
            "876/876 [==============================] - 6s 7ms/step\n",
            "110/110 [==============================] - 23s 206ms/step - loss: 7.8518 - val_loss: 2.9158\n",
            "Epoch 406/1500\n",
            "876/876 [==============================] - 6s 7ms/step\n",
            "110/110 [==============================] - 18s 163ms/step - loss: 7.6814 - val_loss: 1.3049\n",
            "Epoch 407/1500\n",
            "876/876 [==============================] - 6s 6ms/step\n",
            "110/110 [==============================] - 22s 203ms/step - loss: 7.7671 - val_loss: 2.7951\n",
            "Epoch 408/1500\n",
            "876/876 [==============================] - 7s 8ms/step\n",
            "110/110 [==============================] - 18s 166ms/step - loss: 8.1258 - val_loss: 1.5879\n",
            "Epoch 409/1500\n",
            "876/876 [==============================] - 7s 8ms/step\n",
            "110/110 [==============================] - 20s 184ms/step - loss: 7.7310 - val_loss: 1.3411\n",
            "Epoch 410/1500\n",
            "876/876 [==============================] - 5s 6ms/step\n",
            "110/110 [==============================] - 18s 164ms/step - loss: 7.7543 - val_loss: 4.4685\n",
            "Epoch 411/1500\n",
            "876/876 [==============================] - 6s 6ms/step\n",
            "110/110 [==============================] - 18s 167ms/step - loss: 7.9168 - val_loss: 2.9468\n",
            "Epoch 412/1500\n",
            "876/876 [==============================] - 6s 7ms/step\n",
            "110/110 [==============================] - 19s 174ms/step - loss: 7.9421 - val_loss: 1.4027\n",
            "Epoch 413/1500\n",
            "876/876 [==============================] - 7s 8ms/step\n",
            "110/110 [==============================] - 21s 193ms/step - loss: 7.9369 - val_loss: 1.8560\n",
            "Epoch 414/1500\n",
            "876/876 [==============================] - 6s 6ms/step\n",
            "110/110 [==============================] - 19s 176ms/step - loss: 7.8704 - val_loss: 1.7628\n",
            "Epoch 415/1500\n",
            "876/876 [==============================] - 6s 6ms/step\n",
            "110/110 [==============================] - 22s 204ms/step - loss: 7.6304 - val_loss: 1.4165\n",
            "Epoch 416/1500\n",
            "876/876 [==============================] - 6s 7ms/step\n",
            "110/110 [==============================] - 18s 161ms/step - loss: 8.1365 - val_loss: 1.6019\n",
            "Epoch 417/1500\n",
            "876/876 [==============================] - 6s 6ms/step\n",
            "110/110 [==============================] - 23s 207ms/step - loss: 7.6030 - val_loss: 4.7283\n",
            "Epoch 418/1500\n",
            "876/876 [==============================] - 7s 8ms/step\n",
            "110/110 [==============================] - 22s 198ms/step - loss: 8.3001 - val_loss: 2.0039\n",
            "Epoch 419/1500\n",
            "876/876 [==============================] - 6s 7ms/step\n",
            "110/110 [==============================] - 22s 201ms/step - loss: 7.6509 - val_loss: 2.9560\n",
            "Epoch 420/1500\n",
            "876/876 [==============================] - 6s 7ms/step\n",
            "110/110 [==============================] - 19s 172ms/step - loss: 7.8869 - val_loss: 3.1876\n",
            "Epoch 421/1500\n",
            "876/876 [==============================] - 7s 8ms/step\n",
            "110/110 [==============================] - 21s 196ms/step - loss: 7.9845 - val_loss: 2.7023\n",
            "Epoch 422/1500\n",
            "876/876 [==============================] - 6s 6ms/step\n",
            "110/110 [==============================] - 22s 203ms/step - loss: 7.6539 - val_loss: 1.5965\n",
            "Epoch 423/1500\n",
            "876/876 [==============================] - 6s 7ms/step\n",
            "110/110 [==============================] - 22s 204ms/step - loss: 7.5480 - val_loss: 2.2322\n",
            "Epoch 424/1500\n",
            "876/876 [==============================] - 6s 7ms/step\n",
            "110/110 [==============================] - 18s 164ms/step - loss: 8.0661 - val_loss: 2.5781\n",
            "Epoch 425/1500\n",
            "876/876 [==============================] - 6s 6ms/step\n",
            "110/110 [==============================] - 22s 205ms/step - loss: 7.7556 - val_loss: 1.6826\n",
            "Epoch 426/1500\n",
            "876/876 [==============================] - 7s 8ms/step\n",
            "110/110 [==============================] - 20s 183ms/step - loss: 7.7043 - val_loss: 2.0047\n",
            "Epoch 427/1500\n",
            "876/876 [==============================] - 5s 6ms/step\n",
            "110/110 [==============================] - 22s 205ms/step - loss: 7.8772 - val_loss: 4.2547\n",
            "Epoch 428/1500\n",
            "876/876 [==============================] - 7s 8ms/step\n",
            "110/110 [==============================] - 19s 171ms/step - loss: 7.4497 - val_loss: 2.2155\n",
            "Epoch 429/1500\n",
            "876/876 [==============================] - 7s 8ms/step\n",
            "110/110 [==============================] - 18s 164ms/step - loss: 7.8611 - val_loss: 1.3719\n",
            "Epoch 430/1500\n",
            "876/876 [==============================] - 7s 8ms/step\n",
            "110/110 [==============================] - 18s 160ms/step - loss: 7.5196 - val_loss: 1.5440\n",
            "Epoch 431/1500\n",
            "876/876 [==============================] - 6s 7ms/step\n",
            "110/110 [==============================] - 18s 163ms/step - loss: 8.1445 - val_loss: 1.4337\n",
            "Epoch 432/1500\n",
            "876/876 [==============================] - 6s 6ms/step\n",
            "110/110 [==============================] - 18s 164ms/step - loss: 8.2860 - val_loss: 8.0568\n",
            "Epoch 433/1500\n",
            "876/876 [==============================] - 6s 6ms/step\n",
            "110/110 [==============================] - 23s 206ms/step - loss: 9.0346 - val_loss: 1.4233\n",
            "Epoch 434/1500\n",
            "876/876 [==============================] - 7s 8ms/step\n",
            "110/110 [==============================] - 18s 161ms/step - loss: 7.5565 - val_loss: 1.6752\n",
            "Epoch 435/1500\n",
            "876/876 [==============================] - 6s 6ms/step\n",
            "110/110 [==============================] - 18s 164ms/step - loss: 7.5699 - val_loss: 1.2027\n",
            "Epoch 436/1500\n",
            "876/876 [==============================] - 6s 6ms/step\n",
            "110/110 [==============================] - 18s 166ms/step - loss: 8.0102 - val_loss: 1.4571\n",
            "Epoch 437/1500\n",
            "876/876 [==============================] - 6s 7ms/step\n",
            "110/110 [==============================] - 18s 169ms/step - loss: 7.8075 - val_loss: 3.2677\n",
            "Epoch 438/1500\n",
            "876/876 [==============================] - 7s 8ms/step\n",
            "110/110 [==============================] - 19s 174ms/step - loss: 7.4797 - val_loss: 1.1228\n",
            "Epoch 439/1500\n",
            "876/876 [==============================] - 7s 8ms/step\n",
            "110/110 [==============================] - 21s 187ms/step - loss: 7.5556 - val_loss: 2.0867\n",
            "Epoch 440/1500\n",
            "876/876 [==============================] - 5s 6ms/step\n",
            "110/110 [==============================] - 18s 161ms/step - loss: 8.1418 - val_loss: 3.2208\n",
            "Epoch 441/1500\n",
            "876/876 [==============================] - 6s 6ms/step\n",
            "110/110 [==============================] - 23s 206ms/step - loss: 7.5850 - val_loss: 1.3141\n",
            "Epoch 442/1500\n",
            "876/876 [==============================] - 7s 8ms/step\n",
            "110/110 [==============================] - 20s 187ms/step - loss: 7.7108 - val_loss: 1.2520\n",
            "Epoch 443/1500\n",
            "876/876 [==============================] - 6s 6ms/step\n",
            "110/110 [==============================] - 22s 204ms/step - loss: 7.5444 - val_loss: 1.4369\n",
            "Epoch 444/1500\n",
            "876/876 [==============================] - 7s 8ms/step\n",
            "110/110 [==============================] - 18s 161ms/step - loss: 7.7253 - val_loss: 6.8321\n",
            "Epoch 445/1500\n",
            "876/876 [==============================] - 7s 8ms/step\n",
            "110/110 [==============================] - 18s 163ms/step - loss: 7.7796 - val_loss: 1.1390\n",
            "Epoch 446/1500\n",
            "876/876 [==============================] - 6s 6ms/step\n",
            "110/110 [==============================] - 18s 168ms/step - loss: 7.8606 - val_loss: 1.5321\n",
            "Epoch 447/1500\n",
            "876/876 [==============================] - 6s 6ms/step\n",
            "110/110 [==============================] - 23s 208ms/step - loss: 7.7893 - val_loss: 2.1889\n",
            "Epoch 448/1500\n",
            "876/876 [==============================] - 7s 8ms/step\n",
            "110/110 [==============================] - 21s 192ms/step - loss: 7.3176 - val_loss: 2.2772\n",
            "Epoch 449/1500\n",
            "876/876 [==============================] - 6s 6ms/step\n",
            "110/110 [==============================] - 23s 207ms/step - loss: 7.3881 - val_loss: 1.1171\n",
            "Epoch 450/1500\n",
            "876/876 [==============================] - 7s 8ms/step\n",
            "110/110 [==============================] - 18s 164ms/step - loss: 7.9248 - val_loss: 2.4842\n",
            "Epoch 451/1500\n",
            "876/876 [==============================] - 6s 6ms/step\n",
            "110/110 [==============================] - 19s 177ms/step - loss: 7.7922 - val_loss: 1.3708\n",
            "Epoch 452/1500\n",
            "876/876 [==============================] - 6s 6ms/step\n",
            "110/110 [==============================] - 18s 167ms/step - loss: 7.9526 - val_loss: 1.3431\n",
            "Epoch 453/1500\n",
            "876/876 [==============================] - 6s 7ms/step\n",
            "110/110 [==============================] - 19s 172ms/step - loss: 7.6254 - val_loss: 1.3148\n",
            "Epoch 454/1500\n",
            "876/876 [==============================] - 7s 8ms/step\n",
            "110/110 [==============================] - 19s 171ms/step - loss: 7.7924 - val_loss: 1.6776\n",
            "Epoch 455/1500\n",
            "876/876 [==============================] - 7s 8ms/step\n",
            "110/110 [==============================] - 18s 162ms/step - loss: 7.2567 - val_loss: 1.6278\n",
            "Epoch 456/1500\n",
            "876/876 [==============================] - 6s 7ms/step\n",
            "110/110 [==============================] - 21s 196ms/step - loss: 7.8928 - val_loss: 3.9011\n",
            "Epoch 457/1500\n",
            "876/876 [==============================] - 6s 6ms/step\n",
            "110/110 [==============================] - 23s 207ms/step - loss: 7.6705 - val_loss: 1.5010\n",
            "Epoch 458/1500\n",
            "876/876 [==============================] - 6s 7ms/step\n",
            "110/110 [==============================] - 22s 200ms/step - loss: 7.2236 - val_loss: 2.8062\n",
            "Epoch 459/1500\n",
            "876/876 [==============================] - 6s 7ms/step\n",
            "110/110 [==============================] - 23s 207ms/step - loss: 7.7425 - val_loss: 1.2028\n",
            "Epoch 460/1500\n",
            "876/876 [==============================] - 6s 7ms/step\n",
            "110/110 [==============================] - 22s 199ms/step - loss: 8.0118 - val_loss: 2.2593\n",
            "Epoch 461/1500\n",
            "876/876 [==============================] - 6s 7ms/step\n",
            "110/110 [==============================] - 19s 171ms/step - loss: 7.5335 - val_loss: 1.4209\n",
            "Epoch 462/1500\n",
            "876/876 [==============================] - 7s 8ms/step\n",
            "110/110 [==============================] - 19s 173ms/step - loss: 7.2132 - val_loss: 1.2797\n",
            "Epoch 463/1500\n",
            "876/876 [==============================] - 7s 8ms/step\n",
            "110/110 [==============================] - 20s 185ms/step - loss: 7.8964 - val_loss: 1.4626\n",
            "Epoch 464/1500\n",
            "876/876 [==============================] - 6s 6ms/step\n",
            "110/110 [==============================] - 22s 205ms/step - loss: 7.7391 - val_loss: 1.3461\n",
            "Epoch 465/1500\n",
            "876/876 [==============================] - 7s 8ms/step\n",
            "110/110 [==============================] - 19s 175ms/step - loss: 7.3412 - val_loss: 1.1863\n",
            "Epoch 466/1500\n",
            "876/876 [==============================] - 7s 8ms/step\n",
            "110/110 [==============================] - 18s 163ms/step - loss: 7.1984 - val_loss: 1.1510\n",
            "Epoch 467/1500\n",
            "876/876 [==============================] - 7s 8ms/step\n",
            "110/110 [==============================] - 20s 186ms/step - loss: 7.2061 - val_loss: 1.7721\n",
            "Epoch 468/1500\n",
            "876/876 [==============================] - 6s 6ms/step\n",
            "110/110 [==============================] - 23s 207ms/step - loss: 8.2790 - val_loss: 1.2350\n",
            "Epoch 469/1500\n",
            "876/876 [==============================] - 7s 8ms/step\n",
            "110/110 [==============================] - 19s 171ms/step - loss: 7.1996 - val_loss: 1.4983\n",
            "Epoch 470/1500\n",
            "876/876 [==============================] - 7s 8ms/step\n",
            "110/110 [==============================] - 18s 162ms/step - loss: 7.5309 - val_loss: 1.3317\n",
            "Epoch 471/1500\n",
            "876/876 [==============================] - 7s 8ms/step\n",
            "110/110 [==============================] - 21s 190ms/step - loss: 7.3847 - val_loss: 1.8658\n",
            "Epoch 472/1500\n",
            "876/876 [==============================] - 6s 6ms/step\n",
            "110/110 [==============================] - 23s 207ms/step - loss: 7.8651 - val_loss: 1.2824\n",
            "Epoch 473/1500\n",
            "876/876 [==============================] - 7s 8ms/step\n",
            "110/110 [==============================] - 20s 186ms/step - loss: 7.2091 - val_loss: 1.3181\n",
            "Epoch 474/1500\n",
            "876/876 [==============================] - 6s 6ms/step\n",
            "110/110 [==============================] - 18s 164ms/step - loss: 7.3290 - val_loss: 1.2645\n",
            "Epoch 475/1500\n",
            "876/876 [==============================] - 6s 6ms/step\n",
            "110/110 [==============================] - 22s 205ms/step - loss: 7.4953 - val_loss: 1.8335\n",
            "Epoch 476/1500\n",
            "876/876 [==============================] - 7s 8ms/step\n",
            "110/110 [==============================] - 18s 161ms/step - loss: 7.9555 - val_loss: 1.3692\n",
            "Epoch 477/1500\n",
            "876/876 [==============================] - 6s 6ms/step\n",
            "110/110 [==============================] - 18s 166ms/step - loss: 7.3289 - val_loss: 1.3253\n",
            "Epoch 478/1500\n",
            "876/876 [==============================] - 6s 6ms/step\n",
            "110/110 [==============================] - 18s 166ms/step - loss: 7.4523 - val_loss: 1.6416\n",
            "Epoch 479/1500\n",
            "876/876 [==============================] - 6s 7ms/step\n",
            "110/110 [==============================] - 23s 206ms/step - loss: 7.8616 - val_loss: 1.0918\n",
            "Epoch 480/1500\n",
            "876/876 [==============================] - 6s 7ms/step\n",
            "110/110 [==============================] - 18s 163ms/step - loss: 7.3398 - val_loss: 2.3485\n",
            "Epoch 481/1500\n",
            "876/876 [==============================] - 6s 6ms/step\n",
            "110/110 [==============================] - 23s 207ms/step - loss: 7.9091 - val_loss: 2.4953\n",
            "Epoch 482/1500\n",
            "876/876 [==============================] - 7s 8ms/step\n",
            "110/110 [==============================] - 21s 192ms/step - loss: 7.7341 - val_loss: 1.5069\n",
            "Epoch 483/1500\n",
            "876/876 [==============================] - 6s 6ms/step\n",
            "110/110 [==============================] - 18s 167ms/step - loss: 7.4361 - val_loss: 1.4913\n",
            "Epoch 484/1500\n",
            "876/876 [==============================] - 6s 6ms/step\n",
            "110/110 [==============================] - 18s 167ms/step - loss: 7.4704 - val_loss: 3.0173\n",
            "Epoch 485/1500\n",
            "876/876 [==============================] - 6s 7ms/step\n",
            "110/110 [==============================] - 22s 206ms/step - loss: 7.5295 - val_loss: 1.2853\n",
            "Epoch 486/1500\n",
            "876/876 [==============================] - 6s 7ms/step\n",
            "110/110 [==============================] - 22s 203ms/step - loss: 7.8388 - val_loss: 1.2266\n",
            "Epoch 487/1500\n",
            "876/876 [==============================] - 6s 7ms/step\n",
            "110/110 [==============================] - 23s 208ms/step - loss: 7.3798 - val_loss: 1.7277\n",
            "Epoch 488/1500\n",
            "876/876 [==============================] - 6s 7ms/step\n",
            "110/110 [==============================] - 22s 199ms/step - loss: 7.2858 - val_loss: 1.3011\n",
            "Epoch 489/1500\n",
            "876/876 [==============================] - 6s 7ms/step\n",
            "110/110 [==============================] - 23s 206ms/step - loss: 8.3028 - val_loss: 1.0131\n",
            "Epoch 490/1500\n",
            "876/876 [==============================] - 6s 7ms/step\n",
            "110/110 [==============================] - 18s 164ms/step - loss: 7.7964 - val_loss: 1.9818\n",
            "Epoch 491/1500\n",
            "876/876 [==============================] - 6s 6ms/step\n",
            "110/110 [==============================] - 18s 168ms/step - loss: 7.4593 - val_loss: 4.3921\n",
            "Epoch 492/1500\n",
            "876/876 [==============================] - 6s 6ms/step\n",
            "110/110 [==============================] - 18s 168ms/step - loss: 7.1982 - val_loss: 1.4108\n",
            "Epoch 493/1500\n",
            "876/876 [==============================] - 6s 7ms/step\n",
            "110/110 [==============================] - 22s 204ms/step - loss: 7.5743 - val_loss: 1.3421\n",
            "Epoch 494/1500\n",
            "876/876 [==============================] - 6s 7ms/step\n",
            "110/110 [==============================] - 22s 202ms/step - loss: 7.5672 - val_loss: 1.2292\n",
            "Epoch 495/1500\n",
            "876/876 [==============================] - 6s 7ms/step\n",
            "110/110 [==============================] - 19s 174ms/step - loss: 7.2837 - val_loss: 1.8711\n",
            "Epoch 496/1500\n",
            "876/876 [==============================] - 7s 8ms/step\n",
            "110/110 [==============================] - 19s 171ms/step - loss: 7.5814 - val_loss: 2.8521\n",
            "Epoch 497/1500\n",
            "876/876 [==============================] - 7s 8ms/step\n",
            "110/110 [==============================] - 18s 161ms/step - loss: 6.9928 - val_loss: 1.2237\n",
            "Epoch 498/1500\n",
            "876/876 [==============================] - 7s 8ms/step\n",
            "110/110 [==============================] - 21s 193ms/step - loss: 7.0150 - val_loss: 1.6251\n",
            "Epoch 499/1500\n",
            "876/876 [==============================] - 6s 6ms/step\n",
            "110/110 [==============================] - 22s 205ms/step - loss: 7.9787 - val_loss: 1.5813\n",
            "Epoch 500/1500\n",
            "876/876 [==============================] - 6s 7ms/step\n",
            "110/110 [==============================] - 18s 162ms/step - loss: 7.6261 - val_loss: 2.5289\n",
            "Epoch 501/1500\n",
            "876/876 [==============================] - 6s 6ms/step\n",
            "110/110 [==============================] - 23s 206ms/step - loss: 7.3434 - val_loss: 1.2402\n",
            "Epoch 502/1500\n",
            "876/876 [==============================] - 7s 8ms/step\n",
            "110/110 [==============================] - 19s 174ms/step - loss: 7.5384 - val_loss: 1.5495\n",
            "Epoch 503/1500\n",
            "876/876 [==============================] - 7s 8ms/step\n",
            "110/110 [==============================] - 21s 187ms/step - loss: 7.2514 - val_loss: 1.6206\n",
            "Epoch 504/1500\n",
            "876/876 [==============================] - 6s 6ms/step\n",
            "110/110 [==============================] - 23s 207ms/step - loss: 7.6927 - val_loss: 1.1603\n",
            "Epoch 505/1500\n",
            "876/876 [==============================] - 7s 8ms/step\n",
            "110/110 [==============================] - 19s 175ms/step - loss: 7.0923 - val_loss: 1.5224\n",
            "Epoch 506/1500\n",
            "876/876 [==============================] - 7s 8ms/step\n",
            "110/110 [==============================] - 18s 166ms/step - loss: 7.2890 - val_loss: 1.5820\n",
            "Epoch 507/1500\n",
            "876/876 [==============================] - 7s 8ms/step\n",
            "110/110 [==============================] - 18s 161ms/step - loss: 7.3980 - val_loss: 1.3726\n",
            "Epoch 508/1500\n",
            "876/876 [==============================] - 6s 6ms/step\n",
            "110/110 [==============================] - 23s 207ms/step - loss: 7.6082 - val_loss: 1.2978\n",
            "Epoch 509/1500\n",
            "876/876 [==============================] - 7s 8ms/step\n",
            "110/110 [==============================] - 22s 203ms/step - loss: 7.3557 - val_loss: 1.3470\n",
            "Epoch 510/1500\n",
            "876/876 [==============================] - 6s 7ms/step\n",
            "110/110 [==============================] - 18s 166ms/step - loss: 7.3922 - val_loss: 1.6163\n",
            "Epoch 511/1500\n",
            "876/876 [==============================] - 6s 6ms/step\n",
            "110/110 [==============================] - 18s 168ms/step - loss: 7.7373 - val_loss: 1.8337\n",
            "Epoch 512/1500\n",
            "876/876 [==============================] - 6s 7ms/step\n",
            "110/110 [==============================] - 23s 208ms/step - loss: 7.2057 - val_loss: 1.2421\n",
            "Epoch 513/1500\n",
            "876/876 [==============================] - 6s 7ms/step\n",
            "110/110 [==============================] - 22s 202ms/step - loss: 8.4155 - val_loss: 1.6082\n",
            "Epoch 514/1500\n",
            "876/876 [==============================] - 6s 7ms/step\n",
            "110/110 [==============================] - 19s 174ms/step - loss: 7.5748 - val_loss: 2.6776\n",
            "Epoch 515/1500\n",
            "876/876 [==============================] - 7s 8ms/step\n",
            "110/110 [==============================] - 22s 200ms/step - loss: 8.0336 - val_loss: 1.5163\n",
            "Epoch 516/1500\n",
            "876/876 [==============================] - 6s 7ms/step\n",
            "110/110 [==============================] - 23s 207ms/step - loss: 7.1762 - val_loss: 1.2059\n",
            "Epoch 517/1500\n",
            "876/876 [==============================] - 6s 7ms/step\n",
            "110/110 [==============================] - 19s 178ms/step - loss: 7.4876 - val_loss: 1.5203\n",
            "Epoch 518/1500\n",
            "876/876 [==============================] - 7s 8ms/step\n",
            "110/110 [==============================] - 21s 194ms/step - loss: 7.0924 - val_loss: 1.2020\n",
            "Epoch 519/1500\n",
            "876/876 [==============================] - 6s 7ms/step\n",
            "110/110 [==============================] - 22s 205ms/step - loss: 7.1693 - val_loss: 1.2391\n",
            "Epoch 520/1500\n",
            "876/876 [==============================] - 6s 7ms/step\n",
            "110/110 [==============================] - 19s 176ms/step - loss: 7.3690 - val_loss: 1.7338\n",
            "Epoch 521/1500\n",
            "876/876 [==============================] - 7s 8ms/step\n",
            "110/110 [==============================] - 19s 175ms/step - loss: 7.0832 - val_loss: 1.3848\n",
            "Epoch 522/1500\n",
            "876/876 [==============================] - 7s 8ms/step\n",
            "110/110 [==============================] - 18s 162ms/step - loss: 7.1914 - val_loss: 4.8197\n",
            "Epoch 523/1500\n",
            "876/876 [==============================] - 7s 7ms/step\n",
            "110/110 [==============================] - 18s 164ms/step - loss: 7.8858 - val_loss: 1.7301\n",
            "Epoch 524/1500\n",
            "876/876 [==============================] - 6s 6ms/step\n",
            "110/110 [==============================] - 18s 165ms/step - loss: 7.4261 - val_loss: 1.3943\n",
            "Epoch 525/1500\n",
            "876/876 [==============================] - 5s 6ms/step\n",
            "110/110 [==============================] - 18s 165ms/step - loss: 7.2912 - val_loss: 2.0348\n",
            "Epoch 526/1500\n",
            "876/876 [==============================] - 6s 7ms/step\n",
            "110/110 [==============================] - 18s 168ms/step - loss: 7.5263 - val_loss: 1.2989\n",
            "Epoch 527/1500\n",
            "876/876 [==============================] - 7s 7ms/step\n",
            "110/110 [==============================] - 22s 200ms/step - loss: 7.4043 - val_loss: 2.6125\n",
            "Epoch 528/1500\n",
            "876/876 [==============================] - 6s 7ms/step\n",
            "110/110 [==============================] - 18s 163ms/step - loss: 7.0624 - val_loss: 1.6058\n",
            "Epoch 529/1500\n",
            "876/876 [==============================] - 5s 6ms/step\n",
            "110/110 [==============================] - 23s 207ms/step - loss: 7.4936 - val_loss: 1.4841\n",
            "Epoch 530/1500\n",
            "876/876 [==============================] - 7s 8ms/step\n",
            "110/110 [==============================] - 20s 186ms/step - loss: 6.9928 - val_loss: 1.8457\n",
            "Epoch 531/1500\n",
            "876/876 [==============================] - 6s 6ms/step\n",
            "110/110 [==============================] - 18s 164ms/step - loss: 7.4574 - val_loss: 2.3563\n",
            "Epoch 532/1500\n",
            "876/876 [==============================] - 6s 6ms/step\n",
            "110/110 [==============================] - 18s 165ms/step - loss: 7.8833 - val_loss: 1.5750\n",
            "Epoch 533/1500\n",
            "876/876 [==============================] - 6s 6ms/step\n",
            "110/110 [==============================] - 23s 206ms/step - loss: 7.2170 - val_loss: 1.1764\n",
            "Epoch 534/1500\n",
            "876/876 [==============================] - 6s 7ms/step\n",
            "110/110 [==============================] - 18s 164ms/step - loss: 7.2040 - val_loss: 1.6315\n",
            "Epoch 535/1500\n",
            "876/876 [==============================] - 6s 6ms/step\n",
            "110/110 [==============================] - 22s 205ms/step - loss: 7.8204 - val_loss: 4.7039\n",
            "Epoch 536/1500\n",
            "876/876 [==============================] - 7s 8ms/step\n",
            "110/110 [==============================] - 18s 168ms/step - loss: 7.8227 - val_loss: 2.3065\n",
            "Epoch 537/1500\n",
            "876/876 [==============================] - 7s 8ms/step\n",
            "110/110 [==============================] - 21s 190ms/step - loss: 7.3285 - val_loss: 2.0121\n",
            "Epoch 538/1500\n",
            "876/876 [==============================] - 6s 6ms/step\n",
            "110/110 [==============================] - 18s 165ms/step - loss: 7.1331 - val_loss: 1.3086\n",
            "Epoch 539/1500\n",
            "876/876 [==============================] - 6s 6ms/step\n",
            "110/110 [==============================] - 22s 203ms/step - loss: 7.0919 - val_loss: 2.8923\n",
            "Epoch 540/1500\n",
            "876/876 [==============================] - 7s 8ms/step\n",
            "110/110 [==============================] - 21s 188ms/step - loss: 7.3509 - val_loss: 1.4962\n",
            "Epoch 541/1500\n",
            "876/876 [==============================] - 5s 6ms/step\n",
            "110/110 [==============================] - 18s 165ms/step - loss: 8.1398 - val_loss: 1.9059\n",
            "Epoch 542/1500\n",
            "876/876 [==============================] - 5s 6ms/step\n",
            "110/110 [==============================] - 22s 205ms/step - loss: 7.5450 - val_loss: 1.5147\n",
            "Epoch 543/1500\n",
            "876/876 [==============================] - 7s 7ms/step\n",
            "110/110 [==============================] - 18s 162ms/step - loss: 7.2869 - val_loss: 2.4567\n",
            "Epoch 544/1500\n",
            "876/876 [==============================] - 6s 6ms/step\n",
            "110/110 [==============================] - 18s 164ms/step - loss: 7.5103 - val_loss: 1.3220\n",
            "Epoch 545/1500\n",
            "876/876 [==============================] - 5s 6ms/step\n",
            "110/110 [==============================] - 18s 163ms/step - loss: 7.3499 - val_loss: 1.7064\n",
            "Epoch 546/1500\n",
            "876/876 [==============================] - 6s 7ms/step\n",
            "110/110 [==============================] - 19s 169ms/step - loss: 7.0756 - val_loss: 1.3076\n",
            "Epoch 547/1500\n",
            "876/876 [==============================] - 6s 7ms/step\n",
            "110/110 [==============================] - 18s 167ms/step - loss: 6.8824 - val_loss: 1.3464\n",
            "Epoch 548/1500\n",
            "876/876 [==============================] - 7s 8ms/step\n",
            "110/110 [==============================] - 21s 189ms/step - loss: 7.2988 - val_loss: 1.9958\n",
            "Epoch 549/1500\n",
            "876/876 [==============================] - 6s 7ms/step\n",
            "110/110 [==============================] - 18s 164ms/step - loss: 7.2740 - val_loss: 2.5502\n",
            "Epoch 550/1500\n",
            "876/876 [==============================] - 6s 6ms/step\n",
            "110/110 [==============================] - 22s 206ms/step - loss: 7.7221 - val_loss: 1.2994\n",
            "Epoch 551/1500\n",
            "876/876 [==============================] - 7s 8ms/step\n",
            "110/110 [==============================] - 18s 163ms/step - loss: 7.1349 - val_loss: 1.1300\n",
            "Epoch 552/1500\n",
            "876/876 [==============================] - 7s 8ms/step\n",
            "110/110 [==============================] - 18s 160ms/step - loss: 6.9644 - val_loss: 1.7451\n",
            "Epoch 553/1500\n",
            "876/876 [==============================] - 7s 8ms/step\n",
            "110/110 [==============================] - 20s 185ms/step - loss: 7.3108 - val_loss: 1.2990\n",
            "Epoch 554/1500\n",
            "876/876 [==============================] - 5s 6ms/step\n",
            "110/110 [==============================] - 22s 204ms/step - loss: 7.7655 - val_loss: 3.5971\n",
            "Epoch 555/1500\n",
            "876/876 [==============================] - 7s 8ms/step\n",
            "110/110 [==============================] - 21s 195ms/step - loss: 7.2170 - val_loss: 1.5448\n",
            "Epoch 556/1500\n",
            "876/876 [==============================] - 6s 7ms/step\n",
            "110/110 [==============================] - 18s 163ms/step - loss: 6.9940 - val_loss: 2.0830\n",
            "Epoch 557/1500\n",
            "876/876 [==============================] - 5s 6ms/step\n",
            "110/110 [==============================] - 22s 202ms/step - loss: 7.7609 - val_loss: 1.9865\n",
            "Epoch 558/1500\n",
            "876/876 [==============================] - 7s 8ms/step\n",
            "110/110 [==============================] - 18s 162ms/step - loss: 7.5942 - val_loss: 1.7667\n",
            "Epoch 559/1500\n",
            "876/876 [==============================] - 7s 8ms/step\n",
            "110/110 [==============================] - 20s 184ms/step - loss: 7.3147 - val_loss: 1.6665\n",
            "Epoch 560/1500\n",
            "876/876 [==============================] - 5s 6ms/step\n",
            "110/110 [==============================] - 22s 204ms/step - loss: 6.8640 - val_loss: 1.4434\n",
            "Epoch 561/1500\n",
            "876/876 [==============================] - 6s 7ms/step\n",
            "110/110 [==============================] - 22s 202ms/step - loss: 7.2483 - val_loss: 1.2266\n",
            "Epoch 562/1500\n",
            "876/876 [==============================] - 6s 7ms/step\n",
            "110/110 [==============================] - 22s 199ms/step - loss: 7.3985 - val_loss: 3.4547\n",
            "Epoch 563/1500\n",
            "876/876 [==============================] - 6s 7ms/step\n",
            "110/110 [==============================] - 22s 204ms/step - loss: 7.0903 - val_loss: 1.2564\n",
            "Epoch 564/1500\n",
            "876/876 [==============================] - 6s 7ms/step\n",
            "110/110 [==============================] - 18s 162ms/step - loss: 7.0100 - val_loss: 1.9011\n",
            "Epoch 565/1500\n",
            "876/876 [==============================] - 5s 6ms/step\n",
            "110/110 [==============================] - 22s 205ms/step - loss: 6.9132 - val_loss: 2.1421\n",
            "Epoch 566/1500\n",
            "876/876 [==============================] - 7s 8ms/step\n",
            "110/110 [==============================] - 21s 191ms/step - loss: 7.0939 - val_loss: 1.2458\n",
            "Epoch 567/1500\n",
            "876/876 [==============================] - 6s 6ms/step\n",
            "110/110 [==============================] - 22s 202ms/step - loss: 7.2833 - val_loss: 2.2521\n",
            "Epoch 568/1500\n",
            "876/876 [==============================] - 6s 7ms/step\n",
            "110/110 [==============================] - 23s 206ms/step - loss: 7.3041 - val_loss: 1.2712\n",
            "Epoch 569/1500\n",
            "876/876 [==============================] - 6s 7ms/step\n",
            "110/110 [==============================] - 22s 199ms/step - loss: 7.2992 - val_loss: 1.3803\n",
            "Epoch 570/1500\n",
            "876/876 [==============================] - 6s 7ms/step\n",
            "110/110 [==============================] - 22s 205ms/step - loss: 7.7140 - val_loss: 1.9017\n",
            "Epoch 571/1500\n",
            "876/876 [==============================] - 6s 7ms/step\n",
            "110/110 [==============================] - 18s 161ms/step - loss: 6.9008 - val_loss: 1.3334\n",
            "Epoch 572/1500\n",
            "876/876 [==============================] - 5s 6ms/step\n",
            "110/110 [==============================] - 23s 208ms/step - loss: 7.1346 - val_loss: 1.1138\n",
            "Epoch 573/1500\n",
            "876/876 [==============================] - 7s 8ms/step\n",
            "110/110 [==============================] - 18s 167ms/step - loss: 7.2066 - val_loss: 1.9505\n",
            "Epoch 574/1500\n",
            "876/876 [==============================] - 7s 8ms/step\n",
            "110/110 [==============================] - 21s 187ms/step - loss: 7.4466 - val_loss: 1.2264\n",
            "Epoch 575/1500\n",
            "876/876 [==============================] - 6s 7ms/step\n",
            "110/110 [==============================] - 22s 201ms/step - loss: 7.0908 - val_loss: 1.3011\n",
            "Epoch 576/1500\n",
            "876/876 [==============================] - 6s 7ms/step\n",
            "110/110 [==============================] - 18s 167ms/step - loss: 6.8728 - val_loss: 1.3706\n",
            "Epoch 577/1500\n",
            "876/876 [==============================] - 6s 7ms/step\n",
            "110/110 [==============================] - 22s 197ms/step - loss: 6.8818 - val_loss: 1.8147\n",
            "Epoch 578/1500\n",
            "876/876 [==============================] - 6s 7ms/step\n",
            "110/110 [==============================] - 18s 163ms/step - loss: 7.3886 - val_loss: 3.5666\n",
            "Epoch 579/1500\n",
            "876/876 [==============================] - 5s 6ms/step\n",
            "110/110 [==============================] - 22s 204ms/step - loss: 7.1350 - val_loss: 1.6749\n",
            "Epoch 580/1500\n",
            "876/876 [==============================] - 7s 8ms/step\n",
            "110/110 [==============================] - 21s 190ms/step - loss: 7.0947 - val_loss: 1.5971\n",
            "Epoch 581/1500\n",
            "876/876 [==============================] - 6s 6ms/step\n",
            "110/110 [==============================] - 18s 161ms/step - loss: 7.0715 - val_loss: 1.6324\n",
            "Epoch 582/1500\n",
            "876/876 [==============================] - 5s 6ms/step\n",
            "110/110 [==============================] - 22s 204ms/step - loss: 6.7640 - val_loss: 1.0774\n",
            "Epoch 583/1500\n",
            "876/876 [==============================] - 7s 8ms/step\n",
            "110/110 [==============================] - 18s 160ms/step - loss: 7.5572 - val_loss: 1.2212\n",
            "Epoch 584/1500\n",
            "876/876 [==============================] - 7s 8ms/step\n",
            "110/110 [==============================] - 20s 186ms/step - loss: 7.4166 - val_loss: 1.6617\n",
            "Epoch 585/1500\n",
            "876/876 [==============================] - 6s 6ms/step\n",
            "110/110 [==============================] - 18s 164ms/step - loss: 6.9758 - val_loss: 1.5164\n",
            "Epoch 586/1500\n",
            "876/876 [==============================] - 5s 6ms/step\n",
            "110/110 [==============================] - 18s 162ms/step - loss: 7.0792 - val_loss: 1.5672\n",
            "Epoch 587/1500\n",
            "876/876 [==============================] - 6s 7ms/step\n",
            "110/110 [==============================] - 18s 168ms/step - loss: 7.5250 - val_loss: 1.7823\n",
            "Epoch 588/1500\n",
            "876/876 [==============================] - 7s 7ms/step\n",
            "110/110 [==============================] - 22s 196ms/step - loss: 7.1102 - val_loss: 1.2742\n",
            "Epoch 589/1500\n",
            "876/876 [==============================] - 6s 6ms/step\n",
            "110/110 [==============================] - 18s 162ms/step - loss: 7.0169 - val_loss: 1.2734\n",
            "Epoch 590/1500\n",
            "876/876 [==============================] - 5s 6ms/step\n",
            "110/110 [==============================] - 22s 204ms/step - loss: 7.2530 - val_loss: 2.8010\n",
            "Epoch 591/1500\n",
            "876/876 [==============================] - 7s 8ms/step\n",
            "110/110 [==============================] - 17s 158ms/step - loss: 7.2662 - val_loss: 1.1591\n",
            "Epoch 592/1500\n",
            "876/876 [==============================] - 7s 8ms/step\n",
            "110/110 [==============================] - 18s 161ms/step - loss: 6.8820 - val_loss: 1.1508\n",
            "Epoch 593/1500\n",
            "876/876 [==============================] - 7s 8ms/step\n",
            "110/110 [==============================] - 18s 160ms/step - loss: 6.8377 - val_loss: 3.1384\n",
            "Epoch 594/1500\n",
            "876/876 [==============================] - 7s 8ms/step\n",
            "110/110 [==============================] - 20s 185ms/step - loss: 7.1921 - val_loss: 2.0915\n",
            "Epoch 595/1500\n",
            "876/876 [==============================] - 5s 6ms/step\n",
            "110/110 [==============================] - 22s 204ms/step - loss: 7.1950 - val_loss: 1.1809\n",
            "Epoch 596/1500\n",
            "876/876 [==============================] - 6s 7ms/step\n",
            "110/110 [==============================] - 19s 170ms/step - loss: 6.9460 - val_loss: 2.1483\n",
            "Epoch 597/1500\n",
            "876/876 [==============================] - 7s 8ms/step\n",
            "110/110 [==============================] - 21s 193ms/step - loss: 6.7120 - val_loss: 1.3180\n",
            "Epoch 598/1500\n",
            "876/876 [==============================] - 6s 7ms/step\n",
            "110/110 [==============================] - 18s 164ms/step - loss: 7.3285 - val_loss: 1.3636\n",
            "Epoch 599/1500\n",
            "876/876 [==============================] - 5s 6ms/step\n",
            "110/110 [==============================] - 18s 164ms/step - loss: 7.2877 - val_loss: 1.5383\n",
            "Epoch 600/1500\n",
            "876/876 [==============================] - 5s 6ms/step\n",
            "110/110 [==============================] - 22s 205ms/step - loss: 7.1737 - val_loss: 1.1791\n",
            "Epoch 601/1500\n",
            "876/876 [==============================] - 6s 7ms/step\n",
            "110/110 [==============================] - 18s 162ms/step - loss: 7.7401 - val_loss: 1.9001\n",
            "Epoch 602/1500\n",
            "876/876 [==============================] - 5s 6ms/step\n",
            "110/110 [==============================] - 22s 204ms/step - loss: 7.2098 - val_loss: 2.0382\n",
            "Epoch 603/1500\n",
            "876/876 [==============================] - 6s 7ms/step\n",
            "110/110 [==============================] - 19s 169ms/step - loss: 7.4497 - val_loss: 2.0815\n",
            "Epoch 604/1500\n",
            "876/876 [==============================] - 7s 8ms/step\n",
            "110/110 [==============================] - 21s 190ms/step - loss: 6.7655 - val_loss: 1.2709\n",
            "Epoch 605/1500\n",
            "876/876 [==============================] - 6s 7ms/step\n",
            "110/110 [==============================] - 22s 201ms/step - loss: 6.7455 - val_loss: 1.6458\n",
            "Epoch 606/1500\n",
            "876/876 [==============================] - 6s 7ms/step\n",
            "110/110 [==============================] - 22s 204ms/step - loss: 6.9445 - val_loss: 1.1705\n",
            "Epoch 607/1500\n",
            "876/876 [==============================] - 6s 7ms/step\n",
            "110/110 [==============================] - 22s 199ms/step - loss: 6.7845 - val_loss: 1.1507\n",
            "Epoch 608/1500\n",
            "876/876 [==============================] - 6s 6ms/step\n",
            "110/110 [==============================] - 22s 205ms/step - loss: 6.5943 - val_loss: 1.0510\n",
            "Epoch 609/1500\n",
            "876/876 [==============================] - 6s 7ms/step\n",
            "110/110 [==============================] - 18s 163ms/step - loss: 6.9622 - val_loss: 1.8983\n",
            "Epoch 610/1500\n",
            "876/876 [==============================] - 5s 6ms/step\n",
            "110/110 [==============================] - 18s 164ms/step - loss: 7.6076 - val_loss: 1.7758\n",
            "Epoch 611/1500\n",
            "876/876 [==============================] - 6s 6ms/step\n",
            "110/110 [==============================] - 18s 162ms/step - loss: 7.1629 - val_loss: 1.2792\n",
            "Epoch 612/1500\n",
            "876/876 [==============================] - 6s 7ms/step\n",
            "110/110 [==============================] - 19s 172ms/step - loss: 7.0694 - val_loss: 1.0631\n",
            "Epoch 613/1500\n",
            "876/876 [==============================] - 7s 8ms/step\n",
            "110/110 [==============================] - 18s 168ms/step - loss: 7.2184 - val_loss: 5.4977\n",
            "Epoch 614/1500\n",
            "876/876 [==============================] - 7s 8ms/step\n",
            "110/110 [==============================] - 20s 186ms/step - loss: 6.9629 - val_loss: 1.2689\n",
            "Epoch 615/1500\n",
            "876/876 [==============================] - 6s 6ms/step\n",
            "110/110 [==============================] - 18s 162ms/step - loss: 6.9888 - val_loss: 1.2725\n",
            "Epoch 616/1500\n",
            "876/876 [==============================] - 5s 6ms/step\n",
            "110/110 [==============================] - 18s 165ms/step - loss: 6.9340 - val_loss: 2.1042\n",
            "Epoch 617/1500\n",
            "876/876 [==============================] - 6s 6ms/step\n",
            "110/110 [==============================] - 18s 167ms/step - loss: 6.8889 - val_loss: 1.5863\n",
            "Epoch 618/1500\n",
            "876/876 [==============================] - 6s 7ms/step\n",
            "110/110 [==============================] - 22s 202ms/step - loss: 7.0029 - val_loss: 1.4340\n",
            "Epoch 619/1500\n",
            "876/876 [==============================] - 6s 7ms/step\n",
            "110/110 [==============================] - 22s 198ms/step - loss: 6.6564 - val_loss: 1.5890\n",
            "Epoch 620/1500\n",
            "876/876 [==============================] - 6s 7ms/step\n",
            "110/110 [==============================] - 22s 205ms/step - loss: 7.1570 - val_loss: 1.4061\n",
            "Epoch 621/1500\n",
            "876/876 [==============================] - 6s 7ms/step\n",
            "110/110 [==============================] - 21s 196ms/step - loss: 6.8069 - val_loss: 1.7824\n",
            "Epoch 622/1500\n",
            "876/876 [==============================] - 6s 6ms/step\n",
            "110/110 [==============================] - 22s 205ms/step - loss: 7.1755 - val_loss: 1.4065\n",
            "Epoch 623/1500\n",
            "876/876 [==============================] - 6s 7ms/step\n",
            "110/110 [==============================] - 18s 160ms/step - loss: 6.9455 - val_loss: 1.8894\n",
            "Epoch 624/1500\n",
            "876/876 [==============================] - 5s 6ms/step\n",
            "110/110 [==============================] - 22s 205ms/step - loss: 6.8604 - val_loss: 2.6754\n",
            "Epoch 625/1500\n",
            "876/876 [==============================] - 7s 8ms/step\n",
            "110/110 [==============================] - 21s 195ms/step - loss: 6.8896 - val_loss: 2.9139\n",
            "Epoch 626/1500\n",
            "876/876 [==============================] - 6s 6ms/step\n",
            "110/110 [==============================] - 18s 163ms/step - loss: 6.7621 - val_loss: 2.1510\n",
            "Epoch 627/1500\n",
            "876/876 [==============================] - 5s 6ms/step\n",
            "110/110 [==============================] - 23s 206ms/step - loss: 6.8543 - val_loss: 3.2940\n",
            "Epoch 628/1500\n",
            "876/876 [==============================] - 7s 8ms/step\n",
            "110/110 [==============================] - 20s 187ms/step - loss: 7.1586 - val_loss: 1.1421\n",
            "Epoch 629/1500\n",
            "876/876 [==============================] - 6s 7ms/step\n",
            "110/110 [==============================] - 18s 164ms/step - loss: 7.3630 - val_loss: 1.5038\n",
            "Epoch 630/1500\n",
            "876/876 [==============================] - 5s 6ms/step\n",
            "110/110 [==============================] - 18s 165ms/step - loss: 7.2332 - val_loss: 3.4200\n",
            "Epoch 631/1500\n",
            "876/876 [==============================] - 5s 6ms/step\n",
            "110/110 [==============================] - 22s 205ms/step - loss: 7.3604 - val_loss: 1.7175\n",
            "Epoch 632/1500\n",
            "876/876 [==============================] - 6s 7ms/step\n",
            "110/110 [==============================] - 22s 199ms/step - loss: 7.2375 - val_loss: 1.0967\n",
            "Epoch 633/1500\n",
            "876/876 [==============================] - 6s 6ms/step\n",
            "110/110 [==============================] - 18s 168ms/step - loss: 6.7608 - val_loss: 1.8931\n",
            "Epoch 634/1500\n",
            "876/876 [==============================] - 6s 7ms/step\n",
            "110/110 [==============================] - 18s 168ms/step - loss: 7.3157 - val_loss: 1.2554\n",
            "Epoch 635/1500\n",
            "876/876 [==============================] - 7s 8ms/step\n",
            "110/110 [==============================] - 21s 193ms/step - loss: 6.9913 - val_loss: 1.2149\n",
            "Epoch 636/1500\n",
            "876/876 [==============================] - 6s 7ms/step\n",
            "110/110 [==============================] - 22s 201ms/step - loss: 7.0291 - val_loss: 1.8554\n",
            "Epoch 637/1500\n",
            "876/876 [==============================] - 6s 7ms/step\n",
            "110/110 [==============================] - 19s 172ms/step - loss: 6.6823 - val_loss: 1.6215\n",
            "Epoch 638/1500\n",
            "876/876 [==============================] - 7s 7ms/step\n",
            "110/110 [==============================] - 22s 199ms/step - loss: 7.3752 - val_loss: 1.3374\n",
            "Epoch 639/1500\n",
            "876/876 [==============================] - 6s 7ms/step\n",
            "110/110 [==============================] - 22s 200ms/step - loss: 6.7636 - val_loss: 2.7814\n",
            "Epoch 640/1500\n",
            "876/876 [==============================] - 6s 7ms/step\n",
            "110/110 [==============================] - 22s 204ms/step - loss: 7.1518 - val_loss: 1.2865\n",
            "Epoch 641/1500\n",
            "876/876 [==============================] - 6s 7ms/step\n",
            "110/110 [==============================] - 22s 198ms/step - loss: 7.1384 - val_loss: 1.3907\n",
            "Epoch 642/1500\n",
            "876/876 [==============================] - 6s 6ms/step\n",
            "110/110 [==============================] - 22s 204ms/step - loss: 6.9865 - val_loss: 1.6129\n",
            "Epoch 643/1500\n",
            "876/876 [==============================] - 6s 7ms/step\n",
            "110/110 [==============================] - 22s 197ms/step - loss: 6.8963 - val_loss: 1.5058\n",
            "Epoch 644/1500\n",
            "876/876 [==============================] - 6s 7ms/step\n",
            "110/110 [==============================] - 22s 205ms/step - loss: 6.5510 - val_loss: 1.2233\n",
            "Epoch 645/1500\n",
            "876/876 [==============================] - 6s 7ms/step\n",
            "110/110 [==============================] - 18s 163ms/step - loss: 6.9555 - val_loss: 2.4172\n",
            "Epoch 646/1500\n",
            "876/876 [==============================] - 5s 6ms/step\n",
            "110/110 [==============================] - 22s 205ms/step - loss: 6.8802 - val_loss: 1.8813\n",
            "Epoch 647/1500\n",
            "876/876 [==============================] - 6s 7ms/step\n",
            "110/110 [==============================] - 19s 171ms/step - loss: 6.6573 - val_loss: 1.2714\n",
            "Epoch 648/1500\n",
            "876/876 [==============================] - 7s 8ms/step\n",
            "110/110 [==============================] - 21s 191ms/step - loss: 6.6938 - val_loss: 2.7334\n",
            "Epoch 649/1500\n",
            "876/876 [==============================] - 6s 7ms/step\n",
            "110/110 [==============================] - 18s 163ms/step - loss: 7.0284 - val_loss: 1.4647\n",
            "Epoch 650/1500\n",
            "876/876 [==============================] - 6s 6ms/step\n",
            "110/110 [==============================] - 22s 205ms/step - loss: 7.5429 - val_loss: 2.4070\n",
            "Epoch 651/1500\n",
            "876/876 [==============================] - 7s 8ms/step\n",
            "110/110 [==============================] - 19s 169ms/step - loss: 7.0391 - val_loss: 1.4392\n",
            "Epoch 652/1500\n",
            "876/876 [==============================] - 7s 8ms/step\n",
            "110/110 [==============================] - 18s 161ms/step - loss: 6.9401 - val_loss: 1.3853\n",
            "Epoch 653/1500\n",
            "876/876 [==============================] - 7s 8ms/step\n",
            "110/110 [==============================] - 20s 185ms/step - loss: 6.7984 - val_loss: 1.1725\n",
            "Epoch 654/1500\n",
            "876/876 [==============================] - 6s 7ms/step\n",
            "110/110 [==============================] - 18s 162ms/step - loss: 7.0408 - val_loss: 3.9286\n",
            "Epoch 655/1500\n",
            "876/876 [==============================] - 6s 6ms/step\n",
            "110/110 [==============================] - 22s 205ms/step - loss: 6.7294 - val_loss: 2.6140\n",
            "Epoch 656/1500\n",
            "876/876 [==============================] - 7s 8ms/step\n",
            "110/110 [==============================] - 18s 160ms/step - loss: 6.9369 - val_loss: 1.1728\n",
            "Epoch 657/1500\n",
            "876/876 [==============================] - 7s 8ms/step\n",
            "110/110 [==============================] - 18s 161ms/step - loss: 6.7707 - val_loss: 1.2726\n",
            "Epoch 658/1500\n",
            "876/876 [==============================] - 7s 8ms/step\n",
            "110/110 [==============================] - 20s 187ms/step - loss: 6.4985 - val_loss: 1.3662\n",
            "Epoch 659/1500\n",
            "876/876 [==============================] - 6s 6ms/step\n",
            "110/110 [==============================] - 18s 162ms/step - loss: 6.8472 - val_loss: 2.5803\n",
            "Epoch 660/1500\n",
            "876/876 [==============================] - 6s 6ms/step\n",
            "110/110 [==============================] - 18s 165ms/step - loss: 7.1545 - val_loss: 1.4579\n",
            "Epoch 661/1500\n",
            "876/876 [==============================] - 6s 7ms/step\n",
            "110/110 [==============================] - 22s 205ms/step - loss: 6.6860 - val_loss: 1.2813\n",
            "Epoch 662/1500\n",
            "876/876 [==============================] - 6s 7ms/step\n",
            "110/110 [==============================] - 22s 198ms/step - loss: 6.7213 - val_loss: 1.9695\n",
            "Epoch 663/1500\n",
            "876/876 [==============================] - 6s 7ms/step\n",
            "110/110 [==============================] - 22s 205ms/step - loss: 7.3640 - val_loss: 2.1642\n",
            "Epoch 664/1500\n",
            "876/876 [==============================] - 6s 7ms/step\n",
            "110/110 [==============================] - 21s 195ms/step - loss: 6.7588 - val_loss: 1.2803\n",
            "Epoch 665/1500\n",
            "876/876 [==============================] - 6s 6ms/step\n",
            "110/110 [==============================] - 23s 206ms/step - loss: 6.7525 - val_loss: 1.7732\n",
            "Epoch 666/1500\n",
            "876/876 [==============================] - 7s 8ms/step\n",
            "110/110 [==============================] - 21s 194ms/step - loss: 6.8738 - val_loss: 1.4371\n",
            "Epoch 667/1500\n",
            "876/876 [==============================] - 6s 6ms/step\n",
            "110/110 [==============================] - 18s 165ms/step - loss: 6.8394 - val_loss: 1.2594\n",
            "Epoch 668/1500\n",
            "876/876 [==============================] - 6s 7ms/step\n",
            "110/110 [==============================] - 19s 170ms/step - loss: 7.6342 - val_loss: 2.1137\n",
            "Epoch 669/1500\n",
            "876/876 [==============================] - 6s 7ms/step\n",
            "110/110 [==============================] - 19s 169ms/step - loss: 6.5212 - val_loss: 1.3014\n",
            "Epoch 670/1500\n",
            "876/876 [==============================] - 7s 8ms/step\n",
            "110/110 [==============================] - 21s 195ms/step - loss: 6.5984 - val_loss: 2.9231\n",
            "Epoch 671/1500\n",
            "876/876 [==============================] - 6s 7ms/step\n",
            "110/110 [==============================] - 22s 199ms/step - loss: 6.7547 - val_loss: 1.4214\n",
            "Epoch 672/1500\n",
            " 49/110 [============>.................] - ETA: 8s - loss: 6.8787"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-23-150e5e3e1177>\u001b[0m in \u001b[0;36m<cell line: 13>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0mmodel_GRU_multilayers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'adam'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'mse'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0mmetrics_history_callback\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mMetricsHistory\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mY_train\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'Metrics over Epochs on GRU multilayers'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'Loss over Epochs on GRU multilayers'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'/content/drive/MyDrive/Task2/metricsGRU_multilayer.png'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'/content/drive/MyDrive/Task2/lossGRU_multilayer.png'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m \u001b[0mmodel_GRU_multilayers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mY_train\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mvalidation_data\u001b[0m \u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mY_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m \u001b[0;36m1500\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m \u001b[0;36m256\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallbacks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mmetrics_history_callback\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/src/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     63\u001b[0m         \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     64\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 65\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     66\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     67\u001b[0m             \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1805\u001b[0m                         ):\n\u001b[1;32m   1806\u001b[0m                             \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1807\u001b[0;31m                             \u001b[0mtmp_logs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1808\u001b[0m                             \u001b[0;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1809\u001b[0m                                 \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/util/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    148\u001b[0m     \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    149\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 150\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    151\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    152\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    830\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    831\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0mOptionalXlaContext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jit_compile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 832\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    833\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    834\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    866\u001b[0m       \u001b[0;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    867\u001b[0m       \u001b[0;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 868\u001b[0;31m       return tracing_compilation.call_function(\n\u001b[0m\u001b[1;32m    869\u001b[0m           \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_no_variable_creation_config\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    870\u001b[0m       )\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/polymorphic_function/tracing_compilation.py\u001b[0m in \u001b[0;36mcall_function\u001b[0;34m(args, kwargs, tracing_options)\u001b[0m\n\u001b[1;32m    137\u001b[0m   \u001b[0mbound_args\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunction\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunction_type\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbind\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    138\u001b[0m   \u001b[0mflat_inputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunction\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunction_type\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munpack_inputs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbound_args\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 139\u001b[0;31m   return function._call_flat(  # pylint: disable=protected-access\n\u001b[0m\u001b[1;32m    140\u001b[0m       \u001b[0mflat_inputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcaptured_inputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfunction\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcaptured_inputs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    141\u001b[0m   )\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/polymorphic_function/concrete_function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, tensor_inputs, captured_inputs)\u001b[0m\n\u001b[1;32m   1321\u001b[0m         and executing_eagerly):\n\u001b[1;32m   1322\u001b[0m       \u001b[0;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1323\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_inference_function\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcall_preflattened\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1324\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n\u001b[1;32m   1325\u001b[0m         \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/polymorphic_function/atomic_function.py\u001b[0m in \u001b[0;36mcall_preflattened\u001b[0;34m(self, args)\u001b[0m\n\u001b[1;32m    214\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mcall_preflattened\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mSequence\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mAny\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    215\u001b[0m     \u001b[0;34m\"\"\"Calls with flattened tensor inputs and returns the structured output.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 216\u001b[0;31m     \u001b[0mflat_outputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcall_flat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    217\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunction_type\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpack_output\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mflat_outputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    218\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/polymorphic_function/atomic_function.py\u001b[0m in \u001b[0;36mcall_flat\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m    249\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mrecord\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstop_recording\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    250\u001b[0m           \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_bound_context\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexecuting_eagerly\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 251\u001b[0;31m             outputs = self._bound_context.call_function(\n\u001b[0m\u001b[1;32m    252\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    253\u001b[0m                 \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/context.py\u001b[0m in \u001b[0;36mcall_function\u001b[0;34m(self, name, tensor_inputs, num_outputs)\u001b[0m\n\u001b[1;32m   1484\u001b[0m     \u001b[0mcancellation_context\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcancellation\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1485\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mcancellation_context\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1486\u001b[0;31m       outputs = execute.execute(\n\u001b[0m\u001b[1;32m   1487\u001b[0m           \u001b[0mname\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"utf-8\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1488\u001b[0m           \u001b[0mnum_outputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnum_outputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     51\u001b[0m   \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     52\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 53\u001b[0;31m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0m\u001b[1;32m     54\u001b[0m                                         inputs, attrs, num_outputs)\n\u001b[1;32m     55\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    }
  ]
}